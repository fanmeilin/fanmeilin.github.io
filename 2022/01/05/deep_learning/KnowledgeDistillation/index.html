

<!DOCTYPE html>

<html lang="zh-CN" data-default-color-scheme=auto>
<script type="text/javascript" src="/js/jquery.js"></script>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#d8afe4">
  <meta name="description" content="ä¸çµé­‚å…±èˆ">
  <meta name="author" content="Meilin Fan">
  <meta name="keywords" content="ä¸ªäººåšå®¢,å­¦ä¹ ,ç”Ÿæ´»">
  
  <title>Knowledge Distillationç¬”è®° - å¾…æ—¶</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- ä¸»é¢˜ä¾èµ–çš„å›¾æ ‡åº“ï¼Œä¸è¦è‡ªè¡Œä¿®æ”¹ -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- è‡ªå®šä¹‰æ ·å¼ä¿æŒåœ¨æœ€åº•éƒ¨ -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"fanmeilin.github.io","root":"/","version":"1.8.11","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>


<body>	
	<div>
		<div class='real_mask'></div>
		<div id="banner_video_insert">
		</div>	
		<div id='vvd_banner_img'>
		</div>
	</div>
	<div id="banner"></div>
    
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>ä¸çµé­‚å…±èˆ</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                é¦–é¡µ
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                å½’æ¡£
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                åˆ†ç±»
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                æ ‡ç­¾
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                å…³äº
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

	
	<!-- <div class="banner" id="banner" parallax=true
		style="background: url('https://picture.mulindya.com/03990bbe091d5cca73421ac40bacfc46_1.jpg') no-repeat center center;
		background-size: cover;"> -->
        <div class="banner" id='banner' >
		<div class="full-bg-img" >
		
			
				<script>
					var ua = navigator.userAgent;
					var ipad = ua.match(/(iPad).*OS\s([\d_]+)/),
						isIphone = !ipad && ua.match(/(iPhone\sOS)\s([\d_]+)/),
						isAndroid = ua.match(/(Android)\s+([\d.]+)/),
						isMobile = isIphone || isAndroid;

					function set_video_attr(id){

						var height = document.body.clientHeight
						var width = document.body.clientWidth
						var video_item = document.getElementById(id);

						if (height / width < 0.56){
							video_item.setAttribute('width', '100%');
							video_item.setAttribute('height', 'auto');
						} else {
							video_item.setAttribute('height', '100%');
							video_item.setAttribute('width', 'auto');
						}
					}

					$.getJSON('/js/video_url.json', function(data){
						if (!isMobile){
							var video_list_length = data.length
							var seed = Math.random()
							index = Math.floor(seed * video_list_length)
							
							video_url = data[index][0]
							pre_show_image_url = data[index][1]
							
							banner_obj = document.getElementById("banner")
							banner_obj.style.cssText = "background: url('" + pre_show_image_url + "') no-repeat; background-size: cover;"

							vvd_banner_obj = document.getElementById("vvd_banner_img")

							vvd_banner_content = "<img id='banner_img_item' src='" + pre_show_image_url + "' style='height: 100%; position: fixed; z-index: -999'>"
							vvd_banner_obj.innerHTML = vvd_banner_content

							video_html_res = "<video id='video_item' style='position: fixed; z-index: -888;'  muted='muted' src=" + video_url + " autoplay='autoplay' loop='loop'></video>"
							document.getElementById("banner_video_insert").innerHTML = video_html_res;

							set_video_attr('video_item')
							set_video_attr('banner_img_item')
						}
					});

					if (!isMobile){
						window.onresize = function(){
							set_video_attr('video_item')
							}
						}
				</script>
			

			<!-- <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)"> -->
            <div class="mask flex-center">
			  <div class="page-header text-center fade-in-up">
				<span class="h2" id="subtitle" title="Knowledge Distillationç¬”è®°">
				  
				</span>

				
				  <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-01-05 16:38" pubdate>
        2022å¹´1æœˆ5æ—¥ ä¸‹åˆ
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      3.1k å­—
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      46
       åˆ†é’Ÿ
    </span>
  

  
  
</div>

				
			  </div>

			  
			</div>
		</div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Knowledge Distillationç¬”è®°</h1>
            
            <div class="markdown-body">
              <blockquote>
<p>å› ä¸ºé¡¹ç›®ä¸­è¦ä½¿ç”¨åˆ°çŸ¥è¯†è’¸é¦æ¥è®­ç»ƒç½‘ç»œï¼Œæ‰€ä»¥å…ˆå¥½å¥½å­¦ä¸€ä¸‹å®ƒçš„åŸç†ã€‚åœ¨ç½‘ä¸Šæ‰¾åˆ°äº†æå®æ¯…æœºå™¨å­¦ä¹ çš„æ¨¡å‹å‹ç¼©ä¸­è®²åˆ°äº†è¿™ä¸ªï¼Œé‚£ï¼Œå°±å¼€å§‹å­¦ä¹ å­ğŸ˜‰</p>
</blockquote>
<h1>çŸ¥è¯†è’¸é¦ğŸŒŒ</h1>
<h2 id="æ¦‚å¿µ">æ¦‚å¿µ</h2>
<p>å…ˆè®­ç»ƒä¸€ä¸ªå¤§çš„networkï¼ˆteacherï¼‰ï¼Œå†æ ¹æ®è¿™ä¸ªnetworkæ¥åˆ¶é€ å°çš„networkï¼ˆstudentï¼‰ï¼ŒåŒæ—¶studentæ˜¯æ ¹æ®teacherçš„ç»“æ„åšä¸€äº›ä¿®å‰ªå¾—åˆ°çš„å°ç½‘ç»œï¼Œstudent networkæ˜¯æ ¹æ®teacher networkæ¥å­¦ä¹ çš„å“¦ã€‚</p>
<p><img src="https://picture.mulindya.com/kDistillation-1.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>student networkæ˜¯å»æ‹Ÿåˆteacherçš„ç»“æœï¼Œå¯ä»¥ä½¿ç”¨Ensembleçš„ç½‘ç»œä½œä¸ºteacherï¼Œè¿™æ ·è¡¨ç°å¾—ç»“æœæ›´å¥½ã€‚</p>
<p><img src="https://picture.mulindya.com/kDistillation-2.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>åœ¨ä½¿ç”¨çŸ¥è¯†è’¸é¦æ—¶æœ‰ä¸€ä¸ªå°æŠ€å·§ï¼Œå¯ä»¥ç¨å¾®æ”¹ä¸€ä¸‹Softmaxçš„å‡½æ•°ï¼ŒTæ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œå¯ä»¥ä½¿å¾—å‡½æ•°ç‚¹æ›´åŠ å¹³æ»‘ã€‚å› ä¸ºstudentè¦å­¦ä¹ teacherç»™çš„ç»“æœï¼Œå¹¶ä¸”teacherç»™çš„ç»“æœè¦å‘Šè¯‰studentï¼Œå“ªäº›ç±»åˆ«æ¯”è¾ƒç›¸ä¼¼ï¼Œè€Œä¸æ˜¯ç›´æ¥ç»™å‡º1ï¼Œ0ï¼Œ0ï¼ˆå’ŒçœŸå®ç»“æœæ²¡æœ‰å·®åˆ«ï¼‰ï¼Œæ‰€ä»¥teacher çš„è¾“å‡ºä¸åº”è¯¥è¿‡åº¦é›†ä¸­ï¼Œéœ€è¦æ›´åŠ å¹³æ»‘ã€‚è¿™æ ·åˆ†ç±»ç»“æœä¸åŒï¼Œä½†æ˜¯studentå­¦ä¹ æ›´åŠ æœ‰æ„ä¹‰ã€‚åŒæ—¶ä¸ä¸€å®šè¦ç”¨softmaxä¹‹åçš„ç»“æœå»æ‹Ÿåˆstudentï¼Œå®Œå…¨å¯ä»¥ä½¿ç”¨ä¹‹å‰çš„ï¼Œæˆ–è€…ç±»ä¼¼studentçš„ç¬¬6å±‚æ‹Ÿåˆteacherçš„12å±‚ï¼Œç¬¬3å±‚æ‹Ÿåˆteacherçš„ç¬¬6å±‚ï¼Œè¿™æ ·ç»“æœå¾€å¾€ä¼šæ›´å¥½ã€‚</p>
<h2 id="å®ä¾‹ğŸŒ»">å®ä¾‹ğŸŒ»</h2>
<h3 id="Intuition">Intuition</h3>
<p>é€šå¸¸æ¨¡å‹Teacheræ¯”æ¨¡å‹Studentæ›´å¼ºï¼Œåœ¨æ¨¡å‹Teacherçš„å¸®åŠ©ä¸‹ï¼Œæ¨¡å‹studentå¯ä»¥"é’å‡ºäºè“è€Œèƒœäºè“"ğŸ˜‰,å› ä¸ºä»è®¡ç®—èµ„æºçš„è§’åº¦ä¸Šåºå¤§çš„æ¨¡å‹éƒ¨ç½²æœ‰å¾ˆå¤šé—®é¢˜ï¼Œæ‰€ä»¥é€šè¿‡çŸ¥è¯†è’¸é¦å¯ä»¥è®­ç»ƒä¸€ä¸ªç›¸ä¼¼çš„å°æ¨¡å‹å»æ‹Ÿåˆå¤§æ¨¡å‹çš„è®­ç»ƒæ•ˆæœï¼Œè¿™æ ·é¢„æµ‹å’Œéƒ¨ç½²ä¼šä¾¿æ·å¾ˆå¤šã€‚åŒæ—¶ä½¿ç”¨çŸ¥è¯†è’¸é¦çš„æ–¹æ³•å¯ä»¥è®©å°æ¨¡å‹å­¦åˆ°æ ·æœ¬ä¹‹é—´çš„ç›¸ä¼¼å…³ç³»ã€‚</p>
<p><img src="https://picture.mulindya.com/kDistillation-9.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>è¿™é‡Œä¸ä»…ä»…çŸ¥é“è¥¿çº¢æŸ¿æ˜¯çœŸå®æ ‡ç­¾ï¼Œè¿˜å¯ä»¥çŸ¥é“è¿™ä¸ªæ ·æœ¬å’ŒæŸ¿å­è¿™ä¸ªæ ‡ç­¾å¾ˆç›¸ä¼¼ï¼Œè¿™æ ·å¯ä»¥è·å–æ›´å¤šä¿¡æ¯ï¼Œè¿™æ˜¯è’¸é¦æ›´æœ‰ä»·å€¼çš„åœ°æ–¹ã€‚</p>
<h3 id="Loss-Function-in-Pytorch">Loss Function in Pytorch</h3>
<ul>
<li><code>Softmax</code>ï¼šå°†ä¸€ä¸ªæ•°å€¼åºåˆ—æ˜ å°„åˆ°æ¦‚ç‡ç©ºé—´ï¼ˆæ¯ä¸ªå…ƒç´ åˆ†å¸ƒå¹¶ä¸”æ‰€æœ‰å’Œä¸º1ï¼‰</li>
<li><code>log_softmax</code>ï¼šåœ¨softmaxçš„åŸºç¡€ä¸Šå–å¯¹æ•°</li>
<li><code>NLLLoss</code>ï¼šå¯¹log_softmaxä¸one-hotè¿›è¡Œè®¡ç®—</li>
<li><code>CrossEntropy</code>ï¼šè¡¡é‡ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒçš„å·®åˆ«ï¼ˆäº¤å‰ç†µï¼‰</li>
</ul>
<h4 id="ä»£ç å®è¯">ä»£ç å®è¯</h4>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-string">'''</span><br><span class="hljs-string">torch.nn.functional æ¶‰åŠäº†æ‰€æœ‰ torch.nn éœ€è¦ ç±» å’Œ æ–¹æ³• ï¼Œtorch.nn æ„å»ºçš„æ¨¡å—é€šå¸¸å°±æ˜¯è°ƒç”¨ torch.nn.functional é‡Œçš„æ–¹æ³•å®ç°çš„.</span><br><span class="hljs-string">'''</span><br>torch.manual_seed(<span class="hljs-number">0</span>)<br></code></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">output = torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br><span class="hljs-built_in">print</span>(output)<br><span class="hljs-comment">#tensor([[ 1.5410, -0.2934, -2.1788],</span><br><span class="hljs-comment">#        [ 0.5684, -1.0845, -1.3986]])</span><br><span class="hljs-built_in">print</span>(F.softmax(output, dim=<span class="hljs-number">1</span>))<br><span class="hljs-comment"># è¿™é‡Œdimçš„æ„æ€æ˜¯è®¡ç®—Softmaxçš„ç»´åº¦ï¼Œè¿™é‡Œè®¾ç½®dim=1ï¼Œå¯ä»¥çœ‹åˆ°æ¯ä¸€è¡Œçš„åŠ å’Œä¸º1ã€‚0æ˜¯å¯¹åˆ— 1 æ˜¯å¯¹è¡Œ</span><br><span class="hljs-comment">#tensor([[0.8446, 0.1349, 0.0205],</span><br><span class="hljs-comment">#       [0.7511, 0.1438, 0.1051]])</span><br></code></pre></td></tr></tbody></table></figure>
<h4 id="What-is-log-softmax">What is log_softmax</h4>
<p>è¿™ä¸ªå¾ˆå¥½ç†è§£ï¼Œå…¶å®å°±æ˜¯å¯¹<code>softmax</code>å¤„ç†ä¹‹åçš„ç»“æœæ‰§è¡Œä¸€æ¬¡å¯¹æ•°è¿ç®—ã€‚å¯ä»¥ç†è§£ä¸º <code>log(softmax(output))</code></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(F.log_softmax(output, dim=<span class="hljs-number">1</span>))<br><span class="hljs-built_in">print</span>(torch.log(F.softmax(output, dim=<span class="hljs-number">1</span>)))<br><span class="hljs-comment"># è¾“å‡ºç»“æœæ˜¯ä¸€è‡´çš„</span><br></code></pre></td></tr></tbody></table></figure>
<blockquote>
<p>tensor([[-0.1689, -2.0033, -3.8886],        [-0.2862, -1.9392, -2.2532]]) tensor([[-0.1689, -2.0033, -3.8886],        [-0.2862, -1.9392, -2.2532]])</p>
</blockquote>
<h4 id="æŸå¤±å‡½æ•°">æŸå¤±å‡½æ•°</h4>
<h4 id="What-is-NLLLossï¼Ÿ">What is NLLLossï¼Ÿ</h4>
<p>è¯¥å‡½æ•°çš„å…¨ç§°æ˜¯<code>negative log likelihood loss</code>. è‹¥$x_i=[q_1, q_2, â€¦, q_N]$ ä¸ºç¥ç»ç½‘ç»œå¯¹ç¬¬iä¸ªæ ·æœ¬çš„è¾“å‡ºå€¼ï¼Œ$y_i$ä¸ºçœŸå®æ ‡ç­¾ã€‚åˆ™ï¼š<br>
$$<br>
f(x_i,y_i)=-q_{y_i}<br>
$$<br>
å…¶ä¸­è¾“å…¥ï¼šlog_softmax(output), target</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(F.nll_loss(torch.tensor([[-<span class="hljs-number">1.2</span>, -<span class="hljs-number">2</span>, -<span class="hljs-number">3</span>]]), torch.tensor([<span class="hljs-number">0</span>])))<br><span class="hljs-comment">#ç»“æœæ˜¯tensor(1.2000) å°±æ˜¯å–ç¬¬0ä¸ªçš„è´Ÿæ•°</span><br></code></pre></td></tr></tbody></table></figure>
<p><strong>é€šå¸¸æˆ‘ä»¬ç»“åˆ log_softmax å’Œ nll_lossä¸€èµ·ç”¨</strong> ğŸ‘‹ã€‚</p>
<h4 id="CrossEntropyäº¤å‰ç†µ">CrossEntropyäº¤å‰ç†µ</h4>
<p><strong>åœ¨åˆ†ç±»é—®é¢˜ä¸­ï¼ŒCrossEntropyç­‰ä»·äºlog_softmax ç»“åˆ nll_loss</strong></p>
<p>$N$åˆ†ç±»é—®é¢˜ï¼Œå¯¹äºä¸€ä¸ªç‰¹å®šçš„æ ·æœ¬ï¼Œå·²çŸ¥å…¶çœŸå®æ ‡ç­¾ï¼Œ<code>CrossEntropy</code>çš„è®¡ç®—å…¬å¼ä¸ºï¼š</p>
<p>$$<br>
cross_entropy=-\sum_{k=1}^{N}\left(p_{k} * \log q_{k}\right)<br>
$$</p>
<p>å…¶ä¸­pè¡¨ç¤ºçœŸå®å€¼ï¼Œåœ¨è¿™ä¸ªå…¬å¼ä¸­æ˜¯one-hotå½¢å¼ï¼›qæ˜¯ç»è¿‡<code>softmax</code>è®¡ç®—åçš„ç»“æœï¼Œ $q_k$ä¸ºç¥ç»ç½‘ç»œè®¤ä¸ºè¯¥æ ·æœ¬ä¸ºç¬¬$k$ç±»çš„æ¦‚ç‡ã€‚</p>
<p>ä»”ç»†è§‚å¯Ÿå¯ä»¥çŸ¥é“ï¼Œå› ä¸ºpçš„å…ƒç´ ä¸æ˜¯0å°±æ˜¯1ï¼Œè€Œä¸”åˆæ˜¯ä¹˜æ³•ï¼Œæ‰€ä»¥å¾ˆè‡ªç„¶åœ°æˆ‘ä»¬å¦‚æœçŸ¥é“1æ‰€å¯¹åº”çš„indexï¼Œé‚£ä¹ˆå°±ä¸ç”¨åšå…¶ä»–æ— æ„ä¹‰çš„è¿ç®—äº†ã€‚æ‰€ä»¥åœ¨pytorchä»£ç ä¸­targetä¸æ˜¯ä»¥one-hotå½¢å¼è¡¨ç¤ºçš„ï¼Œè€Œæ˜¯ç›´æ¥ç”¨scalarè¡¨ç¤ºã€‚è‹¥è¯¥æ ·æœ¬çš„çœŸå®æ ‡ç­¾ä¸º$y$,åˆ™äº¤å‰ç†µçš„å…¬å¼å¯å˜å½¢ä¸ºï¼š</p>
<p>$$cross_entropy=-\sum_{k=1}^{N}\left(p_{k} * \log q_{k}\right)=-log , q_{y}$$</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">output = torch.tensor([[<span class="hljs-number">1.2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]])<br>target = torch.tensor([<span class="hljs-number">0</span>])<br><br>log_sm_output = F.log_softmax(output, dim=<span class="hljs-number">1</span>)<br>nll_loss_of_log_sm_output = F.nll_loss(log_sm_output, target)<br><span class="hljs-built_in">print</span>(nll_loss_of_log_sm_output)<br></code></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">output = torch.tensor([[<span class="hljs-number">1.2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]])<br>target = torch.tensor([<span class="hljs-number">0</span>])<br><br>ce_loss = F.cross_entropy(output, target)<br><span class="hljs-built_in">print</span>(ce_loss)<br><br>F.cross_entropy ã€Š==ã€‹ F.log_softmax(output, dim=<span class="hljs-number">1</span>)+F.nll_loss(log_sm_output, target)<br></code></pre></td></tr></tbody></table></figure>
<p>è¿™ä¸¤è€…æ˜¯ç­‰ä»·çš„å“¦~</p>
<h4 id="T-softmax">T-softmax</h4>
<p>T-softmaxçš„ç›®çš„æ˜¯å¹³æ»‘åˆ†å¸ƒï¼Œä¸è®©åˆ†å¸ƒå¤ªè¿‡äºæç«¯ã€‚æ¯”å¦‚å¯ä»¥çœ‹ä¸‹é¢çš„å®ä¾‹å“ˆã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">softmax</span>(<span class="hljs-params">x</span>):</span><br>    x_exp = np.exp(x)<br>    <span class="hljs-keyword">return</span> x_exp / np.<span class="hljs-built_in">sum</span>(x_exp)<br><br>output = np.array([<span class="hljs-number">0.1</span>, <span class="hljs-number">1.6</span>, <span class="hljs-number">3.6</span>])<br><span class="hljs-built_in">print</span>(softmax(output))<br><span class="hljs-comment">#[0.02590865 0.11611453 0.85797681]</span><br></code></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">softmax_t</span>(<span class="hljs-params">x, t</span>):</span><br>    x_exp = np.exp(x / t)<br>    <span class="hljs-keyword">return</span> x_exp / np.<span class="hljs-built_in">sum</span>(x_exp)<br><br>output = np.array([<span class="hljs-number">0.1</span>, <span class="hljs-number">1.6</span>, <span class="hljs-number">3.6</span>])<br><span class="hljs-built_in">print</span>(softmax_t(output, <span class="hljs-number">5</span>))<br><span class="hljs-comment">#[0.22916797 0.3093444  0.46148762]</span><br></code></pre></td></tr></tbody></table></figure>
<p>è®¾ç½®ä¸º5å¯ä»¥çœ‹åˆ°åˆ†å¸ƒåœ¨ã€0ï¼Œ1ã€‘çš„æ•°æ›´åŠ å¹³æ»‘äº†å“¦~</p>
<h2 id="KDè®­ç»ƒä»£ç ">KDè®­ç»ƒä»£ç </h2>
<h3 id="å¯¼å…¥åŒ…">å¯¼å…¥åŒ…</h3>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets, transforms<br><span class="hljs-keyword">import</span> torch.utils.data<br>torch.manual_seed(<span class="hljs-number">0</span>)<br>torch.cuda.manual_seed(<span class="hljs-number">0</span>) <span class="hljs-comment">#è®¾ç½®GPUç”Ÿæˆéšæœºæ•°çš„ç§å­ï¼Œæ–¹ä¾¿ä¸‹æ¬¡å¤ç°å®éªŒç»“æœã€‚</span><br></code></pre></td></tr></tbody></table></figure>
<h3 id="ç½‘ç»œæ¶æ„">ç½‘ç»œæ¶æ„</h3>
<h4 id="teacherç½‘ç»œ">teacherç½‘ç»œ</h4>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TeacherNet</span>(<span class="hljs-params">nn.Module</span>):</span> <span class="hljs-comment">#ç»§æ‰¿Module</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>(TeacherNet, self).__init__()<br>        self.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">32</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br>        self.conv2 = nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br>        self.dropout1 = nn.Dropout2d(<span class="hljs-number">0.3</span>)<br>        self.dropout2 = nn.Dropout2d(<span class="hljs-number">0.5</span>)<br>        self.fc1 = nn.Linear(<span class="hljs-number">9216</span>, <span class="hljs-number">128</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        x = self.conv1(x)<br>        x = F.relu(x)<br>        x = self.conv2(x)<br>        x = F.relu(x)<br>        x = F.max_pool2d(x, <span class="hljs-number">2</span>)<br>        x = self.dropout1(x)<br>        x = torch.flatten(x, <span class="hljs-number">1</span>)<br>        x = self.fc1(x)<br>        x = F.relu(x)<br>        x = self.dropout2(x)<br>        output = self.fc2(x)<br>        <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></tbody></table></figure>
<h4 id="studentç½‘ç»œ">studentç½‘ç»œ</h4>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">StudentNet</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>(StudentNet, self).__init__()<br>        self.fc1 = nn.Linear(<span class="hljs-number">28</span> * <span class="hljs-number">28</span>, <span class="hljs-number">128</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">64</span>)<br>        self.fc3 = nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        x = torch.flatten(x, <span class="hljs-number">1</span>)<br>        x = F.relu(self.fc1(x))<br>        x = F.relu(self.fc2(x))<br>        output = F.relu(self.fc3(x))<br>        <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></tbody></table></figure>
<h3 id="teacherç½‘ç»œè®­ç»ƒ">teacherç½‘ç»œè®­ç»ƒ</h3>
<h4 id="å®šä¹‰åŸºæœ¬å‡½æ•°">å®šä¹‰åŸºæœ¬å‡½æ•°</h4>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train_teacher</span>(<span class="hljs-params">model, device, train_loader, optimizer, epoch</span>):</span><br>    model.train() <span class="hljs-comment">#trainè¿‡ç¨‹model.train()çš„ä½œç”¨æ˜¯å¯ç”¨ Batch Normalization å’Œ Dropoutã€‚model.train()æ˜¯ä¿è¯BNå±‚èƒ½å¤Ÿç”¨åˆ°æ¯ä¸€æ‰¹æ•°æ®çš„å‡å€¼å’Œæ–¹å·®</span><br>    trained_samples = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> batch_idx, (data, target) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader):<br>        data, target = data.to(device), target.to(device) <span class="hljs-comment">#æ”¾åˆ°GPU</span><br>        optimizer.zero_grad() <span class="hljs-comment">#å½’0</span><br>        output = model(data) <span class="hljs-comment">#å¾—åˆ°ç»“æœ</span><br>        loss = F.cross_entropy(output, target) <span class="hljs-comment">#è®¡ç®—æŸå¤± ä½¿ç”¨äº¤å‰ç†µ</span><br>        loss.backward() <span class="hljs-comment">#åå‘ä¼ æ’­æ›´æ–°å‚æ•°</span><br>        optimizer.step() <span class="hljs-comment">#ä¼˜åŒ–å™¨è°ƒæ•´è¶…å‚æ•°</span><br><br>        trained_samples += <span class="hljs-built_in">len</span>(data)<br>        progress = math.ceil(batch_idx / <span class="hljs-built_in">len</span>(train_loader) * <span class="hljs-number">50</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">"\rTrain epoch %d: %d/%d, [%-51s] %d%%"</span> %<br>              (epoch, trained_samples, <span class="hljs-built_in">len</span>(train_loader.dataset),<br>               <span class="hljs-string">'-'</span> * progress + <span class="hljs-string">'&gt;'</span>, progress * <span class="hljs-number">2</span>), end=<span class="hljs-string">''</span>)<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test_teacher</span>(<span class="hljs-params">model, device, test_loader</span>):</span><br>    model.<span class="hljs-built_in">eval</span>() <span class="hljs-comment">#ä¿è¯BNå±‚èƒ½å¤Ÿç”¨å…¨éƒ¨è®­ç»ƒæ•°æ®çš„å‡å€¼å’Œæ–¹å·®</span><br>    test_loss = <span class="hljs-number">0</span><br>    correct = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad(): <span class="hljs-comment">#å†»ç»“å‚æ•°</span><br>        <span class="hljs-keyword">for</span> data, target <span class="hljs-keyword">in</span> test_loader:<br>            data, target = data.to(device), target.to(device)<br>            output = model(data) <span class="hljs-comment">#æ¨¡å‹å¾—åˆ°ç»“æœ</span><br>            test_loss += F.cross_entropy(output, target, reduction=<span class="hljs-string">'sum'</span>).item()  <span class="hljs-comment"># ç»Ÿè®¡æ‰€æœ‰çš„losssum up batch loss</span><br>            pred = output.argmax(dim=<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># get the index of the max log-probability å¾—åˆ°æ¯ä¸€è¡Œçš„æœ€å¤§å€¼ä¸‹æ ‡</span><br>            correct += pred.eq(target.view_as(pred)).<span class="hljs-built_in">sum</span>().item() <span class="hljs-comment">#eqæ˜¯ä¸€ä¸ªåˆ¤æ–­å‡½æ•° view_asæ˜¯æ‹‰æˆä¸€åˆ—</span><br><br>    test_loss /= <span class="hljs-built_in">len</span>(test_loader.dataset) <span class="hljs-comment">#å¾—åˆ°å¹³å‡loss</span><br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">'\nTest: average loss: {:.4f}, accuracy: {}/{} ({:.0f}%)'</span>.<span class="hljs-built_in">format</span>(<br>        test_loss, correct, <span class="hljs-built_in">len</span>(test_loader.dataset),<br>        <span class="hljs-number">100.</span> * correct / <span class="hljs-built_in">len</span>(test_loader.dataset)))<br>    <span class="hljs-keyword">return</span> test_loss, correct / <span class="hljs-built_in">len</span>(test_loader.dataset)<br><br></code></pre></td></tr></tbody></table></figure>
<h4 id="è®­ç»ƒä¸»å‡½æ•°">è®­ç»ƒä¸»å‡½æ•°</h4>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">teacher_main</span>():</span><br>    epochs = <span class="hljs-number">10</span><br>    batch_size = <span class="hljs-number">64</span><br>    torch.manual_seed(<span class="hljs-number">0</span>) <span class="hljs-comment">#è®¾ç½®CPUç”Ÿæˆéšæœºæ•°çš„ç§å­ï¼Œæ–¹ä¾¿ä¸‹æ¬¡å¤ç°å®éªŒç»“æœã€‚</span><br><br>    device = torch.device(<span class="hljs-string">"cuda"</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">"cpu"</span>)<br><br>    train_loader = torch.utils.data.DataLoader(<br>        datasets.MNIST(<span class="hljs-string">'../data/MNIST'</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>,<br>                       transform=transforms.Compose([<br>                           transforms.ToTensor(),<br>                           transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))<br>                       ])),<br>        batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>)<br>    test_loader = torch.utils.data.DataLoader(<br>        datasets.MNIST(<span class="hljs-string">'../data/MNIST'</span>, train=<span class="hljs-literal">False</span>, download=<span class="hljs-literal">True</span>, transform=transforms.Compose([<br>            transforms.ToTensor(),<br>            transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))<br>        ])),<br>        batch_size=<span class="hljs-number">1000</span>, shuffle=<span class="hljs-literal">True</span>)<br><br>    model = TeacherNet().to(device) <span class="hljs-comment">#æ¨¡å‹è£…è¿›GPUä¸­</span><br>    optimizer = torch.optim.Adadelta(model.parameters()) <span class="hljs-comment">#å®šä¹‰ä¼˜åŒ–å™¨ å…¶å®éœ€è¦ä¼ å…¥æ¨¡å‹å‚æ•°è®©ä¼˜åŒ–å™¨çŸ¥é“å‚æ•°ç©ºé—´</span><br>    <span class="hljs-string">'''</span><br><span class="hljs-string">    optimzierä¼˜åŒ–å™¨çš„ä½œç”¨ï¼šä¼˜åŒ–å™¨å°±æ˜¯éœ€è¦æ ¹æ®ç½‘ç»œåå‘ä¼ æ’­çš„æ¢¯åº¦ä¿¡æ¯æ¥</span><br><span class="hljs-string">    å†æ¬¡æ›´æ–°ç½‘ç»œçš„å‚æ•°ï¼Œä»¥èµ·åˆ°é™ä½losså‡½æ•°è®¡ç®—å€¼çš„ä½œç”¨ã€‚</span><br><span class="hljs-string">    '''</span><br>    <br>    teacher_history = [] <span class="hljs-comment">#ä¿å­˜å†å²æ•°æ®</span><br><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):<br>        train_teacher(model, device, train_loader, optimizer, epoch)<br>        loss, acc = test_teacher(model, device, test_loader) <span class="hljs-comment">#ç›¸å½“äºéªŒè¯é›†ä½œç”¨ ä¹Ÿå¯ä»¥ç»˜å›¾</span><br>        <br>        teacher_history.append((loss, acc))<br><br>    torch.save(model.state_dict(), <span class="hljs-string">"teacher.pt"</span>)<br>    <span class="hljs-keyword">return</span> model, teacher_history<br></code></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># è®­ç»ƒæ•™å¸ˆç½‘ç»œ</span><br>teacher_model, teacher_history = teacher_main()<br></code></pre></td></tr></tbody></table></figure>
<h3 id="studentç½‘ç»œè®­ç»ƒï¼ˆé‡ç‚¹ï¼‰ğŸŒ¸">studentç½‘ç»œè®­ç»ƒï¼ˆé‡ç‚¹ï¼‰ğŸŒ¸</h3>
<h4 id="ç†è®ºéƒ¨åˆ†">ç†è®ºéƒ¨åˆ†</h4>
<p><img src="https://picture.mulindya.com/kDistillation-10.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>è¿™é‡Œçš„qæ˜¯ç»è¿‡äº†<code>softmax</code>ä¹‹åçš„åˆ†å¸ƒ</p>
<p>studentçš„lossæ¥æºäºä¸¤ä¸ªéƒ¨åˆ†ï¼ŒLosså°†ä¸¤ä¸ªlossç›¸åŠ </p>
<ul>
<li>studetçš„HARD Lossæ˜¯æ ¹æ®one-hotçš„çœŸå®æ ·æœ¬påˆ†å¸ƒå¾—åˆ°ï¼ˆå’Œä¸€èˆ¬çš„lossä¸€æ ·ï¼‰</li>
<li>studentçš„SOFT lossæ˜¯æ¥æºäºteacherçš„åˆ†å¸ƒqâ€™â€˜ï¼ˆæ˜¯å°†qâ€™è’¸é¦å¹³æ»‘åçš„ç»“æœï¼‰</li>
</ul>
<h4 id="å®šä¹‰kdçš„loss">å®šä¹‰kdçš„loss</h4>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># è¿™é‡Œå®šä¹‰çš„æ˜¯SOFT Loss + äº¤å‰ç†µï¼ˆHARD Lossï¼‰</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">distillation</span>(<span class="hljs-params">y, labels, teacher_scores, temp, alpha</span>):</span><br>    <span class="hljs-keyword">return</span> nn.KLDivLoss()(F.log_softmax(y / temp, dim=<span class="hljs-number">1</span>), F.softmax(teacher_scores / temp, dim=<span class="hljs-number">1</span>)) * (<br>            temp * temp * <span class="hljs-number">2.0</span> * alpha) + F.cross_entropy(y, labels) * (<span class="hljs-number">1.</span> - alpha) <span class="hljs-comment">#ä¸¤ä¸ªåˆ†å¸ƒéƒ½æ˜¯T_softmaxæ¥æ±‚ç›¸å¯¹ç†µ</span><br><br></code></pre></td></tr></tbody></table></figure>
<blockquote>
<p>nn.KLDivLoss()(input,target)ç›¸å¯¹ç†µæŸå¤± é€šè¿‡æ±‚æ•£åº¦å¾—åˆ°Losså€¼</p>
<p>ç”¨äºè¡¡é‡ä¸¤ä¸ªåˆ†å¸ƒçš„ç›¸ä¼¼æ€§ï¼Œè¶Šå°è¶Šç›¸ä¼¼</p>
</blockquote>

$$
l_{n}=y_{n} \cdot\left(\log y_{n}-x_{n}\right)
$$

<p>å¯ä»¥æŒ‡å®šloss functionçš„reductionå‚æ•°ï¼Œæ¥è®¾ç½®æ¯ä¸ªæ ·æœ¬lossçš„æœ€åå¾—åˆ°æ•°æ®lossè®¡ç®—æ–¹å¼ï¼›</p>

$$
\ell(x, y)=\left\{\begin{array}{ll}L, &amp; \text { if reduction }=\text { 'none' } \\ \operatorname{mean}(L), &amp; \text { if reduction }=\text { 'mean' } \\ N*\operatorname {mean}(L), &amp; \text { if reduction }=\text { 'batchmean' } \\ \operatorname{sum}(L), &amp; \text { if reduction }=\text { 'sum' }\end{array} \right.
$$

<h4 id="å®šä¹‰åŸºæœ¬å‡½æ•°-2">å®šä¹‰åŸºæœ¬å‡½æ•°</h4>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train_student_kd</span>(<span class="hljs-params">model, device, train_loader, optimizer, epoch</span>):</span><br>    model.train()<br>    trained_samples = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> batch_idx, (data, target) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader):<br>        data, target = data.to(device), target.to(device)<br>        optimizer.zero_grad()<br>        output = model(data)<br>        teacher_output = teacher_model(data)  <span class="hljs-comment">#å¾—åˆ°teacherç½‘ç»œçš„æ¨æ–­ç”¨äºåç»­è®¡ç®—studentçš„loss</span><br>        teacher_output = teacher_output.detach()  <span class="hljs-comment"># åˆ‡æ–­è€å¸ˆç½‘ç»œçš„åå‘ä¼ æ’­</span><br>        loss = distillation(output, target, teacher_output, temp=<span class="hljs-number">5.0</span>, alpha=<span class="hljs-number">0.7</span>)<br>        loss.backward()<br>        optimizer.step()<br><br>        trained_samples += <span class="hljs-built_in">len</span>(data)<br>        progress = math.ceil(batch_idx / <span class="hljs-built_in">len</span>(train_loader) * <span class="hljs-number">50</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">"\rTrain epoch %d: %d/%d, [%-51s] %d%%"</span> %<br>              (epoch, trained_samples, <span class="hljs-built_in">len</span>(train_loader.dataset),<br>               <span class="hljs-string">'-'</span> * progress + <span class="hljs-string">'&gt;'</span>, progress * <span class="hljs-number">2</span>), end=<span class="hljs-string">''</span>)<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test_student_kd</span>(<span class="hljs-params">model, device, test_loader</span>):</span><br>    model.<span class="hljs-built_in">eval</span>()<br>    test_loss = <span class="hljs-number">0</span><br>    correct = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> data, target <span class="hljs-keyword">in</span> test_loader:<br>            data, target = data.to(device), target.to(device)<br>            output = model(data)<br>            test_loss += F.cross_entropy(output, target, reduction=<span class="hljs-string">'sum'</span>).item()  <span class="hljs-comment"># sum up batch loss item()å‡½æ•°å¯ä»¥ç†è§£ä¸ºå¾—åˆ°çº¯ç²¹çš„æ•°å€¼</span><br>            pred = output.argmax(dim=<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># get the index of the max log-probability</span><br>            correct += pred.eq(target.view_as(pred)).<span class="hljs-built_in">sum</span>().item()<br><br>    test_loss /= <span class="hljs-built_in">len</span>(test_loader.dataset)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">'\nTest: average loss: {:.4f}, accuracy: {}/{} ({:.0f}%)'</span>.<span class="hljs-built_in">format</span>(<br>        test_loss, correct, <span class="hljs-built_in">len</span>(test_loader.dataset),<br>        <span class="hljs-number">100.</span> * correct / <span class="hljs-built_in">len</span>(test_loader.dataset)))<br>    <span class="hljs-keyword">return</span> test_loss, correct / <span class="hljs-built_in">len</span>(test_loader.dataset)<br></code></pre></td></tr></tbody></table></figure>
<h4 id="è®­ç»ƒä¸»å‡½æ•°-2">è®­ç»ƒä¸»å‡½æ•°</h4>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">student_kd_main</span>():</span><br>    epochs = <span class="hljs-number">10</span><br>    batch_size = <span class="hljs-number">64</span><br>    torch.manual_seed(<span class="hljs-number">0</span>)<br><br>    device = torch.device(<span class="hljs-string">"cuda"</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">"cpu"</span>)<br><br>    train_loader = torch.utils.data.DataLoader(<br>        datasets.MNIST(<span class="hljs-string">'../data/MNIST'</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>,<br>                       transform=transforms.Compose([<br>                           transforms.ToTensor(),<br>                           transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))<br>                       ])),<br>        batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>)<br>    test_loader = torch.utils.data.DataLoader(<br>        datasets.MNIST(<span class="hljs-string">'../data/MNIST'</span>, train=<span class="hljs-literal">False</span>, download=<span class="hljs-literal">True</span>, transform=transforms.Compose([<br>            transforms.ToTensor(),<br>            transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))<br>        ])),<br>        batch_size=<span class="hljs-number">1000</span>, shuffle=<span class="hljs-literal">True</span>)<br><br>    model = StudentNet().to(device)<br>    optimizer = torch.optim.Adadelta(model.parameters())<br>    <br>    student_history = []<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):<br>        train_student_kd(model, device, train_loader, optimizer, epoch)<br>        loss, acc = test_student_kd(model, device, test_loader)<br>        student_history.append((loss, acc))<br><br>    torch.save(model.state_dict(), <span class="hljs-string">"student_kd.pt"</span>)<br>    <span class="hljs-keyword">return</span> model, student_history<br></code></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">student_kd_model, student_kd_history = student_kd_main()<br></code></pre></td></tr></tbody></table></figure>
<h3 id="ç»˜åˆ¶ç»“æœ">ç»˜åˆ¶ç»“æœ</h3>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>epochs = <span class="hljs-number">10</span><br>x = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, epochs+<span class="hljs-number">1</span>))<br><br>plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>plt.plot(x, [teacher_history[i][<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs)], label=<span class="hljs-string">'teacher'</span>)<br>plt.plot(x, [student_kd_history[i][<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs)], label=<span class="hljs-string">'student with KD'</span>)<br>plt.plot(x, [student_simple_history[i][<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs)], label=<span class="hljs-string">'student without KD'</span>)<br><br>plt.title(<span class="hljs-string">'Test accuracy'</span>)<br>plt.legend()<br><br><br>plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>plt.plot(x, [teacher_history[i][<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs)], label=<span class="hljs-string">'teacher'</span>)<br>plt.plot(x, [student_kd_history[i][<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs)], label=<span class="hljs-string">'student with KD'</span>)<br>plt.plot(x, [student_simple_history[i][<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs)], label=<span class="hljs-string">'student without KD'</span>)<br><br>plt.title(<span class="hljs-string">'Test loss'</span>)<br>plt.legend()<br></code></pre></td></tr></tbody></table></figure>
<p><img src="https://picture.mulindya.com/kDistillation-13.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>å¯ä»¥çœ‹åˆ°åœ¨teacherçš„å¸®åŠ©ä¸‹ï¼Œstudentå¯ä»¥å­¦å¾—æ›´å¥½ğŸ±</p>
<h3 id="teacherç½‘ç»œçš„æš—çŸ¥è¯†ğŸ">teacherç½‘ç»œçš„æš—çŸ¥è¯†ğŸ</h3>
<h4 id="softmax-t">softmax_t</h4>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">softmax_t</span>(<span class="hljs-params">x, t</span>):</span><br>    x_exp = np.exp(x / t)<br>    <span class="hljs-keyword">return</span> x_exp / np.<span class="hljs-built_in">sum</span>(x_exp)<br><br>test_loader_bs1 = torch.utils.data.DataLoader(<br>    datasets.MNIST(<span class="hljs-string">'../data/MNIST'</span>, train=<span class="hljs-literal">False</span>, download=<span class="hljs-literal">True</span>, transform=transforms.Compose([<br>        transforms.ToTensor(),<br>        transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))<br>    ])),<br>    batch_size=<span class="hljs-number">1</span>, shuffle=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></tbody></table></figure>
<h4 id="æ¨æ–­">æ¨æ–­</h4>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python">teacher_model.<span class="hljs-built_in">eval</span>()<br><span class="hljs-keyword">with</span> torch.no_grad():<br>    data, target = <span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(test_loader_bs1))<br>    data, target = data.to(<span class="hljs-string">'cuda'</span>), target.to(<span class="hljs-string">'cuda'</span>)<br>    output = teacher_model(data)<br><br>test_x = data.cpu().numpy() <span class="hljs-comment">#æ”¾è¿›cpuè½¬æ¢æˆnumpy</span><br>y_out = output.cpu().numpy()<br>y_out = y_out[<span class="hljs-number">0</span>, ::]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">'Output (NO softmax):'</span>, y_out)<br><br><br><br>plt.subplot(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>plt.imshow(test_x[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, ::])<br><br>plt.subplot(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>plt.bar(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)), softmax_t(y_out, <span class="hljs-number">1</span>), width=<span class="hljs-number">0.3</span>) <span class="hljs-comment">#ç›´æ–¹å›¾</span><br><br>plt.subplot(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br>plt.bar(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)), softmax_t(y_out, <span class="hljs-number">10</span>), width=<span class="hljs-number">0.3</span>)<br>plt.show()<br></code></pre></td></tr></tbody></table></figure>
<blockquote>
<p>Output (NO softmax): [-31.14481   -30.600847   -3.2787514 -20.624037  -31.863455  -37.684086 -35.177486  -22.72263   -16.028662  -26.460657 ]</p>
</blockquote>
<p><img src="https://picture.mulindya.com/kDistillation-12.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>å¯ä»¥çœ‹åˆ°æ•°æ®æ›´åŠ å¹³æ»‘ï¼Œå¹¶ä¸”å¯ä»¥ä½“ç°å‡ºè¿™ä¸ªæ•°å­—ä¸ä»…æ˜¯2è¿˜å’Œ8æœ‰äº›ç±»ä¼¼â›„ï¸ã€‚</p>
<h2 id="æœ¬è´¨ğŸˆ">æœ¬è´¨ğŸˆ</h2>
<p><img src="https://picture.mulindya.com/kDistillation-11.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>åœ¨çŸ¥è¯†è’¸é¦ä¸­ï¼Œæœ¬è´¨ä¸Šå°±æ˜¯ä½¿ç”¨SOFT Lossæ¥æ›¿ä»£æ­£åˆ™åŒ–é¡¹ï¼Œå»æ‹Ÿåˆteacherçš„æ•ˆæœã€‚</p>
<p>L2å·¦è¾¹æ˜¯æå¤§ä¼¼ç„¶ï¼Œå³è¾¹æ˜¯å…ˆéªŒçŸ¥è¯†ï¼ˆäººä¸ºè®¾ç½®ï¼‰</p>
<p>è¿™é‡Œç”¨teacherçš„çŸ¥è¯†å»æ­£åˆ™åŒ–ä½œä¸ºå…ˆéªŒçŸ¥è¯†ï¼Œå—¯ï¼niceï¼</p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">æ·±åº¦å­¦ä¹ </a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/">æå®æ¯…</a>
                    
                      <a class="hover-with-bg" href="/tags/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/">çŸ¥è¯†è’¸é¦</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 åè®®</a> ï¼Œè½¬è½½è¯·æ³¨æ˜å‡ºå¤„ï¼
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/01/06/deep_learning/dsconv/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Depthwise Separable Convolution</span>
                        <span class="visible-mobile">ä¸Šä¸€ç¯‡</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/01/05/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode17/">
                        <span class="hidden-mobile">leetcode17 ç”µè¯å·ç çš„å­—æ¯ç»„åˆ</span>
                        <span class="visible-mobile">ä¸‹ä¸€ç¯‡</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments" lazyload>
                
                  
                
                
  <div class="disqus" style="width:100%">
    <div id="disqus_thread"></div>
    
      <script type="text/javascript">
        var disqus_config = function() {
          this.page.url = 'https://fanmeilin.github.io/2022/01/05/deep_learning/KnowledgeDistillation/';
          this.page.identifier = '/2022/01/05/deep_learning/KnowledgeDistillation/';
        };
        Fluid.utils.loadComments('#disqus_thread', function() {
          var d = document, s = d.createElement('script');
          s.src = '//' + 'fluid' + '.disqus.com/embed.js';
          s.setAttribute('data-timestamp', new Date());
          (d.head || d.body).appendChild(s);
        });
      </script>
    
    <noscript>Please enable JavaScript to view the comments</noscript>
  </div>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header vvd_contents"><i class="iconfont icon-list"></i>&nbsp;ç›®å½•</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">æœç´¢</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">å…³é”®è¯</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- ä¸è’œå­ç»Ÿè®¡PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            æ€»è®¿é—®é‡ 
            <span id="busuanzi_value_site_pv"></span>
             æ¬¡
          </span>
      
      
        <!-- ä¸è’œå­ç»Ÿè®¡UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            æ€»è®¿å®¢æ•° 
            <span id="busuanzi_value_site_uv"></span>
             äºº
          </span>
      
    
  </div>
  <div class="statistics">
    <a target="_blank" rel="noopener" href="https://developer.hitokoto.cn/" id="hitokoto_text"><span style="color: #DDD;"  id="hitokoto"></span></a>
 <script src="https://v1.hitokoto.cn/?encode=js&select=%23hitokoto" defer></script>
  </div>


  
  <!-- å¤‡æ¡ˆä¿¡æ¯ -->
  <div class="beian">
    <span>
      <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
        é„‚ICPå¤‡2021014492-1å·
      </a>
    </span>
    
  </div>


  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js" ></script>



  <script  src="/js/local-search.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js" ></script>

  





  <script  src="https://cdn.jsdelivr.net/npm/mermaid@8.10.1/dist/mermaid.min.js" ></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({"theme":"default"});
    }
  </script>




  

  

  

  

  

  





<!-- ä¸»é¢˜çš„å¯åŠ¨é¡¹ ä¿æŒåœ¨æœ€åº•éƒ¨ -->
<script  src="/js/boot.js" ></script>


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"left","width":260,"height":480},"mobile":{"show":false},"react":{"opacity":0.9}});</script></body>
</html>
