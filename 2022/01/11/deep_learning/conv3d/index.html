

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>
<script type="text/javascript" src="/js/jquery.js"></script>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#d8afe4">
  <meta name="description" content="与灵魂共舞">
  <meta name="author" content="Meilin Fan">
  <meta name="keywords" content="个人博客,学习,生活">
  
  <title>深度理解3D卷积 - 待时</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"fanmeilin.github.io","root":"/","version":"1.8.11","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>


<body>

  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>与灵魂共舞</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

		<div class="banner" id="banner" parallax=true
			 style="background: url('https://picture.mulindya.com/03990bbe091d5cca73421ac40bacfc46_1.jpg') no-repeat center center;
			   background-size: cover;">

      <div class="full-bg-img" >

		
		<div id="banner_video_insert">
		</div>
		<script>
						
			var ua = navigator.userAgent;
			var ipad = ua.match(/(iPad).*OS\s([\d_]+)/),
				isIphone = !ipad && ua.match(/(iPhone\sOS)\s([\d_]+)/),
				isAndroid = ua.match(/(Android)\s+([\d.]+)/),
				isMobile = isIphone || isAndroid;

			function set_video_attr(id){
				
				var height = document.body.children[0].clientHeight

				var width = document.body.children[0].clientWidth

				var video_item = document.getElementById(id);

				if (height / width < 0.56){
					video_item.setAttribute('width','100%' ); <!--'100%'-->
					video_item.setAttribute('height', 'auto');
				} else {
					video_item.setAttribute('height', '100%'); <!--'100%'-->
					video_item.setAttribute('width', 'auto');
				}
			}

			$.getJSON('/js/video_url.json', function(data){
				if (true){ <!--!isMobile-->
					var video_list_length = data.length
					var seed = Math.random()
					index = Math.floor(seed * video_list_length)
					
					video_url = data[index]
					video_html_res = "<video id='video_item' style='position: absolute;' muted='muted' src=" + video_url + " autoplay='autoplay' loop='loop'></video>"

					document.getElementById("banner_video_insert").innerHTML = video_html_res;
					set_video_attr('video_item')
				}

			});

			if (true){
				window.onresize = function(){
					set_video_attr('video_item')
					}
				}
			</script>

		

        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="深度理解3D卷积">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-01-11 10:59" pubdate>
        2022年1月11日 上午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      2.5k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      36
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">深度理解3D卷积</h1>
            
            <div class="markdown-body">
              <blockquote>
<p>在帕金森数据中涉及三维数据的训练和预测，用到了conv3但是对其背后的原理还有一些模糊的地方，conv2d与多通道的conv2d的区别在哪里？conv3d的思想理论是什么？对此进行探究和记录… 😳</p>
</blockquote>
<blockquote>
<p>首先要明确多通道的2d卷积和3d卷积是不一样的，3d是可以在通道中移动的，2d达咩！</p>
</blockquote>
<h2 id="卷积核的维度">卷积核的维度</h2>
<p>卷积核的维度指的的进行滑窗操作的维度，而滑窗操作不在channel维度上进行，不管有几个channel，它们都共享同一个滑窗位置（虽然2D多channel卷积的时候每个channel上的卷积核权重是独立的，但滑窗位置是共享的）。所以在讨论卷积核维度的时候，是不把channel维加进去的。</p>
<p><font color="purple"><strong>2D conv的卷积核就是$(c, k_h, k_w)$，因此，对于RGB图像做2D卷积，卷积核可以是conv2D(3,3) 而不该是conv3D(3,3,3).</strong></font></p>
<p><font color="purple">**3D conv的卷积核就是$(c, k_d, k_h, k_w)$，其中k_d就是多出来的第三维，根据具体应用，在视频中就是时间维，在CT图像中就是层数维. **</font></p>
<h2 id="2D卷积">2D卷积</h2>
<h3 id="单通道">单通道</h3>
<p>首先了解什么是卷积核，卷积核(filter)是由一组参数构成的张量，卷积核相当于权值，图像相当于输入量，卷积的操作就是根据卷积核对这些输入量进行加权求和。我们通常用卷积来提取图像的特征。</p>
<p>直观理解如下：下图使用的是 3x3卷积核(height x width,简写$ H \times W$) 的卷积，padding为1(周围的虚线部分，卷积时为了使卷积后的图像大小与原来一致，会对原图像进行填充)，两个维度上的strides均为1(滑动步长，这里体现为每次滑动几个小方格)。</p>
<p><img src="https://picture.mulindya.com/2dconv.gif" srcset="/img/loading.gif" lazyload alt=""></p>
<p>针对单通道，输入图像的channel为1，即输入大小为$(1, height, weight)$，卷积核尺寸为 $(1, k_h, k_w)$，卷积核在输入图像上的的空间维度（即(height, width)两维）上进行进行滑窗操作，每次滑窗和 $(k_h, k_w)$ 窗口内的values进行卷积操作（现在都用相关操作取代），得到输出图像中的一个value。</p>
<p>上图是通道数为1的2维图像的卷积操作，静态表示为：</p>
<p><img src="https://picture.mulindya.com/conv3d-1.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h3 id="多通道">多通道</h3>
<p>了解了单通道图像的卷积之后，再来看多通道图像的卷积，我们知道灰度图像只有一个通道，而 RGB 图像有R、G、B三个通道。<br>
多通道图像的一次卷积要对所有通道上同一位置的元素做加权和，因此卷积核的shape变成了 $H \times W \times channels$，没有错卷积核变成了3维，但这不是3维卷积，因为我们区分几维卷积看的是卷积核可以在几个维度上的滑动，卷积核是不能在 channels上滑动的，因为上面提到每次卷积都要关联所有通道上同一位置上的元素。<br>
3通道的卷积表示如下：是对每个通道进行2d卷积操作然后把最后的值相加的到右侧的小方块。</p>
<p><img src="https://picture.mulindya.com/conv3d-2.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>上图将3个通道分开表示，卷积核也分开表示，filter1、filter2、filter3均为二维卷积核，堆叠在一起便形成了$ H \times W \times 3$的卷积核，同样的我们将3个通道也堆叠在一起;</p>
<p>针对多通道，假定输入图像的channel为c，即输入大小为$(c, height, weight)$，卷积核尺寸为 $(c, k_h, k_w)$， 卷积核在输入图像的空间维度即$(height, width)$两维上进行滑窗操作（在channel这一维度没有滑动只有相加），每次滑窗与c个channels上的$ (k_h, k_w)$ 窗口内的所有的values进行相关操作，得到输出图像中的一个value（多通道的信息被完全压缩了)</p>
<p>于是形成了下面的3维表示图：<br>
<img src="https://picture.mulindya.com/conv3d-3.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>虽然是一个卷积核，但是每个filter的权重值是不一样的哦~</p>
<p>如下如所示：在卷积核的每个通道上的权重是不一定相同的，<code>这里的6=4+0+1+偏移1</code></p>
<p><img src="https://picture.mulindya.com/conv3d-6.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h3 id="代码">代码</h3>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, groups=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>, padding_mode=<span class="hljs-string">'zeros'</span>, device=<span class="hljs-literal">None</span>, dtype=<span class="hljs-literal">None</span>)<br></code></pre></td></tr></tbody></table></figure>
<ul>
<li><strong>in_channels</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) – Number of channels in the input image</li>
<li><strong>out_channels</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) – Number of channels produced by the convolution</li>
<li><strong>kernel_size</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a>) – Size of the convolving kernel</li>
<li><strong>stride</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>,</em> <em>optional</em>) – Stride of the convolution. Default: 1</li>
<li><strong>padding</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#str"><em>str</em></a><em>,</em> <em>optional</em>) – Padding added to all four sides of the input. Default: 0</li>
<li><strong>padding_mode</strong> (<em>string</em>*,* <em>optional</em>) – <code>'zeros'</code>, <code>'reflect'</code>, <code>'replicate'</code> or <code>'circular'</code>. Default: <code>'zeros'</code></li>
<li><strong>dilation</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>,</em> <em>optional</em>) – Spacing between kernel elements. Default: 1</li>
<li><strong>groups</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <em>optional</em>) – Number of blocked connections from input channels to output channels. Default: 1</li>
<li><strong>bias</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a><em>,</em> <em>optional</em>) – If <code>True</code>, adds a learnable bias to the output. Default: <code>True</code></li>
</ul>
<p>Applies a 2D convolution over an input signal composed of several input planes.</p>
<p>In the simplest case, the output value of the layer with input size $(N, C_{\text{in}}, H, W)$and output $(N, C_{\text{out}}, H_{\text{out}}, W_{\text{out}})$ can be precisely described as:<br>
$$<br>
\text{out}(N_i, C_{\text{out}<em>j}) = \text{bias}(C</em>{\text{out}<em>j}) + \sum</em>{k = 0}^{C_{\text{in}} - 1} \text{weight}(C_{\text{out}_j}, k) \star \text{input}(N_i, k)<br>
$$</p>
<p>where \star⋆ is the valid 2D <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a> operator, N<em>N</em> is a batch size, C<em>C</em> denotes a number of channels, H<em>H</em> is a height of input planes in pixels, and W<em>W</em> is width in pixels.</p>
<p>This module supports <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/notes/cuda.html#tf32-on-ampere">TensorFloat32</a>.</p>
<ul>
<li>
<p><code>stride</code> controls the stride for the cross-correlation, a single number or a tuple.</p>
</li>
<li>
<p><code>padding</code> controls the amount of padding applied to the input. It can be either a string {‘valid’, ‘same’} or a tuple of ints giving the amount of implicit padding applied on both sides.</p>
</li>
<li>
<p><code>dilation</code> controls the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this <a target="_blank" rel="noopener" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">link</a> has a nice visualization of what <code>dilation</code> does.</p>
</li>
<li>
<p><code>groups</code> controls the connections between inputs and outputs. <code>in_channels</code> and <code>out_channels</code> must both be divisible by <code>groups</code>. For example,</p>
<blockquote>
<ul>
<li>At groups=1, all inputs are convolved to all outputs.</li>
<li>At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels and producing half the output channels, and both subsequently concatenated.</li>
<li>At groups= <code>in_channels</code>, each input channel is convolved with its own set of filters (of size $\frac{\text{out_channels}}{\text{in_channels}}$ ).</li>
</ul>
</blockquote>
</li>
</ul>
<p>The parameters <code>kernel_size</code>, <code>stride</code>, <code>padding</code>, <code>dilation</code> can either be:</p>
<blockquote>
<ul>
<li>a single <code>int</code> – in which case the same value is used for the height and width dimension</li>
<li>a <code>tuple</code> of two ints – in which case, the first int is used for the height dimension, and the second int for the width dimension</li>
</ul>
</blockquote>
<h4 id="example">example</h4>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># With square kernels and equal stride</span><br>m = nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">33</span>, <span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>)<br><span class="hljs-comment"># non-square kernels and unequal stride and with padding</span><br>m = nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">33</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">5</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">4</span>, <span class="hljs-number">2</span>))<br><span class="hljs-comment"># non-square kernels and unequal stride and with padding and dilation</span><br>m = nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">33</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">5</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">4</span>, <span class="hljs-number">2</span>), dilation=(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>))<br><span class="hljs-built_in">input</span> = torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">50</span>, <span class="hljs-number">100</span>)<br>output = m(<span class="hljs-built_in">input</span>)<br></code></pre></td></tr></tbody></table></figure>
<h4 id="2d卷积操作后变化">2d卷积操作后变化</h4>
<p><img src="https://picture.mulindya.com/conv3d-7.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h2 id="3D卷积">3D卷积</h2>
<h3 id="单通道-2">单通道</h3>
<p>用类似的方法我们先分析单通道图像的3D卷积，3D卷积的对象是三维图像，因此卷积核变成了$depth \times height \times width $简写为$D \times H \times W $。单通道的<code>3D卷积</code>动态图如下：<br>
<img src="https://picture.mulindya.com/conv3d.gif" srcset="/img/loading.gif" lazyload alt=""></p>
<p>针对单通道，与2D卷积不同之处在于，<strong>输入图像多了一个 depth 维度</strong>，故输入大小为$(1, depth, height, width)$，卷积核也多了一个$k_d$维度，因此卷积核在输入3D图像的空间维度$(depth,height,width)$上均进行滑窗操作，每次滑窗与$ (k_d, k_h, k_w) $窗口内的values进行相关操作，得到输出3D图像中的一个value，最终输出一个3D的特征图。</p>
<p>这里的3D不是通道导致的，而是深度（多层切片，多帧视频），因此，虽然输入和卷积核和输出都是3D的，但都可以是单通道的。</p>
<p>将上述静态表示成：</p>
<p><img src="https://picture.mulindya.com/conv3d-4.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h3 id="多通道-2">多通道</h3>
<p><img src="https://picture.mulindya.com/conv3d-5.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>然后将filter1、filter2、filter3堆叠在一起形成一个4维卷积核$ D \times H \times W \times 3$，同理将各通道堆叠在一起就形成了多通道的3D卷积输入图像。</p>
<p>针对多通道,比如c个通道，输入大小为$(c, depth, height, width)$，与2D多通道卷积的操作类似，对于每次滑窗，卷积核同时与c个channels上的 $(k_d, k_h, k_w)$ 窗口内的所有values进行相关操作，得到输出3D图像中的一个value。<br>
由于3D卷积中的卷积核是3D的，因此在每个channel下使用的是同样的参数，权重共享。不同于2D多通道下的卷积核，后者在每一个channel使用的权重是一样的，不同的通道权重可能不一样。</p>
<h4 id="代码-2">代码</h4>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.nn.Conv3d(in_channels, out_channels, kernel_size, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, groups=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>, padding_mode=<span class="hljs-string">'zeros'</span>, device=<span class="hljs-literal">None</span>, dtype=<span class="hljs-literal">None</span>)<br></code></pre></td></tr></tbody></table></figure>
<ul>
<li><strong>in_channels</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) – Number of channels in the input image</li>
<li><strong>out_channels</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) – Number of channels produced by the convolution</li>
<li><strong>kernel_size</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a>) – Size of the convolving kernel</li>
<li><strong>stride</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>,</em> <em>optional</em>) – Stride of the convolution. Default: 1</li>
<li><strong>padding</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#str"><em>str</em></a><em>,</em> <em>optional</em>) – Padding added to all six sides of the input. Default: 0</li>
<li><strong>padding_mode</strong> (<em>string</em>*,* <em>optional</em>) – <code>'zeros'</code>, <code>'reflect'</code>, <code>'replicate'</code> or <code>'circular'</code>. Default: <code>'zeros'</code></li>
<li><strong>dilation</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>,</em> <em>optional</em>) – Spacing between kernel elements. Default: 1</li>
<li><strong>groups</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <em>optional</em>) – Number of blocked connections from input channels to output channels. Default: 1</li>
<li><strong>bias</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a><em>,</em> <em>optional</em>) – If <code>True</code>, adds a learnable bias to the output. Default: <code>True</code></li>
</ul>
<p><font color="red"><strong>和2D卷积函数基本上是一样的，只是维度和内部的工作机制不太一样。</strong></font></p>
<p>Applies a 3D convolution over an input signal composed of several input planes.</p>
<p>In the simplest case, the output value of the layer with input size$ (N, C_{in}, D, H, W)$  and output $(N, C_{out}, D_{out}, H_{out}, W_{out})$ can be precisely described as:<br>
$$<br>
out(N_i, C_{out_j}) = bias(C_{out_j}) + \sum_{k = 0}^{C_{in} - 1} weight(C_{out_j}, k) \star input(N_i, k)<br>
$$<br>
where \star⋆ is the valid 3D <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a> operator</p>
<p>This module supports <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/notes/cuda.html#tf32-on-ampere">TensorFloat32</a>.</p>
<ul>
<li>
<p><code>stride</code> controls the stride for the cross-correlation.</p>
</li>
<li>
<p><code>padding</code> controls the amount of padding applied to the input. It can be either a string {‘valid’, ‘same’} or a tuple of ints giving the amount of implicit padding applied on both sides.</p>
</li>
<li>
<p><code>dilation</code> controls the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this <a target="_blank" rel="noopener" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">link</a> has a nice visualization of what <code>dilation</code> does.</p>
</li>
<li>
<p><code>groups</code> controls the connections between inputs and outputs. <code>in_channels</code> and <code>out_channels</code> must both be divisible by <code>groups</code>. For example,</p>
<blockquote>
<ul>
<li>At groups=1, all inputs are convolved to all outputs.</li>
<li>At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels and producing half the output channels, and both subsequently concatenated.</li>
<li>At groups= <code>in_channels</code>, each input channel is convolved with its own set of filters (of size $\frac{\text{out_channels}}{\text{in_channels}}$).</li>
</ul>
</blockquote>
</li>
</ul>
<p>The parameters <code>kernel_size</code>, <code>stride</code>, <code>padding</code>, <code>dilation</code> can either be:</p>
<blockquote>
<ul>
<li>a single <code>int</code> – in which case the same value is used for the depth, height and width dimension</li>
<li>a <code>tuple</code> of three ints – in which case, the first int is used for the depth dimension, the second int for the height dimension and the third int for the width dimension</li>
</ul>
</blockquote>
<p><img src="https://picture.mulindya.com/conv3d-8.png" srcset="/img/loading.gif" lazyload alt=""></p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
                    
                      <a class="hover-with-bg" href="/tags/yuan/">yuan</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/01/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PracticeML3/">
                        <span class="hidden-mobile">praticalML第三章笔记</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments" lazyload>
                
                  
                
                
  <div class="disqus" style="width:100%">
    <div id="disqus_thread"></div>
    
      <script type="text/javascript">
        var disqus_config = function() {
          this.page.url = 'https://fanmeilin.github.io/2022/01/11/deep_learning/conv3d/';
          this.page.identifier = '/2022/01/11/deep_learning/conv3d/';
        };
        Fluid.utils.loadComments('#disqus_thread', function() {
          var d = document, s = d.createElement('script');
          s.src = '//' + 'fluid' + '.disqus.com/embed.js';
          s.setAttribute('data-timestamp', new Date());
          (d.head || d.body).appendChild(s);
        });
      </script>
    
    <noscript>Please enable JavaScript to view the comments</noscript>
  </div>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  <a href="http://www.beian.miit.gov.cn/"  style="color:#f72b07" target="_blank">鄂ICP备2021014492</a>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js" ></script>



  <script  src="/js/local-search.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js" ></script>

  





  <script  src="https://cdn.jsdelivr.net/npm/mermaid@8.10.1/dist/mermaid.min.js" ></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({"theme":"default"});
    }
  </script>




  

  

  

  

  

  





<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"left","width":260,"height":480},"mobile":{"show":false},"react":{"opacity":0.9}});</script></body>
</html>
