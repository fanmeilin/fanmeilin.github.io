

<!DOCTYPE html>

<html lang="zh-CN" data-default-color-scheme=auto>
<script type="text/javascript" src="/js/jquery.js"></script>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#d8afe4">
  <meta name="description" content="与灵魂共舞">
  <meta name="author" content="Meilin Fan">
  <meta name="keywords" content="个人博客,学习,生活">
  
  <title>Deep learning on image denoising--An overview - 待时</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"fanmeilin.github.io","root":"/","version":"1.8.11","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>


<body>	
	<div>
		<div class='real_mask'></div>
		<div id="banner_video_insert">
		</div>	
		<div id='vvd_banner_img'>
		</div>
	</div>
	<div id="banner"></div>
    
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>与灵魂共舞</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

	
	<!-- <div class="banner" id="banner" parallax=true
		style="background: url('https://picture.mulindya.com/03990bbe091d5cca73421ac40bacfc46_1.jpg') no-repeat center center;
		background-size: cover;"> -->
        <div class="banner" id='banner' >
		<div class="full-bg-img" >
		
			
				<script>
					var ua = navigator.userAgent;
					var ipad = ua.match(/(iPad).*OS\s([\d_]+)/),
						isIphone = !ipad && ua.match(/(iPhone\sOS)\s([\d_]+)/),
						isAndroid = ua.match(/(Android)\s+([\d.]+)/),
						isMobile = isIphone || isAndroid;

					function set_video_attr(id){

						var height = document.body.clientHeight
						var width = document.body.clientWidth
						var video_item = document.getElementById(id);

						if (height / width < 0.56){
							video_item.setAttribute('width', '100%');
							video_item.setAttribute('height', 'auto');
						} else {
							video_item.setAttribute('height', '100%');
							video_item.setAttribute('width', 'auto');
						}
					}

					$.getJSON('/js/video_url.json', function(data){
						if (!isMobile){
							var video_list_length = data.length
							var seed = Math.random()
							index = Math.floor(seed * video_list_length)
							
							video_url = data[index][0]
							pre_show_image_url = data[index][1]
							
							banner_obj = document.getElementById("banner")
							banner_obj.style.cssText = "background: url('" + pre_show_image_url + "') no-repeat; background-size: cover;"

							vvd_banner_obj = document.getElementById("vvd_banner_img")

							vvd_banner_content = "<img id='banner_img_item' src='" + pre_show_image_url + "' style='height: 100%; position: fixed; z-index: -999'>"
							vvd_banner_obj.innerHTML = vvd_banner_content

							video_html_res = "<video id='video_item' style='position: fixed; z-index: -888;'  muted='muted' src=" + video_url + " autoplay='autoplay' loop='loop'></video>"
							document.getElementById("banner_video_insert").innerHTML = video_html_res;

							set_video_attr('video_item')
							set_video_attr('banner_img_item')
						}
					});

					if (!isMobile){
						window.onresize = function(){
							set_video_attr('video_item')
							}
						}
				</script>
			

			<!-- <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)"> -->
            <div class="mask flex-center">
			  <div class="page-header text-center fade-in-up">
				<span class="h2" id="subtitle" title="Deep learning on image denoising--An overview">
				  
				</span>

				
				  <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-03-01 11:21" pubdate>
        2022年3月1日 上午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      10.4k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      110
       分钟
    </span>
  

  
  
</div>

				
			  </div>

			  
			</div>
		</div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Deep learning on image denoising--An overview</h1>
            
            <div class="markdown-body">
              <blockquote>
<p>有关自然图像去噪的一篇综述Deep learning on image denoising–An overview.在此记录和总结此篇论文的要点；聚焦于图像去噪的方法，成果，区别，动机和展望。</p>
</blockquote>
<h1>Deep learning on image denoising</h1>
<p>2020发表 156被引用</p>
<h2 id="摘要">摘要</h2>
<h4 id="深度学习去噪">深度学习去噪</h4>
<p>基于深度学习的判别学习可以很好地解决高斯噪声问题。基于深度学习的优化模型对真实噪声的估计是有效的。</p>
<h4 id="分类方法">分类方法</h4>
<p>1，对加性白噪声图像的深层卷积神经网络(CNN)</p>
<p>2，真实噪声图像的深层卷积神经网络(CNN)</p>
<p>3，盲去噪图像的深层卷积神经网络(CNN)</p>
<p>4，混合噪声图像的深层卷积神经网络(CNN)。</p>
<p>它们分别<strong>代表</strong>了噪声图像、模糊图像和低分辨率图像的组合。然后，我们分析了不同类型深度学习方法的<strong>动机和原理</strong>。从定量和定性分析两个方面对公开数据集去噪的最新方法进行了<strong>比较</strong>。</p>
<h4 id="关注点">关注点</h4>
<ul>
<li>定性定量的依据是什么？</li>
<li>如何表示？对应关系如何？</li>
</ul>
<h2 id="结论">结论</h2>
<h3 id="文章总结">文章总结</h3>
<p>本文对用于图像去噪的深度网络进行了比较、研究和总结。</p>
<ul>
<li>深度学习用于图像去噪的<strong>基本框架</strong>。</li>
<li>分析<strong>噪声任务</strong>的深度学习技术，包括加性白噪声图像、盲去噪、真实噪声图像和混合噪声图像；</li>
<li>针对每一类噪声任务，分析了网络去噪的<strong>动因和原理</strong>。</li>
<li>比较不同网络在基准数据集上的去噪效果、效率和视觉<strong>效果</strong>；</li>
<li>不同类型的噪声下，对不同类型的图像去噪方法进行了<strong>交叉比较</strong>。</li>
<li>有待进一步研究的领域，讨论图像去噪面临的<strong>挑战</strong>。</li>
</ul>
<h3 id="挑战与展望">挑战与展望</h3>
<p>在过去的几年里，高斯噪声图像去噪技术已经取得了很大的成功，特别是在高斯噪声是规则的情况下。</p>
<h4 id="现实条件">现实条件</h4>
<ul>
<li>
<p>噪声是复杂和不规则的。（改进硬件设备，以便更好地抑制噪声，以获取高质量的图像非常重要）</p>
</li>
<li>
<p>获取的图像可能会出现模糊、低分辨率和损坏的情况。</p>
</li>
</ul>
<h4 id="挑战">挑战</h4>
<ul>
<li>如何有效地从叠加的噪声图像中恢复出潜在的干净图像是至关重要的。</li>
<li>使用深度学习技术来学习特征需要ground-truth，但获得的真实噪声图像没有ground-truth。</li>
</ul>
<h2 id="引入">引入</h2>
<h3 id="近50年的发展">近50年的发展</h3>
<p><strong>探索阶段</strong>（传统）：非线性和非自适应滤波器被用于图像应用。与线性滤波器不同，非线性滤波器可以保留边缘信息以抑制噪声。自适应非线性滤波器依赖于局部信噪比来导出适当的加权因子，用于从被加性随机、信号相关、脉冲噪声和加性随机噪声的组合所污染的图像中去除噪声。非自适应滤波器可以同时使用边缘信息和信噪比信息来估计噪声。</p>
<p><strong>机器学习</strong>：机器学习方法，如基于稀疏的方法，被成功地应用于图像去噪。一种非局部集中式稀疏表示方法利用非局部自相似性对稀疏方法进行优化，获得了较高的图像去噪性能；降低成本：采用字典学习方法快速过滤去噪。恢复潜在clean图像细节信息：先验知识(即总变异正则化)可以平滑噪声图像，以处理受污染的图像。</p>
<p><strong>更多补充</strong>：马尔可夫随机场（MRF），加权核范数最小化（WNNM），学习同时稀疏编码（LSSC），收缩场级联（CSF），可训练非线性反应扩散（TNRD）和梯度直方图估计和保存（GHEP)</p>
<h5 id="缺点">缺点</h5>
<p>上述大多数方法在图像去噪方面都取得了相当好的性能，但它们也存在一些缺点，包括需要测试阶段的优化方法、手动设置参数以及针对单个去噪任务的特定模型。</p>
<h3 id="深度学习">深度学习</h3>
<p>提出的去噪工作首先使用具有已知<strong>移位不变模糊函数和加性噪声</strong>的神经网络来恢复潜在的干净图像。</p>
<p>后续使用加权因子去除复杂噪声，为了降低计算代价，使用<em><strong>前馈网络</strong></em>折中去噪效果和性能。前馈神经网络利用Kuwahara filters对图像进行平滑处理（类似卷积），还证明均方误差(MSE)是ALOS函数，并不是神经网络所特有的。</p>
<h4 id="优化算法">优化算法</h4>
<p>随后，使用更多的优化算法来加速训练网络的收敛，提高去噪性能</p>
<ul>
<li>最大熵和原对偶La-grangian乘性因子相结合来<strong>增强神经网络的表达能力</strong>；</li>
<li>将贪婪算法和异步算法应用到神经网络中，设计了一种新的网络结构，通过增加深度或改变激活函数来消除噪声来<strong>权衡速度和效果</strong>；</li>
<li>CENNs主要利用带有模板的节点来求取平均函数，有效地抑制噪声。但需要手动设置模板参数。为了解决这个问题，发展了<strong>梯度下降法</strong>。</li>
</ul>
<h5 id="缺点-2">缺点</h5>
<p>网络不允许添加新的插件，这限制了它们在现实世界中的应用</p>
<h4 id="卷积神经网络">卷积神经网络</h4>
<h5 id="瓶颈">瓶颈</h5>
<ol>
<li>深层CNN会产生消失的梯度。</li>
<li>激活函数如Sigmoid和tanh导致较高的计算成本。</li>
<li>硬件平台不支持复杂网络。</li>
</ol>
<h5 id="转折">转折</h5>
<p>在2012年发生了变化，AlexNet在当年的ImageNet大规模视觉识别挑战(ILSVRC)。此后，深度网络结构(如VGG和GoogLeNet)被广泛应用于图像、视频、自然语言处理和语音处理等领域，尤其是低级计算机视觉。</p>
<h5 id="引入图像去噪">引入图像去噪</h5>
<p>深度网络在2015年首次应用于图像去噪。所提出的网络不需要手动设置用于消除噪声的参数。此后，深度网络被广泛应用于语音、视频和图像恢复。</p>
<p>采用多次卷积和反卷积的方法抑制噪声，恢复高分辨率图像。为了通过模型处理多个低层任务，提出了一种由卷积、批归一化(BN)、校正线性单元(RELU)和残差学习(RL)组成的去噪CNN(DnCNN)来处理图像去噪、超分辨率和JPEG图像去块。考虑到去噪性能和速度的折衷。</p>
<h6 id="彩色图像噪声">彩色图像噪声</h6>
<p>彩色非局部网络(CNLNet)将非局部自相似性(NLSS)和CNN相结合，有效地去除了彩色图像噪声。</p>
<p>DnCNN：<a target="_blank" rel="noopener" href="https://readpaper.com/paper/2508457857">https://readpaper.com/paper/2508457857</a> （2017年发表，3793被引用）</p>
<p>CNLNet：<a target="_blank" rel="noopener" href="https://readpaper.com/paper/2550616896%EF%BC%882016%E5%B9%B4%E5%8F%91%E8%A1%A8%EF%BC%8C9%E8%A2%AB%E5%BC%95%E7%94%A8%EF%BC%89">https://readpaper.com/paper/2550616896（2016年发表，9被引用）</a></p>
<h5 id="blind-denoising">blind denoising</h5>
<p>一种快速灵活的去噪CNN(FFDNet)提出了不同的噪声水平，并将含噪图像块作为去噪网络的输入，以提高去噪速度，<strong>进行blind去噪</strong>。</p>
<h6 id="不成对的噪声图像">不成对的噪声图像</h6>
<ul>
<li>
<p>为了处理不成对的噪声图像，生成对抗网络(GAN)CNN盲去噪器(GCBD)解决了这一问题，它首先生成ground-truth，然后将获得的ground-truth输入到GAN中训练去噪器。</p>
</li>
<li>
<p>卷积盲去噪网络(CBDNet)通过两个子网络来去除给定的真实噪声图像中的噪声，其中一个子网络负责估计真实含噪图像的噪声，另一个子网络负责获取潜在的干净图像。</p>
</li>
<li>
<p>对于更复杂的受污染图像，发展了一种深度即插即用超分辨率(DPSR)方法来估计模糊kenel和噪声，并恢复高分辨率图像。</p>
</li>
</ul>
<p>FFDNet：<a target="_blank" rel="noopener" href="https://readpaper.com/paper/2764207251">https://readpaper.com/paper/2764207251</a> （2018年发表 899被引用）</p>
<p>GCBD：<a target="_blank" rel="noopener" href="https://readpaper.com/paper/2798278116">https://readpaper.com/paper/2798278116</a> （2018年发表 294被引用）</p>
<p>CBDNet：<a target="_blank" rel="noopener" href="https://readpaper.com/paper/2832157980">https://readpaper.com/paper/2832157980</a> （2018年发表 9被引用）</p>
<p>DPSR：<a target="_blank" rel="noopener" href="https://readpaper.com/paper/2929525177">https://readpaper.com/paper/2929525177</a> （2019年发表 0被引用）</p>
<h4 id="论文组织">论文组织</h4>
<ul>
<li>
<p>第二部分讨论了流行的图像应用的深度学习框架;(<a href="#%E5%8E%BB%E5%99%AA%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6">Fundamental frameworks of deep learning methods for image denoising</a>)</p>
</li>
<li>
<p>第三部分介绍了深度学习在图像去噪中的主要分类，并对这些方法进行了比较分析;(<a href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%9C%A8%E5%9B%BE%E5%83%8F%E5%8E%BB%E5%99%AA%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8">Deep learning techniques in image denoising</a>)</p>
</li>
<li>
<p>第四节提供了这些去噪方法的性能比较;(Experimental results)</p>
</li>
<li>
<p>第五节讨论了仍然存在的挑战和潜在的研究方向;(Discussion)</p>
</li>
<li>
<p>第六节给出了作者的结论;(<a href="#%E7%BB%93%E8%AE%BA">Conclusion</a>)</p>
</li>
</ul>
<h2 id="去噪基础框架">去噪基础框架</h2>
<p>这一部分讨论深度学习，包括它背后的思想、主要的网络框架(技术)以及硬件和软件，这是本调查涵盖的深入学习图像去噪技术的基础。</p>
<h3 id="机器学习">机器学习</h3>
<p>机器学习方法分为监督学习方法、半监督学习方法和非监督学习方法。</p>
<ul>
<li>
<p>有监督学习方法使用给定的标签使获得的特征更接近目标，以便学习参数和训练去噪模型。<br>
$$<br>
y=x+\mu \<br>
x:干净图像，y:噪声图像，\mu：标准差为\sigma的AWGN<br>
$$</p>
<ul>
<li>通过上述公式和贝叶斯知识，学习降噪模型的参数依赖于配对${x_k,y_k}^N_{k=1}$，$x_k$和$y_k$分别代表第k个干净图像和噪声图像，N是总数。处理可以表示为$x_k=f(y_k,\theta,m)，其中\theta是参数，m是给定的噪声等级$。</li>
</ul>
</li>
<li>
<p>无监督学习方法使用给定的训练样本，寻找pattern（而不是标签匹配），并完成特定任务，诸如对真实的低分辨率图像进行解配对。最近提出的循环内循环GaN(CinCGAN)算法首先估计高分辨率图像作为标签，然后利用获得的标签和损失函数训练超分辨率模型。</p>
</li>
<li>
<p>半监督学习方法将给定数据分布中的模型应用于构建学习器来标记未标记的样本。<strong>这种机制在小样本任务(如医学诊断)中更受青睐</strong>。半监督学习<strong>正弦图</strong>恢复网络(SLSR-NET)可以通过监督网络从成对的正弦图中学习特征分布，然后通过无监督网络将所获得的特征分布从未标记的低剂量正弦图转换为高保真正弦图。</p>
</li>
</ul>
<p>有监督学习方法：</p>
<p><strong><a target="_blank" rel="noopener" href="https://readpaper.com/paper/2592929672">A survey on deep learning in medical image analysis</a></strong>（2017发表 6840被引用）</p>
<p>A Local Consensus Index Scheme for Random-Valued Impulse Noise Detection Systems （2021发表 13被引用 ）</p>
<p><a target="_blank" rel="noopener" href="https://readpaper.com/paper/2946875605">Shared Linear Encoder-Based Multikernel Gaussian Process Latent Variable Model for Visual Classification</a> （2021发表 10被引用 ）</p>
<p>无监督学习方法：</p>
<p><a target="_blank" rel="noopener" href="https://readpaper.com/paper/2605205826">Unsupervised holistic image generation from key local patches</a> （2018发表 8被引用）</p>
<p><a target="_blank" rel="noopener" href="https://readpaper.com/paper/2962903125">Unsupervised Image Super-Resolution Using Cycle-in-Cycle Generative Adversarial Networks</a>（2018发表 210被引用）</p>
<p>半监督学习方法：</p>
<p><a target="_blank" rel="noopener" href="https://readpaper.com/paper/2979557921">Semi-Supervised Learning for Low-Dose CT Image Restoration with Hierarchical Deep Generative Adversarial Network</a> (HD-GAN) （2019发表 6被引用）</p>
<p><a target="_blank" rel="noopener" href="https://readpaper.com/paper/3011790227">Semi-supervised learned sinogram restoration network for low-dose CT image reconstruction</a>（2020发表 4被引用）</p>
<h3 id="神经网络">神经网络</h3>
<p>如果一个神经网络的层数超过三层，它也被称为深度神经网络，堆叠自动编码器(SARS)和深度信念网络(DBN)是典型的深度神经网络。他们在无监督的情况下使用叠加层对模型进行训练，取得了良好的性能。然而，这些网络的实现并不简单，需要大量的人工设置才能实现最佳模型。正因为如此，提出了端到端的连接网络（特别是CNN）。CNNs在图像处理，特别是图像去噪领域有着广泛的应用。</p>
<h4 id="卷积神经网络-2">卷积神经网络</h4>
<h5 id="AlexNet">AlexNet</h5>
<p>提出的AlexNet是深度学习的里程碑。它的成功有几个原因。</p>
<ol>
<li>图形处理单元(GPU)提供了强大的计算能力。</li>
<li>随机裁剪(即丢弃)解决了过拟合问题；</li>
<li>Relu提高了随机梯度下降(SGD)的速度，而不是Sigmoid。</li>
<li>数据增强方法进一步解决了过拟合问题。</li>
</ol>
<p><strong>缺点：</strong></p>
<p>虽然AlexNet取得了很好的性能，但由于其庞大的卷积内核，它需要大量的内存。这限制了它在现实世界中的应用，比如在智能相机中。在此之后，在2014-2016年间，为了提高性能和降低计算成本，更倾向于采用具有小过滤器的更深层次的网络体系结构。</p>
<h5 id="GoogLeNet">GoogLeNet</h5>
<p>随着更深层次网络的成功，研究转向增加它们的<strong>宽度</strong>。GoogLeNet增加了宽度以提高图像应用程序的性能。此外，GoogLeNet还将一个较大的卷积核变换为两个较小的卷积核，以减少参数数量和计算量。GoogLeNet还使用了Inistation模块和Inception模块。</p>
<h5 id="ResNet">ResNet</h5>
<p>VGG和GoogLeNet方法对于图像应用是有效的，但它们有两个缺点：如果网络很深，可能会导致梯度消失或爆炸；以及如果网络很深，可能会导致梯度消失或爆炸；如果网络过宽，可能会出现过度拟合的现象。</p>
<p>为了克服这些问题，2016年提出Resnet。每个block通过在ResNet中加入残差学习操作来提高图像识别性能。</p>
<h4 id="总结">总结</h4>
<p>自2014年以来，深度网络已广泛应用于真实世界的图像应用，例如面部识别和医疗诊断。</p>
<p>然而，在许多应用中，捕获的图像(例如真实的噪声图像)是不够的，并且深层CNN在图像应用中的性能往往很差。为此，Gans应运而生。GANS由两个网络组成：生成性网络和鉴别性网络。产生式网络(也称为生成器)用于根据输入样本生成样本。判别网络(也称为鉴别器)用于判断输入样本和生成样本的真实性。这两个网络是对抗性的。请注意，如果鉴别器能够准确区分真实样本并从生成器生成样本，则认为训练的模型已完成。图6中可以看到GaN的网络结构。由于其构建补充训练样本的能力，GaN对于小样本任务非常有效，例如面部识别和复杂噪声图像去噪。这些CNN是图像去噪的基本网络。</p>
<h3 id="软硬件使用">软硬件使用</h3>
<h4 id="硬件">硬件</h4>
<p>深度学习成功的一个原因是GPU。GPU采用CUDA、OpenCL和cuDNN平台，增强了并行计算能力，速度比CPU快10~30倍。GPU由NVIDIA显卡(即GTX 680、GTX 980、GTX 1070、GTX 1070Ti、GTX1080、GTX 1080Ti、RTX2070、RTX 2080、RTX 2080Ti、Tesla K40c、Tesla K80、Quadro M6000、Quadro GP100、QuadroP6000和Tesla V100)和AMD(即Radeon Vega 64)组成。</p>
<h4 id="软件">软件</h4>
<p>深度学习软件可以提供调用GPU的接口。目前流行的软件包有：</p>
<p>(1) 基于C<ins>的Caffe，提供C</ins>、Python和Matlab接口，既可以在CPU上运行，也可以在GPU上运行。它被广泛用于目标检测任务。然而，它要求开发人员掌握C++。</p>
<p>(2) Theano是一个用于处理大规模神经网络的数学表达式编译器。Theano提供了Python接口，用于图像的超分辨率、去噪和分类。</p>
<p>(3) MatConvernet提供了Matlab接口。它可用于图像分类、去噪和超分辨率，以及视频跟踪。但这需要掌握Matlab。</p>
<p>(4) TensorFlow是一个相对高阶的机器学习库。它比Theanofor编译速度更快。TensorFlow提供C++和Python接口，用于目标检测、图像分类、去噪和超分辨率。</p>
<p>(5) 基于TensorFlow和Theano的KERAS在Python中实现，并提供Python接口。它可以用于图像分类、目标检测、图像分辨率、图像去噪和动作识别。</p>
<p>(6) PyTorch是用Python实现的，并提供了Python接口。它应用于图像分类、目标检测、图像分割、动作识别、图像超分辨率、图像去噪和视频跟踪。</p>
<h2 id="深度学习技术在图像去噪中的应用">深度学习技术在图像去噪中的应用</h2>
<h3 id="加性白噪声图像去噪的深度学习技术">加性白噪声图像去噪的深度学习技术</h3>
<p>由于真实噪声图像的不足，加性白噪声图像(AWNI)被广泛用于训练去噪模型。AWNI包括高斯、泊松、椒盐、胡椒和乘性噪声图像。用于AWNI去噪的深度学习技术有几种，包括CNN/NN、CNN/NN与普通特征提取方法的结合以及优化方法与CNN/NN的结合。</p>
<h4 id="CNN-NN-在AWNI去噪中的应用">CNN/NN 在AWNI去噪中的应用</h4>
<p>自动特征提取方法可以在降低图像应用的计算成本方面发挥重要作用。为此，已开发出用于图像去噪的CNN，Zhang提出DnCNN来解决多个低级视觉任务，即通过CNN的图像去噪、超分辨率和去块、批归一化和残差学习技术。Wang等人还提出了用于图像去噪的更深层CNN的残差学习。然而，更深层的CNN技术依赖于更深的层，而不是浅层，这导致了长期的依赖问题。为了解决这个问题，人们提出了几种基于信号的方法。Tai 提出利用递归和门单元自适应地挖掘更精确的特征并恢复清晰的图像。受低阶Hankel矩阵的启发，Ye et al提供了卷积框架，通过卷积局部基和非局部基来解释信号处理和深度学习之间的联系。为了解决不充分的噪声图像(即高光谱图像和医学图像)，最近的一些工作试图通过使用改进的CNN来提取更多有用的信息。例如，袁等人将深度CNN、残差学习和多尺度知识相结合，对高光谱噪声图像进行去噪处理。然而，这些建议的CNN导致了计算成本和内存消耗的增加，这不利于现实世界的应用。为了解决这一现象，Gholizadeh等人在不增加CT图像去噪成本的情况下，利用膨胀卷积来扩大接收范围和减小网络深度。Lian等人提出了一种基于多尺度交叉路径级联的残差网络来抑制噪声。上述方法大多依赖于改进的CNN来处理噪声。因此，设计网络架构对于图像去噪非常重要。</p>
<p>改变网络架构包含下列方法：</p>
<ul>
<li>从一个CNN的多个输入融合特征
<ul>
<li>同一个样本的不同部分作为输入</li>
<li>同一个样本的不同视角作为输入</li>
<li>同一个样本的不同通道作为输入</li>
</ul>
</li>
<li>改变损失函数——根据自然图像的特征设计不同的损失函数提取更鲁棒的特征
<ul>
<li>Chen et al. [34]结合欧式和感知损失函数挖掘更多边缘信息</li>
</ul>
</li>
<li>提升CNN的深度或宽度
<ul>
<li>增加网络深度</li>
<li>增加网络宽度</li>
</ul>
</li>
<li>增加一些辅助插件
<ul>
<li>激活函数</li>
<li>扩张卷积</li>
<li>全连接层</li>
<li>池化</li>
</ul>
</li>
<li>引入跳连或者级联操作
<ul>
<li>skip connection</li>
<li>cascade operation</li>
</ul>
</li>
</ul>
<p>具体地说，</p>
<ol>
<li>第一种方法包括三种类型：一个样本的不同部分作为来自不同网络的多个输入；一个样本作为输入的不同视角，例如多尺度；以及CNN的不同频道作为输入。</li>
<li>第二种方法是根据自然图像的特点设计不同的损失函数，以提取更稳健的特征。例如，Chen等人联合EU-CLIEDINE函数和感知损失函数，挖掘更多的边缘信息，用于图像去噪。</li>
<li>第三种方法通过增加网络的深度或宽度来增大接收野的大小以提高去噪性能。</li>
<li>第四种方法利用插件，如激活函数、膨胀卷积、全连接层和合并操作来增强CNN的表达能力。</li>
<li>第五种方法利用跳跃连接或级联操作来为CNN中的深层提供补充信息。</li>
</ol>
<p>表1提供了用于AWNI去噪的CNN的概述。</p>
<p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_1.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h4 id="CNN-NN和常用特征提取的AWNI的去噪方法">CNN/NN和常用特征提取的AWNI的去噪方法</h4>
<p>特征提取在图像处理中用来表示整幅图像，对机器学习非常重要。然而，由于深度学习技术是黑盒技术，它们不允许选择特征，因此不能保证所获得的特征是最健壮的。受问题的启发，<strong>研究了将常用特征提取方法嵌入到神经网络中</strong>，以达到图像去噪的目的。他们这样做的原因有五个：</p>
<ol>
<li>弱边缘信息噪声图像</li>
<li>非线性噪声图像</li>
<li>高维噪声图像</li>
<li>不显著噪声图像，</li>
<li>较高的计算代价。</li>
</ol>
<ul>
<li>
<p>对于弱边缘信息噪声图像，关等人提出了基于变换域的CNN方法。然而，它们在消除噪音方面并不有效。具体地说，在文献<strong>Multi-level Wavelet-CNN for Image Restoration</strong>中，提出的方法使用小波方法和U-网来消除膨胀卷积的网格效应，以扩大图像恢复的接收范围。</p>
</li>
<li>
<p>对于非线性噪声图像，带有核方法的CNN被证明是有用的。这些方法主要包括三个步骤。第一步使用CNN进行特征提取。第二步利用核方法将得到的非线性特征转化为线性特征。第三步利用残差学习构造潜在的干净图像。</p>
</li>
<li>
<p>对于高维噪声图像，提出了CNN与降维相结合的方法。例如，Khaw等人采用基于主成分分析(PCA)的细胞神经网络(CNN)进行图像去噪。这包括三个步骤。第一步采用卷积运算提取特征。第二步利用主成分分析对所获得的特征进行降维。第三步采用卷积的方法对PCA得到的特征进行处理，重建出干净的图像。</p>
</li>
<li>
<p>对于噪声不明显的图像，信号处理可以指导CNN提取显著特征[94,103,174，2]。具体地说，跳过连接是信号处理的典型操作。</p>
</li>
<li>
<p>对于涉及高计算成本的任务，具有图像像素关系性质的CNN在降低复杂度方面非常有效。例如，Ahn等人采用具有非局部自相似性的细胞神经网络(CNN)对噪声进行过滤去噪，其中给定噪声图像的相似特征可以加快特征提取的速度，降低计算成本.</p>
</li>
</ul>
<p>关于这些方法的更多详细信息可以见表2。</p>
<p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_2.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h4 id="最优化方法与CNN-NN相结合的AWNI去噪">最优化方法与CNN/NN相结合的AWNI去噪</h4>
<p>机器学习使用优化技术和判别性学习方法来处理图像应用。虽然优化方法在不同的低层视觉任务上都有很好的性能，但是这些方法需要手动设置参数，非常耗时。判别性学习方法图像恢复速度快，但对低水平视觉任务不灵活。为了在效率和灵活性之间实现折衷，提出了一种基于判别学习优化的图像应用方法，如图像去噪。<strong>基于正则项损失函数的先验知识CNN是图像去噪中常用的方法，可分为提高去噪速度和改善去噪性能两大类。</strong></p>
<p>为了提高去噪速度，利用CNN的优化方法是快速找到图像去噪最优解的有效工具。例如，采用最大后验概率(MAP)方法的GaN被用来估计噪声和处理其他任务，如图像修复和超分辨率。基于经验的贪婪算法和使用CNN的迁移学习策略可以加速遗传算法以获得干净的图像。噪声图像和噪声级映射是CNN的输入，在预测噪声方面执行速度更快。</p>
<p>为提高去噪性能，采用神经网络(CNN)组合优化方法对含噪图像进行平滑处理。具有全变差去噪的CNN降低了噪声像素的影响。将分裂Bregman迭代算法与CNN相结合，可以通过图像深度对像素进行增强，得到一幅潜在的干净图像。具有特征匹配的两阶段CNN可以更好地恢复干净图像的细节信息，特别是噪声图像。采用最近邻算法的GAN在过滤干净图像中的噪声图像方面是有效的。一种组合的CNN使用波前编码通过变换域来增强潜在清洁图像的像素。文献显示了其他有效的去噪方法。表3显示了优化方法和CNN/NN在AWNI去噪中组合的详细信息。</p>
<p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_3.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h3 id="真实噪声图像去噪中的深度学习技术">真实噪声图像去噪中的深度学习技术</h3>
<p>用于图像去噪的深度学习技术主要有两种：单一的端到端CNN和先验知识与CNN的结合。</p>
<p>对于第一种方法，改变网络结构是从给定的真实损坏图像中去除噪声的有效方法。多尺度知识是图像去噪的有效方法。例如，由卷积、REU和RL组成的CNN采用不同的相位特征来增强微光图像去噪模型的表达能力。为了克服模糊和虚假的图像伪影，提出了一种具有跳跃连接的双U网用于CT图像重建。为了解决资源约束问题，等人提出了解决方案使用具有批量重整化、RL和膨胀卷积的双重CNN来处理真实的噪声图像。基于光图像的性质，两个CNN利用各向异性视差分析来生成真实噪声图像的结构视差信息。在弱光条件下使用CNN解析遥感和医学图像被证明是有效的。为了提取更详细的信息，循环连接被用来增强对真实世界中的损坏图像的表示能力。为了处理未知的噪声图像，利用残差结构来促进低频特征，然后可以应用注意机制从通道中提取更多潜在的特征。为了产生含噪图像，有一种技术使用模拟摄像管道来构建退化模型，以便过滤(Alipay)获得真实的含噪图像。为了解决含噪图像无配对的无噪声图像的问题，一种嵌入无监督学习方法到cnn中的方法在图像去噪上是有效的。自洽的GaN首先使用一个CNN来估计给定噪声图像的噪声作为一个标签，然后应用另一个CNN和所得到的标签来去除其他噪声图像的噪声。这一概念也已扩展到一般的CNN。Noise2InversemMethod使用CNN根据周围的噪音像素预测噪音像素的值。**合并到3D自监督网络中的注意机制可以提高从医学噪声图像中去除噪声的效率。**有关上述研究的更详细资料参见表4。</p>
<p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_4.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>将CNN和先验知识相结合的方法可以更好地处理真实噪声图像中的速度和复杂噪声任务。张等人提出了利用半二次分裂(HQS)和细胞神经网络(CNN)对给定的真实含噪图像进行噪声估计的方法。Guo等人提出了一种三阶段去噪方法。</p>
<ol>
<li>第一阶段使用高斯噪声和相机内处理流水线来合成噪声图像。将合成的噪声图像和真实的噪声图像进行融合，以更好地表示真实的噪声图像。</li>
<li>第二阶段采用具有非对称总变分损失的子网络来估计真实含噪图像的噪声。</li>
<li>第三阶段利用原始含噪图像，估计噪声，恢复潜在的干净图像。</li>
</ol>
<p>为了解决不成对噪声图像的问题，以半监督的方式发展了CNN和先验知识的组合。分层深层GaN(HD-GAN)首先使用聚类算法对每个患者的CT进行多类别分类，然后通过收集不同患者的同一类别的图像来构建数据集。最后，使用GaN对获得的数据集进行处理，以进行图像去噪和分类。类似的方法在3D映射中表现良好。</p>
<p>具有信道先验知识的CNN对于微光图像增强是有效的，表5显示了关于上述研究的详细信息。</p>
<p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_5.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h3 id="深度学习技术在盲降噪中的应用">深度学习技术在盲降噪中的应用</h3>
<p>在现实世界中，图像很容易被破坏，噪声也很复杂。因此，盲去噪技术非常重要。FFDNet使用噪声电平和噪声作为CNN的输入来训练未知噪声图像的去噪器。随后，提出了几种解决盲去噪问题的方法。Kenzo等人提出的一种成像器件机构。利用软性收缩调整噪声水平进行盲去噪。对于未配对的噪声图像，使用CNN估计噪声被证明是有效的。Yang等人使用已知的噪声水平训练去噪器，然后利用该去噪器来估计噪声水平。为了解决随机噪声衰减的问题，采用具有RL的细胞神经网络对过滤复合噪声进行处理。改变网络结构可以提高盲去噪的去噪性能。马琼达·埃塔尔提出对撞击未知噪声采用自动编码器。对于混合噪声，级联神经网络能有效去除加性高斯白噪声(AWGN)和脉冲噪声。表6显示了有关这些去噪方法的更多信息。</p>
<p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_6.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h3 id="混合噪声图像去噪的深度学习技术">混合噪声图像去噪的深度学习技术</h3>
<p>在现实世界中，捕获的图像会受到复杂环境的影响。受此启发，几位研究人员提出了混合噪声图像去噪技术。Li等人提出将CNN与翘曲导引相结合来解决噪声、模糊和JPEG压缩问题。张等人使用一种模型来处理噪声、模糊核和低分辨率图像等多种退化问题。为了增强原始传感器数据，Kokkinos等人提出了一种基于残差细胞神经网络的图像去马赛克和去噪迭代算法。为了处理任意模糊核，张等人提出采用级联去模糊和单幅图像超分辨率(SISR)网络来恢复即插即用超分辨率图像。表7给出了这些混合噪声图像去噪方法。</p>
<p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_7.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h4 id="突发噪声">突发噪声</h4>
<p>值得注意的是，图像携带的信息是有限的，这在实际应用中是不利的。为了解决这个问题，突发技术被开发出来。然而，爆裂受到噪声和相机抖动的影响，增加了实施实际任务的难度。最近，用于突发图像去噪的深度学习技术引起了人们的极大兴趣，即逐帧去除噪声。递归全卷积深度神经网络可以对任意长度序列中所有帧的噪声进行过滤去噪，将细胞神经网络与核方法相结合可以提高突发噪声图像的去噪性能。针对复杂背景噪声图像，提出了一种结合核和CNN的注意力机制来增强关键特征对突发图像去噪的效果，加快了训练速度。对于微光条件，使用CNN将给定的突发噪声图像映射到sRGB输出可以获得多帧去噪图像序列。为了降低网络复杂性，具有残差学习的CNN直接训练去噪模型，而不是显式的对齐过程。表8列出了这些突发去噪方法。</p>
<p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_8.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h4 id="视频噪声">视频噪声</h4>
<p>类似于突发图像，视频检测被分解到每一帧中。因此，加性白噪声图像去噪、实噪声图像去噪、盲去噪、混合噪声图像去噪等深入研究技术也适用于视频去噪。重现的神经网络利用端到端的CNN从被破坏的视频中去除噪声。为了提高视频去噪效果，降低视频冗余度是一种有效的方法。一种非局部拼接融合的CNN可以有效地抑制视频和图像去噪的噪声。在视频去噪中，CNN结合时间信息在性能和训练效率之间进行权衡。对于盲视频去噪，两级CNN被证明是一个很好的选择。第一阶段通过微调预先训练的AWGN去噪网络来训练视频去噪模型。第二阶段利用得到的视频去噪模型得到潜在的干净视频。这些视频去噪方法如表9所示。</p>
<p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_9.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h2 id="实验结果">实验结果</h2>
<h3 id="数据集">数据集</h3>
<h4 id="训练集">训练集</h4>
<p>训练集划分为两类：灰度噪声和彩色噪声图像。</p>
<p>灰度噪声图像数据集可用于训练高斯去噪器和盲去噪器。包括BSD400和Waterloo Exploration Database。BSD400由400张.png格式的图像组成，并裁剪到180*180用于训练一个去噪模型。Waterloo Exploration Database由4744个.png格式的自然图像组成。</p>
<p>彩色噪声图像包括BSD432，Waterloo Exploration Database和polyU-Real-World-Noisy-Images数据集。polyU-Real-World-Noisy-Images由100个真实噪声图像组成，尺寸2784*1856，由5个摄影机获得：Nikon D800，Canon 5D Mark Ⅱ，Sony A7 Ⅱ， Canon 80D和Canon 600D。</p>
<h4 id="测试集">测试集</h4>
<p>测试集包含灰度噪声和彩色噪声图像数据集。</p>
<p>灰度噪声数据集由Set12和BSD68组成。Set12包含12个场景。BSD68包含68个自然图像。它们用于测试高斯去噪器和盲噪声去噪器。</p>
<p>彩色噪声数据集包含CBSD68，Kodak24，McMaster，cc，DND，NC12，SIDD和Nam。Kodak24和McMaster分别包含24和18个彩色噪声图像。cc包含15个不同ISO（1600，3200，6400）的真实噪声图像。DND包含50个真实噪声图像，干净图像由低ISO捕获图像。NC12包含12个噪声图像并且没有groud-truth干净图像。SIDD包含来自智能手机的真实噪声图像，由320个噪声、ground-truch图像对构成。Nam包含11个场景，以JPEG格式保存。</p>
<h3 id="实验结果-2">实验结果</h3>
<p>为了验证一些方法的去噪表现，在Set12, BSD68, CBSD68, Kodak24, McMaster, DND, SIDD, Nam, cc和NC12数据集上进行了定量定性评估。定量评估主要使用不同去噪器的PSNR值来测试去噪效果。此外，我们利用去噪一张图像的时间来支持PSNR的定量评估。定性评估采用直观的图形表示恢复后的干净图像。</p>
<h4 id="加性白噪声图像去噪的深度学习技巧">加性白噪声图像去噪的深度学习技巧</h4>
<p>去噪方法的对比应该考虑加性白噪声，包括：高斯、泊松、微光噪声和盐、胡椒噪声，所有这些的噪声水平都有很大的不同。另外，很多方法使用不同的工具，对去噪结果影响很大。基于这些原因，选择<strong>典型高斯噪声</strong>来测试去噪表现。此外，大多数方法使用PSNR作为定量指标。所以，使用 BSD68, Set12, CBSD68, Kodak24和McMaster数据集来测试对于加性白噪声深度学习技巧的去噪表现。</p>
<p>【具有不同噪声水平的不同网络用于灰度加法白噪声图像去噪的PSNR值。ELDRN[165]表现最好】</p>
<p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_17_Table_10.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>【为理解不同方法的去噪表现，使用FSIM（feature similarity index，特征相似性指数）作为视觉质量指标来进行在BSD68上不同噪声水平的实验】</p>
<p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_17_Table_11.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>【为测试不同网络处理单个灰度加性白噪声图像的能力，在Set12上进行实验】</p>
<p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_19_Table_12.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>【不同去噪方法对彩色加性白噪声图像的去噪表现】</p>
<p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_20_Table_13.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>【不同方法图像去噪的效率】</p>
<p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_20_Table_14.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>对于定性分析，对不同方法放大潜在干净图像的一个区域。观察得越清晰，说明去噪效果越好。</p>
<h4 id="真实噪声图像去噪的深度学习技巧">真实噪声图像去噪的深度学习技巧</h4>
<p>基于DND,SIDD,Nam,CC数据集。不使用NC12数据集的原因是NC12的ground-truth干净图像不可获得。</p>
<p>为了帮助更好理解这些方法，增加了一些传统去噪方法，比如BM3D作为比较方法。</p>
<p>从表15、16可看出，<strong>DRDN在DND和SSID上对真实噪声去噪获得了最好结果。</strong></p>
<p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_23_Table_15.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_24_Table_16.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>从表17看出，<strong>对于压缩噪声图像，AGAN获得了很好的表现。</strong></p>
<p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_24_Table_17.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>从表18看出，<strong>对于不同ISO值的真实噪声图像，SDNet和BRDNet获得了最佳和此佳去噪表现。</strong></p>
<p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_18.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h4 id="盲去噪的深度学习技巧">盲去噪的深度学习技巧</h4>
<p>众所周知，噪声在现实世界中是复杂的，不受规则的约束。这就是为什么盲去噪技术，特别是深度学习技术被开发出来的原因。比较不同深度学习技术的去噪性能是非常有用的。</p>
<p>实验采用DnCNN、FFDNet、Adnet、SCNN和G2G1等先进的去噪方法在BSD68和Set12上进行实验设计。</p>
<p><strong>FFDNet和Adnet在盲去噪方面优于其他方法</strong>，分别如表19和表20所示。</p>
<p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_24_Table_19.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_25_Table_20.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h4 id="混合噪声去噪的深度学习技巧">混合噪声去噪的深度学习技巧</h4>
<p>在现实世界中，损坏的图像可能包含不同种类的噪声，这使得恢复潜在的干净图像非常困难。为了解决这个问题，人们提出了基于深度学习技术的多退化思想。如表21所示，<strong>WarpNet与其他流行方法对比（如DnCNN和MemNet），有很强的竞争力。</strong></p>
<p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_25_Table_21.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h2 id="Discussion">Discussion</h2>
<p>指出未来研究的潜在区域和一些目前未解决的问题。</p>
<p>基于深度学习技术的图像去噪主要是为了<strong>提高去噪性能和效率，完成复杂的去噪任务</strong>。</p>
<p>改善去噪<strong>性能</strong>的解决方案包括以下几个方面：</p>
<ol>
<li><strong>增大感受野</strong>可以捕获更多上下文信息。增大感受野可以通过扩大网络深度和宽度完成。但这会导致高计算代价和更多内存消耗。一个解决方法是<strong>膨胀卷积</strong>，不仅可以获得更好的表现和效率，还可以有效地挖掘更多边缘信息。</li>
<li>使用CNN的同时还<strong>使用额外信息（也称先验知识）<strong>是便于获取更精确特征的有效方法。通过</strong>设计损失函数</strong>实现。</li>
<li><strong>结合局部和全局信息</strong>可以增强深层对浅层的记忆能力，从而更好地对抗噪声。两个解决方法是<strong>残差操作和递归操作</strong>。</li>
<li>可以使用<strong>单一的处理方法</strong>来抑制噪声。将单一的加工技术融合到深度CNN中，可以获得优异的性能。<strong>例如，小波技术</strong>被聚集到U-Net中来处理图像恢复[137]。</li>
<li><strong>数据增强</strong>，如水平翻转、垂直翻转和颜色抖动，可以帮助去噪方法学习更多类型的噪声，从而增强去噪模型的表达能力。另外，利用GAN构造虚拟噪声图像也有利于图像去噪。</li>
<li><strong>迁移学习、图搜索和神经结构搜索</strong>等方法可以获得较好的去噪效果。</li>
<li><strong>改进硬件或摄像机制</strong>可以降低噪声对采集图像的影响。</li>
</ol>
<p><strong>压缩深度神经网络</strong>在提高去噪<strong>效率</strong>方面取得了很大的成功。<strong>减小深层神经网络的深度或宽度</strong>可以降低这些网络在图像去噪中的复杂度。此外，使用<strong>小卷积核和分组卷积</strong>可以减少参数的数量，从而加快训练速度。<strong>与降维方法的融合</strong>，比如CNN与PCA的结合，也可以提高去噪效率。</p>
<p>对于<strong>复杂的含噪图像</strong>，<strong>分步处理</strong>是一种非常流行的方法。例如，使用两步机制是处理低分辨率噪声图像的一种方式，第一步涉及由CNN恢复高分辨率图像。第二步，用另一个新的CNN过滤来消除高分辨率图像的噪声。在上面的示例中，两个CNN通过级联操作实现。这种两步机制是<strong>无监督噪声任务</strong>的理想选择，例如真实噪声图像和盲去噪。也就是说，第一步依赖于具有优化算法的CNN，即最大后验，以估计噪声为地面事实(称为标签)。第二步，利用另一种CNN，获得地面真实情况，训练去噪模型，用于真噪声图像去噪或盲去噪；第二步，利用另一种CNN，训练去噪模型，用于真噪声图像去噪或盲去噪。<strong>融合到CNN中的自监督学习</strong>是<strong>真实噪声图像去噪或盲去噪</strong>的一个很好的选择。</p>
<p>虽然深度学习技术在这三种场景中都取得了很大的成功，但在图像去噪领域仍然存在<strong>挑战</strong>。这些措施包括：</p>
<ol>
<li>更深的网络需要<strong>更多的内存</strong>资源</li>
<li><strong>训练更深的去噪网络</strong>对于真实噪声图像、无配对的噪声图像、多降质任务<strong>不是一个稳定的解决方法</strong></li>
<li>真实噪声图像不是容易捕捉的，<strong>训练样本不足</strong></li>
<li>深度CNNs<strong>很难解决无监督</strong>去噪任务</li>
<li>需要<strong>更精确的</strong>去噪任务<strong>指标</strong>，PSNR、SSIM是流行的图像恢复指标。<strong>峰值信噪比(PSNR)存在过度平滑的问题，很难识别难以区分的图像。SSIM依赖于亮度、对比度和结构，因此不能准确地评价图像的感知质量。</strong></li>
</ol>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E6%96%87%E7%8C%AE/">文献</a>
                    
                      <a class="hover-with-bg" href="/categories/%E6%96%87%E7%8C%AE/%E7%BB%BC%E8%BF%B0/">综述</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E6%96%87%E7%8C%AE/">文献</a>
                    
                      <a class="hover-with-bg" href="/tags/%E7%BB%BC%E8%BF%B0/">综述</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/03/02/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer55-2/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">剑指offer55-2 平衡二叉树</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/02/25/%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3/buildnet-runerror1/">
                        <span class="hidden-mobile">RuntimeError--expected dtype Double but got dtype Float</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments" lazyload>
                
                  
                
                
  <div class="disqus" style="width:100%">
    <div id="disqus_thread"></div>
    
      <script type="text/javascript">
        var disqus_config = function() {
          this.page.url = 'https://fanmeilin.github.io/2022/03/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E7%BB%BC%E8%BF%B0/%E8%87%AA%E7%84%B6%E5%9B%BE%E5%83%8F%E5%8E%BB%E5%99%AA%E7%BB%BC%E8%BF%B0/';
          this.page.identifier = '/2022/03/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E7%BB%BC%E8%BF%B0/%E8%87%AA%E7%84%B6%E5%9B%BE%E5%83%8F%E5%8E%BB%E5%99%AA%E7%BB%BC%E8%BF%B0/';
        };
        Fluid.utils.loadComments('#disqus_thread', function() {
          var d = document, s = d.createElement('script');
          s.src = '//' + 'fluid' + '.disqus.com/embed.js';
          s.setAttribute('data-timestamp', new Date());
          (d.head || d.body).appendChild(s);
        });
      </script>
    
    <noscript>Please enable JavaScript to view the comments</noscript>
  </div>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header vvd_contents"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>
  <div class="statistics">
    <a target="_blank" rel="noopener" href="https://developer.hitokoto.cn/" id="hitokoto_text"><span style="color: #DDD;"  id="hitokoto"></span></a>
 <script src="https://v1.hitokoto.cn/?encode=js&select=%23hitokoto" defer></script>
  </div>


  
  <!-- 备案信息 -->
  <div class="beian">
    <span>
      <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
        鄂ICP备2021014492号-1
      </a>
    </span>
    
  </div>


  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js" ></script>



  <script  src="/js/local-search.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js" ></script>

  





  <script  src="https://cdn.jsdelivr.net/npm/mermaid@8.10.1/dist/mermaid.min.js" ></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({"theme":"default"});
    }
  </script>




  

  

  

  

  

  





<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"left","width":260,"height":480},"mobile":{"show":false},"react":{"opacity":0.9}});</script></body>
</html>
