

<!DOCTYPE html>

<html lang="zh-CN" data-default-color-scheme=auto>
<script type="text/javascript" src="/js/jquery.js"></script>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#d8afe4">
  <meta name="description" content="与灵魂共舞">
  <meta name="author" content="Meilin Fan">
  <meta name="keywords" content="个人博客,学习,生活">
  
  <title>A Multi-Task Mean Teacher for Semi-Supervised Shadow Detection - 待时</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"fanmeilin.github.io","root":"/","version":"1.8.11","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>


<body>	
	<div>
		<div class='real_mask'></div>
		<div id="banner_video_insert">
		</div>	
		<div id='vvd_banner_img'>
		</div>
	</div>
	<div id="banner"></div>
    
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>与灵魂共舞</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

	
	<!-- <div class="banner" id="banner" parallax=true
		style="background: url('https://picture.mulindya.com/03990bbe091d5cca73421ac40bacfc46_1.jpg') no-repeat center center;
		background-size: cover;"> -->
        <div class="banner" id='banner' >
		<div class="full-bg-img" >
		
			
				<script>
					var ua = navigator.userAgent;
					var ipad = ua.match(/(iPad).*OS\s([\d_]+)/),
						isIphone = !ipad && ua.match(/(iPhone\sOS)\s([\d_]+)/),
						isAndroid = ua.match(/(Android)\s+([\d.]+)/),
						isMobile = isIphone || isAndroid;

					function set_video_attr(id){

						var height = document.body.clientHeight
						var width = document.body.clientWidth
						var video_item = document.getElementById(id);

						if (height / width < 0.56){
							video_item.setAttribute('width', '100%');
							video_item.setAttribute('height', 'auto');
						} else {
							video_item.setAttribute('height', '100%');
							video_item.setAttribute('width', 'auto');
						}
					}

					$.getJSON('/js/video_url.json', function(data){
						if (!isMobile){
							var video_list_length = data.length
							var seed = Math.random()
							index = Math.floor(seed * video_list_length)
							
							video_url = data[index][0]
							pre_show_image_url = data[index][1]
							
							banner_obj = document.getElementById("banner")
							banner_obj.style.cssText = "background: url('" + pre_show_image_url + "') no-repeat; background-size: cover;"

							vvd_banner_obj = document.getElementById("vvd_banner_img")

							vvd_banner_content = "<img id='banner_img_item' src='" + pre_show_image_url + "' style='height: 100%; position: fixed; z-index: -999'>"
							vvd_banner_obj.innerHTML = vvd_banner_content

							video_html_res = "<video id='video_item' style='position: fixed; z-index: -888;'  muted='muted' src=" + video_url + " autoplay='autoplay' loop='loop'></video>"
							document.getElementById("banner_video_insert").innerHTML = video_html_res;

							set_video_attr('video_item')
							set_video_attr('banner_img_item')
						}
					});

					if (!isMobile){
						window.onresize = function(){
							set_video_attr('video_item')
							}
						}
				</script>
			

			<!-- <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)"> -->
            <div class="mask flex-center">
			  <div class="page-header text-center fade-in-up">
				<span class="h2" id="subtitle" title="A Multi-Task Mean Teacher for Semi-Supervised Shadow Detection">
				  
				</span>

				
				  <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-03-18 14:59" pubdate>
        2022年3月18日 下午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      8.2k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      91
       分钟
    </span>
  

  
  
</div>

				
			  </div>

			  
			</div>
		</div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">A Multi-Task Mean Teacher for Semi-Supervised Shadow Detection</h1>
            
            <div class="markdown-body">
              <blockquote>
<p><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?noteId=660745891978698752&amp;pdfId=660745407483162624">https://readpaper.com/pdf-annotate/note?noteId=660745891978698752&amp;pdfId=660745407483162624</a></p>
</blockquote>
<h1>A Multi-Task Mean Teacher for Semi-Supervised Shadow Detection 🎍</h1>
<h2 id="0-Abstract-🎒">0. Abstract 🎒</h2>
<p>现有的阴影检测方法在依赖有限的标记数据集方面存在固有的局限性，在一些复杂的场地上可能会产生较差的结果。为了提高阴影检测的性能，利用未标记的数据，探索并学习阴影的多个信息，提出了一种半监督阴影检测的多任务mean teacher模型。具体地说，我们首先构建了一个多任务基线模型，通过利用阴影区域、阴影边缘和阴影计数的互补信息来同时检测阴影区域、阴影边缘和阴影计数，并将该基线模型分配给学生和教师网络。然后，我们将来自学生和教师网络的三个任务的预测保持一致，以计算未标记数据的一致性损失，然后将其添加到多任务基线模型预测的标记数据的有监督损失中。在三个广泛使用的基准数据集上的实验结果表明，我们的方法的性能一致优于所有比较的最先进的方法，这验证了所提出的网络可以有效地利用额外的未标记数据来提高阴影检测的性能。</p>
<h3 id="提炼内容">提炼内容</h3>
<h4 id="问题">问题</h4>
<p>现有的阴影检测方法在依赖有限的标记数据集方面存在固有的局限性，在一些复杂的场地上可能会产生较差的结果。</p>
<h4 id="方法">方法</h4>
<p>​	为了提高阴影检测的性能，利用未标记的数据，探索并学习阴影的多个信息，提出了一种半监督阴影检测的多任务mean teacher模型。</p>
<p>​	具体地说，我们首先构建了一个多任务基线模型，通过利用阴影区域、阴影边缘和阴影计数的互补信息来同时检测阴影区域、阴影边缘和阴影计数，并将该基线模型分配给学生和教师网络。然后，我们将来自学生和教师网络的三个任务的预测保持一致，以计算未标记数据的一致性损失，然后将其添加到多任务基线模型预测的标记数据的有监督损失中。</p>
<h4 id="结果">结果</h4>
<p>​	在三个广泛使用的基准数据集上的实验结果表明，我们的方法的性能一致优于所有比较的最先进的方法，这验证了所提出的网络可以有效地利用额外的未标记数据来提高阴影检测的性能。</p>
<h2 id="5-Conclusion-🎃">5. Conclusion 🎃</h2>
<p>本文通过开发一个多任务的mean teacher框架，提出了一种新的单幅图像阴影检测网络。我们的主要思想是首先建立一个多任务网络，利用它们的<strong>互补信息同时预测阴影区域检测、阴影边缘检测和阴影计数估计</strong>，然后利用mean teacher<strong>半监督学习</strong>来利用额外的未标记数据来进一步提高检测性能。在三个基准数据集上的实验结果表明，我们的网络的性能一直远远优于最先进的方法。与其他工作[43，41，12]一样，我们的方法可能不能很好地处理具有多个复杂阴影的图像。重新解决这一具有挑战性的问题被认为是我们今后工作的方向。</p>
<h4 id="未解决的问题">未解决的问题</h4>
<p>与其他工作[43，41，12]一样，我们的方法可能不能很好地处理具有多个复杂阴影的图像。重新解决这一具有挑战性的问题被认为是我们今后工作的方向。</p>
<h2 id="1-Introduce-➿">1. Introduce ➿</h2>
<p>作为日常生活中的一种普遍现象，自然图像中的阴影对提取场景几何[29，17]、光线方向[22]、摄像机位置及其参数[16]有一定的提示作用，有利于图像分割[4]、目标检测[2]、目标跟踪[27]等不同的高层图像理解任务。对于这些应用，我们需要高精度地检测图像中的阴影。</p>
<p>现有的方法通过开发颜色和光照的物理模型来检测阴影[6，5],通过人工提取特征或者从卷积神经网络提取特征来驱动数据。虽然目前的方法已经在基准数据集[33，42，35，10]上取得了很高的准确率，但是它们几乎需要足够的标注数据来进行训练，而且这样的训练数据通常是在有限的场景中捕获的，然而，为不同的场景创建大的标注数据集是昂贵和耗时的。Le等人[24]提出通过弱化原始训练图像的阴影区域来增强训练图像，但是我们注意到这些增强后的图像往往是假的，并且它们的非阴影背景与原始训练图像的背景相似，从而阻碍了泛化能力。与已有的数据集相比，在实际应用中，我们可以很容易地收集到丰富的未标记阴影图像。因此，当使用有限的标记数据进行训练时，利用额外的未标记数据来提高阴影检测性能是非常必要的。</p>
<p><img src="https://picture.mulindya.com/Apaper_collect/Mean_Teacher_fig1.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>另一方面，在测试各种自然图像的现有方法时，我们发现他们可能会忽略小的阴影块，将暗区误认为阴影，由于边界较弱而漏掉了不明显或柔和的阴影。这些情况会导致阴影边界较差，并可能改变阴影区域的数量。受多任务学习在许多计算机视觉应用中的成功应用[14，3，18，26]的启发，我们决定在工作中研究阴影区域、阴影边缘和阴影计数的互补信息，以增强从全局和细节两个角度的阴影区域检测。具体地说，阴影计数检测对阴影区域的总数设置全局约束，而阴影边缘检测对阴影区域的边界设置细节级别的约束。</p>
<p>在这方面，我们开发了一个多任务均值教师框架(MTMT-Net)来提高阴影检测的性能。我们首先设计了一个多任务CNN，**用于相互学习三个任务(即阴影区域检测、阴影边缘检测和阴影计数检测)**记为MT-CNN，并将该MT-CNN模型作为学生网络和教师网络。然后，我们提出了一种标签数据的监督多任务损失函数，以整合所有三个任务上的监督损失。之后，我们强制学生网络和教师网络的三个任务的结果分别在所有未标记的数据上保持一致。<strong>通过加入改进的MT-CNN的监督损失和三个任务的一致性损失来训练模型</strong>，我们的网络可以比现有的方法更准确地检测出阴影区域。我们的主要工作概括如下：</p>
<ol>
<li>首先，我们开发了一种用于阴影检测的多任务CNN(MT-CNN)，通过从单输入图像中同时检测阴影区域、阴影边缘和阴影计数。MT-CNN对已标注数据的阴影检测效果要好于单一的阴影检测任务。</li>
<li>其次，我们提出设计一个多任务均值教师框架来<strong>融合来自三个预测任务的未标记数据的一致性损失，以进行阴影检测</strong>。作为一种自集成模型，我们的框架有可能用于开发其他视觉任务的半监督框架，包括显著性检测、边界检测和语义分割。</li>
<li>最后，在三个广泛使用的基准数据集上，我们证明了所提出的网络比最先进的方法有很大的差距。</li>
</ol>
<h2 id="2-Related-Work-🔓">2. Related Work 🔓</h2>
<h4 id="传统的方法">传统的方法</h4>
<p>早期的尝试[6，5，32]利用照明模型和颜色信息来识别阴影区域，并且它们中的大多数只在高质量和良好约束的图像上工作得很好[28，41]。后来的数据驱动策略在标注数据上设计了特定的手工特征[42，23，7，13，34]，并将这些特征提供给不同的分类器[42，23，7，13，34]进行阴影检测，虽然提高了准确率，但在手工特征不足以区分阴影区域的复杂情况下，这些策略通常会出现性能下降的问题。</p>
<h4 id="基于深度学习的方法">基于深度学习的方法</h4>
<p>受深度学习在各种视觉任务中取得的显著进展的启发，基于卷积神经网络(CNN)的阴影检测方法被发展为从标记数据集中学习深度阴影干扰特征的方法。Khan等人。[19]通过构建7层CNN，形成了第一个对图像像素进行阴影/非阴影分类的网络，它首先从超像素级别提取深度特征，然后将特征喂到条件随机场模型（CRF）来平滑阴影检测结果。icente等人学习图像级阴影先验知识，并将其与局部图像块相结合，训练基于patch的CNN生成阴影模板。然后，一个基于生成性对抗网络的阴影检测器，称为scGAN[28]，通过在输入图像上形成一个条件生成器来预测阴影映射。[8]中的一种快速深阴影检测网络从手工制作的特征中获得阴影先验图，应用patch级CNN预测面片的阴影掩模，并结合多尺度面片的结果来预测整个阴影图。</p>
<p>最近，胡等人提出了一个新的观点。[12]通过学习方向感知的空间上下文特征检测出阴影像素。朱埃塔尔[43]设计了一种循环注意残差(RAR)模型，将相邻两个CNN层的上下文进行合并，并构造了两系列RAR模块来迭代整合CNN层上的空间上下文。勒埃塔尔[24]将生成辅助训练示例的阴影检测网络(D-NET)与阴影衰减网络(A-NET)相结合。Wang等人[37]堆叠多个并行融合分支，在深度监督框架中融合全局语义线索和局部空间细节。郑某等人[41]提出了一种分心感知阴影(DS)模型来预测假阳性和假阴性像素，并将获得的分心特征在每一层CNN中进行融合以进行阴影检测。</p>
<h5 id="缺点">缺点</h5>
<p>现有的阴影检测方法虽然改进了阴影检测条，但存在训练检测网络需要大量像素级标注数据的固有局限性。虽然Adnet[24]通过削弱阴影区域来增强来自单个阴影图像的训练图像，但是增强的图像往往是假的，背景与原始训练图像非常相似，导致泛化能力有限。在本文中，我们利用未标记的数据来辅助阴影检测。为此，我们将多任务学习嵌入到自集成框架中，以增强阴影检测任务的一致性损失。结果表明，我们的方法比后面实验部分详细描述的最先进的阴影检测器性能更好。</p>
<h2 id="3-Methodology-🔎">3. Methodology 🔎</h2>
<p><img src="https://picture.mulindya.com/Apaper_collect/Mean_Teacher_fig2.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>图2显示了所提出的MTMT-Net的工作流程，该MTMT-Net通过使用mean teacher半监督学习来整合标记数据和未标记数据。具体地说，通过考虑阴影区域检测、阴影边缘检测和阴影计数检测三个任务，提出了一种多任务卷积神经网络(MT-CNN)。</p>
<p><strong>MT-CNN既用于学生网络，也用于教师网络。</strong></p>
<ul>
<li>
<p>在训练过程中，将标注后的数据送入学生网络，通过融合三个任务损失计算出一个多任务监督损失。</p>
</li>
<li>
<p>对于未标记的数据，我们从输入的图像中生成一个辅助阴影图，并将其分别馈送到学生网络和教师网络。</p>
</li>
<li>
<p>对两组预测阴影信息进行多任务一致性损失计算，在测试阶段只利用<strong>学生网络</strong>对输入图像进行阴影图预测。</p>
</li>
</ul>
<h3 id="3-1-Multi-task-Convolutional-Neural-Network-MT-CNN">3.1 Multi-task Convolutional Neural Network(MT-CNN)</h3>
<p>现有的阴影检测方法虽然取得了显著的效果，但由于边界较弱，在检测软阴影时存在性能下降的问题。他们也往往会忽略小的阴影区域或者将暗处的非阴影区域错认为阴影区域，从而会改变检测到的阴影区域的技术。为了解决这些问题，我们认为明确考虑阴影边缘和阴影计数有助于提高阴影区域检测的定位精度和分割质量。在本文中，我们提出了一个多任务CNN(MT-CNN)，它以端到端的方式对单个网络中的阴影边缘、阴影计数和阴影区域信息进行建模和融合，如图3所示。</p>
<p><img src="https://picture.mulindya.com/Apaper_collect/Mean_Teacher_fig3.png" srcset="/img/loading.gif" lazyload alt=""></p>
<h4 id="3-1-1-Shadow-Region-Detection">3.1.1 Shadow Region Detection</h4>
<p>给定一幅输入的阴影图像，我们首先使用卷积神经网络(在我们的实验中是ResNeXt-101[38])来<strong>产生一组不同尺度的特征映射</strong>(表示为EF1、EF2、EF3、EF4和EF5)(见图3)。</p>
<p>注意到阴影检测在不同的CNN层之间有互补的信息，在浅层的CNN层捕捉阴影细节和非阴影细节，在深层的CNN忽略大部分非阴影像素也会遗漏部分阴影区域。这里，我们使用short connections[9]来合并最后四个CNN层的特征映射，得到四个新的特征映射(表示为DF2、DF3、DF4和DF5)。具体的说，合并后的feature map的第k层CNN层$DF_k$：</p>

$$
DF_k = Conv(concat(EF_k,...,EF_5)) \quad \quad (1)
$$

<p>然后，我们将最浅的特征（EF1）和最深的特征（EF5）合并，已生成一个新的特征图标记为DF1用于预测阴影边缘。</p>
<p>之后<strong>为了继承阴影边缘和阴影区域信息</strong>，我们首先将它们向上采样到DF1的空间然后逐个元素的添加DF1,提炼feature map表示为{$RF_k,k=2,…,5$},定义为：</p>

$$
RF_k= up(DF_k) + DF_1 \quad \quad (2)
$$

<p>最后，我们预测了来自DF2、DF3、DF4和DF5的4个阴影区map（来自RF2、RF3、RF4和RF5的4个阴影区map）以及由精化的特征映射(图3中记为$S_f$)，该阴影映射是通过逐个元素地相加而产生的。</p>

$$
S_f = Pred(\sum _{k=2}^5 RF_k) \quad \quad (3)
$$

<p>预测Pred($\cdot$)是通过在特征上使用3×3卷积层、1×1卷积层和Sigmoid激活层[43]来实现的。</p>
<h4 id="3-1-2-Shadow-Edge-Detection">3.1.2 Shadow Edge Detection</h4>
<p>通过观察阴影图像，我们注意到对于软阴影，边界可能无法和周围的非阴影区域区分开。这促使我们利用边缘知识来提高检测性能，最近的显著性检测器也证明了边缘知识有助于提高显著性检测的质量。</p>
<p>在MT-CNN中，我们将CNN的低层特征$EF_1$和最深CNN层的高层特征$EF_5$进行融合，生成特征图$DF_1$，然后用它来预测阴影边缘图。虽然低层特征$EF_1$捕获了足够的阴影边缘信息，但仅使用$EF_1$检测阴影边缘是不够的，因为EF1还编码了许多非阴影背景细节。另一方面，深层特征$EF_5$具有最大的感受野，可以有效地抑制非阴影像素。具体地说，$DF_1$是通过对$EF_1$和$EF_5$进行逐个元素的相加来计算的。</p>
<h4 id="3-1-3-Shadow-Count-Detection">3.1.3 Shadow Count Detection</h4>
<p>通过分析现有阴影检测方法的检测结果，我们发现了三种常见的失败情况：</p>
<ul>
<li>
<p>丢失小的阴影区域；</p>
</li>
<li>
<p>误识别非阴影区域；</p>
</li>
<li>
<p>误检测附近的阴影区域。</p>
</li>
</ul>
<p>这些情况都会导致不准确的阴影区域数。因此，为了提高阴影检测的性能，我们探索了阴影区域的数量。</p>
<p>**检测阴影区域数目需要对整个图像进行全局理解。**如图3所示，我们依靠CNN最深层的$EF_5$进行检测。具体地说，我们应用单个全连通的层$EF_5$来获得表示阴影计数的Score(A)。由于阴影区域的数量可能非常大，为了使计算可行，我们设置了最大约束$N_max$，并经验地计算了标量A作为回归问题：<br>
$$<br>
A = \frac{min(N_{actual},N_{max})}{N_{max}} \quad \quad (4)<br>
$$<br>
这里的$N_{adtual}$表示阴影区域的实际数目，$N_{max}$经验取值为8。也就是最大的区域数目限制在8以下。</p>
<h3 id="3-2-标签数据的多任务监督损失">3.2 标签数据的多任务监督损失</h3>
<p>对于带标签的数据，我们可以有一对数据（输入的图像和对应的掩膜）；因此我们将带标签掩膜数据作为阴影检测（$G_r$）的ground-truth。同时，我们将Canny算子（边缘检测算子）应用于标签掩膜生成对应的边缘图作为阴影边缘检测的ground-true（$G_e$）。我们进一步观察每一个标注图像，手动计算阴影区域的数目。这个是阴影计数的基础（$G_c$）。</p>
<p>在得到ground-truth之后，多任务监督损失（表示为$\mathcal{L}<sup>s$）是将阴影区域检测损失（$\mathcal{L}</sup>s_r$）阴影边缘检测损失（$\mathcal{L}<sup>s_e$）和阴影计数损失（$\mathcal{L}</sup>s_c$）三者相加得到:</p>

$$
\mathcal{L}^s(x) = \mathcal{L}^s_r+\alpha \mathcal{L}^s_e + \beta \mathcal{L}^s_c \quad \quad (5)
$$

<p>这里的</p>

$$
\begin{equation}
\begin{aligned}
\mathcal{L}^s_r &amp; = \sum_{j=1} ^9 \Phi_{BCE}(P_r(j),G_r) ,\\
\mathcal{L}^s_e &amp; = \Phi_{BCE}(P_e,G_e) , \quad \quad \quad \quad (6) \\
\mathcal{L}^s_c &amp; = \Phi_{BCE}(P_c,G_c) \\
\end{aligned}
\end{equation}
$$

<p><strong>MSE 模型的预测值与标签的L2距离。</strong></p>
<p><strong>BCE <a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E4%BA%A4%E5%8F%89%E7%86%B5&amp;spm=1001.2101.3001.7020">交叉熵</a>损失函数，衡量两个分布之间的差异，一般用于分类问题。</strong></p>
<p>这里，$P_r(j)$表示九个预测阴影图中的一个，$P_e$是预测阴影边缘图，$P_c$是预测阴影计数值。$\Phi_{BCE}$和$\Phi_{MSE}$分别是二元交叉熵损失函数和MAE损失函数。我们在网络训练中经验地设置了权值$\alpha=10$和$\beta=1$。</p>
<h3 id="3-3-无标签数据的多任务一致性损失">3.3 无标签数据的多任务一致性损失</h3>
<p>对于未标注数据，我们将其输入到学生和教师网络以获得三个任务的结果，即九个阴影区域图（表示未$S_{r_1}$和 $S_{r_9}$），阴影边缘图（表示未$S_e$）和阴影计数（表示为$S_c$）Score，<strong>然后我们强制使得来自学生网络和教师网络的三个任务预测一致</strong>，从而多任务一致性损失为$L^c$:</p>

$$
\mathcal L^c(y) = \mathcal L^c_r + \mathcal L^c_e  + \mathcal L^c_c \quad \quad \quad \quad (7)
$$

<p>这里的</p>

$$
\begin{equation}
\begin{aligned}
\mathcal L^c_r &amp;= \sum^9_{j=1} \Phi_{MSE}(S_{r_j},T_{r_j}),\\
\mathcal L^c_e &amp;= \Phi_{MSE}(S_e,T_e), \quad \quad \quad \quad (8) \\
\mathcal L^c_c &amp;= \Phi_{MSE}(S_c,T_c)
\end{aligned}
\end{equation}
$$

<p>这里的$\mathcal L^c_r,\mathcal L^c_e,\mathcal L^c_c$分别表示阴影区域，阴影边界，阴影计数的一致性损失。</p>
<h3 id="3-4-Our-Network">3.4 Our Network</h3>
<p>我们将半监督自集成模型的多任务学习应用于阴影检测，网络的总损失为：</p>

$$
\mathcal L_{total} = \sum^N_{i=1} \mathcal L^s(x_i) + \lambda \sum_{j=1}^M \mathcal L^c(y_j) \quad \quad \quad \quad (9)
$$

<p>这里的N表示训练集中标签数据图像的数量，M表示未标记数据的数量。$\mathcal L^s(x_i)$表示对于第i个标记图像的多任务监督损失函数（公式5），$\mathcal L^c(y_j)$表示用于第j个未标记图像多任务一致性损失(公式7）。$\lambda$用于平衡<strong>标记数据</strong>上的<strong>多任务监督损失</strong>和<strong>未标记</strong>数据上的多任务<strong>一致性损失</strong>。</p>
<p>通过使用以来时间的高斯预热函数来更新$\lambda$:$\lambda(t) = \lambda_{max}e^{-5(1- \frac {t}{t_{max}})^2}$,这里的t表示当前的训练迭代，$t_{max}$表示训练的最大迭代次数。在我们的实验中，经验设置$\lambda _{max} = 10$。</p>
<p>我们最小化$\mathcal L_{total}$来训练学生网络，通过指数移动平均（EMA）策略来更新每个训练迭代中的教师网络参数，在第t轮训练教师网络参数表示：</p>

$$
\theta ^{\prime}_t = \eta \theta ^{\prime}_{t-1} + (1-\eta)\theta ^{\prime}_t \quad \quad \quad \quad (10)
$$

<p>这里的$\theta _t$表示在第t轮训练的学生网络参数，如文献[21,31]建议的EMA衰减因子$\eta$经验设置未0.99。</p>
<h4 id="我们的未标记数据">我们的未标记数据</h4>
<p>在我们的工作中，未标记的数据有3424张带阴影的图像。它由两部分组成：一部分是来自最近的阴影去除工作的USR数据集[11]，另一部分是我们从互联网上收集的979张图像。USR数据集[11]具有2445个没有阴影检测注释的阴影图像。</p>
<h3 id="3-5-训练和测试策略">3.5 训练和测试策略</h3>
<h4 id="训练参数">训练参数</h4>
<p>为了加快训练过程，降低过拟合风险，**我们使用ResNeXt[38]初始化MT-CNN(学生网络)的参数，ResNeXt[38]已经针对ImageNet上的图像分类任务进行了很好的训练。**MT-CNN中的其他参数被初始化为随机值。采用动量为0.9%、权值为0.0005的随机梯度下降法（SGD）对整个网络进行1万次迭代优化。学习率由（Poly Strategy）多策略调整[25]，初始学习率为0.005，幂为0.9%。我们将所有已标记和未标记图像的大小调整为<code>416×416</code>，用于在单个GTX2080Ti GPU上训练网络，并通过随机水平翻转来扩大训练集。我们使用的最小批次大小为6，它由4个标记图像和2个未标记数据图像组成。</p>
<h4 id="推论">推论</h4>
<p>在测试过程中，我们将输入图像的大小调整为<code>416×416</code>，将调整后的图像送入<strong>学生网络</strong>，并获取最右侧的阴影区域检测map(图3中的$S_f$)作为MTMT-Net的最终输出。在最近的阴影检测网络[43，41]的基础上，我们应用<strong>全连通条件随机场(CRF)</strong>[20]对网络的预测结果进行了进一步的后处理。</p>
<h2 id="4-Experimental-Results-💡">4. Experimental Results 💡</h2>
<p>在这节，我们首先展示了阴影检测基准数据集和评估度量，进而比较了MTMT-net和现在先进的关于阴影检测器和阴影去除，显著性检测和语义分割的结果，最后报告消融研究结果。我们在三个基准数据集上的代码、模型参数和阴影检测结果已在https://github.com/eraserNut/MTMT.发布</p>
<h3 id="4-1-数据集和评估指标">4.1 数据集和评估指标</h3>
<h4 id="Benchmark-datasets">Benchmark datasets</h4>
<p>我们在三个广泛使用的阴影检测基准数据集SBU[33]、UCF[42]和ISTD[35]上对我们的方法进行了评估：(I)SBU数据集是最大的带标注的阴影数据集，有4089幅训练图像和638幅测试图像；(Ii)UCF数据集包括145幅训练图像和76幅测试图像，覆盖了室外场景；(Iii)ISTD是最近开发的一种同时用于阴影检测和去除的数据集。它有1870个三元组的阴影图像、阴影贴图和无阴影图像，其中540个用于测试。类似于最近的工作[12，24，43，41]，对于SBU和UCF，我们通过在SBU训练集和我们的未标记数据集上训练我们的网络来获得评估结果。由于ISTD只包含与SBU图像不同的投射阴影图像，按照[41]，我们使用未标记的数据在ISTD训练数据集上重新训练我们的方法和大多数竞争对手。我们SBU的培训时间是1小时，ISTD的培训时间是0.5小时。我们网络的模型规模是169米。在测试中，我们的MTMT-Net处理一幅416×416图像的分辨率大约需要0.05秒。</p>
<h4 id="Evaluation-metric">Evaluation metric</h4>
<p>我们使用一个常用的度量，即平衡错误率(BER)来定量评估阴影检测性能。BER[43，12]同等考虑阴影区域和非阴影区域的质量，这由以下公式给出：</p>

$$
BER = (1- \frac 1 2(\frac {N_{tp}}{N_p}+ \frac {N_{tn}}{N_n})) \times 100, \quad \quad (11)
$$

<p>这里的$N_{tp},N_{tn},N_p,N_n$分别表示的是真阳性数目，真阴性数目，一张图片的阴影像素和非阴影像素的数目。较小的BER值表示较好的阴影检测性能。</p>
<h3 id="4-2-Comparison-with-the-State-of-the-art-ShadowDetectors">4.2 Comparison with the State-of-the-art ShadowDetectors</h3>
<p>比较了DSDNet[41]、DC-DSPF[37]、BDRAR[43]、AD-Net[24]、DSC[12]、ST-CGAN[35]、Patched-CNN[8]、scGAN[28]、Stack-CNN[33]和Unary-Pair[7]等10种阴影检测器的性能。</p>
<h4 id="质量对比">质量对比</h4>
<p><img src="https://picture.mulindya.com/Apaper_collect/Mean_Teacher_tab1.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>表1总结了不同方法在三个基准数据集上的定量结果。BER分数是阴影和非阴影BER分数的平均值。显然，基于深度学习的方法[33，12，8]比手工设计的检测器[7]具有更小的误码率，因为它们可以从标注的训练图像中学习到更强大的阴影检测特征。在基于深度学习的阴影检测器中，DSDNet[41]是性能第二好的方法，它显式学习并集成虚拟干扰区域的语义来推断阴影。与现有性能最好的方法相比，我们的方法在SBU、UCF和ISTD上的误码率得分分别降低了8.70%、1.58%和20.7%。此外，对于SBU和UCF，我们的方法在非阴影像素上具有更好的误码率得分，对于ISTD，在阴影像素上具有更好的误码率得分。这表明我们的网络对SBU和UCF预测了更多的阴影像素，并减少了对ISTD的非阴影区域的误报预测。与三种比较方法[43，12，41]一样，我们也使用CRF[20]作为后处理。在图表1的第二行展示了不使用CRF情况下的MTMT-net。结果表明，主要是在UCF数据集上使用CRF取得了一定程度的改进，而不使用CRF仍然取得了比大多数最先进的方法更好的性能。</p>
<h4 id="视觉对比">视觉对比</h4>
<p><img src="https://picture.mulindya.com/Apaper_collect/Mean_Teacher_fig4.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>我们进一步将我们的方法生成的阴影检测图与目前最先进的阴影检测图进行了直观的比较，如图4所示。从结果可以看出，我们的MTMT网(图4的第3列)在所有阴影检测器中具有最好的性能。它可以有效地定位不同背景下的不同阴影，并成功地将真实阴影与具有阴影外观的非阴影区域区分开来。例如，在第3、5和7行，MTMT-Net能够准确地检测出阴影区域，而其他算法则分别错误地识别了道路、天空和暗地阴影。此外，对于大阴影区域中的高对比度目标，MTMT-NET仍能将其识别为阴影，如后两行所示。</p>
<h3 id="4-3-阴影去除、稳健性检测和语义分割方法的比较">4.3 阴影去除、稳健性检测和语义分割方法的比较</h3>
<p>要注意的是，为阴影移动、显著检测和语义分割而设计的深层网络可以通过使用带注释的阴影数据集来重新训练以用于阴影检测。为了进一步评估我们方法的有效性，我们应用了</p>
<ul>
<li>
<p>阴影去除模型</p>
<ul>
<li>DeshadowNet</li>
</ul>
</li>
<li>
<p>三种显著检测模型：</p>
<ul>
<li>SRM</li>
<li>Amulet</li>
<li>EGNet</li>
</ul>
</li>
<li>
<p>基于阴影检测数据集的语义分割模型</p>
<ul>
<li>PSPNet</li>
</ul>
</li>
</ul>
<p><img src="https://picture.mulindya.com/Apaper_collect/Mean_Teacher_tab1.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>我们采用已有的比较方法的结果，无论是重新训练发布的代码还是使用报告的方法，为了公平比较，我们尽量微调它们的训练参数，选择最好的阴影检测结果。表1中的最后五行报告了它们的误码率值，我们看到这些模型可以获得比一些现有阴影检测器更好的误码率性能，但仍然比我们的网络差。</p>
<h3 id="4-4-Ablation-Analysis">4.4 Ablation Analysis</h3>
<blockquote>
<p>「消融分析」（Ablative analysis）尝试去解释一些基线表现（通常表现更差）与当前表现的差别。</p>
<p><strong>消融分析的方法是从最佳表现出发，逐步去除这些特征，观察算法的准确率变化</strong>，目的其实就是为了控制变量。</p>
</blockquote>
<h4 id="Baseline-network-design">Baseline network design</h4>
<h5 id="多任务监督损失">多任务监督损失</h5>

$$
\mathcal{L}^s(x) = \mathcal{L}^s_r+\alpha \mathcal{L}^s_e + \beta \mathcal{L}^s_c \quad \quad (5)
$$

<h5 id="多任务一致性损失">多任务一致性损失</h5>

$$
\mathcal L^c(y) = \mathcal L^c_r + \mathcal L^c_e  + \mathcal L^c_c \quad \quad \quad \quad (7)
$$

<p>我们执行消融研究实验来评估所提议的多任务监督损失(见公式(5))和多任务一致性损失(参见公式(7)我们的MTMT-Net。这里，我们考虑七个基线网络。</p>
<p>前四个基线网络是通过重新移除教师模型来构建的。这意味着只有标签数据的监督丢失才能用于MT-CNN的训练。具体地说，第一基线网络(表示为“BASIC”)仅考虑阴影区域检测监督损失($\mathcal L^s_r$ inEq.(5))。第二种(表示为“basic+SE”)是添加阴影边缘检测监督损失($\mathcal L^s_e$ of Eq.(5))，而第三个(表示为“basic+SC”)是添加阴影计数检测监督损失($\mathcal L^s_c$of Eq.(5))。四是将三项任务的监督损失融合在一起。</p>
<p>另外三个基线网络是建立用于检验在未标注多任务一致性损失。第一种方法(记为“basic-MT”)只考虑阴影区域任务的Mean teacher模型。,通过融合等式的监督损失($\mathcal L^s_R$of 公式(5))和一致性损失($\mathcal L^c_r $  of 公式(7))。第二种方法(记为“basic-MT+SE-MT”)是将mean teacher模型应用于阴影区域检测和阴影边缘检测，即等式(5)中的$\mathcal{L}<sup>s_r,\mathcal{L}</sup>s_e$以及方程(7)中的$\mathcal{L}<sup>c_r,\mathcal{L}</sup>c_e$用于训练网络。最后一种方法(记为“basic-MT+SC-MT”)采用平均教师模型进行阴影区域检测和阴影计数检测。换言之，监督损失(等式（5）中的$\mathcal{L}<sup>s_r,\mathcal{L}</sup>s_c$）和一致性损失(等式(7)中的$\mathcal{L}<sup>c_r,\mathcal{L}</sup>c_c$)用于网络训练。</p>
<p>我们使用SBU训练集和我们的未标记数据对所有七个基线网络进行训练，以获得SBU和UCF的结果。对于ISTD，我们使用ISTD训练集和我们的未标记数据来训练所有四个网络，并使用ISTD测试集对它们进行测试。</p>
<h4 id="质量对比-2">质量对比</h4>
<p><img src="https://picture.mulindya.com/Apaper_collect/Mean_Teacher_tab2.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>表2总结了我们的网络和七个基准网络在三个基准数据集上的BER值。结果表明：</p>
<h5 id="Basis">Basis</h5>
<p>(i)“BASIC+SE”和“BASIC+SC”比“BASIC”具有更高的误码率，这意味着<strong>阴影边界和阴影计数的检测可以为阴影检测提供有用的信息。</strong></p>
<p>(ii)“BASIC+三任务”比“BASIC+SE”和“BASIC+SC”具有更好的误码率性能，说明将这三个任务融合在一起进行有监督的阴影检测具有更好的检测性能。</p>
<p>(iii)“BASIC-MT”比“BASIC”能更准确地检测出阴影像素，因为它的误码率较小。这表明了额外的未标记数据的一致性损失具有更好的阴影检测性能。</p>
<h5 id="MTMT">MTMT</h5>
<p>(iv)“BASIC-MT+SE-MT”和“BASIC-MT+SC-MT”比“BASIC-MT”产生的误码率小，说明阴影边缘检测和阴影区域检测有利于阴影检测的mean-teacher模型。</p>
<p>(v)由于“BASIC-MT+SE-MT”比“BASIC-MT+SC-MT”具有更好的误码率结果，所以<strong>阴影边缘检测比阴影计数检测对我们方法的成功有更大的贡献，这是因为“BASIC-MT+SE-MT”比“BASIC-MT+SC-MT”有更好的误码率。</strong></p>
<p>(vi)通过设计一个三任务mean teacher模型，我们的MTMT-Net在三个基准上具有最好的误码率性能。</p>
<h4 id="视觉对比-2">视觉对比</h4>
<p><img src="https://picture.mulindya.com/Apaper_collect/Mean_Teacher_fig5.png" srcset="/img/loading.gif" lazyload alt=""></p>
<p>此外，图(5)直观地比较了我们的MTMT网和七个基线网络生成的阴影图。显然，无论在阴影分割质量还是定位精度上，我们的方法都比所有七个基线网络都能更好地识别阴影。这证明了在一个框架内考虑阴影边缘、阴影计数信息和未标记数据的有效性。</p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E6%96%87%E7%8C%AE/">文献</a>
                    
                      <a class="hover-with-bg" href="/categories/%E6%96%87%E7%8C%AE/%E5%8E%BB%E5%99%AA/">去噪</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E6%96%87%E7%8C%AE/">文献</a>
                    
                      <a class="hover-with-bg" href="/tags/%E5%8E%BB%E5%99%AA/">去噪</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/03/19/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft53/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">CodeTop_Microsoft53最大子数组和</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/03/16/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft207/">
                        <span class="hidden-mobile">CodeTop_Microsoft207 课程表</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments" lazyload>
                
                  
                
                
  <div class="disqus" style="width:100%">
    <div id="disqus_thread"></div>
    
      <script type="text/javascript">
        var disqus_config = function() {
          this.page.url = 'https://fanmeilin.github.io/2022/03/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E5%8E%BB%E5%99%AA/Mean-Teacher/';
          this.page.identifier = '/2022/03/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E5%8E%BB%E5%99%AA/Mean-Teacher/';
        };
        Fluid.utils.loadComments('#disqus_thread', function() {
          var d = document, s = d.createElement('script');
          s.src = '//' + 'fluid' + '.disqus.com/embed.js';
          s.setAttribute('data-timestamp', new Date());
          (d.head || d.body).appendChild(s);
        });
      </script>
    
    <noscript>Please enable JavaScript to view the comments</noscript>
  </div>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header vvd_contents"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>
  <div class="statistics">
    <a target="_blank" rel="noopener" href="https://developer.hitokoto.cn/" id="hitokoto_text"><span style="color: #DDD;"  id="hitokoto"></span></a>
 <script src="https://v1.hitokoto.cn/?encode=js&select=%23hitokoto" defer></script>
  </div>


  
  <!-- 备案信息 -->
  <div class="beian">
    <span>
      <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
        鄂ICP备2021014492-1号
      </a>
    </span>
    
  </div>


  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js" ></script>



  <script  src="/js/local-search.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-svg.js" ></script>

  





  <script  src="https://cdn.jsdelivr.net/npm/mermaid@8.10.1/dist/mermaid.min.js" ></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({"theme":"default"});
    }
  </script>




  

  

  

  

  

  





<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"left","width":260,"height":480},"mobile":{"show":false},"react":{"opacity":0.9}});</script></body>
</html>
