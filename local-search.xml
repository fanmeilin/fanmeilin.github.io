<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>CodeTop88 合并两个有序数组</title>
    <link href="/2022/06/18/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop88/"/>
    <url>/2022/06/18/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop88/</url>
    
    <content type="html"><![CDATA[<blockquote><p>合并两个有序数组</p></blockquote><h2 id="题目">题目</h2><p>给你两个按 非递减顺序 排列的整数数组&nbsp;nums1 和 nums2，另有两个整数 m 和 n ，分别表示 nums1 和 nums2 中的元素数目。</p><p>请你 合并 nums2 到 nums1 中，使合并后的数组同样按 非递减顺序 排列。</p><p>注意：最终，合并后数组不应由函数返回，而是存储在数组 nums1 中。为了应对这种情况，nums1 的初始长度为 m + n，其中前 m 个元素表示应合并的元素，后 n 个元素为 0 ，应忽略。nums2 的长度为 n 。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：nums1 = <span class="hljs-comment">[1,2,3,0,0,0]</span>, m = 3, nums2 = <span class="hljs-comment">[2,5,6]</span>, n = 3<br>输出：<span class="hljs-comment">[1,2,2,3,5,6]</span><br>解释：需要合并 <span class="hljs-comment">[1,2,3]</span> 和 <span class="hljs-comment">[2,5,6]</span> 。<br>合并结果是 <span class="hljs-comment">[1,2,2,3,5,6]</span> ，其中斜体加粗标注的为 nums1 中的元素。<br><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：nums1 = <span class="hljs-comment">[1]</span>, m = 1, nums2 = <span class="hljs-comment">[]</span>, n = 0<br>输出：<span class="hljs-comment">[1]</span><br>解释：需要合并 <span class="hljs-comment">[1]</span> 和 <span class="hljs-comment">[]</span> 。<br>合并结果是 <span class="hljs-comment">[1]</span> 。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例3：">示例3：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：nums1 = <span class="hljs-comment">[0]</span>, m = 0, nums2 = <span class="hljs-comment">[1]</span>, n = 1<br>输出：<span class="hljs-comment">[1]</span><br>解释：需要合并的数组是 <span class="hljs-comment">[]</span> 和 <span class="hljs-comment">[1]</span> 。<br>合并结果是 <span class="hljs-comment">[1]</span> 。<br>注意，因为 m = 0 ，所以 nums1 中没有元素。nums1 中仅存的 0 仅仅是为了确保合并结果可以顺利存放到 nums1 中。<br><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>nums1.length == m + n</li><li>nums2.length == n</li><li>0 &lt;= m, n &lt;= 200</li><li>1 &lt;= m + n &lt;= 200</li><li>-109 &lt;= nums1[i], nums2[j] &lt;= 109</li></ul><h2 id="题解">题解</h2><h4 id="双指针顺序搜索">双指针顺序搜索</h4><p>这里按照常规方法会新建一个数组，逐个元素添加，但是题目的要求是直接对nums修改。因此会存在覆盖的问题，这里可以使用一个临时数组，最后<strong>赋值</strong>到nums1。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">merge</span>(<span class="hljs-params">self, nums1: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], m: <span class="hljs-built_in">int</span>, nums2: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-literal">None</span>:</span><br>        <span class="hljs-string">"""</span><br><span class="hljs-string">        Do not return anything, modify nums1 in-place instead.</span><br><span class="hljs-string">        """</span><br>        <span class="hljs-comment">#从前向后 使用临时数组</span><br>        result = []<br>        i, j = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>        <span class="hljs-keyword">while</span>(i&lt;m <span class="hljs-keyword">and</span> j&lt;n):<br>            <span class="hljs-keyword">if</span> nums1[i]&lt;nums2[j]:<br>                result.append(nums1[i])<br>                i += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                result.append(nums2[j])<br>                j += <span class="hljs-number">1</span><br>        result += nums1[i:m] <span class="hljs-keyword">if</span> i&lt;m <span class="hljs-keyword">else</span> nums2[j:n]<br>        nums1[:] = result <span class="hljs-comment">#[:] 赋值 如果直接等于就会创建新变量</span><br><br></code></pre></td></tr></tbody></table></figure><h4 id="双指针逆序搜索">双指针逆序搜索</h4><p>从后向前更新nums1的值，每次取最大的值填入。这样nums1的有效数字不会被覆盖。循环只需要针对nums2的遍历，如果数组2被遍历完成，则nums1的结果（已经顺序填好）也就是最终的结果。</p><p>这样空间复杂度会进一步降低。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">merge</span>(<span class="hljs-params">self, nums1: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], m: <span class="hljs-built_in">int</span>, nums2: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-literal">None</span>:</span><br>        <span class="hljs-comment">#从后向前</span><br>        p1, p2 = m - <span class="hljs-number">1</span>, n - <span class="hljs-number">1</span><br>        tail = <span class="hljs-built_in">len</span>(nums1) - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> p2 &gt;= <span class="hljs-number">0</span>: <span class="hljs-comment">#nums2未放完</span><br>            <span class="hljs-keyword">if</span> p1 &lt; <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> nums1[p1] &lt; nums2[p2]: <span class="hljs-comment"># p1放完 或者 p2对应更大</span><br>                nums1[tail] = nums2[p2]<br>                p2 -= <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:  <span class="hljs-comment">#否则填入p1内容</span><br>                nums1[tail] = nums1[p1]<br>                p1 -= <span class="hljs-number">1</span><br>            tail -= <span class="hljs-number">1</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>指针</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>指针</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Codetop141 环形链表</title>
    <link href="/2022/06/17/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop141/"/>
    <url>/2022/06/17/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop141/</url>
    
    <content type="html"><![CDATA[<blockquote><p>环形链表</p></blockquote><h2 id="题目">题目</h2><p>给你一个链表的头节点 head ，判断链表中是否有环。</p><p>如果链表中有某个节点，可以通过连续跟踪 next 指针再次到达，则链表中存在环。 为了表示给定链表中的环，评测系统内部使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。注意：pos 不作为参数进行传递&nbsp;。仅仅是为了标识链表的实际情况。</p><p>如果链表中存在环&nbsp;，则返回 true 。 否则，返回 false 。</p><h3 id="示例-1：">示例 1：</h3><p><img src="https://picture.mulindya.com/Aleetcode/CodeTop141-1.png" alt=""></p><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">head</span> = [<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>,-<span class="hljs-number">4</span>], <span class="hljs-attr">pos</span> = <span class="hljs-number">1</span><br>输出：<span class="hljs-literal">true</span><br>解释：链表中有一个环，其尾部连接到第二个节点。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><p><img src="https://picture.mulindya.com/Aleetcode/CodeTop141-2.png" alt=""></p><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">head</span> = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>], <span class="hljs-attr">pos</span> = <span class="hljs-number">0</span><br>输出：<span class="hljs-literal">true</span><br>解释：链表中有一个环，其尾部连接到第一个节点。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例3">示例3</h3><p><img src="https://picture.mulindya.com/Aleetcode/CodeTop141-3.png" alt=""></p><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">head</span> = [<span class="hljs-number">1</span>], <span class="hljs-attr">pos</span> = -<span class="hljs-number">1</span><br>输出：<span class="hljs-literal">false</span><br>解释：链表中没有环。<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>链表中节点的数目范围是 [0, 10^4]</li><li>-10^5 &lt;= Node.val &lt;= 10^5</li><li>pos 为 -1 或者链表中的一个 有效索引 。</li></ul><h2 id="题解">题解</h2><h4 id="标号">标号</h4><p>选择一个不出现的记号作为是否visit，选用浮点数1.5作为标记。但是有投机取巧之嫌。</p><ul><li>时间复杂度为O(N)，空间复杂度为O(1)</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode:</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.next = None</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hasCycle</span>(<span class="hljs-params">self, head: <span class="hljs-type">Optional</span>[ListNode]</span>) -&gt; <span class="hljs-built_in">bool</span>:</span><br>        <span class="hljs-keyword">while</span>(head):<br>            head.val = <span class="hljs-number">1.5</span><br>            pnext = head.<span class="hljs-built_in">next</span><br>            <span class="hljs-keyword">if</span> pnext <span class="hljs-keyword">and</span> pnext.val==<span class="hljs-number">1.5</span>:<span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>            head = pnext<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br></code></pre></td></tr></tbody></table></figure><h4 id="哈希表">哈希表</h4><p>使用哈希表来存储所有已经访问过的节点。每次我们到达一个节点，如果该节点已经存在于哈希表中，则说明该链表是环形链表，否则就将该节点加入哈希表中。重复这一过程，直到我们遍历完整个链表即可。</p><p>可以使用set来记录出现的各个节点。</p><ul><li>时间复杂度为O(N)，空间复杂度为O(N)</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hasCycle</span>(<span class="hljs-params">self, head: ListNode</span>) -&gt; <span class="hljs-built_in">bool</span>:</span><br>        seen = <span class="hljs-built_in">set</span>()<br>        <span class="hljs-keyword">while</span> head:<br>            <span class="hljs-keyword">if</span> head <span class="hljs-keyword">in</span> seen: <span class="hljs-comment">#in 查找 O(1) set本身是一个哈希表           </span><br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>            seen.add(head)<br>            head = head.<span class="hljs-built_in">next</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br></code></pre></td></tr></tbody></table></figure><h4 id="快慢指针-⭐">快慢指针 ⭐</h4><p>这里使用快慢指针，<strong>快指针表示每次移动两个节点，慢指针表示每次移动一个节点。</strong></p><p>如果链表没有环时，最终快指针先于慢指针达到链表尾部，每个节点最多被访问两次。</p><p>如果存在环形，快指针原本先于慢指针，但是当进入环形之后（快指针先进入环形），快指针变成追赶慢指针，并且在每一次移动之后，两个指针的距离就会减少一个节点，最终肯定会相遇。</p><ul><li>时间复杂度为O(N)，空间复杂度为O(1)</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hasCycle</span>(<span class="hljs-params">self, head: ListNode</span>) -&gt; <span class="hljs-built_in">bool</span>:</span><br>        fast = slow = head<br>        <span class="hljs-keyword">while</span> fast <span class="hljs-keyword">and</span> fast.<span class="hljs-built_in">next</span>:<br>            fast = fast.<span class="hljs-built_in">next</span>.<span class="hljs-built_in">next</span> <span class="hljs-comment">#两步</span><br>            slow = slow.<span class="hljs-built_in">next</span><br>            <span class="hljs-keyword">if</span> fast == slow:<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>链表</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>链表</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop121 买卖股票的最佳时机</title>
    <link href="/2022/06/16/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop121/"/>
    <url>/2022/06/16/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop121/</url>
    
    <content type="html"><![CDATA[<blockquote><p>买卖股票的最佳时机</p></blockquote><h2 id="题目">题目</h2><p>给定一个数组 prices ，它的第&nbsp;i 个元素&nbsp;prices[i] 表示一支给定股票第 i 天的价格。</p><p>你只能选择 某一天 买入这只股票，并选择在 未来的某一个不同的日子 卖出该股票。设计一个算法来计算你所能获取的最大利润。</p><p>返回你可以从这笔交易中获取的最大利润。如果你不能获取任何利润，返回 0</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight tap"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs tap">输入：[7,1,5,3,6,4]<br>输出：5<br>解释：在第<span class="hljs-number"> 2 </span>天（股票价格 = 1）的时候买入，在第<span class="hljs-number"> 5 </span>天（股票价格 = 6）的时候卖出，最大利润 = 6-1 =<span class="hljs-number"> 5 </span>。<br>     注意利润不能是 7-1 = 6, 因为卖出价格需要大于买入价格；同时，你不能在买入前卖出股票。<br><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight accesslog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">输入：prices = <span class="hljs-string">[7,6,4,3,1]</span><br>输出：<span class="hljs-number">0</span><br>解释：在这种情况下, 没有交易完成, 所以最大利润为 <span class="hljs-number">0</span>。<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><code>1 &lt;= prices.length &lt;= 105</code></li><li><code>0 &lt;= prices[i] &lt;= 104</code></li></ul><h2 id="题解">题解</h2><p>找寻抛售股票最佳时机实际上在找一个前后差值最大的结果。最暴力的解法就是对每个起止点找最佳的抛点，在取其最大，这种需要n平方的复杂度。</p><p>也可以理解为对相邻两天的差价做一个数组，对这个gap数组找寻最大子序列和。</p><p>求解最大子序列和的代码：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">resum,result = <span class="hljs-number">0</span>,<span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> gap:<br>resum = <span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>,resum+x) <span class="hljs-comment">#resum是当前为终止点的最大子序列和，如果为负数就恢复为0（不取用），也不采用当前点</span><br>result = <span class="hljs-built_in">max</span>(result,resum) <span class="hljs-comment">#result记录数组中最大的子序列和</span><br></code></pre></td></tr></tbody></table></figure><p>完整代码：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maxProfit</span>(<span class="hljs-params">self, prices: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        gap = [prices[i+<span class="hljs-number">1</span>]-prices[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(prices)-<span class="hljs-number">1</span>)]<br>        <span class="hljs-built_in">print</span>(gap)<br>        resum,result = <span class="hljs-number">0</span>,<span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> gap:<br>            resum = <span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>,resum+x)<br>            result = <span class="hljs-built_in">max</span>(result,resum)<br>            <span class="hljs-built_in">print</span>(resum)<br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></tbody></table></figure><p>此时遍历了数组两遍 也就是O(2n)</p><p>实际上无需建立数组gap，可以进一步提高时间，空间复杂度</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maxProfit</span>(<span class="hljs-params">self, prices: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        resum, result = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(prices)-<span class="hljs-number">1</span>):<br>            gap = prices[i+<span class="hljs-number">1</span>]-prices[i]<br>            resum = resum+gap <span class="hljs-keyword">if</span> resum+gap&gt;<span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span> <span class="hljs-comment"># resum = max(0,resum+gap)</span><br>            <span class="hljs-keyword">if</span> resum&gt;result: result = resum <span class="hljs-comment"># result = max(result,resum)   </span><br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>动态规划</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>动态规划</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop20 有效的括号</title>
    <link href="/2022/06/15/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop20/"/>
    <url>/2022/06/15/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop20/</url>
    
    <content type="html"><![CDATA[<blockquote><p>有效的括号</p></blockquote><h2 id="题目">题目</h2><p>给定一个只包括 ‘(’，‘)’，‘{’，‘}’，‘[’，‘]’ 的字符串 s ，判断字符串是否有效。</p><p>有效字符串需满足：</p><p>左括号必须用相同类型的右括号闭合。<br>左括号必须以正确的顺序闭合。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">s</span> = <span class="hljs-string">"()"</span><br>输出：<span class="hljs-literal">true</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">s</span> = <span class="hljs-string">"()[]{}"</span><br>输出：<span class="hljs-literal">true</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-3：">示例 3：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">s</span> = <span class="hljs-string">"(]"</span><br>输出：<span class="hljs-literal">false</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-4：">示例 4：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">s</span> = <span class="hljs-string">"([)]"</span><br>输出：<span class="hljs-literal">false</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-5：">示例 5：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">s</span> = <span class="hljs-string">"{[]}"</span><br>输出：<span class="hljs-literal">true</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= s.length &lt;= 104</li><li>s 仅由括号 ‘()[]{}’ 组成</li></ul><h2 id="题解">题解</h2><p>使用栈来处理这类问题，当遇到反括号时，对栈顶元素进行判断，如果可以匹配就pop进行抵消，否则就压入栈中，最后只需要判断stack是否为空即可。如果是正确的括号形式，栈最后就会为空。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">isValid</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">bool</span>:</span><br>        <span class="hljs-comment"># 使用栈</span><br>        record = {<span class="hljs-string">')'</span>:<span class="hljs-string">'('</span>,<span class="hljs-string">']'</span>:<span class="hljs-string">'['</span>,<span class="hljs-string">'}'</span>:<span class="hljs-string">'{'</span>}<br>        stack = []<br>        <span class="hljs-keyword">for</span> ch <span class="hljs-keyword">in</span> s:<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> stack : stack.append(ch) <span class="hljs-comment">#为空时压栈</span><br>            <span class="hljs-keyword">elif</span> (ch <span class="hljs-keyword">in</span> record) <span class="hljs-keyword">and</span> (stack[-<span class="hljs-number">1</span>]==record[ch]):stack.pop(-<span class="hljs-number">1</span>) <span class="hljs-comment">#栈不为空并且ch和栈顶相抵消时</span><br>            <span class="hljs-keyword">else</span>: stack.append(ch)<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">not</span> stack<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>栈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>栈</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop102</title>
    <link href="/2022/06/13/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop102/"/>
    <url>/2022/06/13/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop102/</url>
    
    <content type="html"><![CDATA[<blockquote><p>二叉树的层序遍历</p></blockquote><h2 id="题目">题目</h2><p>给你二叉树的根节点 root ，返回其节点值的 层序遍历 。 （即逐层地，从左到右访问所有节点）。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：root = <span class="hljs-comment">[3,9,20,null,null,15,7]</span><br>输出：<span class="hljs-comment">[<span class="hljs-comment">[3]</span>,<span class="hljs-comment">[9,20]</span>,<span class="hljs-comment">[15,7]</span>]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight lua"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs lua">输入：root = [<span class="hljs-number">1</span>]<br>输出：<span class="hljs-string">[[1]]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-3：">示例 3：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：root = <span class="hljs-comment">[]</span><br>输出：<span class="hljs-comment">[]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>树中节点数目在范围 [0, 2000] 内</li><li>-1000 &lt;= Node.val &lt;= 1000</li></ul><h2 id="题解">题解</h2><p>层序遍历标配队列。<br>这里需要按照每一层创建数组，将队列元素append到数组中直到队列为空，那么这一层的数据则记录完整。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">levelOrder</span>(<span class="hljs-params">self, root: TreeNode</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]:</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root: <span class="hljs-keyword">return</span>[]<br>        queue,result = [],[]<br>        queue.append(root)<br>        <span class="hljs-keyword">while</span> queue:<br>            tmp,nextlayer = [],[]<br>            <span class="hljs-keyword">while</span> queue:<br>                top = queue.pop(<span class="hljs-number">0</span>)<br>                tmp.append(top.val)<br>                <span class="hljs-keyword">if</span> top.left:nextlayer.append(top.left)<br>                <span class="hljs-keyword">if</span> top.right:nextlayer.append(top.right)<br>            queue = nextlayer<br>            result.append(tmp)<br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>树</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop1 两数之和</title>
    <link href="/2022/06/10/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop1/"/>
    <url>/2022/06/10/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>两数之和</p></blockquote><h2 id="题目">题目</h2><p>给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target  的那 两个 整数，并返回它们的数组下标。</p><p>你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。</p><p>你可以按任意顺序返回答案。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：nums = <span class="hljs-comment">[2,7,11,15]</span>, target = 9<br>输出：<span class="hljs-comment">[0,1]</span><br>解释：因为 nums<span class="hljs-comment">[0]</span> + nums<span class="hljs-comment">[1]</span> == 9 ，返回 <span class="hljs-comment">[0, 1]</span> 。<br><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：nums = <span class="hljs-comment">[3,2,4]</span>, target = 6<br>输出：<span class="hljs-comment">[1,2]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-3：">示例 3：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：nums = <span class="hljs-comment">[3,3]</span>, target = 6<br>输出：<span class="hljs-comment">[0,1]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>2 &lt;= nums.length &lt;= 104</li><li>-109 &lt;= nums[i] &lt;= 109</li><li>-109 &lt;= target &lt;= 109</li><li>只会存在一个有效答案<br>进阶：你可以想出一个时间复杂度小于 O(n2) 的算法吗？</li></ul><h2 id="题解">题解</h2><p>使用哈希表记录数字出现情况可以使得复杂度降维O(N),但是要注意重复数字的问题，一开始的思路是采用哈希表将所有数字存入dict，键值对分别对应数字和索引。但是这里会出现覆盖的情况，比如出现重复的值，那么只能记录最新的索引。<br>因此需要考虑重复值的情况，一种是将哈希表记录所有的值对应的索引用数组来存储。<br>另外一种巧妙的方法是转换顺序，在遍历所有值的时候，先判断该差值是否在哈希表中，如果存在直接return对应结果，如果不存在将当前值再插入到哈希表。这样可以避免重复值的索引被更新的情况。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">twoSum</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:</span><br>    dictT = <span class="hljs-built_in">dict</span>()<br>    <span class="hljs-keyword">for</span> i,num <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(nums):<br>    <span class="hljs-keyword">if</span> target-num <span class="hljs-keyword">in</span> dictT:<br>    <span class="hljs-keyword">return</span> [i,dictT[target-num]]<br>    dictT[num] = i<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>哈希表</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>哈希表</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>计算模型的GFlops和Params</title>
    <link href="/2022/06/04/python/compute-gflops/"/>
    <url>/2022/06/04/python/compute-gflops/</url>
    
    <content type="html"><![CDATA[<blockquote><p>计算模型的参数量和计算量可以更加公平的评估模型的真实效果，记录一些使用的工具来测量。</p><p><strong>torchstat.stat</strong>：计算<a href="https://so.csdn.net/so/search?q=Pytorch&amp;spm=1001.2101.3001.7020">Pytorch</a>模型的FLOPs、模型参数量、MAdd、模型显存占用量<br><strong>thop</strong>：工具包仅支持FLOPs和参数量的计算<br><strong>ptflops</strong>：统计 参数量 和 FLOPs<br><strong>torchsummary</strong>：用来计算网络的计算参数等信息</p></blockquote><h3 id="概念">概念</h3><p><code>FLOPs</code>是floating point operations的缩写（s表复数），意指浮点运算数，理解为计算量，用以衡量算法/模型复杂度。<br><code>MACs</code> 每秒执行的定点乘累加操作次数的缩写，它是衡量计算机定点处理能力的量，这个量经常用在那些需要大量定点乘法累加运算的科学运算中，记为<code>MACs</code>。</p><blockquote><p>GMAC=0.5GFLOPs</p></blockquote><h3 id="换算">换算</h3><p>一个 MFLOPS (megaFLOPS) 等于每秒1百万 (=10^6) 次的浮点运算，<br>一个 GFLOPS (gigaFLOPS) 等于每秒10亿 (=10^9) 次的浮点运算，<br>一个 TFLOPS (teraFLOPS) 等于每秒1万亿 (=10^12) 次的浮点运算，<br>一个 PFLOPS (petaFLOPS) 等于每秒1千万亿 (=10^15) 次的浮点运算</p><h3 id="thop">thop</h3><h4 id="安装">安装</h4><figure class="highlight cmake"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip <span class="hljs-keyword">install</span> thop<br></code></pre></td></tr></tbody></table></figure><h4 id="使用方法">使用方法</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> thop <span class="hljs-keyword">import</span> profile, clever_format<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> networks <span class="hljs-keyword">import</span> Network<br>sigmaFlag = <span class="hljs-literal">False</span><br>net = Network<br><span class="hljs-built_in">input</span> = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>)<br>flops, params = profile(net, inputs=(<span class="hljs-built_in">input</span>,))<br>flops, params = clever_format([flops, params], <span class="hljs-string">"%.3f"</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">'FLOPs = '</span> , flops)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">'Params = '</span>,params)<br></code></pre></td></tr></tbody></table></figure><h3 id="ptflops">ptflops</h3><h4 id="安装-2">安装</h4><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">pip install ptflops 或者 pip install --upgrade git+https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/sovrasov/</span>flops-counter.pytorch.git<br></code></pre></td></tr></tbody></table></figure><h4 id="使用方法-2">使用方法</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision.models <span class="hljs-keyword">as</span> models<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> ptflops <span class="hljs-keyword">import</span> get_model_complexity_info<br><br><span class="hljs-keyword">with</span> torch.cuda.device(<span class="hljs-number">0</span>):<br>  net = models.densenet161()<br>  macs, params = get_model_complexity_info(net, (<span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>), as_strings=<span class="hljs-literal">True</span>,<br>                                           print_per_layer_stat=<span class="hljs-literal">True</span>, verbose=<span class="hljs-literal">True</span>)<br>  <span class="hljs-built_in">print</span>(<span class="hljs-string">'{:&lt;30}  {:&lt;8}'</span>.<span class="hljs-built_in">format</span>(<span class="hljs-string">'Computational complexity: '</span>, macs))<br>  <span class="hljs-built_in">print</span>(<span class="hljs-string">'{:&lt;30}  {:&lt;8}'</span>.<span class="hljs-built_in">format</span>(<span class="hljs-string">'Number of parameters: '</span>, params))<br></code></pre></td></tr></tbody></table></figure><p>其中print_per_layer_stat用来管理是否输出每一层的参数量和计算量。</p>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NBnet paper 要点</title>
    <link href="/2022/05/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E5%8E%BB%E5%99%AA%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE/NBnet-paper/"/>
    <url>/2022/05/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E5%8E%BB%E5%99%AA%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE/NBnet-paper/</url>
    
    <content type="html"><![CDATA[<blockquote><p>近年来的去噪顶刊《 NBNet: Noise Basis Learning for Image Denoising with Subspace Projection》发表于2021年的cvpr，在DND数据集的benchmark上的位居第三名。在实验中使用到NBnet，因此对这篇文章进行研读，以下是记录的要点。</p></blockquote><p><img src="https://picture.mulindya.com/Apaper_collect%2FDND_benchmark.png" alt=""></p><h2 id="Abstract">Abstract</h2><ul><li><p>解决问题：图像去噪；</p></li><li><p>新的视角：使用图像自适应的投影降噪；</p></li><li><p>方法：<br>1，特征空间的重构基，训练一个分离信号和噪声的网络</p><p>​Specifically, we propose to train a network that can separate signal and noise by learning a set of reconstruction basis in the fea-ture space.<br>2，选择对应信号子空间的基，并投影实现去噪<br>image denosing can be achieved by selecting corresponding basis of the signal subspace and projecting the input into such space</p></li><li><p>Key insight：<br>projection can naturally maintain the local strcture of insight signal. especially for areas with low light or weak textures.</p></li><li><p>Proposed key：</p><ul><li>SSA：<ul><li>非局部注意力模块</li><li>learn the basis generation as well as subspace projection</li></ul></li></ul></li><li><p>成果<br>我们对基准进行评估，包括SIDD和DND, NBNet在PSNR和SSIM上实现了最先进的性能，大大降低了计算成本。</p></li></ul><p><img src="https://picture.mulindya.com/Apaper_collect%2FGflops_NBnet.png" alt=""></p><h2 id="引入">引入</h2><p>图像去噪是病态问题，因此使用图像先验和去噪模型从噪声观测中估计干净图像和噪声。</p><ul><li><p>传统方法：</p><ul><li>NLM，BM3D ：利用图片的局部相似性和噪声独立的特性</li><li>NBNet: Noise Basis Learning for Image Denoising with Subspace Projectionnoising：利用在变换域图片的稀疏性；</li></ul></li><li><p>DNN方法：利用图像先验和监督学习噪声分布</p></li></ul><h3 id="挑战：">挑战：</h3><p>在硬场景，比如纹理较弱或高频细节恢复高质量图像仍然具有挑战性。</p><h3 id="理论：">理论：</h3><p>卷积网络通常依赖于局部滤波器对噪声和信号的响应。但是在低信噪比的硬场景中，如果没有全局的结构信息，局部的响应容易被混淆。</p><h3 id="应对方法：">应对方法：</h3><p>通过投影机制使用非局部图像信息，对于自然图像而言，通常处于低秩信号子空间中，通过对基向量的学习和生成，重构的图像可以保留大部分的原始信息而抑制噪声。</p><p><img src="https://picture.mulindya.com/Apaper_collect%2FNB_fig2.png" alt=""></p><h2 id="2-相关工作">2 相关工作</h2><h3 id="2-1传统经典方法">2.1传统经典方法</h3><p>传统方法是基于图像先验（NLM，sparse coding，BM3D），但是算法复杂度较高，泛化程度有限。</p><h3 id="2-2-网络架构">2.2 网络架构</h3><ul><li>FFDNet，非盲去噪方法，将噪声水平作为一个map输入到噪声图像，对过平滑细节的图像的真实噪声图像具备空间不变性。</li><li>MIRNet提出了一种去噪和超分辨率图像增强的通用网络架构。使用提取，交换，利用多尺度特征信息的新型模块。</li><li>NBnet 采用带有空间注意力模块（SSA）的unet架构。SSA是用于学习子空间基和图像投影而非区域或者特征选择。</li></ul><h3 id="2-3噪声分布">2.3噪声分布</h3><p>噪声合成：<br>高斯-泊松分布，摄像机内过程模拟，高斯混合模型，gan生成噪声。</p><h2 id="3方法">3方法</h2><h3 id="3-1-子空间投影">3.1 子空间投影</h3><p>Figure 2:</p><ul><li>投影分为两个步骤<br>1， 基向量的生成：从图像的特征图中生成子空间基向量；<br>2， 投影：特征图变换到到信号空间；<br>用$X_1,X_2$表示单张图片的两个特征图，是卷积激活的中间层，可以由不同层产生，但是size一致。由$X_1,X_2$估计k个基向量，基向量的尺寸为(HW,1)，然后将X1变换为由基向量表示的子空间。</li></ul><h4 id="3-1-1-基向量的生成">3.1.1 基向量的生成</h4><p>两个feature map进行concat后卷积生成k通道的same特征图，再进行reshape操作，转换为HW*K的size。</p><h4 id="3-1-2-投影">3.1.2 投影</h4><p>通过正交线性投影将图像特征X1投影到V。通过V求出正交投影矩阵将N空间投影到V空间。<br>正交矩阵P定义为</p>$$V(V^TV)^{-1}V^T$$<p>维度是(HW,HW),最后使用PX1进行重构。</p><h3 id="3-2-网络架构和损失函数">3.2 网络架构和损失函数</h3><p><img src="https://picture.mulindya.com/Apaper_collect%2FNB_fig3.png" alt=""></p><ul><li>架构</li></ul><p>使用Unet架构，SSA模块放在每个skip-connection，因为低层次的特征包含更多的原始图像细节信息，因此将低层次的特征图作为X1，高层次的特征图作为X2放入SSA、然后将高层次特征和投影特征进行融合输出到下一个decoder。<br>与传统的方式相比，NBnet主要区别在于低级特征在融合前由SSA模块处理。最后一个decoder输出由3*3的卷积核作为全局残差传递到输入图像得到结果。</p><ul><li>损失函数</li></ul><p>使用1范数作为损失函数。</p><h3 id="结果">结果</h3><p><img src="https://picture.mulindya.com/Apaper_collect%2FNB_tab1.png" alt=""></p><p><img src="https://picture.mulindya.com/Apaper_collect%2FNB_tab3.png" alt=""></p><p><img src="https://picture.mulindya.com/Apaper_collect%2FNB_tab4.png" alt=""></p><h2 id="4-实验">4 实验</h2><h3 id="4-1-训练设置">4.1 训练设置</h3><ul><li>无预训练</li><li>K 16</li><li>优化器 AdamW （0.9，0.999）</li><li>学习率 2e-4</li><li>学习率衰减 cosine annealing</li><li>iterations 70000</li><li>batch size 32</li><li>数据增强 rotaion cropping flipping</li></ul><h3 id="4-2-合成高斯噪声">4.2 合成高斯噪声</h3><ul><li><p>训练数据集</p><ul><li>BSD：432</li><li>imagenet：400</li><li>Waterloo Exploration Database：4744</li></ul></li><li><p>测试数据集</p><ul><li>Set5</li><li>LIVE1</li><li>BSD68<br>为了实现公平性对比，使用独立同分布的高斯噪声。</li></ul></li></ul><h3 id="4-3-真实噪声SIDD">4.3 真实噪声SIDD</h3><p>SIDD提供10个场景30000个噪声图片，benchmark是切分其中1280作为验证。</p><p><img src="https://picture.mulindya.com/Apaper_collect%2FNB_fig4.png" alt=""></p><h3 id="4-4-真实噪声DND">4.4 真实噪声DND</h3><p>DND包括50个真实噪声图像和对应的干净图像。源图像以基准ISO水平拍摄，而噪声图像以更高的ISO和适当调整的曝光时间拍摄。DND数据集不提供训练数据，因此通过结合SIDD和Renoir数据来训练，通过使用SIDD基准上的最佳验证效果的模型。将结果提交到DND进行测试。计算成本比MIRNet更好，但是计算成本更低。该方法可以在保持图像纹理和清晰度的同时，输出清晰的图像。</p><p><img src="https://picture.mulindya.com/Apaper_collect%2FNB_fig5.png" alt=""></p><h3 id="4-5-消融实验">4.5 消融实验</h3><p>模型三个决定因素<br>a) 网络的SSA模块<br>b) 信号的子空间维数–基向量的数量K<br>c)  投影的选择</p><h4 id="4-5-1-整合到DnCNN">4.5.1 整合到DnCNN</h4><p>为了评估SSA模块的有效性，我们考虑使用另一个经典架构DbCNN作为基线，为了使用X1和X2，使用第一次卷积的特征为X1，最后的卷积特征为X2，简单的concat X1和X2可以提高0.2db的psnr，使用SSA模块可以提高0.5db</p><h4 id="4-5-2-超参数K的影响">4.5.2 超参数K的影响</h4><p>K取32时模型无法收敛，这是因为第一阶段的通道数本身为32因此SSA模块不能进行有效的投影，K值等于空间的维度，另一方面，子空间的高维度会增加模型拟合的难度，从而导致训练的不稳定。而K值太小会导致子空间的信息不足，信息丢失严重，将K设置为8和16可以得到类似的性能，SSA模块会创建一个低维，紧凑，可分类的子空间。</p><blockquote><p>投影到低维的子空间，由低维的子空间基对低层次的信息进行投影还原Y，从而过滤掉噪声信息，再进行特征融合到下一阶段。</p></blockquote><p><img src="https://picture.mulindya.com/Apaper_collect%2FNB_ablation.png" alt=""></p><h4 id="4-5-3-投影方式的选择">4.5.3 投影方式的选择</h4><p>Proj(a,b)表示将a投影到b生成的基。参见表8，可以看到，对于X1生成的基会使得训练不稳定无法收敛。对X2参与生成的基可以达到一个好的效果，同时考虑X1和X2可以生成更好的基空间，网络效果更好。</p><p><img src="https://picture.mulindya.com/Apaper_collect%2FNB_ablation2.png" alt=""></p><h4 id="4-6-基向量的可视化和讨论">4.6 基向量的可视化和讨论</h4><p>参见图7</p><p>使用SSA模块后，对于暗色区域的虚线纹理被恢复，当SSA模块被禁用时，会导致暗色区域模糊，因此NBnet可以在弱纹理区域表现得更好。</p><p>这种现象是因为投影基向量产生非局部相关性。</p><p>相反，传统的卷积神经网络依赖于定值局部滤波器的响应和下采样特征的粗信息。当滤波器响应不显著且粗信息模糊时，例如在纹理较弱的区域，非局部信息很难改善局部响应。</p><blockquote><p>因此使用HW*K进行投影，以达到对全局信息的响应。</p></blockquote><h2 id="5-结论">5 结论</h2><p>所提出的子空间基生成和投影运算，不依赖于复杂的网络架构，自然可以将全局结构信息引入到去噪过程中，较好地保持了局部细节。我们进一步证明，这种基础生成和投影可以通过SSA端到端学习，并产生比添加卷积块更好的效果。子空间学习是图像去噪和其他低水平视觉任务的一个很有前途的方向，值得进一步探索。</p>]]></content>
    
    
    <categories>
      
      <category>文献</category>
      
      <category>去噪</category>
      
    </categories>
    
    
    <tags>
      
      <tag>文献</tag>
      
      <tag>去噪</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop200 岛屿数量</title>
    <link href="/2022/05/25/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop200/"/>
    <url>/2022/05/25/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop200/</url>
    
    <content type="html"><![CDATA[<blockquote><p>岛屿数量</p></blockquote><h2 id="题目">题目</h2><p>给你一个由&nbsp;‘1’（陆地）和 ‘0’（水）组成的的二维网格，请你计算网格中岛屿的数量。</p><p>岛屿总是被水包围，并且每座岛屿只能由水平方向和/或竖直方向上相邻的陆地连接形成。</p><p>此外，你可以假设该网格的四条边均被水包围。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight prolog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs prolog">输入：grid = [<br>  [<span class="hljs-string">"1"</span>,<span class="hljs-string">"1"</span>,<span class="hljs-string">"1"</span>,<span class="hljs-string">"1"</span>,<span class="hljs-string">"0"</span>],<br>  [<span class="hljs-string">"1"</span>,<span class="hljs-string">"1"</span>,<span class="hljs-string">"0"</span>,<span class="hljs-string">"1"</span>,<span class="hljs-string">"0"</span>],<br>  [<span class="hljs-string">"1"</span>,<span class="hljs-string">"1"</span>,<span class="hljs-string">"0"</span>,<span class="hljs-string">"0"</span>,<span class="hljs-string">"0"</span>],<br>  [<span class="hljs-string">"0"</span>,<span class="hljs-string">"0"</span>,<span class="hljs-string">"0"</span>,<span class="hljs-string">"0"</span>,<span class="hljs-string">"0"</span>]<br>]<br>输出：<span class="hljs-number">1</span><br><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight prolog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs prolog">输入：grid = [<br>  [<span class="hljs-string">"1"</span>,<span class="hljs-string">"1"</span>,<span class="hljs-string">"0"</span>,<span class="hljs-string">"0"</span>,<span class="hljs-string">"0"</span>],<br>  [<span class="hljs-string">"1"</span>,<span class="hljs-string">"1"</span>,<span class="hljs-string">"0"</span>,<span class="hljs-string">"0"</span>,<span class="hljs-string">"0"</span>],<br>  [<span class="hljs-string">"0"</span>,<span class="hljs-string">"0"</span>,<span class="hljs-string">"1"</span>,<span class="hljs-string">"0"</span>,<span class="hljs-string">"0"</span>],<br>  [<span class="hljs-string">"0"</span>,<span class="hljs-string">"0"</span>,<span class="hljs-string">"0"</span>,<span class="hljs-string">"1"</span>,<span class="hljs-string">"1"</span>]<br>]<br>输出：<span class="hljs-number">3</span><br><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>m == <code>grid.length</code></li><li>n == <code>grid[i].length</code></li><li>1 &lt;= m, n &lt;= 300</li><li><code>grid[i][j]</code> 的值为 ‘0’ 或 ‘1’</li></ul><h2 id="题解">题解</h2><h4 id="解法一-DFS">解法一 DFS</h4><p>目标是找到矩阵中的岛屿数量，上下左右相连为1的数字是合并的岛屿</p><p>dfs方法：设当前指针指向的岛屿中的某点(i,j)，寻找包括此点的岛屿边界</p><ul><li>从当前出发对上下左右的点进行深度搜索，即(i,j+1),(i,j-1),(i-1,j),(i+1,j);</li><li>终止条件：<ul><li>越过矩阵边界</li><li>矩阵对应的点为0，代表此点已经越过了岛屿边界</li></ul></li><li>在搜索岛屿的同时，还需要将<code>grid[i][j]</code>都设置为0，也就是将记录过的岛屿点删除，避免之后重复搜索。</li><li>主循环<ul><li>遍历整个矩阵，当遇到点为1时，进行dfs递归，岛屿数count+1且在深度优先搜索中删除此岛屿。</li></ul></li><li>最终返回count即可。</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">numIslands</span>(<span class="hljs-params">self, grid: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dfs</span>(<span class="hljs-params">grid,i,j</span>):</span> <span class="hljs-comment">#传入grid（数组形式）直接对grid进行修改</span><br>            h,w = <span class="hljs-built_in">len</span>(grid),<span class="hljs-built_in">len</span>(grid[<span class="hljs-number">0</span>]) <span class="hljs-comment">#行列</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span>(<span class="hljs-number">0</span> &lt;= i &lt; h) <span class="hljs-keyword">or</span> <span class="hljs-keyword">not</span>(<span class="hljs-number">0</span> &lt;= j &lt; w) <span class="hljs-keyword">or</span> grid[i][j]==<span class="hljs-string">'0'</span>: <span class="hljs-keyword">return</span> <span class="hljs-comment">#可以使用连续的比较符号 终止循环</span><br>            grid[i][j] = <span class="hljs-string">'0'</span> <span class="hljs-comment">#剔除该结点</span><br>            dfs(grid,i,j-<span class="hljs-number">1</span>)<br>            dfs(grid,i,j+<span class="hljs-number">1</span>)<br>            dfs(grid,i-<span class="hljs-number">1</span>,j)<br>            dfs(grid,i+<span class="hljs-number">1</span>,j)<br>            <br>        count = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,<span class="hljs-built_in">len</span>(grid)):  <span class="hljs-comment">#采用顺序遍历的形式</span><br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,<span class="hljs-built_in">len</span>(grid[<span class="hljs-number">0</span>])):<br>                <span class="hljs-keyword">if</span> grid[i][j] == <span class="hljs-string">'1'</span>: <span class="hljs-comment">#当寻找到岛屿的某一点将会整片岛屿进行消除</span><br>                    dfs(grid,i,j)<br>                    count += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> count<br></code></pre></td></tr></tbody></table></figure><h4 id="解法二-BFS">解法二 BFS</h4><ul><li>主循环的方法一致，但是搜索岛屿边界的方法不同。</li><li>使用队列queue，判断队列的首部节点(i,j)是否未越界并且为’1’  (摸索岛屿边缘)<ul><li>首先将其点置为0，并且将其上下左右的节点加入队列中 （消除整座岛屿）</li><li>否则，跳过该节点</li></ul></li><li>循环pop该队列，直到队列为空，则消除完整片岛屿。</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">numIslands</span>(<span class="hljs-params">self, grid: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">bfs</span>(<span class="hljs-params">grid,i,j</span>):</span><br>            queue = [[i,j]]<br>            <span class="hljs-keyword">while</span> queue:<br>                [i,j] = queue.pop(<span class="hljs-number">0</span>) <span class="hljs-comment">#pop函数，0表示pop元素的index</span><br>                <span class="hljs-keyword">if</span> <span class="hljs-number">0</span> &lt;= i &lt; <span class="hljs-built_in">len</span>(grid) <span class="hljs-keyword">and</span> <span class="hljs-number">0</span> &lt;= j &lt; <span class="hljs-built_in">len</span>(grid[<span class="hljs-number">0</span>]) <span class="hljs-keyword">and</span> grid[i][j]==<span class="hljs-string">'1'</span>: <br>                <span class="hljs-comment">#可以先将其上下左右节点入队列之后在对邻居节点特性进行判断，只需保证该节点为岛屿节点即可</span><br>                    grid[i][j] = <span class="hljs-number">0</span><br>                    queue += [[i,j+<span class="hljs-number">1</span>],[i,j-<span class="hljs-number">1</span>],[i+<span class="hljs-number">1</span>,j],[i-<span class="hljs-number">1</span>,j]]<br>                    <br>        count = <span class="hljs-number">0</span><br>        <span class="hljs-comment"># len(grid)为行数</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,<span class="hljs-built_in">len</span>(grid)):  <span class="hljs-comment">#采用顺序遍历的形式</span><br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,<span class="hljs-built_in">len</span>(grid[<span class="hljs-number">0</span>])):<br>                <span class="hljs-keyword">if</span> grid[i][j] == <span class="hljs-string">'1'</span>: <span class="hljs-comment">#当寻找到岛屿的某一点将会整片岛屿进行消除</span><br>                    <span class="hljs-comment"># dfs(grid,i,j)</span><br>                    bfs(grid,i,j)<br>                    count += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> count<br></code></pre></td></tr></tbody></table></figure><h4 id="解法三-并查集">解法三 并查集</h4><p>使用并查集代替搜索，</p><p>可以扫描整个二位网格，如果有一个位置上为1，则将其与邻居节点的1在并查集中进行合并，最终的岛屿数就是连通分类的数目。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">UnionFind</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, grid</span>):</span><br>        m, n = <span class="hljs-built_in">len</span>(grid), <span class="hljs-built_in">len</span>(grid[<span class="hljs-number">0</span>])<br>        self.count = <span class="hljs-number">0</span><br>        self.parent = [-<span class="hljs-number">1</span>] * (m * n)<br>        self.rank = [<span class="hljs-number">0</span>] * (m * n)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(m):<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>                <span class="hljs-keyword">if</span> grid[i][j] == <span class="hljs-string">"1"</span>:<br>                    self.parent[i * n + j] = i * n + j<br>                    self.count += <span class="hljs-number">1</span>  <span class="hljs-comment">#所有1的数目，原本可以自成一方</span><br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">find</span>(<span class="hljs-params">self, i</span>):</span><br>        <span class="hljs-keyword">if</span> self.parent[i] != i:<br>            self.parent[i] = self.find(self.parent[i])<br>        <span class="hljs-keyword">return</span> self.parent[i]<br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">union</span>(<span class="hljs-params">self, x, y</span>):</span><br>        rootx = self.find(x)<br>        rooty = self.find(y)<br>        <span class="hljs-keyword">if</span> rootx != rooty: <span class="hljs-comment">#连通该节点</span><br>            <span class="hljs-keyword">if</span> self.rank[rootx] &lt; self.rank[rooty]: <span class="hljs-comment">#向更大的父节点上添加</span><br>                rootx, rooty = rooty, rootx<br>            self.parent[rooty] = rootx<br>            <span class="hljs-keyword">if</span> self.rank[rootx] == self.rank[rooty]:<br>                self.rank[rootx] += <span class="hljs-number">1</span>  <span class="hljs-comment">#单个节点进行的连通</span><br>            self.count -= <span class="hljs-number">1</span> <span class="hljs-comment">#用统一的父节点代替该岛屿</span><br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getCount</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">return</span> self.count<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">numIslands</span>(<span class="hljs-params">self, grid: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        nr,nc = <span class="hljs-built_in">len</span>(grid),<span class="hljs-built_in">len</span>(grid[<span class="hljs-number">0</span>])<br>        <span class="hljs-keyword">if</span> nr == <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>        uf = UnionFind(grid)<br>        num_islands = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(nr):<br>            <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(nc):<br>                <span class="hljs-keyword">if</span> grid[r][c] == <span class="hljs-string">"1"</span>:<br>                    grid[r][c] = <span class="hljs-string">"0"</span><br>                    <span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> [(r - <span class="hljs-number">1</span>, c), (r + <span class="hljs-number">1</span>, c), (r, c - <span class="hljs-number">1</span>), (r, c + <span class="hljs-number">1</span>)]:<br>                        <span class="hljs-keyword">if</span> <span class="hljs-number">0</span> &lt;= x &lt; nr <span class="hljs-keyword">and</span> <span class="hljs-number">0</span> &lt;= y &lt; nc <span class="hljs-keyword">and</span> grid[x][y] == <span class="hljs-string">"1"</span>: <span class="hljs-comment">#位置满足要求且为岛屿</span><br>                            uf.union(r * nc + c, x * nc + y)<br>        <br>        <span class="hljs-keyword">return</span> uf.getCount()<br><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>算法</category>
      
      <category>优先遍历</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>算法</tag>
      
      <tag>优先遍历</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>博客bug排查</title>
    <link href="/2022/05/24/%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3/hexo-bug/"/>
    <url>/2022/05/24/%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3/hexo-bug/</url>
    
    <content type="html"><![CDATA[<blockquote><p>很久没有更新博客，突然发现博客的界面渲染崩掉了。</p></blockquote><p>执行命令<code>hexo g</code> 和<code>hexo s</code></p><p>都会出现警告：</p><figure class="highlight crmsh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs crmsh"><span class="hljs-literal">INF</span>O  Files loaded <span class="hljs-keyword">in</span> <span class="hljs-number">23</span> s<br>(<span class="hljs-keyword">node</span><span class="hljs-title">:11164</span>) Warning: Accessing non-existent <span class="hljs-keyword">property</span><span class="hljs-title"> </span>'lineno' of module exports inside circular dependency<br>(Use `<span class="hljs-keyword">node</span> <span class="hljs-title">--trace-warnings</span> ...` to show where the warning was created)<br>(<span class="hljs-keyword">node</span><span class="hljs-title">:11164</span>) Warning: Accessing non-existent <span class="hljs-keyword">property</span><span class="hljs-title"> </span>'column' of module exports inside circular dependency<br>(<span class="hljs-keyword">node</span><span class="hljs-title">:11164</span>) Warning: Accessing non-existent <span class="hljs-keyword">property</span><span class="hljs-title"> </span>'filename' of module exports inside circular dependency<br>(<span class="hljs-keyword">node</span><span class="hljs-title">:11164</span>) Warning: Accessing non-existent <span class="hljs-keyword">property</span><span class="hljs-title"> </span>'lineno' of module exports inside circular dependency<br>(<span class="hljs-keyword">node</span><span class="hljs-title">:11164</span>) Warning: Accessing non-existent <span class="hljs-keyword">property</span><span class="hljs-title"> </span>'column' of module exports inside circular dependency<br>(<span class="hljs-keyword">node</span><span class="hljs-title">:11164</span>) Warning: Accessing non-existent <span class="hljs-keyword">property</span><span class="hljs-title"> </span>'filename' of module exports inside circular dependency<br></code></pre></td></tr></tbody></table></figure><p>虽然是警告，但是以前没有遇到过，因此怀疑是版本的问题导致hexo和node不兼容。</p><p><strong>解决方案1</strong>：</p><p>出现警告，是因为<code>node</code>版本太高，切换成低版本的<code>node</code>来安装<code>Hexo</code>就可以了.但是不太建议，容易引起其他的依赖问题。</p><p><strong>解决方案2：</strong></p><p>找到下面的文件：<br><code>node_modules\stylus\lib\nodes\index.js</code><br>在<code>index.js</code>文件中加上以下代码</p><figure class="highlight ini"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">exports.lineno</span> = null<span class="hljs-comment">;</span><br><span class="hljs-attr">exports.column</span> = null<span class="hljs-comment">;</span><br><span class="hljs-attr">exports.filename</span> = null<span class="hljs-comment">;</span><br></code></pre></td></tr></tbody></table></figure><blockquote><p>但是在我的index.js文件中已经设置了该代码。所以还是不太行~~</p></blockquote><p><strong>解决办法3：</strong></p><p>Hexo 这里的 warning是由于<a href="https://link.zhihu.com/?target=https%3A//github.com/stylus/stylus">stylus</a>导致的，幸运的是stylus 在 0.54.8 版本修复了这个问题，所以对于 Hexo 用户来说，重新装一下<code>hexo-renderer-stylus</code>，就可正常使用。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">npm install hexo-renderer-stylus --save<br></code></pre></td></tr></tbody></table></figure><p>成功解决！</p><blockquote><p>参考博客：</p><p><a href="https://zhuanlan.zhihu.com/p/397813964">https://zhuanlan.zhihu.com/p/397813964</a></p><p><a href="https://blog.csdn.net/m0_46374969/article/details/121727107">https://blog.csdn.net/m0_46374969/article/details/121727107</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>报错解决</category>
      
    </categories>
    
    
    <tags>
      
      <tag>报错解决</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>常见的hexo问题记录和解决</title>
    <link href="/2022/05/22/%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3/hexo-common-bug/"/>
    <url>/2022/05/22/%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3/hexo-common-bug/</url>
    
    <content type="html"><![CDATA[<h2 id="⛄Hexo常见问题">⛄Hexo常见问题</h2><h3 id="👀问题一，hexo命令运行出错">👀问题一，hexo命令运行出错</h3><p><strong>①问题描述</strong>：运行Hexo报错hexo : 无法加载文件hexo.ps1，因为在此系统上禁止运行脚本</p><p>使用如下命令安装 <code>Hexo</code>成功：</p><figure class="highlight avrasm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">PLAINTEXT<br>npm install hexo-<span class="hljs-keyword">cli</span> -g<br></code></pre></td></tr></tbody></table></figure><p>运行<code>hexo -v、hexo clean、hexo g、hexo s、hexo d</code>会出现错误：</p><figure class="highlight excel"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs excel">PLAINTEXT<br>bashPS <span class="hljs-symbol">C:</span>\Users\Desktop\heartlovelife&gt; hexo s<br>hexo <span class="hljs-symbol">:</span> 无法加载文件 <span class="hljs-symbol">C:</span>\Users\AppData\Roaming\npm\hexo.<span class="hljs-symbol">ps1</span>，因为在此系统上禁止运行脚本。有关详细信息，请参阅 htt<span class="hljs-symbol">ps:</span>/go.microsoft.com/fwlink/?LinkID<br>=<span class="hljs-number">135170</span> 中的 about_Execution_Policies。<br>所在位置 行<span class="hljs-symbol">:1</span> 字符<span class="hljs-symbol">:</span> <span class="hljs-number">1</span><br>+ hexo s<br>+ ~~~~<br>    + CategoryInfo          <span class="hljs-symbol">:</span> SecurityErr<span class="hljs-symbol">or:</span> (<span class="hljs-symbol">:</span>) []，PSSecurityException<br>    + FullyQualifiedErrorId <span class="hljs-symbol">:</span> UnauthorizedAccess<br></code></pre></td></tr></tbody></table></figure><p><strong>②解决方案</strong>：针对<code>windows</code>系统，设置-&gt;隐私和安全性-&gt;开发者选项-&gt;允许本地<code>PowerShell</code>脚本在为签名的情况下运行。</p><h3 id="👀问题二，-hexo-init初始化失败">👀问题二， <code>hexo init</code>初始化失败</h3><p><strong>①问题描述</strong>：<code>WARN Failed to install dependencies. Please run ‘npm install’ manually!</code></p><p><strong>②解决方案</strong>：如果我们输入命令<code>npm install</code>还是会出现错误，这时我们需要修改<code>npm</code>的镜像：</p><figure class="highlight vala"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs vala">PLAINTEXT<br>bashnpm -v<br><span class="hljs-meta"># 修改镜像</span><br>npm install -g cnpm --registry=https:<span class="hljs-comment">//registry.npm.taobao.org</span><br><span class="hljs-meta"># 初始化</span><br>hexo init<br><span class="hljs-meta"># 利用cnpm执行cnpm install</span><br>cnpm install <br></code></pre></td></tr></tbody></table></figure><h3 id="👀问题三，hexo-d部署失败">👀问题三，<code>hexo d</code>部署失败</h3><p><strong>①问题描述</strong>：<code>fatal: unable to auto-detect email address....</code></p><figure class="highlight applescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs applescript">PLAINTEXT<br>bashfatal: unable <span class="hljs-keyword">to</span> auto-detect email address<br><span class="hljs-keyword">error</span>:src refspec HEAD <span class="hljs-keyword">does</span> <span class="hljs-keyword">not</span> match any<br><span class="hljs-keyword">error</span>:failed <span class="hljs-keyword">to</span> push <span class="hljs-keyword">some</span> refs <span class="hljs-keyword">to</span> <span class="hljs-string">"*******"</span><br>FATAL {<br>err:Error:Spawn failed<br>.......<br>}<br></code></pre></td></tr></tbody></table></figure><p><strong>②解决方案</strong>：在文件浏览器中勾选显示隐藏的项目，进入我们的博客目录</p><figure class="highlight taggerscript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs taggerscript">PLAINTEXT<br>D:<span class="hljs-symbol">\B</span>log_Hexo<span class="hljs-symbol">\B</span>log<span class="hljs-symbol">\.</span>deploy_git<span class="hljs-symbol">\.</span>git<br></code></pre></td></tr></tbody></table></figure><p>找到config文件，添加</p><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs nix">PLAINTEXT<br><br>[user]<br><span class="hljs-attr">email</span> = <span class="hljs-number">3086786161</span>@qq.com<br><span class="hljs-attr">name</span> = HeartLoveLife<br>[core]<br><span class="hljs-attr">repositoryformatversion</span> = <span class="hljs-number">0</span><br><span class="hljs-attr">filemode</span> = <span class="hljs-literal">false</span><br><span class="hljs-attr">bare</span> = <span class="hljs-literal">false</span><br><span class="hljs-attr">logallrefupdates</span> = <span class="hljs-literal">true</span><br><span class="hljs-attr">symlinks</span> = <span class="hljs-literal">false</span><br><span class="hljs-attr">ignorecase</span> = <span class="hljs-literal">true</span><br>[branch <span class="hljs-string">"main"</span>]<br><span class="hljs-attr">remote</span> = https://github.com/HeartLoveLife/HeartLoveLife.github.io.git<br><span class="hljs-attr">merge</span> = refs/heads/main<br></code></pre></td></tr></tbody></table></figure><h3 id="👀问题四，hexo-s出现警告">👀问题四，<code>hexo s</code>出现警告</h3><p><strong>①问题描述</strong>：<code>Accessing non-existent property '*' of module exports inside circular dependency</code></p><figure class="highlight crmsh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">PLAINTEXT<br><br>bash<span class="hljs-literal">INF</span>O  <span class="hljs-literal">Start</span> processing<br><span class="hljs-literal">INF</span>O  Hexo is running at http://localhost:<span class="hljs-number">4000</span>/ . Press Ctrl+C to <span class="hljs-literal">stop</span>.<br>(<span class="hljs-keyword">node</span><span class="hljs-title">:60224</span>) Warning: Accessing non-existent <span class="hljs-keyword">property</span><span class="hljs-title"> </span>'lineno' of module exports inside circular dependency<br>(Use `<span class="hljs-keyword">node</span> <span class="hljs-title">--trace-warnings</span> ...` to show where the warning was created)<br>(<span class="hljs-keyword">node</span><span class="hljs-title">:60224</span>) Warning: Accessing non-existent <span class="hljs-keyword">property</span><span class="hljs-title"> </span>'column' of module exports inside circular dependency<br>(<span class="hljs-keyword">node</span><span class="hljs-title">:60224</span>) Warning: Accessing non-existent <span class="hljs-keyword">property</span><span class="hljs-title"> </span>'filename' of module exports inside circular dependency<br>(<span class="hljs-keyword">node</span><span class="hljs-title">:60224</span>) Warning: Accessing non-existent <span class="hljs-keyword">property</span><span class="hljs-title"> </span>'lineno' of module exports inside circular dependency<br>(<span class="hljs-keyword">node</span><span class="hljs-title">:60224</span>) Warning: Accessing non-existent <span class="hljs-keyword">property</span><span class="hljs-title"> </span>'column' of module exports inside circular dependency<br>(<span class="hljs-keyword">node</span><span class="hljs-title">:60224</span>) Warning: Accessing non-existent <span class="hljs-keyword">property</span><span class="hljs-title"> </span>'filename' of module exports inside circular dependency<br></code></pre></td></tr></tbody></table></figure><p><strong>②解决方案</strong>：出现警告，是因为<code>node</code>版本太高，切换成低版本的<code>node</code>来安装<code>Hexo</code>就可以了</p><h2 id="⛄Hexo更换主题">⛄Hexo更换主题</h2><p>在博客的项目文件夹下打开<code>git bash</code>执行命令，以<code>hexo-theme-butterfly</code>主题为例</p><figure class="highlight crmsh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">PLAINTEXT<br>git <span class="hljs-keyword">clone</span> <span class="hljs-title">-b</span> <span class="hljs-keyword">master</span> <span class="hljs-title">https</span>://github.com/jerryc127/hexo-theme-butterfly.git themes/butterfly<br></code></pre></td></tr></tbody></table></figure><p>运行成功之后，在项目文件夹<code>source</code>中可以查看到新的主题<code>themes</code>文件夹：<code>butterfly</code></p><p>在博客的项目文件夹下，修改<code>_config.yml</code>配置文件如下:</p><figure class="highlight avrasm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">YML<br><span class="hljs-meta"># theme: landscape  默认主题</span><br><span class="hljs-symbol">theme:</span> butterfly<br></code></pre></td></tr></tbody></table></figure><p>此时主题还不能正常配置使用，需要安装<code>pug</code> 以及<code>stylus</code> 的渲染器:</p><figure class="highlight mel"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mel">PLAINTEXT<br>bash# npm install hexo-<span class="hljs-keyword">renderer</span>-pug hexo-<span class="hljs-keyword">renderer</span>-stylus --save<br>cnpm install hexo-<span class="hljs-keyword">renderer</span>-pug hexo-<span class="hljs-keyword">renderer</span>-stylus --save<br></code></pre></td></tr></tbody></table></figure><p>执行<code>hexo s</code>部署到本地运行</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">PLAINTEXT<br><span class="hljs-meta">bash#</span><span class="bash"> 清除缓存b.json 和已生成的静态文件 public</span><br>hexo clean<br><span class="hljs-meta">#</span><span class="bash"> 生成静态页面到默认设置的 public 文件夹</span><br>hexo g<br><span class="hljs-meta">#</span><span class="bash"> 启动本地服务器，用于预览</span><br>hexo s<br><span class="hljs-meta">#</span><span class="bash"> 自动生成网站静态文件，并部署到设定的仓库或上传部署至服务端</span><br>hexo d<br></code></pre></td></tr></tbody></table></figure><p>默认地址：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">PLAINTEXT<br>http://localhost:4000/<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>报错解决</category>
      
    </categories>
    
    
    <tags>
      
      <tag>报错解决</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>现代管理理论和方法复习整理</title>
    <link href="/2022/04/26/%E8%AF%BE%E7%A8%8B%E5%A4%8D%E4%B9%A0/manager-review/"/>
    <url>/2022/04/26/%E8%AF%BE%E7%A8%8B%E5%A4%8D%E4%B9%A0/manager-review/</url>
    
    <content type="html"><![CDATA[<h1>现代管理理论和方法</h1><h2 id="一-题型">一 题型</h2><p><strong>一、选择（20分）</strong><br><strong>二、概念（10分）</strong><br><strong>三、简答（<code>4x5</code>分）</strong><br><strong>四、论述（18分）</strong><br><strong>五、案例分析（<code>4x8</code>分）</strong></p><h2 id="二-概念及简答">二 概念及简答</h2><h3 id="管理者类型">管理者类型</h3><h4 id="1，高层管理者">1，高层管理者</h4><h5 id="决策层">决策层</h5><ul><li>对组织负有<strong>全面责任</strong></li><li>决定<strong>组织</strong>大政<strong>方针</strong>（目标、战略）。</li><li>对外<strong>协调和交往</strong></li></ul><h4 id="2，中层管理者">2，中层管理者</h4><h5 id="执行层">执行层</h5><ul><li><strong>贯彻</strong>大政方针，<strong>指挥基层管理</strong>者。</li><li><strong>分配</strong>具体<strong>任务</strong>，注重日常管理事务。</li></ul><h4 id="3，基层管理者">3，基层管理者</h4><h5 id="作业层">作业层</h5><ul><li><strong>直接</strong>指挥和<strong>监督现场作业</strong>人员。</li><li><strong>协调</strong>基层<strong>人员</strong>，<strong>完成</strong>上级下达的各项<strong>计划和指令</strong>。</li></ul><p><img src="https://picture.mulindya.com/image-20220423140500852.png" alt=""></p><p>基层管理者：领导，组织</p><p>中层管理者：领导，组织</p><p>高层管理者：组织，计划</p><h3 id="2-1-三种技能-⭐">2.1 三种技能 ⭐</h3><ol><li>技术技能<ul><li>从事自己<strong>管理范围内</strong>的工作所需的<strong>技术和方法</strong>。方能更好地<strong>指导下属</strong>工作、更好地<strong>培养下属</strong>，才能赢得下级的尊重。</li></ul></li><li>人际技能<ul><li>与<strong>组织中上下左右的人打交道</strong>的能力，包括联络、处理和协调<strong>组织内外人际关系</strong>、激励和诱导<strong>下属积极性</strong>、正确指导和指挥成员开展工作的能力。</li><li>人际技能，对各层管理者都很重要。</li></ul></li><li>概念技能<ul><li>对<strong>事物的洞察、分析、判断、抽象和概括</strong>的能力。包括：对复杂环境和管理问题的观察、分析能力；对全局性的、战略性的、长远性的重大问题处理与决断的能力；对突发性紧急处境的应变能力等。其核心是观察力和思维能力。</li><li>出色的概念技能，可使管理者作出更佳的决策，对高层管理者尤为重要。</li></ul></li></ol><p><img src="https://picture.mulindya.com/image-20220423135432843.png" alt=""></p><h3 id="2-2-计划-⭐">2.2 计划 ⭐</h3><h4 id="2-2-1-概念">2.2.1 概念</h4><p>计划工作是管理的首要职能，其他工作都只有在确定了目标、制订了计划以后才能展开，并将围绕着计划的变化而变化。 但在我国的管理实践中，计划工作普遍不受重视，致使各项工作缺乏明确的目标，短期行为严重，结果不确定程度较大。</p><p><img src="https://picture.mulindya.com/image-20220423154916385.png" alt=""></p><p>狭义计划是只包含制定计划；</p><p>狭义的计划工作是指管理者事先对未来应采取的行动所作的谋划和安排。</p><h5 id="计划工作内容">计划工作内容</h5><p>5W1H：what，why，when，where，who，how</p><h5 id="计划工作的基本特征">计划工作的基本特征</h5><ol><li>目的性</li><li>主导性</li><li>普遍性</li><li>效率性</li><li>创造性</li></ol><h5 id="编制计划的方法">编制计划的方法</h5><ul><li><code>PDCA</code>循环法（戴明循环）</li><li>滚动计划法</li><li>网络计划技术</li><li>线性规划法</li></ul><h4 id="2-2-2-滚动计划-⭐">2.2.2 滚动计划 ⭐</h4><p>是一种<strong>定期修订未来计划</strong>的方法。</p><h5 id="编制方法">编制方法</h5><p>在原计划的基础上，每经过<strong>一段固定时期（滚动期）</strong>，便根据计划的执行情况和环境变化情况修订计划，并逐期向前推移，使<strong>短期计划、中期计划和长期计划有机结合起来。</strong></p><h5 id="应用场景">应用场景</h5><p>该方法主要应用于长期计划的制定和调整。</p><h5 id="特定">特定</h5><ul><li>计划分为若干个执行期，其中<strong>近期行动计划编制得详细具体，而远期计划则相对粗略。</strong></li><li><strong>计划执行一定时期</strong>，就根据执行情况和环境变化对以后各期计划内容进行<strong>修改、调整。</strong></li><li>组织的计划工作始终是一个<strong>动态过程</strong>。该方法避免了计划的凝固化，提高了计划的<strong>适应</strong>性。</li></ul><h5 id="评价">评价</h5><ul><li><strong>推迟</strong>了对远期计划的<strong>决策</strong>，<strong>增加</strong>了计划的<strong>准确性</strong>，<strong>提高</strong>了计划工作的<strong>质量</strong>（优）</li><li>既保证了<strong>长期计划的指导作用</strong>，使得各期计划能够基本<strong>保持一致</strong>；（优）</li><li>也保证了计划应具有的<strong>弹性</strong>，特别是在环境剧烈变化的今天，有助于提高组织的<strong>应变能力</strong>。（优）</li><li>加大了计划的工作量。（缺）</li></ul><h4 id="2-2-3-网络计划-⭐">2.2.3 网络计划 ⭐</h4><ul><li>首先，用<strong>网络图的形式</strong>来表达一项计划中各项工作(任务、活动、工序等)的<strong>先后顺序和相互关系</strong>；</li><li>其次,通过计算找出计划中的<strong>关键工序和关键线路</strong>；</li><li>然后，通过不断<strong>改善网络图选择最优方案</strong>,并在计划<strong>执行过程中</strong>进行有效的监督控制,保证取得最佳的经济效益。</li></ul><h3 id="2-3-组织">2.3 组织</h3><h5 id="概念">概念</h5><p>进行<strong>专业分工</strong>，建立使各部分有机协调配合的系统。</p><h5 id="任务">任务</h5><p>建立<strong>组织结构</strong>和明确<strong>组织</strong>内部的相互<strong>关系</strong></p><h5 id="结果">结果</h5><p>提供组织结构系统图、部门职能说明书、岗位结构图、职务说明书、岗位工作标准、业务流程与管理标准。</p><h5 id="组织设计的原则">组织设计的原则</h5><ul><li><strong>因事设职、因职用人</strong>。即“事事有人做”，而非“人人有事做”。</li><li><strong>权责对等</strong>。权小于责，任务无法完成；权大于责，会导致权力滥用。</li><li><strong>命令统一</strong>。组织中的任何成员只能接受一个上司的领导，不允许存在“多头领导”、“越级指挥”现象。</li></ul><h4 id="2-3-1-直线组织">2.3.1 直线组织</h4><p><img src="https://picture.mulindya.com/image-20220423164534211.png" alt=""></p><p>直线型组织结构是最简单、最原始的一种组织结构类型。“直线”在这里指，职权从组织上层“流向”组织的基层。</p><p>①每个主管人员在其管辖的范围内，对直接下属有绝对的职权或完全的职权。</p><p>②每个下属只有一个上级，只接受一个上级的指挥，也只向一个上级报告。</p><h5 id="优点">优点</h5><p>结构简单，命令统一，责任明确；</p><p>信息沟通快，决策迅速，管理效率高。</p><h5 id="缺点">缺点</h5><p>①管理工作简单粗放；</p><p>②主管人员负担过重；</p><p>③成员之间和部门之间横向联系差。</p><h5 id="适用范围：">适用范围：</h5><p>小型组织、企业初建阶段或现场作业管理。</p><h4 id="2-3-2-职能组织">2.3.2 职能组织</h4><p><img src="https://picture.mulindya.com/image-20220423164606846.png" alt=""></p><h5 id="概念-2">概念</h5><p>职能制组织结构<strong>按专业分工</strong>设置管理<strong>职能部门</strong>，各职能部门在其业务范围内有权向下级发布命令</p><p>每一级组织<strong>既服从上级</strong>的指挥，也<strong>听从几个职能部门</strong>的指挥。</p><h5 id="优点-2">优点</h5><p>能发挥专家的作用，对下级工作的指导较为具体，减轻了上层主管人员的负担。</p><h5 id="缺点-2">缺点</h5><p>容易形成多头领导，造成下级无所适从,极大违背了统一指挥原则。</p><h5 id="适用范围">适用范围</h5><p>任务较复杂的<strong>社会管理组织</strong>，如高校、医院、图书馆、设计院、会计事务所。</p><h4 id="2-3-3-直线职能组织">2.3.3 直线职能组织</h4><p><img src="https://picture.mulindya.com/image-20220423164853802.png" alt=""></p><h5 id="概念-3">概念</h5><p>直线职能制组织结构结合了直线型及职能型的优点，在<strong>坚持直线指挥的前提下，充分调动各职能部门的作用</strong>。<br>职能部门通常拥有参谋权，但在某些特殊的任务上可能被授予一定的指挥权。当参谋部门与下属直线部门产生矛盾时，由上层直线主管协调解决。</p><h5 id="优点-3">优点</h5><p>既保证了<strong>集中统一的指挥</strong>，又能发<strong>挥各类专家的作用</strong>，大大提高了管理的有效性。</p><h5 id="缺点-3">缺点</h5><p><strong>协调工作量大</strong>、<strong>难</strong>以培养<strong>综合型管理</strong>人才。</p><h5 id="适用范围-2">适用范围</h5><p>用<strong>标准化技术进行常规性大批量生产</strong>的场合。 我国<strong>大多数企业</strong>，尤其是生产制造企业均采用这种组织结构。</p><h4 id="2-3-4-事业部组织">2.3.4 事业部组织</h4><p><img src="https://picture.mulindya.com/image-20220423165222886.png" alt=""></p><p><img src="https://picture.mulindya.com/image-20220423165248801.png" alt=""></p><h5 id="概念-4">概念</h5><p>事业部制是一种在国外大企业中普遍采用的组织结构形式。</p><p>它是在<strong>总公司领导</strong>之下按<strong>产品分类</strong>,统一进行产品设计、原料采购、生产和销售,相对独立核算、自负盈亏的部门分权化结构。</p><p>该结构是由20世纪20年代初美国通用汽车公司副总斯隆研究和设计出来的。</p><h5 id="优点：">优点：</h5><p>1)<strong>责权利明确</strong>；<br>2)<strong>决策迅速</strong>，提高了管理的<strong>灵活性和适应性</strong>；<br>3)通过事业部独立的生产经营活动，能为公司不断培养出<strong>高级管理人才</strong>。</p><h5 id="缺点-4">缺点</h5><p>1)机构重叠，增加了<strong>管理成本</strong>；<br>2)<strong>相互支援性差；</strong><br>3)易产生本位主义，引起<strong>内耗</strong>。</p><h5 id="适用范围-3">适用范围</h5><p>主要适用于产品多样化和从事多元化经营的组织。</p><h4 id="2-3-5-矩阵组织">2.3.5 矩阵组织</h4><p><img src="https://picture.mulindya.com/image-20220423170327491.png" alt=""></p><p>矩阵制组织结构<strong>综合了职能制和事业部制</strong>的优点，按职能和产品（项目）组合成一个<strong>双重结构</strong>。在矩阵制组织中，每一个成员既隶属于纵向的职能单位，又隶属于一个或几个横向的产品（项目）单位。</p><h5 id="优点-4">优点</h5><ul><li>加强了横向联系；</li><li>专业设备和人员得到了充分利用，具有较大的机动性；</li><li>促进各种专业人员互相帮助，互相激发。</li></ul><h5 id="缺点-5">缺点</h5><p>双重领导问题。</p><h5 id="适应范围">适应范围</h5><p>适应于外界环境<strong>变化非常剧烈</strong>，组织需要处理的信息量巨大，分享组织资源的要求特别迫切等情况，如<strong>大型运动会组委会</strong>、<strong>电影制片</strong>应用研究单位 。</p><h4 id="2-3-6-授权">2.3.6 授权</h4><h5 id="集权和分权">集权和分权</h5><p>集权与分权是用来描述决策权在组织指挥链上的分布情况的一对概念。</p><ol><li>权力较多地集中在组织的高层，即为集权；</li><li><strong>权力较多地下放给基层，则为分权。</strong></li></ol><p>职权的<strong>集中和分散是一种趋向性，是一种相对的状态</strong>。现实中没有绝对的集权与分权。</p><h6 id="特点">特点</h6><ol><li>集权有利于组织实现统一指挥、协调工作和更为有效的控制；但另一方面会加重上层管理者的负担，从而影响决策质量，且不利于调动下属的积极性。分权的优缺点则正好相反。</li><li>我们要研究的不是应该集权还是分权，而是哪些权力宜于集中，哪些权力宜于分散；何时集权的成分应多一点，何时需要较多的分权。</li></ol><blockquote><p>计划、人事、财务等决策权应较多地集中于高层；业务与日常管理权应尽可能多地放给基层。</p></blockquote><h5 id="分权的标志">分权的标志</h5><p>①决策的频度或数目</p><p>②决策的重要性</p><p>③决策的幅度</p><p>④对下级决策的控制程度</p><h5 id="分权的途径">分权的途径</h5><ul><li>制度分权</li><li>工作授权</li></ul><p><img src="https://picture.mulindya.com/image-20220423195028163.png" alt=""></p><h3 id="2-4-领导">2.4 领导</h3><h5 id="含义">含义</h5><ul><li>斯托格迪（Ralph M.Stogdill）：领导是对组织内群体或个人施加影响的活动过程。</li><li>泰瑞(George R.Terry) ：领导是影响人们自动为达到群体目标而努力的一种行为。</li><li>罗伯特(Johnnie L.Roberts)：领导是在某种条件下，经由意见交流的过程所实行出来的一种为了达到某种目标的影响力。</li><li>戴维斯(Keith Davis):领导是一种说服他人热心于一定目标的能力。</li></ul><h5 id="国内观点">国内观点</h5><h6 id="传统观点">传统观点</h6><p>​    领导是组织赋予一个人职位和权力，以率领其下属实现组织目标。</p><h6 id="现代观点">现代观点</h6><p>​    认为领导是一种影响力，是对人们施加影响，从而使人们心甘情愿地为实现组织目标而努力的艺术过程。</p><h5 id="领导的实质">领导的实质</h5><p>对个体和群体<strong>施加影响力</strong>，处理好<strong>人际关系</strong>。</p><h4 id="2-4-影响力来源">2.4. 影响力来源</h4><ul><li><strong>职位</strong>权力<ul><li><em>法定</em>权力：利用下属的信任来影响他们的权力。</li><li><em>奖赏</em>权力：通过给予别人期望得到的东西来影响他们的行为。</li><li><em>强制</em>权力：通过惩罚来影响别人行为的能力。</li></ul></li><li><strong>个人</strong>权力<ul><li><em>专家</em>权力：个人通过别人需要的知识、经验或消息来影响别人行为的能力。</li><li>参照（<em>模范</em>）权力</li></ul></li></ul><blockquote><p>领导作用：</p><p>指挥作用－－指点迷津、明确方向；<br>协调作用－－协调关系、调解矛盾；<br>激励作用－－排忧解难、鼓舞斗志；<br>浇灌作用－－上下沟通、培养情感;<br>先行作用－－身先士卒、同舟共济。</p></blockquote><p><img src="https://picture.mulindya.com/image-20220423205720348.png" alt=""></p><h3 id="2-5-控制">2.5 控制</h3><h5 id="概念-5">概念</h5><p>对<strong>组织内部</strong>的管理<strong>活动</strong>及其<strong>效果</strong>进行衡量和校正，以确保<strong>组织的目标及计划得以实现</strong>。是直线主管人员的一项主要职责<br>[检查工作是否按既定的计划、标准和方法进行，发现偏差，分析原因，进行纠正，以确保组织目标实现的活动]</p><h5 id="控制与计划二者间的联系">控制与计划二者间的联系</h5><p>1、计划提供了控制的标准，而控制则是按计划指导实施的行为，是实施计划的保证。<br>2、计划工作有赖于获取各个部门、各生产线的实际状况才能作出，而这些信息的获取是通过控制过程得到的，完善的管理信息系统对计划、控制工作都是基础性的。<br>3、没有计划来表明控制的目标，管理者不可能进行有效的控制，而仅有计划，没有控制，管理工作不可能成为一个闭环系统，目标也不可能有效实现，计划和控制都是完成组织目标不可或缺的，是互相依存的。</p><h4 id="2-5-1-前馈控制">2.5.1 前馈控制</h4><p>前馈控制：<strong>后果还未出现</strong>，还来得及采取纠正措施时，提供相应信息，使主管人员采取相应措施，<strong>防患于未然</strong><br>方法：不断利用最新的信息进行<strong>预测</strong>，把所<strong>期望的结果同预测的结果</strong>进行比较，采取措施使投入和实施活动与期望的结果相吻合。</p><h5 id="举例">举例</h5><ul><li>高射炮打飞机时有一定的提前量</li><li>司机上坡时为车速不致降低加大油门</li></ul><h4 id="2-5-2-反馈控制（控制工作的主要方式）">2.5.2 反馈控制（控制工作的主要方式）</h4><p>根据系统的<strong>输出与标准间的差距</strong>，引发更正错误的行为过程，达到控制的目的<br>主要问题：存在着<strong>时间滞后</strong>，从发现偏差到采取更正措施之间有时间延迟——影响了控制的有效性。<br>有时可能已出现一定的后果与损失，发现一批产品合格率降低，将次、废品挑出来返工；或调整机器运行状态已在系统内部造成损害，并且已无法补偿，反馈控制主要作用防止今后事态继续恶化。</p><h4 id="2-5-3-区别">2.5.3 区别</h4><p>反馈控制；以系统输出的变化信息作为馈入信息<br>目的：防止已经发生的偏差今后继续发生或<strong>恶化</strong></p><p>前馈控制：以系统输入的变化信息作为馈入信息输入<br>目的：<strong>控制系统</strong>的投入或过程，以获得期望的<strong>产出</strong><br>优点：克服了反馈控制中时滞带来的缺陷。</p><h3 id="2-6-决策">2.6 决策</h3><p>决策是指为了达到一定的目标，从<strong>多个可行方案中选择一个合理方案</strong>的<strong>分析判断过程</strong>。</p><h4 id="2-6-1-决策分类">2.6.1 决策分类</h4><h5 id="按决策的重要程度">按决策的重要程度</h5><ul><li>战略决策——高层管理者</li><li>战术决策——中层管理者</li><li>业务决策——基层管理者</li></ul><h5 id="按决策的重复程度">按决策的重复程度</h5><ul><li>程序化决策（结构良好的决策）<ul><li>重复出现的、日常的例行事务</li></ul></li><li>非程序化决策（结构不良的决策）<ul><li>一次性、新出现的、偶然发生的问题</li></ul></li></ul><h5 id="按参与人数的多少">按参与人数的多少</h5><ul><li>群体决策</li><li>个体决策</li></ul><h5 id="按决策的可靠程度">按决策的可靠程度</h5><ul><li>确定型决策</li><li>风险型决策</li><li>不确定型决策</li></ul><h4 id="2-6-2-科学决策的基本观点">2.6.2 科学决策的基本观点</h4><p>科学决策遵循的是满意原则</p><ol><li>决策要有明确的目的</li><li>决策要有若干可行的备择方案</li><li>决策要进行方案的分析比较</li><li>决策结果是选择满意的方案</li><li>决策是一个分析判断过程</li><li>决策是管理者从事管理工作的基础</li></ol><h4 id="2-6-3-程序化决策与非程序化决策-⭐">2.6.3 程序化决策与非程序化决策 ⭐</h4><p><img src="https://picture.mulindya.com/image-20220423153912602.png" alt=""></p><h3 id="2-7-SWOT分析方法-⭐">2.7 SWOT分析方法 ⭐</h3><p>通过对企业综合情况进行客观公正的评价，发现问题，找到解决方法，并明确发展方向，且能将问题按轻重缓急分类。</p><ul><li>Strength</li><li>Weakness</li><li>Opportunity</li><li>Threat</li></ul><p><img src="https://picture.mulindya.com/image-20220423154631076.png" alt=""></p><h2 id="三，简答">三，简答</h2><h3 id="3-1泰勒的科学管理理论">3.1泰勒的科学管理理论</h3><h4 id="3-1-1-科学管理理论的主要观点">3.1.1 科学管理理论的主要观点</h4><p>1、科学管理的中心是提高<strong>效率</strong>。<br>2、达到最高工作效率的重要手段，是用<strong>科学的管理方法</strong>代替旧的经验管理。<br>3、<strong>劳资双方</strong>的“精神革命”。</p><h4 id="3-1-2-管理制度">3.1.2 管理制度</h4><p>1、规定<strong>科学</strong>的<strong>操作方法</strong>。<br>2、实行<strong>差别计件工资制</strong>。<br>3、对工人进行科学的<strong>选择、培训和提高</strong>。<br>4、制定科学的<strong>工艺规程</strong>，并用<strong>文件形式固定</strong>下来以利推广。<br>5、<strong>管理</strong>职能与<strong>作业</strong>职能<strong>分离</strong>。</p><h4 id="3-1-3-评价">3.1.3 评价</h4><h5 id="优点-5">优点</h5><ul><li>泰罗是世界上第一个提出<strong>系统性管理理论</strong>的人。</li><li>科学管理理论使管理从<strong>经验走向科学</strong>。</li><li>极大地推动了生产的发展和社会经济的<strong>繁荣</strong>。</li><li><em><strong>工作定额原理、标准化原理、差别工资制度、管理职能的分离</strong></em>等主张一直沿用至今。</li></ul><h5 id="缺点-6">缺点</h5><ul><li>把工人看成是<strong>纯粹的“经济人”</strong>，是会说话的机器.</li><li>主要着眼于<strong>基层管理</strong>.</li></ul><h3 id="3-2-梅奥的霍桑试验">3.2 梅奥的霍桑试验</h3><p>（梅奥的“人际关系学说”）</p><blockquote><p>群体实验。对工人的群体行为进行观察和记录，发现非正式组织（成员在共同工作的过程中，由于共同的兴趣、爱好、社会感情而形成的社会团体）存在。</p></blockquote><h4 id="结论">结论</h4><ul><li>工人首先是**“社会人”**，而不是早期科学管理理论所描述的“经济人”。</li><li><strong>提高工人的“士气”<strong>是提高生产效率的</strong>关键</strong>。而“士气”的高低取决于<strong>工人社会欲望的满足程度</strong>。</li><li>重视**“非正式组织”**的存在和作用。</li><li>企业应采用<strong>新型的领导方法</strong>。</li></ul><h3 id="3-3-法约尔的组织理论">3.3 法约尔的组织理论</h3><h4 id="3-3-1-一般管理理论的主要内容">3.3.1 一般管理理论的主要内容</h4><ul><li>明确了管理的五大职能：<strong>计划、组织、指挥、协调、控制</strong></li><li>倡导管理教育：<strong>管理能力</strong>可以通过<strong>教育</strong>来获得</li><li>归纳了14条管理原则</li></ul><h4 id="3-3-2-14项管理原则">3.3.2 14项管理原则</h4><ol><li>劳动分工</li><li>权力与责任统一</li><li>纪律</li><li>统一指挥：一个人只能有一个上司</li><li>统一领导：一个领导，一个计划</li><li>个人利益服从整体利益</li><li>人员报酬要公平</li><li>权利的集中化</li><li>等级链：明确的职权等级系列（经理——主任——工长——监工——工头——工人）</li><li>秩序：成员明确其岗位</li><li>公正：对下属仁慈、公平</li><li>保持人员稳定</li><li>首创精神</li><li>团队精神</li></ol><h4 id="3-3-3-评价">3.3.3 评价</h4><ul><li>提出了管理活动所必需的<strong>五大职能</strong></li><li>提出了<strong>14项管理原则</strong></li><li>法约尔为<strong>管理教育</strong>提供了理论依据</li><li>为管理科学提供了一套科学的理论构架</li><li>一般管理理论后来成为管理过程学派的理论基础</li></ul><h3 id="3-4-X理论与Y理论–麦格雷戈">3.4 X理论与Y理论–麦格雷戈</h3><h4 id="3-4-1-X理论">3.4.1 X理论</h4><p>①大多数人生来就懒惰，总想少干点工作；</p><p>②一般人没什么雄心，不愿负责任，宁愿受人指挥；</p><p>③以自我为中心是人的本性，对组织（集体）的目标不关心；</p><p>④人缺乏自制能力，易受他人影响。</p><h5 id="特点-2">特点</h5><p>“X理论”的典型管理特点就是“胡萝卜加大棒”；</p><p>胡萝卜的作用在于<strong>满足人的物质追求</strong>，大棒的作用在于<strong>迫使人的行为与组织目标一致</strong>。</p><h4 id="3-4-2-Y理论">3.4.2 Y理论</h4><p>①人们愿意承担责任；</p><p>②人们因工作而变得成熟，有独立自主的倾向；</p><p>③人有自发、自制的能力 ；</p><p>④ 人们都热衷于发挥自己的才能和创造力。</p><h5 id="特点-3">特点</h5><p>“Y理论” 认为<strong>人性本善</strong>，只要充分发挥其优点，员工就能把工作做好。</p><p>管理者应尽量把工作安排得<strong>富有意义和挑战性</strong>，使工人工作之后能引以为自豪。</p><h3 id="3-5-理性决策的六步骤">3.5 <em>理性决策</em>的六步骤</h3><h4 id="3-5-1-步骤">3.5.1 步骤</h4><p>1）确认<strong>问题</strong> （ 比如报考哪所学校，选择哪家单位）<br>2）确定<strong>决策标准</strong><br>3）分配<strong>权重</strong><br>4）<strong>开发</strong>备选方案<br>5）<strong>评估</strong>备选方案<br>6）<strong>挑选</strong>最佳方案</p><h4 id="3-5-2-隐含假设">3.5.2 隐含假设</h4><ul><li><strong>问题是清晰</strong>的</li><li>所有<strong>备选方案</strong>已知</li><li><strong>偏好明确</strong>且稳定</li><li>决策<strong>没有</strong>时间或成本<strong>限制</strong></li></ul><h4 id="3-5-3-适用情况">3.5.3 适用情况</h4><ul><li>问题简单</li><li>备选方案不多</li><li>搜寻评估备选方案低成本</li></ul><p><img src="https://picture.mulindya.com/image-20220423145950895.png" alt=""></p><h4 id="3-5-6-有限理性">3.5.6 有限理性</h4><p>有限理性：信息不全面、思维加工的偏差</p><p><img src="https://picture.mulindya.com/image-20220423150118626.png" alt=""></p><h5 id="特点-4">特点</h5><p>备选方案被考虑的顺序是重要的；（最优化模型的选择结果与方案顺序无关）<br>最接近于现实并达到标准的方案最可能被选择</p><h3 id="3-6-计划工作的程序">3.6 计划工作的程序</h3><p>1 估量机会<br>2 确定目标<br>3 明确条件<br>4 拟定可供选择的方案<br>5 评价各种备选方案<br>6 选择方案<br>7 拟定辅助计划（派生计划）<br>8 编制预算</p><blockquote><p>诸葛亮的“隆中策”是我国最早、最大的成功计划工作案例之一。<br>隆中策的第一步是确定组织目标：兴汉室，图中原，统一天下。第二步是制定分步实施方案，即确定分步计划的阶段目标：第一，先取荆州为家，形成“三分天下”之势；第二，再取西川建立基业，壮大实力，以成鼎足之状；第三，“待天下有变，命一上将将荆州之兵以向宛、洛，将军身率益州之众以出秦川”，这样，“大业可成，汉室可兴矣”。隆中策的第三步是确定实现目标的指导方针：“北让曹操占天时，南让孙权占地利，将军可占人和”。内修政理，外结孙权，西和诸戎，南抚彝、越，等待良机。<br>隆中策又进一步对敌、我、友、天、地、人做了极为细致透彻的分析，论证了为什么应当有这样的指导方针。<br>试运用计划的相关知识对这一案例进行分析评价。</p><p>答：诸葛亮所作之隆中策并非主观臆断，而是在调查研究和预测的基础上，在于他准确、及时、充分地掌握信息。诸葛亮的信息来源，一靠交友，二靠云游，这才能做到知天下事、知天下人，不然怎么能画出西川54州图呢?<br>诸葛亮的隆中策不正是一项完整的计划工作吗？三分天下之后，如果不是后来关羽交恶东吴，丢了荆州；如果不是刘备又在战术上犯了错误，使鼎盛时期的蜀汉大伤元气；如果后主刘禅是明君，诸葛亮也不会功败垂成。蜀汉之所以被晋灭掉，并非隆中决策之失，而是执行计划有误。</p></blockquote><h3 id="3-7-PDCA循环">3.7 PDCA循环</h3><h4 id="3-7-1-含义">3.7.1 含义</h4><p>指任何一项工作都要先有</p><ol><li>计划（plan）</li></ol><p>然后按照计划的规定去</p><ol start="2"><li><p>执行（do）</p></li><li><p>检查（check）</p></li><li><p>总结（action）</p></li></ol><p>这个过程周而复始，不断循环前进，并进一步地提高水平</p><p><img src="https://picture.mulindya.com/image-20220423155822094.png" alt=""></p><h4 id="3-7-2-PDCA工作程序（4个阶段8个步骤）">3.7.2 PDCA工作程序（4个阶段8个步骤）</h4><p>1、分析现状，找出问题<br>2、分析产生问题的原因<br>3、要因确认<br>4、拟定措施、制定计划<br>5、执行措施、执行计划<br>6、检查验证、评估效果<br>7、标准化，固定成绩<br>8、处理遗留问题</p><h4 id="3-7-3-特点">3.7.3 特点</h4><ol><li>周而复始<ul><li>一定要按顺序进行，靠组织的力量来推动， 像车轮一样向前进。</li><li>一个循环结束了，解决了一部分问题，可能还有问题没有解决，或者又出现了新的问题，再进行下一个PDCA循环，依此类推，周而复始。</li></ul></li><li>大环套小环<ul><li>企业每个部门、车间、工段、班组，直至个人的工作均有一个PDCA循环，这样一层一层地解决问题，而且大环套小环，一环扣一环，小环保大环，推动大循环。</li></ul></li><li>阶梯式上升<ul><li>不是在同一水平上循环，每循环一次，就解决一部分问题，取得一部分成果，工作就前进一步，水平（质量水平和管理水平）就提高一步。</li><li>每通过一次PDCA循环，都要进行总结，提出新目标，再进行第二次PDCA循环，使质量管理的车轮滚滚向前。</li></ul></li></ol><h3 id="3-8-激励理论">3.8 激励理论</h3><h4 id="3-8-1-需求层次理论">3.8.1 需求层次理论</h4><p><img src="https://picture.mulindya.com/image-20220423200128240.png" alt=""></p><ol><li><p>人的需求是按<strong>重要性、从基本需求到复杂需求</strong>顺序排列的。五层次：</p><ol><li>生理需求</li><li>安全需求</li><li>友爱和归属需求</li><li>尊重的需要</li><li>自我实现</li></ol></li><li><p>需求<strong>层次递进规律</strong></p><p>只有在较低层次的需求基本满足后，才会上升至较高层次的需求</p></li><li><p>需求影响人的行为，只有<strong>未被满足的需求才可以激发行为</strong>。</p><p>人的最迫切的需要是激励行为的主导性动机</p><table><thead><tr><th><strong>需求</strong></th><th><strong>具体表现</strong></th><th><strong>组织激励措施</strong></th></tr></thead><tbody><tr><td><strong>生理需要</strong></td><td><strong>衣食住行、性</strong></td><td><strong>工作环境、条件、食堂、交通补贴、房贴、劳保用品</strong></td></tr><tr><td><strong>安全需要</strong></td><td><strong>工作保障、安全保障、稳定</strong></td><td><strong>终生雇佣、职业安全、工伤保险、医疗保险、失业保险</strong></td></tr><tr><td><strong>归属与爱的需要</strong></td><td><strong>优异、和谐的人际关系、认同、相互关爱</strong></td><td><strong>提供沟通与交流的机会、互助、娱乐制度、教育培训</strong></td></tr><tr><td><strong>尊重的需要</strong></td><td><strong>地位、名誉、认可、权力</strong></td><td><strong>公平晋升、奖励与表彰制度、职称、头衔、参与组织事务、职权与待遇</strong></td></tr><tr><td><strong>自我实现的需要</strong></td><td><strong>晋升、成就感、挑战性的工作、发明与创造</strong></td><td><strong>营造自我实现的工作条件、个人影响力的扩大、长期利润分配制度</strong></td></tr></tbody></table></li></ol><h5 id="评价-2">评价</h5><h6 id="优点-6">优点</h6><p>提供了一个比较科学的理论框架，成为激励理论的基础；<br>发现人的需要是从低级向高级发展的，并指出了每一层次需要的具体内容。</p><h6 id="缺陷">缺陷</h6><p>对需要的5个层次划分过于<strong>机械</strong>；<br>分析过于简单，缺乏实证基础。</p><h4 id="3-8-2-双因素理论-⭐">3.8.2 双因素理论 ⭐</h4><ul><li><strong>保健因素</strong>  这属于和工作<strong>环境或条件相关</strong>的因素；（实际，当下）<ul><li>如公司的政策和管理、人际关系、工作环境的条件、工作的安全性、工资和福利等，当人们得到这些方面的满足时，只是消除了不满，却不会调动人们的工作积极性。</li></ul></li><li><strong>激励因素</strong>  这属于和<strong>工作本身</strong>相关的因素；（抽象，未来）<ul><li>包括的：工作成就感、工作挑战性、工作中得到的<strong>认可与赞美</strong>、工作的<strong>发展前途</strong>、个人成才与晋升的机会等。当人们得到这些方面的满足时，会对工作产生浓厚的兴趣，产生很大的工作积极性。</li></ul></li></ul><h5 id="评价-3">评价</h5><ol><li>认识上，采取某项激励措施后不一定就带来满意，更不等于生产率的提高； 满足各种需要所引起的激励深度和效果是不一样的，注意区别保健因素与激励因素。</li><li><strong>工资和奖金不仅是保健因素，也具有激励作用 (取决于发放办法)</strong></li><li>内在激励的重要性增加–工作丰富化     等内在激励重要性增加</li><li>物质利益、工作条件等外部因素与工作安排、 量才录用等内在因素相结合</li></ol><h4 id="3-8-3-成就需求理论">3.8.3 成就需求理论</h4><h5 id="麦克利兰理论的基本内容">麦克利兰理论的基本内容</h5><p>（1）<strong>权力</strong>需要：影响和控制他人的欲望<br>（2）<strong>合群</strong>需要：建立亲密和友好的人际关系的欲望<br>（3）<strong>成就</strong>需要：追求卓越以实现目标的内驱力</p><blockquote><p>发现：高层次的管理者成就需要和权力需要越高， 而合群需要较低。高成就需要的人对企业、国家有重要作用</p></blockquote><h5 id="启发">启发</h5><p>1、高成就需要者喜欢能独立负责、可获得信息反馈,中度风险的工作环境</p><p>2、<strong>成就需求与业绩两者强烈正相关，归属需要则负相关</strong></p><p>3、<strong>归属</strong>需要和<strong>权力</strong>需要与<strong>管理的成功</strong>密切相关</p><p>4、可以通过<strong>培训</strong>激发员工的成就需要</p><h4 id="3-8-4-期望理论">3.8.4 期望理论</h4><p>由美国心理学家弗鲁姆提出。这一理论通过人们<strong>的努力行为与预期奖酬</strong>之间的因果关系来研究激励的过程。</p><p>认为人们对某项工作积极性的高低，取决于他对这种工作能<strong>满足其需要的程度 及 实现可能性大小</strong>的评价。</p><h5 id="具体">具体</h5><p>激励力量=效价×期望值 （M=V×E）</p><ul><li>激励力量(Motivation)：激励作用的大小</li><li>效价(Valence)：指<strong>目标对于满足个人需要的价值</strong></li><li>期望值(Expectancy)：指采取某种行动实现目标可能性的大小。</li></ul><h5 id="基本公式的扩展">基本公式的扩展</h5><p>​                  激励 = 效价 * 关联性 * 期望<br>​                        M   =    V   *      I       *    E<br>关联性 I 是工作<strong>绩效与所得报酬</strong>之间相关联系，取值范围是[-1，+1]</p><p><img src="https://picture.mulindya.com/image-20220423203355897.png" alt=""></p><h5 id="应用">应用</h5><p>1、确定适宜的绩效<strong>目标</strong>，提高<strong>期望值</strong><br>2、增强工作<strong>绩效</strong>与所得<strong>报酬</strong>之间的关联性，避免不守信<br>3、正确认识报酬在职工心中的效价，<strong>效价与期望</strong>之间的<strong>适度平衡</strong>，难度高的，重奖（赏）。<br>4、尽可能增加效价的综合值，加大期望行为与非期望行为间的效价差<br>5、绩效档次与效价等级之间内在相容</p><h4 id="3-8-5-公平理论">3.8.5 公平理论</h4><p>由美国心理学家亚当斯提出。该理论侧重研究<strong>报酬分配的公平性</strong>对员工积极性的影响，认为人的积极性不仅受其所得**绝对报酬（自己的实际收入）<strong>的影响，<em><strong>更重要</strong></em>的是受其</strong>相对报酬（自己收入与他人收入的比例）**的影响。</p><ul><li>横向比较（社会比较）：在同一时间内以自身同其他人的报酬相比较。</li><li>纵向比较（历史比较）：即拿自己不同时期的付出与报酬进行比较。</li></ul><p><img src="https://picture.mulindya.com/image-20220423204044599.png" alt=""></p><h5 id="比较结果">比较结果</h5><ul><li>情绪（生气、抱怨、压力）</li><li>态度（组织承诺、工作满意感）</li><li>行为（职责履行、组织公民、怠工）</li></ul><p>（1）<code>Op/Ip  =  Or/Ir</code>，交换是公平的，继续努力工作<br>（2） <code>Op/Ip  &lt; Or/Ir</code>,    吃亏,心理不平衡,情绪紧张<br>减少工作投入或要求增加收益<br>减少参照对象收益或要求增加其工作投入<br>（3） <code>Op/Ip  &gt;  Or/Ir</code>, 占了便宜，内心不安<br>增加自己投入或要求减少报酬<br>重新解释自己的投入与报酬</p><h5 id="复杂性">复杂性</h5><p>1、个人的<strong>主观判断</strong>、认知有关，对吃亏、占便宜感的非对称性<br>2、与<strong>个人所持有的公平标准</strong>有关<br>3、与<strong>绩效评定</strong>有关，数量或质量，时间，难度，复杂性</p><h5 id="在管理中的应用">在管理中的应用</h5><p>1、正确诱导，改变认知，公平心理疏导<br>2、科学考评，合理奖酬<br>3、各有依据，透明化奖励规则。帮助员工建立科学评判尺度</p><h3 id="3-9-领导理论">3.9 领导理论</h3><h4 id="3-9-1-三种领导方式理论">3.9.1 三种领导方式理论</h4><ul><li><strong>专断型</strong>领导方式<ul><li>所有政策均由领导者决定，所有工作步骤、技术、工作分配及组合也由领导者发号施令，要求下属绝对服从，领导者对下属较少接触。</li></ul></li><li><strong>民主型</strong>领导方式<ul><li>主要政策由组织成员集体讨论决定，领导者采取鼓励与协助态度；通过讨论，下属对工作全貌有所认识，对工作步骤和采用的技术有相当的选择机会。</li></ul></li><li><strong>放任型</strong>领导方式<ul><li>组织成员有完全的决策权，领导者放任自流，只给下属提供信息，偶尔表示意见。工作几乎完全依赖成员，个人自行负责。</li></ul></li></ul><h4 id="3-9-2-费德勒权变理论-⭐">3.9.2 费德勒权变理论 ⭐</h4><p><img src="https://picture.mulindya.com/image-20220423201512906.png" alt=""></p><p><img src="https://picture.mulindya.com/image-20220423201529524.png" alt=""></p><p>领导风格是与生俱来的，你不可能改变你的风格去适应变化的情境。因此提高领导的有效性实际上只有两条途径：<br>（1）替换领导者以适应环境。比如，如果群体所处的情境被评估为十分不利，而目前又是一个关系取向的管理者进行领导，那么替换一个任务取向的管理者则能提高群体绩效。<br>（2）改变情境以适应领导者。</p><h4 id="3-9-3-生命周期理论-⭐">3.9.3 生命周期理论 ⭐</h4><h5 id="主要观点">主要观点</h5><p>领导的<strong>风格</strong>应与下属的<strong>成熟程度</strong>相适应<br>1、情境：成熟度</p><ul><li>生理成熟度：独立、自主工作的技能、经验</li><li>心理成熟度：成熟的动机，负责任的意愿和能力组合出四种情境</li></ul><p>2、领导方式：两个维度</p><ul><li><p>工作行为</p></li><li><p>关系行为</p><p>组合：四种领导方式<br>1）、命令型<br>2）、说服型<br>3）、参与型<br>4）、授权型</p></li></ul><p><img src="https://picture.mulindya.com/image-20220423201608131.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>课程复习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>课程复习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AN IMAGE IS WORTH 16X16 WORDS</title>
    <link href="/2022/04/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87/vit/"/>
    <url>/2022/04/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87/vit/</url>
    
    <content type="html"><![CDATA[<blockquote><p>再读一遍vision transformer，笔记记录于pdf中，所以就直接放pdf在此处~ 😉</p></blockquote><h3 id="学习视频链接">学习视频链接</h3><p><a href="https://www.bilibili.com/video/BV15P4y137jb?spm_id_from=333.999.0.0">https://www.bilibili.com/video/BV15P4y137jb?spm_id_from=333.999.0.0</a></p><h3 id="pdf链接">pdf链接</h3><p><a href="https://paper.mulindya.com/newAN%20IMAGE%20IS%20WORTH%2016X16%20WORDS.pdf">https://paper.mulindya.com/newAN IMAGE IS WORTH 16X16 WORDS.pdf</a></p><h3 id="论文学习链接">论文学习链接</h3><p>更多论文请见：<a href="https://github.com/mli/paper-reading">https://github.com/mli/paper-reading</a></p><h3 id="论文pdf">论文pdf</h3><iframe src="/js/pdfjs_old/web/viewer.html?file=https://paper.mulindya.com/newAN%20IMAGE%20IS%20WORTH%2016X16%20WORDS.pdf" width="100%" height="700"></iframe>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>paper</category>
      
    </categories>
    
    
    <tags>
      
      <tag>学习笔记</tag>
      
      <tag>经典论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>虚拟环境构建和使用</title>
    <link href="/2022/04/14/python/conda-env/"/>
    <url>/2022/04/14/python/conda-env/</url>
    
    <content type="html"><![CDATA[<blockquote><p>在anaconda中配置虚拟环境，现在需要使用grpc框架使用pytorch构建的模型和权重文件，</p></blockquote><h4 id="创建虚拟环境">创建虚拟环境</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">conda create -n envname python=<span class="hljs-number">3.7</span><br></code></pre></td></tr></tbody></table></figure><h4 id="查看虚拟环境">查看虚拟环境</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">conda env <span class="hljs-built_in">list</span><br></code></pre></td></tr></tbody></table></figure><h4 id="删除虚拟环境">删除虚拟环境</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">conda remove -n envname --<span class="hljs-built_in">all</span><br></code></pre></td></tr></tbody></table></figure><h4 id="激活虚拟环境">激活虚拟环境</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">conda activate envname<br></code></pre></td></tr></tbody></table></figure><h4 id="退出当前虚拟环境">退出当前虚拟环境</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">conda deactivate<br></code></pre></td></tr></tbody></table></figure><h4 id="显示，克隆虚拟环境">显示，克隆虚拟环境</h4><h5 id="显示安装过的所有虚拟环境">显示安装过的所有虚拟环境</h5><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">conda info --envs<br>或<br>conda info -e<br>或<br>conda env <span class="hljs-built_in">list</span><br></code></pre></td></tr></tbody></table></figure><p>2）复制/克隆环境</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">conda create --name new_env_name --clone copied_env_name<br></code></pre></td></tr></tbody></table></figure><p>备注：<br>copied_env_name即为被复制/克隆环境名。</p><p>new_env_name即为复制之后新环境的名称。</p><h4 id="安装包">安装包</h4><p><strong>进入虚拟环境</strong>后：</p><figure class="highlight cmake"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cmake"><span class="hljs-comment"># conda安装</span><br>conda <span class="hljs-keyword">install</span> 要安装的包名<br> <br><span class="hljs-comment">#pip安装</span><br>pip <span class="hljs-keyword">install</span> 安装的包名<br></code></pre></td></tr></tbody></table></figure><p>安装<code>pytorch</code></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#cpu 版本</span><br>pip install torch==<span class="hljs-number">1.8</span><span class="hljs-number">.1</span> torchvision==<span class="hljs-number">0.9</span><span class="hljs-number">.1</span> torchaudio==<span class="hljs-number">0.8</span><span class="hljs-number">.1</span><br><br><span class="hljs-comment"># CUDA 10.2</span><br>conda install pytorch==<span class="hljs-number">1.8</span><span class="hljs-number">.1</span> torchvision==<span class="hljs-number">0.9</span><span class="hljs-number">.1</span> torchaudio==<span class="hljs-number">0.8</span><span class="hljs-number">.1</span> cudatoolkit=<span class="hljs-number">10.2</span> -c pytorch<br><br><span class="hljs-comment"># CUDA 10.2</span><br>pip install torch==<span class="hljs-number">1.8</span><span class="hljs-number">.1</span>+cu102 torchvision==<span class="hljs-number">0.9</span><span class="hljs-number">.1</span>+cu102 torchaudio==<span class="hljs-number">0.8</span><span class="hljs-number">.1</span> -f https://download.pytorch.org/whl/torch_stable.html<br></code></pre></td></tr></tbody></table></figure><p>安装<code>nb_conda</code></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#这样可以在jupyter notebook下指定内核</span><br>pip install nb_conda<br></code></pre></td></tr></tbody></table></figure><p>如果报错无法找到动态源，则删除提示相应路径下的<code>pywintype37.dll</code>和<code>pythoncom37.dll</code></p><p>安装<code>simpleITK</code>（医学影像常用包），<code>tqdm</code></p><figure class="highlight cmake"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip <span class="hljs-keyword">install</span> simpleitk<br>pip <span class="hljs-keyword">install</span> tqdm<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop_Microsoft450 删除二叉搜索树中的节点</title>
    <link href="/2022/04/12/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft450/"/>
    <url>/2022/04/12/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft450/</url>
    
    <content type="html"><![CDATA[<blockquote><p>删除二叉搜索树中的节点<br><a href="https://leetcode-cn.com/problems/delete-node-in-a-bst/">https://leetcode-cn.com/problems/delete-node-in-a-bst/</a></p></blockquote><h2 id="题目">题目</h2><p>给定一个二叉搜索树的根节点 root 和一个值 key，删除二叉搜索树中的 key 对应的节点，并保证二叉搜索树的性质不变。返回二叉搜索树（有可能被更新）的根节点的引用。</p><p>一般来说，删除节点可分为两个步骤：</p><p>首先找到需要删除的节点；<br>如果找到了，删除它。</p><h3 id="示例-1：">示例 1：</h3><p><img src="https://picture.mulindya.com/Aleetcode/leetcode450-1.jpg" alt=""></p><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">root</span> = [<span class="hljs-number">5</span>,<span class="hljs-number">3</span>,<span class="hljs-number">6</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">7</span>], <span class="hljs-attr">key</span> = <span class="hljs-number">3</span><br>输出：[<span class="hljs-number">5</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">2</span>,<span class="hljs-literal">null</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">7</span>]<br>解释：给定需要删除的节点值是 <span class="hljs-number">3</span>，所以我们首先找到 <span class="hljs-number">3</span> 这个节点，然后删除它。<br>一个正确的答案是 [<span class="hljs-number">5</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">2</span>,<span class="hljs-literal">null</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">7</span>], 如下图所示。<br>另一个正确答案是 [<span class="hljs-number">5</span>,<span class="hljs-number">2</span>,<span class="hljs-number">6</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">4</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">7</span>]。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入: <span class="hljs-attr">root</span> = [<span class="hljs-number">5</span>,<span class="hljs-number">3</span>,<span class="hljs-number">6</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">7</span>], <span class="hljs-attr">key</span> = <span class="hljs-number">0</span><br>输出: [<span class="hljs-number">5</span>,<span class="hljs-number">3</span>,<span class="hljs-number">6</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">7</span>]<br>解释: 二叉树不包含值为 <span class="hljs-number">0</span> 的节点。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-3：">示例 3：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入: root = <span class="hljs-comment">[]</span>, key = 0<br>输出: <span class="hljs-comment">[]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>节点数的范围 [0, 104].</li><li>-105 &lt;= Node.val &lt;= 105</li><li>节点值唯一</li><li>root 是合法的二叉搜索树</li><li>-105 &lt;= key &lt;= 105</li></ul><h2 id="题解">题解</h2><p>开始的想法是先找到这个节点和他的父节点再进行删除操作，后来发现其实使用递归就好了，返回该子树的根节点；</p><p>利用搜索树的性质，搜索待删除的节点，找到后进行删除操作：</p><ul><li><p>如果左子树是空，直接将右子树接入</p></li><li><p>如果右子树是空，直接将左子树接入</p></li><li><p>如果两者皆非空，可以选择左子树或者右子树根节点代替该删除节点，需要考虑如果融合左右子树，也就是要<strong>融合左子树的右分支和右子树的左分支</strong>。</p><ul><li>选择左子树根节点代替，就意味左子树的右分支需要融合到右子树中，此时右分支应该接入右子树节点的最左侧</li><li>选择右子树根节点代替，就意味右子树的左分支需要融合到左子树中，此时左分支应该接入左子树节点的最右侧</li></ul></li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for a binary tree node.</span><br><span class="hljs-comment"># class TreeNode:</span><br><span class="hljs-comment">#     def __init__(self, val=0, left=None, right=None):</span><br><span class="hljs-comment">#         self.val = val</span><br><span class="hljs-comment">#         self.left = left</span><br><span class="hljs-comment">#         self.right = right</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">deleteNode</span>(<span class="hljs-params">self, root: <span class="hljs-type">Optional</span>[TreeNode], key: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">Optional</span>[TreeNode]:</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root: <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">if</span> root.val&gt;key: root.left = self.deleteNode(root.left,key) <span class="hljs-comment">#如果当前节点小于key，就在左子树中找，同时更新左子树</span><br>        <span class="hljs-keyword">elif</span> root.val&lt;key: root.right = self.deleteNode(root.right,key) <span class="hljs-comment">#如果当前节点大于key，就在右子树中找，同时更新右子树</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root.left: <span class="hljs-keyword">return</span> root.right <span class="hljs-comment">#如果左子树为空树则直接返回右子树</span><br>            <span class="hljs-keyword">elif</span> <span class="hljs-keyword">not</span> root.right: <span class="hljs-keyword">return</span> root.left<br>            <span class="hljs-keyword">else</span>:<br>                cur = root.right <span class="hljs-comment">#cur用于找寻右子树的最左侧</span><br>                <span class="hljs-keyword">while</span> cur.left:cur = cur.left<br>                cur.left = root.left.right <span class="hljs-comment">#将左子树右分支接入右子树中</span><br>                root.left.right = root.right <span class="hljs-comment">#更新左子树的右分支</span><br>                <span class="hljs-keyword">return</span> root.left <span class="hljs-comment">#使用左子树代替删除节点</span><br>        <span class="hljs-keyword">return</span> root <span class="hljs-comment">#返回根节点</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>微软</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>微软</tag>
      
      <tag>树</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop912 排序数组</title>
    <link href="/2022/04/10/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop912/"/>
    <url>/2022/04/10/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop912/</url>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://leetcode-cn.com/problems/sort-an-array/">排序数组</a></p><p>频度206</p></blockquote><h2 id="题目">题目</h2><p>给你一个整数数组 <code>nums</code>，请你将该数组升序排列。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight dns"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs dns">输入：nums = [<span class="hljs-number">5,2,3,1</span>]<br>输出：[<span class="hljs-number">1,2,3,5</span>]<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight accesslog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">输入：nums = <span class="hljs-string">[5,1,1,2,0,0]</span><br>输出：<span class="hljs-string">[0,0,1,1,2,5]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><code>1 &lt;= nums.length &lt;= 5 * 104</code></li><li><code>-5 * 104 &lt;= nums[i] &lt;= 5 * 104</code></li></ul><h2 id="题解">题解</h2><p>快速排序，在partition中使用随机选择pivot，到末尾位置，再使用循环遍历调整位置，i是定位所有小于等于pivot的数到前方即可。再使用qsort递归。在这两个函数中，<strong>传入nums数组，这里的传入和返回数组对象时都是直接的引用传递。</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sortArray</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:</span><br>        <span class="hljs-comment">#手撕快排</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">partition</span>(<span class="hljs-params">nums,left,right</span>):</span><br>            tindex = random.randint(left,right)<br>            nums[right], nums[tindex] = nums[tindex], nums[right] <br>            pivot,i = nums[right], left-<span class="hljs-number">1</span> <span class="hljs-comment">#注意i初始化left-1 而非-1哦</span><br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(left,right+<span class="hljs-number">1</span>):<br>                <span class="hljs-keyword">if</span> nums[j]&lt;=pivot:<br>                    i+=<span class="hljs-number">1</span><br>                    nums[i],nums[j] = nums[j],nums[i]<br>            <span class="hljs-keyword">return</span> i<br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">qsort</span>(<span class="hljs-params">nums,left,right</span>):</span><br>            <span class="hljs-keyword">if</span> left&gt;=right: <span class="hljs-keyword">return</span><br>            index = partition(nums,left,right)<br>            qsort(nums,left,index-<span class="hljs-number">1</span>)<br>            qsort(nums,index+<span class="hljs-number">1</span>,right)<br>            <br>        qsort(nums,<span class="hljs-number">0</span>,<span class="hljs-built_in">len</span>(nums)-<span class="hljs-number">1</span>) <span class="hljs-comment">#nums作为参数传入，对于python而言，是指针传入，会直接修改</span><br>        <span class="hljs-keyword">return</span> nums<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>排序</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>排序</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop25 K个一组翻转链表</title>
    <link href="/2022/04/08/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop25/"/>
    <url>/2022/04/08/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop25/</url>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://leetcode-cn.com/problems/reverse-nodes-in-k-group/">K个一组翻转链表</a></p><p>频度227</p></blockquote><h2 id="题目">题目</h2><p>给你一个链表，每 k 个节点一组进行翻转，请你返回翻转后的链表。</p><p>k 是一个正整数，它的值小于或等于链表的长度。</p><p>如果节点总数不是 k 的整数倍，那么请将最后剩余的节点保持原有顺序。</p><p>进阶：</p><p>你可以设计一个只使用常数额外空间的算法来解决此问题吗？<br>你不能只是单纯的改变节点内部的值，而是需要实际进行节点交换。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight accesslog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">输入：head = <span class="hljs-string">[1,2,3,4,5]</span>, k = <span class="hljs-number">2</span><br>输出：<span class="hljs-string">[2,1,4,3,5]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight accesslog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">输入：head = <span class="hljs-string">[1,2,3,4,5]</span>, k = <span class="hljs-number">3</span><br>输出：<span class="hljs-string">[3,2,1,4,5]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-3：">示例 3：</h3><figure class="highlight accesslog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">输入：head = <span class="hljs-string">[1,2,3,4,5]</span>, k = <span class="hljs-number">1</span><br>输出：<span class="hljs-string">[1,2,3,4,5]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-4：">示例 4：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：head = <span class="hljs-comment">[1]</span>, k = 1<br>输出：<span class="hljs-comment">[1]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>列表中节点的数量在范围 <code>sz</code> 内</li><li><code>1 &lt;= sz &lt;= 5000</code></li><li><code>0 &lt;= Node.val &lt;= 1000</code></li><li><code>1 &lt;= k &lt;= sz</code></li></ul><h2 id="题解">题解</h2><p>反转链表的套路</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">cur, pre = head, <span class="hljs-literal">None</span><br><span class="hljs-keyword">while</span> cur:<br>temp, cur.<span class="hljs-built_in">next</span> = cur.<span class="hljs-built_in">next</span>, pre<br>pre,cur = cur,temp<br></code></pre></td></tr></tbody></table></figure><p>现在需要分组反转，就需要暂时记录本组的尾节点，同时在最后反转完成（反转了k个元素）后，将上一组的尾节点和当前的头节点“链接”上。</p><p>最本组反转完成后：</p><p>ptail指向上一组的尾节点；</p><p>pre指向当前组的头节点；</p><p>ptail_temp表示当前组的尾节点；</p><p>cur指向下一组等待反转的元素。</p><p>如果最后不足k个元素，就恢复反转，也就是说将当前组再反转一次即可。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode:</span><br><span class="hljs-comment">#     def __init__(self, val=0, next=None):</span><br><span class="hljs-comment">#         self.val = val</span><br><span class="hljs-comment">#         self.next = next</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reverseKGroup</span>(<span class="hljs-params">self, head: <span class="hljs-type">Optional</span>[ListNode], k: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">Optional</span>[ListNode]:</span><br>        cur,ptail = head,<span class="hljs-literal">None</span><br>        flag = <span class="hljs-literal">False</span><br>        <span class="hljs-keyword">while</span> cur:<br>            count,pre = <span class="hljs-number">0</span>,<span class="hljs-literal">None</span><br>            <span class="hljs-keyword">while</span> cur <span class="hljs-keyword">and</span> count&lt;k: <span class="hljs-comment">#小段处理</span><br>                temp,cur.<span class="hljs-built_in">next</span> = cur.<span class="hljs-built_in">next</span>,pre<br>                <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> pre:ptail_temp = cur<br>                pre,cur = cur,temp<br>                count += <span class="hljs-number">1</span><br>                <span class="hljs-keyword">if</span> count==k:   <br>                    <span class="hljs-keyword">if</span> flag:<br>                        ptail.<span class="hljs-built_in">next</span> = pre<br>                    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> flag:<br>                        head, flag = pre, <span class="hljs-literal">True</span><br>                    ptail = ptail_temp<br>        <span class="hljs-comment">#恢复尾部信息</span><br>        <span class="hljs-keyword">if</span> count&lt;k:<br>            ptail.<span class="hljs-built_in">next</span> = ptail_temp<br>            cur, pre = pre, <span class="hljs-literal">None</span><br>            <span class="hljs-keyword">while</span> cur:<br>                temp, cur.<span class="hljs-built_in">next</span> = cur.<span class="hljs-built_in">next</span>,pre<br>                pre,cur = cur,temp<br>        <span class="hljs-keyword">return</span> head<br><span class="hljs-comment">#时间复杂度O(n) 空间复杂度O(1)</span><br></code></pre></td></tr></tbody></table></figure><p>也可以封装一下函数：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-comment"># 翻转一个子链表，并且返回新的头与尾</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reverse</span>(<span class="hljs-params">self, head: ListNode, tail: ListNode</span>):</span><br>        prev = tail.<span class="hljs-built_in">next</span><br>        p = head<br>        <span class="hljs-keyword">while</span> prev != tail:<br>            nex = p.<span class="hljs-built_in">next</span><br>            p.<span class="hljs-built_in">next</span> = prev<br>            prev = p<br>            p = nex<br>        <span class="hljs-keyword">return</span> tail, head<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reverseKGroup</span>(<span class="hljs-params">self, head: ListNode, k: <span class="hljs-built_in">int</span></span>) -&gt; ListNode:</span><br>        hair = ListNode(<span class="hljs-number">0</span>)<br>        hair.<span class="hljs-built_in">next</span> = head<br>        pre = hair<br><br>        <span class="hljs-keyword">while</span> head:<br>            tail = pre<br>            <span class="hljs-comment"># 查看剩余部分长度是否大于等于 k</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(k):<br>                tail = tail.<span class="hljs-built_in">next</span><br>                <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> tail:<br>                    <span class="hljs-keyword">return</span> hair.<span class="hljs-built_in">next</span><br>            nex = tail.<span class="hljs-built_in">next</span><br>            head, tail = self.reverse(head, tail)<br>            <span class="hljs-comment"># 把子链表重新接回原链表</span><br>            pre.<span class="hljs-built_in">next</span> = head<br>            tail.<span class="hljs-built_in">next</span> = nex<br>            pre = tail<br>            head = tail.<span class="hljs-built_in">next</span><br>        <br>        <span class="hljs-keyword">return</span> hair.<span class="hljs-built_in">next</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>字节</category>
      
      <category>链表</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>链表</tag>
      
      <tag>字节</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop15 三数之和</title>
    <link href="/2022/04/01/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop15/"/>
    <url>/2022/04/01/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop15/</url>
    
    <content type="html"><![CDATA[<blockquote><p>三数之和 频度为209<br><a href="https://leetcode-cn.com/problems/3sum/">https://leetcode-cn.com/problems/3sum/</a></p></blockquote><h2 id="题目">题目</h2><p>给你一个包含 n 个整数的数组&nbsp;nums，判断&nbsp;nums&nbsp;中是否存在三个元素 a，b，c ，使得&nbsp;a + b + c = 0 ？请你找出所有和为 0 且不重复的三元组。</p><p>注意：答案中不可以包含重复的三元组。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight subunit"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs subunit">输入：nums = [<span class="hljs-string">-1</span>,0,1,2,<span class="hljs-string">-1</span>,<span class="hljs-string">-4</span>]<br>输出：[[<span class="hljs-string">-1</span>,<span class="hljs-string">-1</span>,2],[<span class="hljs-string">-1</span>,0,1]]<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：nums = <span class="hljs-comment">[]</span><br>输出：<span class="hljs-comment">[]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例3：">示例3：</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">输入：nums = [<span class="hljs-number">0</span>]<br>输出：[]<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><code>0 &lt;= nums.length &lt;= 3000</code></li><li><code>-105 &lt;= nums[i] &lt;= 105</code></li></ul><h2 id="题解">题解</h2><p>第一想法是使用字典存储</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">threeSum</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]:</span><br>        nums = <span class="hljs-built_in">sorted</span>(nums)<br>        result = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(nums)-<span class="hljs-number">2</span>):<br>            <span class="hljs-keyword">if</span> nums[i] &gt; <span class="hljs-number">0</span>: <span class="hljs-keyword">break</span> <br>            <span class="hljs-keyword">if</span> i&gt;<span class="hljs-number">0</span> <span class="hljs-keyword">and</span> nums[i]==nums[i-<span class="hljs-number">1</span>]:<span class="hljs-keyword">continue</span> <br>            left,right = i+<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(nums)-<span class="hljs-number">1</span><br>            <span class="hljs-keyword">while</span> left&lt;right:<br>                <span class="hljs-keyword">if</span> nums[i]+nums[left]+nums[right]==<span class="hljs-number">0</span>: <br>                    result.append([nums[i],nums[left],nums[right]])<br>                    <span class="hljs-comment">#避免重复添加元素</span><br>                    <span class="hljs-keyword">while</span>(left&lt;right <span class="hljs-keyword">and</span> nums[left+<span class="hljs-number">1</span>]==nums[left]):left+=<span class="hljs-number">1</span><br>                    <span class="hljs-keyword">while</span>(left&lt;right <span class="hljs-keyword">and</span> nums[right-<span class="hljs-number">1</span>]==nums[right]):right-=<span class="hljs-number">1</span><br>                    left,right = left+<span class="hljs-number">1</span>,right-<span class="hljs-number">1</span><br>                <span class="hljs-keyword">elif</span> nums[i]+nums[left]+nums[right]&gt;<span class="hljs-number">0</span>: right -= <span class="hljs-number">1</span><br>                <span class="hljs-keyword">else</span>: left +=<span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> result<br>                <br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>微软</category>
      
      <category>双指针</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>微软</tag>
      
      <tag>双指针</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop_Microsoft106 从中序与后序遍历序列构造二叉树</title>
    <link href="/2022/04/01/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft106/"/>
    <url>/2022/04/01/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft106/</url>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://leetcode-cn.com/problems/construct-binary-tree-from-inorder-and-postorder-traversal/">从中序与后序遍历序列构造二叉树</a></p></blockquote><h2 id="题目">题目</h2><p>给定两个整数数组 inorder 和 postorder ，其中 inorder 是二叉树的中序遍历， postorder 是同一棵树的后序遍历，请你构造并返回这颗 二叉树 。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">inorder</span> = [<span class="hljs-number">9</span>,<span class="hljs-number">3</span>,<span class="hljs-number">15</span>,<span class="hljs-number">20</span>,<span class="hljs-number">7</span>], <span class="hljs-attr">postorder</span> = [<span class="hljs-number">9</span>,<span class="hljs-number">15</span>,<span class="hljs-number">7</span>,<span class="hljs-number">20</span>,<span class="hljs-number">3</span>]<br>输出：[<span class="hljs-number">3</span>,<span class="hljs-number">9</span>,<span class="hljs-number">20</span>,<span class="hljs-literal">null</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">15</span>,<span class="hljs-number">7</span>]<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：inorder = <span class="hljs-comment">[-1]</span>, postorder = <span class="hljs-comment">[-1]</span><br>输出：<span class="hljs-comment">[-1]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= inorder.length &lt;= 3000</li><li>postorder.length == inorder.length</li><li>-3000 &lt;= inorder[i], postorder[i] &lt;= 3000</li><li>inorder 和 postorder 都由 不同 的值组成</li><li>postorder 中每一个值都在 inorder 中</li><li>inorder 保证是树的中序遍历</li><li>postorder 保证是树的后序遍历</li></ul><h2 id="题解">题解</h2><p>根据后序遍历中的节点定位根节点，在中序遍历序列查找该节点，以此可知左右子树的个数。从而确定后序序列中相应的左右子树的区间来递归左右子树根节点。</p><p>建立根节点，递归左子树和右子树返回左右子树根节点，返回根节点。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for a binary tree node.</span><br><span class="hljs-comment"># class TreeNode:</span><br><span class="hljs-comment">#     def __init__(self, val=0, left=None, right=None):</span><br><span class="hljs-comment">#         self.val = val</span><br><span class="hljs-comment">#         self.left = left</span><br><span class="hljs-comment">#         self.right = right</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">buildTree</span>(<span class="hljs-params">self, inorder: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], postorder: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; TreeNode:</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">buildfunc</span>(<span class="hljs-params">posindex,start,end</span>):</span><br>            <span class="hljs-keyword">if</span> start&gt;end: <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br>            root = TreeNode(postorder[posindex])<br>            index = inorder.index(postorder[posindex],start,end+<span class="hljs-number">1</span>)<br>            root.left = buildfunc(posindex-(end-index+<span class="hljs-number">1</span>),start,index-<span class="hljs-number">1</span>)<br>            root.right =  buildfunc(posindex-<span class="hljs-number">1</span>,index+<span class="hljs-number">1</span>,end)<br>            <span class="hljs-keyword">return</span> root<br>        <span class="hljs-keyword">return</span> buildfunc(<span class="hljs-built_in">len</span>(postorder)-<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-built_in">len</span>(inorder)-<span class="hljs-number">1</span>)<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>微软</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>微软</tag>
      
      <tag>树</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop_Microsoft146 LRU缓存</title>
    <link href="/2022/03/31/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft146/"/>
    <url>/2022/03/31/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft146/</url>
    
    <content type="html"><![CDATA[<blockquote><p>LRU缓存 <a href="https://leetcode-cn.com/problems/lru-cache/">https://leetcode-cn.com/problems/lru-cache/</a></p></blockquote><h2 id="题目">题目</h2><p>请你设计并实现一个满足  LRU (最近最少使用) 缓存 约束的数据结构。<br>实现 LRUCache 类：<br>LRUCache(int capacity) 以 正整数 作为容量 capacity 初始化 LRU 缓存<br>int get(int key) 如果关键字 key 存在于缓存中，则返回关键字的值，否则返回 -1 。<br>void put(int key, int value) 如果关键字 key 已经存在，则变更其数据值 value ；如果不存在，则向缓存中插入该组 key-value 。如果插入操作导致关键字数量超过 capacity ，则应该 逐出 最久未使用的关键字。<br>函数 get 和 put 必须以 O(1) 的平均时间复杂度运行。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight haxe"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs haxe">输入<br>[<span class="hljs-string">"LRUCache"</span>, <span class="hljs-string">"put"</span>, <span class="hljs-string">"put"</span>, <span class="hljs-string">"get"</span>, <span class="hljs-string">"put"</span>, <span class="hljs-string">"get"</span>, <span class="hljs-string">"put"</span>, <span class="hljs-string">"get"</span>, <span class="hljs-string">"get"</span>, <span class="hljs-string">"get"</span>]<br>[[<span class="hljs-number">2</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">1</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">2</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">1</span>], [<span class="hljs-number">3</span>], [<span class="hljs-number">4</span>]]<br>输出<br>[<span class="hljs-literal">null</span>, <span class="hljs-literal">null</span>, <span class="hljs-literal">null</span>, <span class="hljs-number">1</span>, <span class="hljs-literal">null</span>, <span class="hljs-number">-1</span>, <span class="hljs-literal">null</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]<br><br>解释<br>LRUCache lRUCache = <span class="hljs-keyword">new</span> <span class="hljs-type">LRUCache</span>(<span class="hljs-number">2</span>);<br>lRUCache.put(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>); <span class="hljs-comment">// 缓存是 {1=1}</span><br>lRUCache.put(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>); <span class="hljs-comment">// 缓存是 {1=1, 2=2}</span><br>lRUCache.<span class="hljs-keyword">get</span>(<span class="hljs-number">1</span>);    <span class="hljs-comment">// 返回 1</span><br>lRUCache.put(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>); <span class="hljs-comment">// 该操作会使得关键字 2 作废，缓存是 {1=1, 3=3}</span><br>lRUCache.<span class="hljs-keyword">get</span>(<span class="hljs-number">2</span>);    <span class="hljs-comment">// 返回 -1 (未找到)</span><br>lRUCache.put(<span class="hljs-number">4</span>, <span class="hljs-number">4</span>); <span class="hljs-comment">// 该操作会使得关键字 1 作废，缓存是 {4=4, 3=3}</span><br>lRUCache.<span class="hljs-keyword">get</span>(<span class="hljs-number">1</span>);    <span class="hljs-comment">// 返回 -1 (未找到)</span><br>lRUCache.<span class="hljs-keyword">get</span>(<span class="hljs-number">3</span>);    <span class="hljs-comment">// 返回 3</span><br>lRUCache.<span class="hljs-keyword">get</span>(<span class="hljs-number">4</span>);    <span class="hljs-comment">// 返回 4</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= capacity &lt;= 3000</li><li>0 &lt;= key &lt;= 10000</li><li>0 &lt;= value &lt;= 105</li><li>最多调用 2 * 105 次 get 和 put</li></ul><h2 id="题解">题解</h2><p>使用哈希表+双向链表</p><p><a href="https://leetcode-cn.com/problems/lru-cache/solution/lruhuan-cun-ji-zhi-by-leetcode-solution/">https://leetcode-cn.com/problems/lru-cache/solution/lruhuan-cun-ji-zhi-by-leetcode-solution/</a></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ListNode</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self,value=<span class="hljs-literal">None</span>,key=<span class="hljs-literal">None</span></span>):</span> <span class="hljs-comment">#还要记录key</span><br>        self.value = value<br>        self.key = key<br>        self.leftnode = <span class="hljs-literal">None</span><br>        self.rightnode = <span class="hljs-literal">None</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LRUCache</span>:</span><br><span class="hljs-comment">## 使用双链表和哈希表 这样可以保证O(1)的时间复杂度 新建head tail头尾节点便于对节点操作是一致的，哈希表是key是键 value尾双链表中的node</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, capacity: <span class="hljs-built_in">int</span></span>):</span><br>        self.capacity = capacity<br>        self.hashmap = {}<br>        self.head = ListNode()<br>        self.tail = ListNode()<br>        self.head.rightnode = self.tail<br>        self.tail.leftnode = self.head<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">move2tail</span>(<span class="hljs-params">self,key</span>):</span><br>        node = self.hashmap[key] <span class="hljs-comment">#查找目标节点</span><br>        <span class="hljs-comment">#更新目标节点的左右节点的连接</span><br>        node.leftnode.rightnode = node.rightnode<br>        node.rightnode.leftnode = node.leftnode<br><br>        <span class="hljs-comment">#移动到尾部</span><br>        self.tail.leftnode.rightnode = node<br>        node.leftnode = self.tail.leftnode<br>        node.rightnode = self.tail<br>        self.tail.leftnode = node<br><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get</span>(<span class="hljs-params">self, key: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        res = self.hashmap.get(key,-<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">if</span> res==-<span class="hljs-number">1</span>:<span class="hljs-keyword">return</span> -<span class="hljs-number">1</span> <span class="hljs-comment">#不存在时</span><br>        self.move2tail(key) <span class="hljs-comment">#查找到就移动到尾部</span><br>        <span class="hljs-keyword">return</span> res.value<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">put</span>(<span class="hljs-params">self, key: <span class="hljs-built_in">int</span>, value: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-literal">None</span>:</span><br>        res = self.hashmap.get(key,-<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">if</span> res==-<span class="hljs-number">1</span>: <span class="hljs-comment">#不存在</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(self.hashmap) == self.capacity:<br>                <span class="hljs-comment">#去除第一个节点</span><br>                self.hashmap.pop(self.head.rightnode.key) <span class="hljs-comment">#剔除key  </span><br>                <span class="hljs-comment">#先处理hashmap再修改链表</span><br>                self.head.rightnode = self.head.rightnode.rightnode <br>                self.head.rightnode.leftnode = self.head  <br>            node = ListNode(value,key)<br>            self.hashmap[key] = node<br><br>            self.tail.leftnode.rightnode = node<br>            node.leftnode = self.tail.leftnode<br>            self.tail.leftnode = node<br>            node.rightnode = self.tail<br>        <span class="hljs-keyword">else</span>: <span class="hljs-comment">#存在 移到末尾</span><br>            self.hashmap[key].value = value <span class="hljs-comment">#注意更新他的value而不是node</span><br>            self.move2tail(key)<br><br><br><span class="hljs-comment"># Your LRUCache object will be instantiated and called as such:</span><br><span class="hljs-comment"># obj = LRUCache(capacity)</span><br><span class="hljs-comment"># param_1 = obj.get(key)</span><br><span class="hljs-comment"># obj.put(key,value)</span><br></code></pre></td></tr></tbody></table></figure><p>时间复杂度：对于 put 和 get 都是 O(1)。</p><p>空间复杂度：O(capacity)，因为哈希表和双向链表最多存储 capacity+1 个元素。</p>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>微软</category>
      
      <category>数据结构组合</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>微软</tag>
      
      <tag>数据结构组合</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Momentum Contrast for Unsupervised Visual Representation Learning</title>
    <link href="/2022/03/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87/moco/"/>
    <url>/2022/03/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87/moco/</url>
    
    <content type="html"><![CDATA[<blockquote><p>笔记记录于pdf中，所以就直接放pdf在此处~ 😉</p></blockquote><h3 id="学习视频链接">学习视频链接</h3><p><a href="https://www.bilibili.com/video/BV1C3411s7t9?spm_id_from=333.880.my_history.page.click">https://www.bilibili.com/video/BV1C3411s7t9?spm_id_from=333.880.my_history.page.click</a></p><h3 id="pdf链接">pdf链接</h3><p><a href="https://paper.mulindya.com/moco.pdf">https://paper.mulindya.com/moco.pdf</a></p><h3 id="论文学习链接">论文学习链接</h3><p>更多论文请见：<a href="https://github.com/mli/paper-reading">https://github.com/mli/paper-reading</a></p><h3 id="论文pdf">论文pdf</h3><iframe src="/js/pdfjs_old/web/viewer.html?file=https://paper.mulindya.com/moco.pdf" width="100%" height="700"></iframe>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>paper</category>
      
    </categories>
    
    
    <tags>
      
      <tag>学习笔记</tag>
      
      <tag>经典论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop_Microsoft236 二叉树的最近公共祖先</title>
    <link href="/2022/03/29/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft236/"/>
    <url>/2022/03/29/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft236/</url>
    
    <content type="html"><![CDATA[<blockquote><p>二叉树的最近公共祖先</p><p>可以对比<a href="https://www.mulindya.com/2022/02/06/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer68-1/">二叉搜索树的最近公共祖先</a></p></blockquote><h2 id="题目">题目</h2><p>给定一个二叉树, 找到该树中两个指定节点的最近公共祖先。</p><p>百度百科中最近公共祖先的定义为：“对于有根树 T 的两个节点 p、q，最近公共祖先表示为一个节点 x，满足 x 是 p、q 的祖先且 x 的深度尽可能大（一个节点也可以是它自己的祖先）。”</p><h3 id="示例-1：">示例 1：</h3><p><img src="https://picture.mulindya.com/Aleetcode/CodeTop236-1.png" alt=""></p><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">root</span> = [<span class="hljs-number">3</span>,<span class="hljs-number">5</span>,<span class="hljs-number">1</span>,<span class="hljs-number">6</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>,<span class="hljs-number">8</span>,<span class="hljs-literal">null</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">7</span>,<span class="hljs-number">4</span>], <span class="hljs-attr">p</span> = <span class="hljs-number">5</span>, <span class="hljs-attr">q</span> = <span class="hljs-number">1</span><br>输出：<span class="hljs-number">3</span><br>解释：节点 <span class="hljs-number">5</span> 和节点 <span class="hljs-number">1</span> 的最近公共祖先是节点 <span class="hljs-number">3</span> 。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><p><img src="https://picture.mulindya.com/Aleetcode/CodeTop236-2.png" alt=""></p><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">root</span> = [<span class="hljs-number">3</span>,<span class="hljs-number">5</span>,<span class="hljs-number">1</span>,<span class="hljs-number">6</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>,<span class="hljs-number">8</span>,<span class="hljs-literal">null</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">7</span>,<span class="hljs-number">4</span>], <span class="hljs-attr">p</span> = <span class="hljs-number">5</span>, <span class="hljs-attr">q</span> = <span class="hljs-number">4</span><br>输出：<span class="hljs-number">5</span><br>解释：节点 <span class="hljs-number">5</span> 和节点 <span class="hljs-number">4</span> 的最近公共祖先是节点 <span class="hljs-number">5</span> 。因为根据定义最近公共祖先节点可以为节点本身。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例3：">示例3：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">root</span> = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>], <span class="hljs-attr">p</span> = <span class="hljs-number">1</span>, <span class="hljs-attr">q</span> = <span class="hljs-number">2</span><br>输出：<span class="hljs-number">1</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>树中节点数目在范围 [2, 105] 内。</li><li>-109 &lt;= Node.val &lt;= 109</li><li>所有 Node.val 互不相同 。</li><li>p != q</li><li>p 和 q 均存在于给定的二叉树中。</li></ul><h2 id="题解">题解</h2><p>如果两个节点分别在根节点root的左右子树中，则该节点就是最近公共祖先。先序遍历的思想来递归：</p><ul><li><p>该节点为p或者q就返回该节点（根节点本身为其中一个），如果为空节点也返回空。</p></li><li><p>如果不是根节点，就查找左右子树是否存在最近公共祖先。</p><ul><li><p>左子树返回为空就说明最近公共祖先在右子树中</p></li><li><p>右子树返回为空就说明最近公共祖先在左子树中</p></li><li><p>左右子树都不为空说明左右子树中不存在最近公共祖先，说明该根节点即为最近公共祖先</p></li></ul></li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for a binary tree node.</span><br><span class="hljs-comment"># class TreeNode:</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.left = None</span><br><span class="hljs-comment">#         self.right = None</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lowestCommonAncestor</span>(<span class="hljs-params">self, root: <span class="hljs-string">'TreeNode'</span>, p: <span class="hljs-string">'TreeNode'</span>, q: <span class="hljs-string">'TreeNode'</span></span>) -&gt; 'TreeNode':</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root <span class="hljs-keyword">or</span> q==root <span class="hljs-keyword">or</span> p==root: <span class="hljs-keyword">return</span> root <span class="hljs-comment">#pq有一个是该节点 返回该节点</span><br>        left = self.lowestCommonAncestor(root.left,p,q) <span class="hljs-comment">#查找公共祖先是否存在于左子树中</span><br>        right = self.lowestCommonAncestor(root.right,p,q) <span class="hljs-comment">#查找公共祖先是否存在于右子树中</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> left: <span class="hljs-keyword">return</span> right<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> right: <span class="hljs-keyword">return</span> left<br>        <span class="hljs-keyword">return</span> root<br></code></pre></td></tr></tbody></table></figure><h3 id="类比">类比</h3><p>最小搜索树中查找无需考虑空节点的情况是因为按照规律查找不会碰到空节点回溯，因此也可以用循环遍历。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lowestCommonAncestor</span>(<span class="hljs-params">self, root: <span class="hljs-string">'TreeNode'</span>, p: <span class="hljs-string">'TreeNode'</span>, q: <span class="hljs-string">'TreeNode'</span></span>) -&gt; 'TreeNode':</span><br>        <span class="hljs-keyword">if</span> root.val &lt; p.val <span class="hljs-keyword">and</span> root.val &lt; q.val:<br>            <span class="hljs-keyword">return</span> self.lowestCommonAncestor(root.right, p, q)<br>        <span class="hljs-keyword">if</span> root.val &gt; p.val <span class="hljs-keyword">and</span> root.val &gt; q.val:<br>            <span class="hljs-keyword">return</span> self.lowestCommonAncestor(root.left, p, q)<br>        <span class="hljs-keyword">return</span> root<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lowestCommonAncestor</span>(<span class="hljs-params">self, root: <span class="hljs-string">'TreeNode'</span>, p: <span class="hljs-string">'TreeNode'</span>, q: <span class="hljs-string">'TreeNode'</span></span>) -&gt; 'TreeNode':</span><br>        <span class="hljs-keyword">if</span> p.val &gt; q.val: p, q = q, p <span class="hljs-comment"># 保证 p.val &lt; q.val</span><br>        <span class="hljs-keyword">while</span> root:<br>            <span class="hljs-keyword">if</span> root.val &lt; p.val: <span class="hljs-comment"># p,q 都在 root 的右子树中</span><br>                root = root.right <span class="hljs-comment"># 遍历至右子节点</span><br>            <span class="hljs-keyword">elif</span> root.val &gt; q.val: <span class="hljs-comment"># p,q 都在 root 的左子树中</span><br>                root = root.left <span class="hljs-comment"># 遍历至左子节点</span><br>            <span class="hljs-keyword">else</span>: <span class="hljs-keyword">break</span><br>        <span class="hljs-keyword">return</span> root<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>微软</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>微软</tag>
      
      <tag>树</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>三 结构化机器学习项目--机器学习策略（1）</title>
    <link href="/2022/03/28/deep_learning/Andrew%20Wu/DeepLearning-3-1/"/>
    <url>/2022/03/28/deep_learning/Andrew%20Wu/DeepLearning-3-1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>此为吴恩达的深度学习课程的第三门课的第一周内容总结，记下相关要点，方便后续的复习和巩固。😉</p></blockquote><h1>ML策略</h1><p>优化深度学习系统的想法：</p><ul><li><p>收集更多数据</p></li><li><p>增加训练集的多样性</p></li><li><p>梯度下降更久</p></li><li><p>使用其他的优化算法</p></li><li><p>使用更大或者更小的网络</p></li><li><p>使用dropout或者L2正则化</p></li><li><p>修改网络架构…</p></li></ul><h2 id="正交化">正交化</h2><p>要优化深度学习的效果的方法（使用正交的控制）</p><ol><li>在训练集上得到的效果不错。 （更大的网络，优化算法）</li><li>在开发集上效果不错。 （正则化，更多数据）</li><li>在测试集上效果不错。（使用更多开发数据）</li><li>在测试集上的成本函数在实际使用中效果不错。 （改变开发及或者成本函数）</li></ol><p>早停这个方法对1，2都有影响，所以不是非常正交的影响。</p><h2 id="单一数字评估指标">单一数字评估指标</h2><h3 id="查准率（precision）">查准率（precision）</h3><p>在所有判断为猫猫的例子中有多少是真的猫猫</p><p>所以说当一个分类器是95%，就可以说有95%概率说对了</p><h3 id="查全率-（Recall）">查全率 （Recall）</h3><p>在所有的猫猫中有多少被识别出来了</p><p>当分类器查全率为90%，意味着这个分类器准确分辨了90%的猫猫，还有10%猫猫分辨错误了。</p><h3 id="F1">F1</h3><p>使用F1分数可以结合两者，可以看作是查准率P和查全率R的平均数，准确说是调和平均：<br>$$<br>F1 = \frac 2 {\frac 1 P+ \frac 1 R} = \frac {2PR} {P+R}<br>$$<br>所以需要一个单实数评估指标可以提高优化算法的效率，或是提高团队做出决策的效率。</p><h2 id="满足和优化指标">满足和优化指标</h2><p>如何设置优化和满足指标</p><p>在满足某个指标的情况下（比如运行时间），优化某个指标（比如准确率）。</p><p>对于N个指标 可能是1个优化，N-1个满足指标。需要明确满足指标和优化指标。</p><h2 id="train-dev-test-dataset">train dev test dataset</h2><p>dev也是验证集</p><p>在选择验证集和测试集要能够翻译未来会得到的数据，认为很重要的数据。dev数据集和test数据集可能来自相同分布，未来得到的新的数据要随机分配到dev和test数据集中。</p><h3 id="数据集划分">数据集划分</h3><p>机器学习早期 数据量比较小的时候（100，1000，10000）</p><p>train：test 分为7：3</p><p>train：dev：test分为6：2：2</p><p>现代机器学习 拥有海量数据</p><p>如果有一百万数据的话，应该98%作为训练集 1%为开发集 1%为测试集</p><p>test数据集的作用是完成系统开发之后，评估投产系统的性能，所以要令test数据集的数目能够以高置信度评估系统的整体性能即可。这个数目远小于总数据集的30%。</p><p>有时，人们只把数据集分成训练集和开发集，但是不建议。</p><h3 id="改变开发-测试集和指标">改变开发-测试集和指标</h3><p>根据需求和效果改变评估指标，修改惩罚因子的大小</p><p>两个独立步骤：设立目标，如何精准瞄准目标；</p><p>如果开发中得到的结果和用户使用时得到的结果相差很大时，说明开发集不够好，要使用在实际使用中真正需要，且够完备。</p><h4 id="模型表现">模型表现</h4><p>机器学习任务在学习过程中开始会很快达到人类水平，之后会缓慢增加性能逼近只贝叶斯最优错误率</p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
      <category>吴恩达</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>吴恩达</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop_Microsoft124 二叉树的最大路径和</title>
    <link href="/2022/03/25/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft124/"/>
    <url>/2022/03/25/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft124/</url>
    
    <content type="html"><![CDATA[<blockquote><p>二叉树的最大路径和</p></blockquote><h2 id="题目">题目</h2><p>路径 被定义为一条从树中任意节点出发，沿父节点-子节点连接，达到任意节点的序列。同一个节点在一条路径序列中 至多出现一次 。该路径 至少包含一个 节点，且不一定经过根节点。</p><p>路径和 是路径中各节点值的总和。</p><p>给你一个二叉树的根节点 root ，返回其 最大路径和 。</p><h3 id="示例-1：">示例 1：</h3><p><img src="https://picture.mulindya.com/Aleetcode/CodeTop124-1.png" alt=""></p><figure class="highlight tap"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs tap">输入：root = [1,2,3]<br>输出：6<br>解释：最优路径是<span class="hljs-number"> 2 </span>-&gt;<span class="hljs-number"> 1 </span>-&gt;<span class="hljs-number"> 3 </span>，路径和为<span class="hljs-number"> 2 </span>+<span class="hljs-number"> 1 </span>+<span class="hljs-number"> 3 </span>= 6<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><p><img src="https://picture.mulindya.com/Aleetcode/CodeTop124-2.png" alt=""></p><figure class="highlight tap"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs tap">输入：root = [-10,9,20,null,null,15,7]<br>输出：42<br>解释：最优路径是<span class="hljs-number"> 15 </span>-&gt;<span class="hljs-number"> 20 </span>-&gt;<span class="hljs-number"> 7 </span>，路径和为<span class="hljs-number"> 15 </span>+<span class="hljs-number"> 20 </span>+<span class="hljs-number"> 7 </span>= 42<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>树中节点数目范围是 [1, 3 * 104]</li><li>-1000 &lt;= Node.val &lt;= 1000</li></ul><h2 id="题解">题解</h2><p>使用后序遍历和递归，同时剪枝。和最大子序列和类似，只是把数组换成了树的形式。所以要注意到后序遍历。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maxPathSum</span>(<span class="hljs-params">self, root: <span class="hljs-type">Optional</span>[TreeNode]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-comment"># def getMax(root): #更新节点的值，设置为包含该节点的情况下的最优路径和</span><br>        <span class="hljs-comment">#     if not root:return 0</span><br>        <span class="hljs-comment">#     leftsum = root.left.val if root.left else 0 </span><br>        <span class="hljs-comment">#     rightsum = root.right.val if root.right else 0</span><br>        <span class="hljs-comment">#     # print(root.val, max(root.val,root.val+leftsum,root.val+rightsum,root.val+leftsum+rightsum))</span><br>        <span class="hljs-comment">#     if self.result&lt;(root.val+leftsum+rightsum):  self.result = (root.val+leftsum+rightsum)</span><br>        <span class="hljs-comment">#     root.val =  max(root.val,root.val+leftsum,root.val+rightsum)</span><br>        <span class="hljs-comment">#     return root.val</span><br><br>        <span class="hljs-comment"># def backdfs(root):</span><br>        <span class="hljs-comment">#     if not root: return</span><br>        <span class="hljs-comment">#     backdfs(root.left)</span><br>        <span class="hljs-comment">#     backdfs(root.right)</span><br>        <span class="hljs-comment">#     ret = getMax(root)</span><br>        <span class="hljs-comment">#     if self.result&lt;ret: self.result = ret</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getMax</span>(<span class="hljs-params">root</span>):</span> <span class="hljs-comment">#更新节点的值，设置为包含该节点的情况下的最优路径和</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root:<span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>            leftsum = <span class="hljs-built_in">max</span>(getMax(root.left),<span class="hljs-number">0</span>) <span class="hljs-comment">#剪枝</span><br>            rightsum = <span class="hljs-built_in">max</span>(getMax(root.right),<span class="hljs-number">0</span>)<br>            <span class="hljs-keyword">if</span> self.result&lt;(root.val+leftsum+rightsum):  self.result = (root.val+leftsum+rightsum) <span class="hljs-comment">#以该节点位根节点的双边判断来更新result</span><br>            <span class="hljs-keyword">return</span> root.val + <span class="hljs-built_in">max</span>(leftsum,rightsum) <span class="hljs-comment">#返回包含该节点的单边</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root: <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>        self.result = -<span class="hljs-number">1000</span><br>        getMax(root)<br>        <span class="hljs-keyword">return</span> self.result<br></code></pre></td></tr></tbody></table></figure><blockquote><p>max( x, y, z, … )可以填入多个值</p></blockquote><h5 id="对比">对比</h5><p>数组的最大子序列和</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maxSubArray</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-comment">#贪心算法1</span><br>        tempsum, tempmax, result= <span class="hljs-number">0</span>, -<span class="hljs-number">10000</span>, <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> nums:<br>            <span class="hljs-keyword">if</span> item&gt;tempmax:tempmax = item<br>            tempsum += item<br>            <span class="hljs-keyword">if</span> tempsum&lt;<span class="hljs-number">0</span>: tempsum = <span class="hljs-number">0</span> <span class="hljs-comment">#剪枝</span><br>            <span class="hljs-keyword">if</span> result&lt;tempsum:result = tempsum<br>        <span class="hljs-keyword">return</span> result <span class="hljs-keyword">if</span> result&gt;<span class="hljs-number">0</span> <span class="hljs-keyword">else</span> tempmax<br></code></pre></td></tr></tbody></table></figure><p>设置tempsum为包含当前元素的最大连续子序列和，使用result来更新最大的子序列和，初始化为数组的第一个元素。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maxSubArray</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-comment">#贪心算法2</span><br>        tempsum, result = <span class="hljs-number">0</span>, nums[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> nums:<br>            tempsum = tempsum+item <span class="hljs-keyword">if</span> tempsum+item&gt;item <span class="hljs-keyword">else</span> item  <br>            <span class="hljs-keyword">if</span> result&lt;tempsum:result = tempsum<br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>微软</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>微软</tag>
      
      <tag>树</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop_Microsoft215数组中的第K个最大元素</title>
    <link href="/2022/03/24/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft215/"/>
    <url>/2022/03/24/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft215/</url>
    
    <content type="html"><![CDATA[<blockquote><p>数组中的第K个最大元素</p></blockquote><h2 id="题目">题目</h2><p>给定整数数组 nums 和整数 k，请返回数组中第 k 个最大的元素。</p><p>请注意，你需要找的是数组排序后的第 k 个最大的元素，而不是第 k 个不同的元素。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入: [3,2,1,5,6,4] 和 k = 2</span><br><span class="hljs-section">输出: 5</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight dns"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs dns">输入: [<span class="hljs-number">3,2,3,1</span>,<span class="hljs-number">2,4,5,5</span>,<span class="hljs-number">6</span>] 和 k = <span class="hljs-number">4</span><br>输出: <span class="hljs-number">4</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= k &lt;= nums.length &lt;= 104</li><li>-104 &lt;= nums[i] &lt;= 104</li></ul><h2 id="题解">题解</h2><p>该题有三种解法：</p><ul><li>排序</li><li>分而治之（使用快排的pivot）</li><li>优先队列</li></ul><p>重点应该理解第二种方法，还有要注意这里题目的意思是<strong>第K大</strong>。</p><h3 id="排序">排序</h3><p>使用排序是效率最低的方法，其空间复杂度为O(N),时间复杂度为O(NlogN)</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">findKthLargest</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], k: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        nums = <span class="hljs-built_in">sorted</span>(nums)<br>        <span class="hljs-keyword">return</span> nums[<span class="hljs-built_in">len</span>(nums)-k]<br></code></pre></td></tr></tbody></table></figure><h3 id="分治法">分治法</h3><p>主要就是对快速排序中的<code>partition</code>的理解，将pivot放到其正确的位置，使其左右的元素要么大于pivot，要么小于pivot(等于的情况在任意一边即可)。</p><p>对于归位好的pivot可以得到它的下标，根据其下标和k进行比较，判断继续对pivot的左半部分还是右半部分继续查找。</p><blockquote><p>这里又分为递归的方法，循环的方法。递归时空间复杂度为O(logN),时间复杂度为O(N)【O(2N-1)】,每次将pivot位的时间复杂度位O(N)</p></blockquote><h4 id="partition">partition</h4><p>先总结以下pivot的partition的方法：</p><h5 id="exchange">exchange</h5><p>注意首元素作为<code>pivot</code>，**先移动<code>j</code>指针到需要交换的元素，再移动<code>i</code>指针到需要交换的元素。**用于约束<code>i</code>的范围，最后交换首元素和停止的位置。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getIndex</span>(<span class="hljs-params">Istart, Iend, nums</span>):</span>     <br>    <span class="hljs-keyword">if</span> Istart&gt;Iend: <span class="hljs-keyword">return</span><br>    pivot = nums[Istart]<br>    i,j = Istart,Iend<br>    <span class="hljs-keyword">while</span> i&lt;j: <br>        <span class="hljs-keyword">while</span> i&lt;j <span class="hljs-keyword">and</span> nums[j]&gt;pivot: j-=<span class="hljs-number">1</span>  <span class="hljs-comment">#先j后i，约束i</span><br>        <span class="hljs-keyword">while</span> i&lt;j <span class="hljs-keyword">and</span> nums[i]&lt;=pivot:i+=<span class="hljs-number">1</span><br>        nums[i],nums[j] = nums[j],nums[i]<br>    nums[j],nums[Istart] = pivot,nums[j] <span class="hljs-comment">#最后ij都会指向同一元素</span><br><span class="hljs-keyword">return</span> j<br></code></pre></td></tr></tbody></table></figure><p>也可以不采用交换的方法，将pivot移到对应的位置</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getIndex</span>(<span class="hljs-params">Istart, Iend, nums</span>):</span>     <br>    <span class="hljs-keyword">if</span> Istart&gt;Iend: <span class="hljs-keyword">return</span><br>    pivot = nums[Istart]<br>    i,j = Istart,Iend<br>    <span class="hljs-keyword">while</span> i&lt;j: <br>        <span class="hljs-keyword">while</span> i&lt;j <span class="hljs-keyword">and</span> nums[j]&gt;pivot: j-=<span class="hljs-number">1</span>  <span class="hljs-comment">#先j后i，约束i</span><br>        nums[i] = nums[j] <br>        <span class="hljs-keyword">while</span> i&lt;j <span class="hljs-keyword">and</span> nums[i]&lt;=pivot:i+=<span class="hljs-number">1</span><br>        nums[j] = nums[i]<br>    nums[j] = pivot <span class="hljs-comment">#最后ij都会指向同一元素</span><br><span class="hljs-keyword">return</span> j<br></code></pre></td></tr></tbody></table></figure><h5 id="荷兰国旗的变种">荷兰国旗的变种</h5><p>不采用交换的方法，遍历数组，将小于等于pivot的元素都放置到数组的前方就好了，这样之后的元素自然是大于pivot的数字，代码更加简洁易懂。这里将最后的元素作为pivot，使用j来遍历数组。它在最后被赋值时，这里要注意不包含最后的元素。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getIndex</span>(<span class="hljs-params">Istart,Iend</span>):</span> <span class="hljs-comment">#快排partition的变形</span><br>    <span class="hljs-keyword">if</span> Istart &gt; Iend: <span class="hljs-keyword">return</span><br>    pivot,i = nums[Iend],Istart <span class="hljs-comment">#末尾元素作为pivot</span><br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(Istart,Iend): <span class="hljs-comment">#j遍历 注意不包括最后的数字pivot </span><br>        <span class="hljs-keyword">if</span> nums[j]&lt;=pivot: <br>            nums[i],nums[j] = nums[j],nums[i]<br>            i += <span class="hljs-number">1</span><br>    nums[i],nums[Iend] = nums[Iend],nums[i]<br>    <span class="hljs-keyword">return</span> i <br></code></pre></td></tr></tbody></table></figure><p>也可以在循环遍历的过程中将pivot归位。此时将<code>i</code>初始化为<code>Istart-1</code>，每次指向待交换的下标。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getIndex</span>(<span class="hljs-params">Istart,Iend</span>):</span> <span class="hljs-comment">#快排partition的变形</span><br>    <span class="hljs-keyword">if</span> Istart &gt; Iend: <span class="hljs-keyword">return</span><br>    pivot,i = nums[Iend],Istart-<span class="hljs-number">1</span> <span class="hljs-comment">#末尾元素作为pivot</span><br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(Istart,Iend+<span class="hljs-number">1</span>): <br>        <span class="hljs-keyword">if</span> nums[j]&lt;=pivot: <br>            i += <span class="hljs-number">1</span><br>            nums[i],nums[j] = nums[j],nums[i] <span class="hljs-comment">#交换i和j的元素</span><br>    <span class="hljs-keyword">return</span> i <br></code></pre></td></tr></tbody></table></figure><h4 id="完整代码">完整代码</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">findKthLargest</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], k: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getIndex</span>(<span class="hljs-params">Istart,Iend</span>):</span> <span class="hljs-comment">#快排partition的变形</span><br>            <span class="hljs-keyword">if</span> Istart &gt; Iend: <span class="hljs-keyword">return</span><br>            pivot,i = nums[Iend],Istart-<span class="hljs-number">1</span> <span class="hljs-comment">#末尾元素作为pivot</span><br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(Istart,Iend+<span class="hljs-number">1</span>): <br>                <span class="hljs-keyword">if</span> nums[j]&lt;=pivot: <br>                    i += <span class="hljs-number">1</span><br>                    nums[i],nums[j] = nums[j],nums[i] <span class="hljs-comment">#交换i和j的元素</span><br>            <span class="hljs-keyword">return</span> i    <br>        left,right = <span class="hljs-number">0</span>,<span class="hljs-built_in">len</span>(nums)-<span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>            index = getIndex(left,right) <span class="hljs-comment">#使用循环比使用递归的内存消耗要少 这样空间复杂度为O(1)</span><br>            <span class="hljs-keyword">if</span> index==<span class="hljs-built_in">len</span>(nums)-k:<span class="hljs-keyword">return</span> nums[index]<br>            <span class="hljs-keyword">elif</span> index&gt;<span class="hljs-built_in">len</span>(nums)-k:  right = index-<span class="hljs-number">1</span>  <span class="hljs-comment">#j表示第j-1大的数字</span><br>            <span class="hljs-keyword">else</span>: left = index+<span class="hljs-number">1</span><br></code></pre></td></tr></tbody></table></figure><p>此时的时间复杂度为O(N)【每一次查找的时间复杂度为N，但是不需要logn次,O(2N-1)】空间复杂度为O(1)。如果使用递归那么空间复杂度为O(logN)。</p><h3 id="优先队列">优先队列</h3><p>使用java的PriorityQueue，默认是小根堆，选出第k大的元素，如果说大于k元素就弹出堆顶元素，最后只剩下k个元素返回堆顶。</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span> </span>{<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">findKthLargest</span><span class="hljs-params">(<span class="hljs-keyword">int</span>[] nums, <span class="hljs-keyword">int</span> k)</span> </span>{<br>        PriorityQueue&lt;Integer&gt; heap = <span class="hljs-keyword">new</span> PriorityQueue&lt;&gt;();<br>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> num : nums) {<br>            heap.add(num);<br>            <span class="hljs-keyword">if</span> (heap.size() &gt; k) {<br>                heap.poll();<br>            }<br>        }<br>        <span class="hljs-keyword">return</span> heap.peek();<br>    }<br>}<br></code></pre></td></tr></tbody></table></figure><blockquote><p>peek()//返回队首元素</p><p>poll()//返回队首元素，队首元素出队列</p><p>add()//添加元素</p><p>size()//返回队列元素个数</p><p>isEmpty()//判断队列是否为空，为空返回true,不空返回false</p></blockquote><p>时间复杂度：O(NlogK)，遍历数据 O(N)，堆内元素调整 O(logK)；<br>空间复杂度：O(K)。</p>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>微软</category>
      
      <category>排序</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>微软</tag>
      
      <tag>排序</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop_Microsoft53 反转链表</title>
    <link href="/2022/03/23/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft206/"/>
    <url>/2022/03/23/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft206/</url>
    
    <content type="html"><![CDATA[<blockquote><p>反转链表</p></blockquote><h2 id="题目">题目</h2><p>给你单链表的头节点 <code>head</code> ，请你反转链表，并返回反转后的链表。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight accesslog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">输入：head = <span class="hljs-string">[1,2,3,4,5]</span><br>输出：<span class="hljs-string">[5,4,3,2,1]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：head = <span class="hljs-comment">[1,2]</span><br>输出：<span class="hljs-comment">[2,1]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：-2">示例 2：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：head = <span class="hljs-comment">[]</span><br>输出：<span class="hljs-comment">[]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>链表中节点的数目范围是 <code>[0, 5000]</code></li><li><code>-5000 &lt;= Node.val &lt;= 5000</code></li></ul><p>**进阶：**链表可以选用迭代或递归方式完成反转。你能否用两种方法解决这道题？</p><h2 id="题解">题解</h2><h4 id="迭代">迭代</h4><p>第一个想法是使用迭代遍历的方法反转链表，记录phead是反转链表的头节点，移动head，使用temp记录当前元素的后一个元素。</p><p>时间复杂度O(n)，空间复杂度O(1)</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reverseList</span>(<span class="hljs-params">self, head: ListNode</span>) -&gt; ListNode:</span><br>        <span class="hljs-comment"># 迭代方法 时间复杂度O(n)，空间复杂度O(1)</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> head: <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br>        phead = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">while</span> head:<br>            temp = head.<span class="hljs-built_in">next</span><br>            head.<span class="hljs-built_in">next</span> = phead<br>            phead,head = head,temp<br>        <span class="hljs-keyword">return</span> phead<br></code></pre></td></tr></tbody></table></figure><h4 id="递归">递归</h4><p>使用递归的方法，如果该链表为空或者为单一元素则返回head。反转head之后的链表得到ret，ret即为反转后的头节点，然后将head的下一节点的指向修改为head，最后将head的指向修改为None。</p><p>时间复杂度O(n)，空间复杂度O(n)</p><ul><li>使用递归函数，一直递归到链表的最后一个结点，该结点就是反转后的头结点，记作 ret.</li><li>此后，每次函数在返回的过程中，让当前结点的下一个结点的 next 指针指向当前节点。</li><li>同时让当前结点的 next 指针指向 NULL ，从而实现从链表尾部开始的局部反转</li><li>当递归函数全部出栈后，链表反转完成。</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reverseList</span>(<span class="hljs-params">self, head: ListNode</span>) -&gt; ListNode:</span><br>        <span class="hljs-comment">#递归方法</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> head <span class="hljs-keyword">or</span> <span class="hljs-keyword">not</span> head.<span class="hljs-built_in">next</span>: <span class="hljs-comment">#为空或者是单元素</span><br>            <span class="hljs-keyword">return</span> head<br>        ret = self.reverseList(head.<span class="hljs-built_in">next</span>) <span class="hljs-comment">#反转head之后的元素</span><br>        head.<span class="hljs-built_in">next</span>.<span class="hljs-built_in">next</span> = head<br>        head.<span class="hljs-built_in">next</span> = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">return</span> ret    <br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>微软</category>
      
      <category>链表</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>微软</tag>
      
      <tag>链表</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop_Microsoft53 最大子数组和</title>
    <link href="/2022/03/19/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft53/"/>
    <url>/2022/03/19/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft53/</url>
    
    <content type="html"><![CDATA[<blockquote><p>最大子数组和</p></blockquote><h2 id="题目">题目</h2><p>给你一个整数数组 nums ，请你找出一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。</p><p>子数组 是数组中的一个连续部分。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight subunit"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs subunit">输入：nums = [<span class="hljs-string">-2</span>,1,<span class="hljs-string">-3</span>,4,<span class="hljs-string">-1</span>,2,1,<span class="hljs-string">-5</span>,4]<br>输出：6<br>解释：连续子数组 [4,<span class="hljs-string">-1</span>,2,1] 的和最大，为 6 。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight fix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs fix"><span class="hljs-attr">输入：nums </span>=<span class="hljs-string"> [1]</span><br><span class="hljs-string">输出：1</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-3：">示例 3：</h3><figure class="highlight accesslog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">输入：nums = <span class="hljs-string">[5,4,-1,7,8]</span><br>输出：<span class="hljs-number">23</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= nums.length &lt;= 10^5</li><li>-10^4 &lt;= nums[i] &lt;= 10^4</li></ul><h2 id="题解">题解</h2><p>记录动态规划的转移方程：<br>$$<br>dp[i] = max(nums[i],dp[i-1]+nums[i])<br>$$<br>根据「状态转移方程」，<code>dp[i]</code> 的值只和 <code>dp[i - 1]</code> 有关，因此可以使用「滚动变量」的方式将代码进行优化。</p><p>贪心算法是动态规划算法的一个特例。</p><p>使用贪心算法求解，时间复杂度为O(n)，空间复杂度为O(1);<br>设置一个变量tempsum来记录数组在当前元素为止，包含该元素的最大连续子数组和，如果加上item大于0就可以继续添加元素，否则为0继续向后查找。如果全是负数，就返回数组最大的负数，result是记录一个数组的最大子序列和。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maxSubArray</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-comment">#贪心算法1</span><br>        tempsum, tempmax, result= <span class="hljs-number">0</span>, -<span class="hljs-number">10000</span>, <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> nums:<br>            <span class="hljs-keyword">if</span> item&gt;tempmax:tempmax = item<br>            tempsum += item<br>            <span class="hljs-keyword">if</span> tempsum&lt;<span class="hljs-number">0</span>: tempsum = <span class="hljs-number">0</span><br>            <span class="hljs-keyword">if</span> result&lt;tempsum:result = tempsum<br>        <span class="hljs-keyword">return</span> result <span class="hljs-keyword">if</span> result&gt;<span class="hljs-number">0</span> <span class="hljs-keyword">else</span> tempmax<br></code></pre></td></tr></tbody></table></figure><p>这里实际上不需要tempmax，可以设置tempsum为包含当前元素的最大连续子序列和，使用result来更新最大的子序列和，初始化为数组的第一个元素。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maxSubArray</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-comment">#贪心算法2</span><br>        tempsum, result = <span class="hljs-number">0</span>, nums[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> nums:<br>            tempsum = tempsum+item <span class="hljs-keyword">if</span> tempsum+item&gt;item <span class="hljs-keyword">else</span> item <br>            <span class="hljs-keyword">if</span> result&lt;tempsum:result = tempsum<br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>微软</category>
      
      <category>贪心法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>微软</tag>
      
      <tag>贪心法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>A Multi-Task Mean Teacher for Semi-Supervised Shadow Detection</title>
    <link href="/2022/03/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E5%8E%BB%E5%99%AA/Mean-Teacher/"/>
    <url>/2022/03/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E5%8E%BB%E5%99%AA/Mean-Teacher/</url>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://readpaper.com/pdf-annotate/note?noteId=660745891978698752&amp;pdfId=660745407483162624">https://readpaper.com/pdf-annotate/note?noteId=660745891978698752&amp;pdfId=660745407483162624</a></p></blockquote><h1>A Multi-Task Mean Teacher for Semi-Supervised Shadow Detection 🎍</h1><h2 id="0-Abstract-🎒">0. Abstract 🎒</h2><p>现有的阴影检测方法在依赖有限的标记数据集方面存在固有的局限性，在一些复杂的场地上可能会产生较差的结果。为了提高阴影检测的性能，利用未标记的数据，探索并学习阴影的多个信息，提出了一种半监督阴影检测的多任务mean teacher模型。具体地说，我们首先构建了一个多任务基线模型，通过利用阴影区域、阴影边缘和阴影计数的互补信息来同时检测阴影区域、阴影边缘和阴影计数，并将该基线模型分配给学生和教师网络。然后，我们将来自学生和教师网络的三个任务的预测保持一致，以计算未标记数据的一致性损失，然后将其添加到多任务基线模型预测的标记数据的有监督损失中。在三个广泛使用的基准数据集上的实验结果表明，我们的方法的性能一致优于所有比较的最先进的方法，这验证了所提出的网络可以有效地利用额外的未标记数据来提高阴影检测的性能。</p><h3 id="提炼内容">提炼内容</h3><h4 id="问题">问题</h4><p>现有的阴影检测方法在依赖有限的标记数据集方面存在固有的局限性，在一些复杂的场地上可能会产生较差的结果。</p><h4 id="方法">方法</h4><p>​为了提高阴影检测的性能，利用未标记的数据，探索并学习阴影的多个信息，提出了一种半监督阴影检测的多任务mean teacher模型。</p><p>​具体地说，我们首先构建了一个多任务基线模型，通过利用阴影区域、阴影边缘和阴影计数的互补信息来同时检测阴影区域、阴影边缘和阴影计数，并将该基线模型分配给学生和教师网络。然后，我们将来自学生和教师网络的三个任务的预测保持一致，以计算未标记数据的一致性损失，然后将其添加到多任务基线模型预测的标记数据的有监督损失中。</p><h4 id="结果">结果</h4><p>​在三个广泛使用的基准数据集上的实验结果表明，我们的方法的性能一致优于所有比较的最先进的方法，这验证了所提出的网络可以有效地利用额外的未标记数据来提高阴影检测的性能。</p><h2 id="5-Conclusion-🎃">5. Conclusion 🎃</h2><p>本文通过开发一个多任务的mean teacher框架，提出了一种新的单幅图像阴影检测网络。我们的主要思想是首先建立一个多任务网络，利用它们的<strong>互补信息同时预测阴影区域检测、阴影边缘检测和阴影计数估计</strong>，然后利用mean teacher<strong>半监督学习</strong>来利用额外的未标记数据来进一步提高检测性能。在三个基准数据集上的实验结果表明，我们的网络的性能一直远远优于最先进的方法。与其他工作[43，41，12]一样，我们的方法可能不能很好地处理具有多个复杂阴影的图像。重新解决这一具有挑战性的问题被认为是我们今后工作的方向。</p><h4 id="未解决的问题">未解决的问题</h4><p>与其他工作[43，41，12]一样，我们的方法可能不能很好地处理具有多个复杂阴影的图像。重新解决这一具有挑战性的问题被认为是我们今后工作的方向。</p><h2 id="1-Introduce-➿">1. Introduce ➿</h2><p>作为日常生活中的一种普遍现象，自然图像中的阴影对提取场景几何[29，17]、光线方向[22]、摄像机位置及其参数[16]有一定的提示作用，有利于图像分割[4]、目标检测[2]、目标跟踪[27]等不同的高层图像理解任务。对于这些应用，我们需要高精度地检测图像中的阴影。</p><p>现有的方法通过开发颜色和光照的物理模型来检测阴影[6，5],通过人工提取特征或者从卷积神经网络提取特征来驱动数据。虽然目前的方法已经在基准数据集[33，42，35，10]上取得了很高的准确率，但是它们几乎需要足够的标注数据来进行训练，而且这样的训练数据通常是在有限的场景中捕获的，然而，为不同的场景创建大的标注数据集是昂贵和耗时的。Le等人[24]提出通过弱化原始训练图像的阴影区域来增强训练图像，但是我们注意到这些增强后的图像往往是假的，并且它们的非阴影背景与原始训练图像的背景相似，从而阻碍了泛化能力。与已有的数据集相比，在实际应用中，我们可以很容易地收集到丰富的未标记阴影图像。因此，当使用有限的标记数据进行训练时，利用额外的未标记数据来提高阴影检测性能是非常必要的。</p><p><img src="https://picture.mulindya.com/Apaper_collect/Mean_Teacher_fig1.png" alt=""></p><p>另一方面，在测试各种自然图像的现有方法时，我们发现他们可能会忽略小的阴影块，将暗区误认为阴影，由于边界较弱而漏掉了不明显或柔和的阴影。这些情况会导致阴影边界较差，并可能改变阴影区域的数量。受多任务学习在许多计算机视觉应用中的成功应用[14，3，18，26]的启发，我们决定在工作中研究阴影区域、阴影边缘和阴影计数的互补信息，以增强从全局和细节两个角度的阴影区域检测。具体地说，阴影计数检测对阴影区域的总数设置全局约束，而阴影边缘检测对阴影区域的边界设置细节级别的约束。</p><p>在这方面，我们开发了一个多任务均值教师框架(MTMT-Net)来提高阴影检测的性能。我们首先设计了一个多任务CNN，**用于相互学习三个任务(即阴影区域检测、阴影边缘检测和阴影计数检测)**记为MT-CNN，并将该MT-CNN模型作为学生网络和教师网络。然后，我们提出了一种标签数据的监督多任务损失函数，以整合所有三个任务上的监督损失。之后，我们强制学生网络和教师网络的三个任务的结果分别在所有未标记的数据上保持一致。<strong>通过加入改进的MT-CNN的监督损失和三个任务的一致性损失来训练模型</strong>，我们的网络可以比现有的方法更准确地检测出阴影区域。我们的主要工作概括如下：</p><ol><li>首先，我们开发了一种用于阴影检测的多任务CNN(MT-CNN)，通过从单输入图像中同时检测阴影区域、阴影边缘和阴影计数。MT-CNN对已标注数据的阴影检测效果要好于单一的阴影检测任务。</li><li>其次，我们提出设计一个多任务均值教师框架来<strong>融合来自三个预测任务的未标记数据的一致性损失，以进行阴影检测</strong>。作为一种自集成模型，我们的框架有可能用于开发其他视觉任务的半监督框架，包括显著性检测、边界检测和语义分割。</li><li>最后，在三个广泛使用的基准数据集上，我们证明了所提出的网络比最先进的方法有很大的差距。</li></ol><h2 id="2-Related-Work-🔓">2. Related Work 🔓</h2><h4 id="传统的方法">传统的方法</h4><p>早期的尝试[6，5，32]利用照明模型和颜色信息来识别阴影区域，并且它们中的大多数只在高质量和良好约束的图像上工作得很好[28，41]。后来的数据驱动策略在标注数据上设计了特定的手工特征[42，23，7，13，34]，并将这些特征提供给不同的分类器[42，23，7，13，34]进行阴影检测，虽然提高了准确率，但在手工特征不足以区分阴影区域的复杂情况下，这些策略通常会出现性能下降的问题。</p><h4 id="基于深度学习的方法">基于深度学习的方法</h4><p>受深度学习在各种视觉任务中取得的显著进展的启发，基于卷积神经网络(CNN)的阴影检测方法被发展为从标记数据集中学习深度阴影干扰特征的方法。Khan等人。[19]通过构建7层CNN，形成了第一个对图像像素进行阴影/非阴影分类的网络，它首先从超像素级别提取深度特征，然后将特征喂到条件随机场模型（CRF）来平滑阴影检测结果。icente等人学习图像级阴影先验知识，并将其与局部图像块相结合，训练基于patch的CNN生成阴影模板。然后，一个基于生成性对抗网络的阴影检测器，称为scGAN[28]，通过在输入图像上形成一个条件生成器来预测阴影映射。[8]中的一种快速深阴影检测网络从手工制作的特征中获得阴影先验图，应用patch级CNN预测面片的阴影掩模，并结合多尺度面片的结果来预测整个阴影图。</p><p>最近，胡等人提出了一个新的观点。[12]通过学习方向感知的空间上下文特征检测出阴影像素。朱埃塔尔[43]设计了一种循环注意残差(RAR)模型，将相邻两个CNN层的上下文进行合并，并构造了两系列RAR模块来迭代整合CNN层上的空间上下文。勒埃塔尔[24]将生成辅助训练示例的阴影检测网络(D-NET)与阴影衰减网络(A-NET)相结合。Wang等人[37]堆叠多个并行融合分支，在深度监督框架中融合全局语义线索和局部空间细节。郑某等人[41]提出了一种分心感知阴影(DS)模型来预测假阳性和假阴性像素，并将获得的分心特征在每一层CNN中进行融合以进行阴影检测。</p><h5 id="缺点">缺点</h5><p>现有的阴影检测方法虽然改进了阴影检测条，但存在训练检测网络需要大量像素级标注数据的固有局限性。虽然Adnet[24]通过削弱阴影区域来增强来自单个阴影图像的训练图像，但是增强的图像往往是假的，背景与原始训练图像非常相似，导致泛化能力有限。在本文中，我们利用未标记的数据来辅助阴影检测。为此，我们将多任务学习嵌入到自集成框架中，以增强阴影检测任务的一致性损失。结果表明，我们的方法比后面实验部分详细描述的最先进的阴影检测器性能更好。</p><h2 id="3-Methodology-🔎">3. Methodology 🔎</h2><p><img src="https://picture.mulindya.com/Apaper_collect/Mean_Teacher_fig2.png" alt=""></p><p>图2显示了所提出的MTMT-Net的工作流程，该MTMT-Net通过使用mean teacher半监督学习来整合标记数据和未标记数据。具体地说，通过考虑阴影区域检测、阴影边缘检测和阴影计数检测三个任务，提出了一种多任务卷积神经网络(MT-CNN)。</p><p><strong>MT-CNN既用于学生网络，也用于教师网络。</strong></p><ul><li><p>在训练过程中，将标注后的数据送入学生网络，通过融合三个任务损失计算出一个多任务监督损失。</p></li><li><p>对于未标记的数据，我们从输入的图像中生成一个辅助阴影图，并将其分别馈送到学生网络和教师网络。</p></li><li><p>对两组预测阴影信息进行多任务一致性损失计算，在测试阶段只利用<strong>学生网络</strong>对输入图像进行阴影图预测。</p></li></ul><h3 id="3-1-Multi-task-Convolutional-Neural-Network-MT-CNN">3.1 Multi-task Convolutional Neural Network(MT-CNN)</h3><p>现有的阴影检测方法虽然取得了显著的效果，但由于边界较弱，在检测软阴影时存在性能下降的问题。他们也往往会忽略小的阴影区域或者将暗处的非阴影区域错认为阴影区域，从而会改变检测到的阴影区域的技术。为了解决这些问题，我们认为明确考虑阴影边缘和阴影计数有助于提高阴影区域检测的定位精度和分割质量。在本文中，我们提出了一个多任务CNN(MT-CNN)，它以端到端的方式对单个网络中的阴影边缘、阴影计数和阴影区域信息进行建模和融合，如图3所示。</p><p><img src="https://picture.mulindya.com/Apaper_collect/Mean_Teacher_fig3.png" alt=""></p><h4 id="3-1-1-Shadow-Region-Detection">3.1.1 Shadow Region Detection</h4><p>给定一幅输入的阴影图像，我们首先使用卷积神经网络(在我们的实验中是ResNeXt-101[38])来<strong>产生一组不同尺度的特征映射</strong>(表示为EF1、EF2、EF3、EF4和EF5)(见图3)。</p><p>注意到阴影检测在不同的CNN层之间有互补的信息，在浅层的CNN层捕捉阴影细节和非阴影细节，在深层的CNN忽略大部分非阴影像素也会遗漏部分阴影区域。这里，我们使用short connections[9]来合并最后四个CNN层的特征映射，得到四个新的特征映射(表示为DF2、DF3、DF4和DF5)。具体的说，合并后的feature map的第k层CNN层$DF_k$：</p>$$DF_k = Conv(concat(EF_k,...,EF_5)) \quad \quad (1)$$<p>然后，我们将最浅的特征（EF1）和最深的特征（EF5）合并，已生成一个新的特征图标记为DF1用于预测阴影边缘。</p><p>之后<strong>为了继承阴影边缘和阴影区域信息</strong>，我们首先将它们向上采样到DF1的空间然后逐个元素的添加DF1,提炼feature map表示为{$RF_k,k=2,…,5$},定义为：</p>$$RF_k= up(DF_k) + DF_1 \quad \quad (2)$$<p>最后，我们预测了来自DF2、DF3、DF4和DF5的4个阴影区map（来自RF2、RF3、RF4和RF5的4个阴影区map）以及由精化的特征映射(图3中记为$S_f$)，该阴影映射是通过逐个元素地相加而产生的。</p>$$S_f = Pred(\sum _{k=2}^5 RF_k) \quad \quad (3)$$<p>预测Pred($\cdot$)是通过在特征上使用3×3卷积层、1×1卷积层和Sigmoid激活层[43]来实现的。</p><h4 id="3-1-2-Shadow-Edge-Detection">3.1.2 Shadow Edge Detection</h4><p>通过观察阴影图像，我们注意到对于软阴影，边界可能无法和周围的非阴影区域区分开。这促使我们利用边缘知识来提高检测性能，最近的显著性检测器也证明了边缘知识有助于提高显著性检测的质量。</p><p>在MT-CNN中，我们将CNN的低层特征$EF_1$和最深CNN层的高层特征$EF_5$进行融合，生成特征图$DF_1$，然后用它来预测阴影边缘图。虽然低层特征$EF_1$捕获了足够的阴影边缘信息，但仅使用$EF_1$检测阴影边缘是不够的，因为EF1还编码了许多非阴影背景细节。另一方面，深层特征$EF_5$具有最大的感受野，可以有效地抑制非阴影像素。具体地说，$DF_1$是通过对$EF_1$和$EF_5$进行逐个元素的相加来计算的。</p><h4 id="3-1-3-Shadow-Count-Detection">3.1.3 Shadow Count Detection</h4><p>通过分析现有阴影检测方法的检测结果，我们发现了三种常见的失败情况：</p><ul><li><p>丢失小的阴影区域；</p></li><li><p>误识别非阴影区域；</p></li><li><p>误检测附近的阴影区域。</p></li></ul><p>这些情况都会导致不准确的阴影区域数。因此，为了提高阴影检测的性能，我们探索了阴影区域的数量。</p><p>**检测阴影区域数目需要对整个图像进行全局理解。**如图3所示，我们依靠CNN最深层的$EF_5$进行检测。具体地说，我们应用单个全连通的层$EF_5$来获得表示阴影计数的Score(A)。由于阴影区域的数量可能非常大，为了使计算可行，我们设置了最大约束$N_max$，并经验地计算了标量A作为回归问题：<br>$$<br>A = \frac{min(N_{actual},N_{max})}{N_{max}} \quad \quad (4)<br>$$<br>这里的$N_{adtual}$表示阴影区域的实际数目，$N_{max}$经验取值为8。也就是最大的区域数目限制在8以下。</p><h3 id="3-2-标签数据的多任务监督损失">3.2 标签数据的多任务监督损失</h3><p>对于带标签的数据，我们可以有一对数据（输入的图像和对应的掩膜）；因此我们将带标签掩膜数据作为阴影检测（$G_r$）的ground-truth。同时，我们将Canny算子（边缘检测算子）应用于标签掩膜生成对应的边缘图作为阴影边缘检测的ground-true（$G_e$）。我们进一步观察每一个标注图像，手动计算阴影区域的数目。这个是阴影计数的基础（$G_c$）。</p><p>在得到ground-truth之后<br>多任务监督损失(表示为$\mathcal{L}^s$）是将以下三者相加得到:</p><ol><li>阴影区域检测损失（$\mathcal{L}^s_r$）</li><li>阴影边缘检测损失（$\mathcal{L}^s_e$）</li><li>阴影计数损失（$\mathcal{L}^s_c$）</li></ol>$$\mathcal{L}^s(x) = \mathcal{L}^s_r+\alpha \mathcal{L}^s_e + \beta \mathcal{L}^s_c \quad \quad (5)$$<p>这里的</p>$$\begin{equation}\begin{aligned}\mathcal{L}^s_r &amp; = \sum_{j=1} ^9 \Phi_{BCE}(P_r(j),G_r) ,\\\mathcal{L}^s_e &amp; = \Phi_{BCE}(P_e,G_e) , \quad \quad \quad \quad (6) \\\mathcal{L}^s_c &amp; = \Phi_{BCE}(P_c,G_c) \\\end{aligned}\end{equation}$$<p><strong>MSE 模型的预测值与标签的L2距离。</strong></p><p><strong>BCE <a href="https://so.csdn.net/so/search?q=%E4%BA%A4%E5%8F%89%E7%86%B5&amp;spm=1001.2101.3001.7020">交叉熵</a>损失函数，衡量两个分布之间的差异，一般用于分类问题。</strong></p><p>这里，$P_r(j)$表示九个预测阴影图中的一个，$P_e$是预测阴影边缘图，$P_c$是预测阴影计数值。$\Phi_{BCE}$和$\Phi_{MSE}$分别是二元交叉熵损失函数和MAE损失函数。我们在网络训练中经验地设置了权值$\alpha=10$和$\beta=1$。</p><h3 id="3-3-无标签数据的多任务一致性损失">3.3 无标签数据的多任务一致性损失</h3><p>对于未标注数据，我们将其输入到学生和教师网络以获得三个任务的结果，即九个阴影区域图（表示未$S_{r_1}$和 $S_{r_9}$），阴影边缘图（表示未$S_e$）和阴影计数（表示为$S_c$）Score，<strong>然后我们强制使得来自学生网络和教师网络的三个任务预测一致</strong>，从而多任务一致性损失为$L^c$:</p>$$\mathcal L^c(y) = \mathcal L^c_r + \mathcal L^c_e  + \mathcal L^c_c \quad \quad \quad \quad (7)$$<p>这里的</p>$$\begin{equation}\begin{aligned}\mathcal L^c_r &amp;= \sum^9_{j=1} \Phi_{MSE}(S_{r_j},T_{r_j}),\\\mathcal L^c_e &amp;= \Phi_{MSE}(S_e,T_e), \quad \quad \quad \quad (8) \\\mathcal L^c_c &amp;= \Phi_{MSE}(S_c,T_c)\end{aligned}\end{equation}$$<p>这里的$\mathcal L^c_r,\mathcal L^c_e,\mathcal L^c_c$分别表示阴影区域，阴影边界，阴影计数的一致性损失。</p><h3 id="3-4-Our-Network">3.4 Our Network</h3><p>我们将半监督自集成模型的多任务学习应用于阴影检测，网络的总损失为：</p>$$\mathcal L_{total} = \sum^N_{i=1} \mathcal L^s(x_i) + \lambda \sum_{j=1}^M \mathcal L^c(y_j) \quad \quad \quad \quad (9)$$<p>这里的N表示训练集中标签数据图像的数量，M表示未标记数据的数量。$\mathcal L^s(x_i)$表示对于第i个标记图像的多任务监督损失函数（公式5），$\mathcal L^c(y_j)$表示用于第j个未标记图像多任务一致性损失(公式7）。$\lambda$用于平衡<strong>标记数据</strong>上的<strong>多任务监督损失</strong>和<strong>未标记</strong>数据上的多任务<strong>一致性损失</strong>。</p><p>通过使用以来时间的高斯预热函数来更新$\lambda$:$\lambda(t) = \lambda_{max}e^{-5(1- \frac {t}{t_{max}})^2}$,这里的t表示当前的训练迭代，$t_{max}$表示训练的最大迭代次数。在我们的实验中，经验设置$\lambda _{max} = 10$。</p><p>我们最小化$\mathcal L_{total}$来训练学生网络，通过指数移动平均（EMA）策略来更新每个训练迭代中的教师网络参数，在第t轮训练教师网络参数表示：</p>$$\theta ^{\prime}_t = \eta \theta ^{\prime}_{t-1} + (1-\eta)\theta ^{\prime}_t \quad \quad \quad \quad (10)$$<p>这里的$\theta _t$表示在第t轮训练的学生网络参数，如文献[21,31]建议的EMA衰减因子$\eta$经验设置未0.99。</p><h4 id="我们的未标记数据">我们的未标记数据</h4><p>在我们的工作中，未标记的数据有3424张带阴影的图像。它由两部分组成：一部分是来自最近的阴影去除工作的USR数据集[11]，另一部分是我们从互联网上收集的979张图像。USR数据集[11]具有2445个没有阴影检测注释的阴影图像。</p><h3 id="3-5-训练和测试策略">3.5 训练和测试策略</h3><h4 id="训练参数">训练参数</h4><p>为了加快训练过程，降低过拟合风险，**我们使用ResNeXt[38]初始化MT-CNN(学生网络)的参数，ResNeXt[38]已经针对ImageNet上的图像分类任务进行了很好的训练。**MT-CNN中的其他参数被初始化为随机值。采用动量为0.9%、权值为0.0005的随机梯度下降法（SGD）对整个网络进行1万次迭代优化。学习率由（Poly Strategy）多策略调整[25]，初始学习率为0.005，幂为0.9%。我们将所有已标记和未标记图像的大小调整为<code>416×416</code>，用于在单个GTX2080Ti GPU上训练网络，并通过随机水平翻转来扩大训练集。我们使用的最小批次大小为6，它由4个标记图像和2个未标记数据图像组成。</p><h4 id="推论">推论</h4><p>在测试过程中，我们将输入图像的大小调整为<code>416×416</code>，将调整后的图像送入<strong>学生网络</strong>，并获取最右侧的阴影区域检测map(图3中的$S_f$)作为MTMT-Net的最终输出。在最近的阴影检测网络[43，41]的基础上，我们应用<strong>全连通条件随机场(CRF)</strong>[20]对网络的预测结果进行了进一步的后处理。</p><h2 id="4-Experimental-Results-💡">4. Experimental Results 💡</h2><p>在这节，我们首先展示了阴影检测基准数据集和评估度量，进而比较了MTMT-net和现在先进的关于阴影检测器和阴影去除，显著性检测和语义分割的结果，最后报告消融研究结果。我们在三个基准数据集上的代码、模型参数和阴影检测结果已在https://github.com/eraserNut/MTMT.发布</p><h3 id="4-1-数据集和评估指标">4.1 数据集和评估指标</h3><h4 id="Benchmark-datasets">Benchmark datasets</h4><p>我们在三个广泛使用的阴影检测基准数据集SBU[33]、UCF[42]和ISTD[35]上对我们的方法进行了评估：(I)SBU数据集是最大的带标注的阴影数据集，有4089幅训练图像和638幅测试图像；(Ii)UCF数据集包括145幅训练图像和76幅测试图像，覆盖了室外场景；(Iii)ISTD是最近开发的一种同时用于阴影检测和去除的数据集。它有1870个三元组的阴影图像、阴影贴图和无阴影图像，其中540个用于测试。类似于最近的工作[12，24，43，41]，对于SBU和UCF，我们通过在SBU训练集和我们的未标记数据集上训练我们的网络来获得评估结果。由于ISTD只包含与SBU图像不同的投射阴影图像，按照[41]，我们使用未标记的数据在ISTD训练数据集上重新训练我们的方法和大多数竞争对手。我们SBU的培训时间是1小时，ISTD的培训时间是0.5小时。我们网络的模型规模是169米。在测试中，我们的MTMT-Net处理一幅416×416图像的分辨率大约需要0.05秒。</p><h4 id="Evaluation-metric">Evaluation metric</h4><p>我们使用一个常用的度量，即平衡错误率(BER)来定量评估阴影检测性能。BER[43，12]同等考虑阴影区域和非阴影区域的质量，这由以下公式给出：</p>$$BER = (1- \frac 1 2(\frac {N_{tp}}{N_p}+ \frac {N_{tn}}{N_n})) \times 100, \quad \quad (11)$$<p>这里的$N_{tp},N_{tn},N_p,N_n$分别表示的是真阳性数目，真阴性数目，一张图片的阴影像素和非阴影像素的数目。较小的BER值表示较好的阴影检测性能。</p><h3 id="4-2-Comparison-with-the-State-of-the-art-ShadowDetectors">4.2 Comparison with the State-of-the-art ShadowDetectors</h3><p>比较了DSDNet[41]、DC-DSPF[37]、BDRAR[43]、AD-Net[24]、DSC[12]、ST-CGAN[35]、Patched-CNN[8]、scGAN[28]、Stack-CNN[33]和Unary-Pair[7]等10种阴影检测器的性能。</p><h4 id="质量对比">质量对比</h4><p><img src="https://picture.mulindya.com/Apaper_collect/Mean_Teacher_tab1.png" alt=""></p><p>表1总结了不同方法在三个基准数据集上的定量结果。BER分数是阴影和非阴影BER分数的平均值。显然，基于深度学习的方法[33，12，8]比手工设计的检测器[7]具有更小的误码率，因为它们可以从标注的训练图像中学习到更强大的阴影检测特征。在基于深度学习的阴影检测器中，DSDNet[41]是性能第二好的方法，它显式学习并集成虚拟干扰区域的语义来推断阴影。与现有性能最好的方法相比，我们的方法在SBU、UCF和ISTD上的误码率得分分别降低了8.70%、1.58%和20.7%。此外，对于SBU和UCF，我们的方法在非阴影像素上具有更好的误码率得分，对于ISTD，在阴影像素上具有更好的误码率得分。这表明我们的网络对SBU和UCF预测了更多的阴影像素，并减少了对ISTD的非阴影区域的误报预测。与三种比较方法[43，12，41]一样，我们也使用CRF[20]作为后处理。在图表1的第二行展示了不使用CRF情况下的MTMT-net。结果表明，主要是在UCF数据集上使用CRF取得了一定程度的改进，而不使用CRF仍然取得了比大多数最先进的方法更好的性能。</p><h4 id="视觉对比">视觉对比</h4><p><img src="https://picture.mulindya.com/Apaper_collect/Mean_Teacher_fig4.png" alt=""></p><p>我们进一步将我们的方法生成的阴影检测图与目前最先进的阴影检测图进行了直观的比较，如图4所示。从结果可以看出，我们的MTMT网(图4的第3列)在所有阴影检测器中具有最好的性能。它可以有效地定位不同背景下的不同阴影，并成功地将真实阴影与具有阴影外观的非阴影区域区分开来。例如，在第3、5和7行，MTMT-Net能够准确地检测出阴影区域，而其他算法则分别错误地识别了道路、天空和暗地阴影。此外，对于大阴影区域中的高对比度目标，MTMT-NET仍能将其识别为阴影，如后两行所示。</p><h3 id="4-3-阴影去除、稳健性检测和语义分割方法的比较">4.3 阴影去除、稳健性检测和语义分割方法的比较</h3><p>要注意的是，为阴影移动、显著检测和语义分割而设计的深层网络可以通过使用带注释的阴影数据集来重新训练以用于阴影检测。为了进一步评估我们方法的有效性，我们应用了</p><ul><li><p>阴影去除模型</p><ul><li>DeshadowNet</li></ul></li><li><p>三种显著检测模型：</p><ul><li>SRM</li><li>Amulet</li><li>EGNet</li></ul></li><li><p>基于阴影检测数据集的语义分割模型</p><ul><li>PSPNet</li></ul></li></ul><p><img src="https://picture.mulindya.com/Apaper_collect/Mean_Teacher_tab1.png" alt=""></p><p>我们采用已有的比较方法的结果，无论是重新训练发布的代码还是使用报告的方法，为了公平比较，我们尽量微调它们的训练参数，选择最好的阴影检测结果。表1中的最后五行报告了它们的误码率值，我们看到这些模型可以获得比一些现有阴影检测器更好的误码率性能，但仍然比我们的网络差。</p><h3 id="4-4-Ablation-Analysis">4.4 Ablation Analysis</h3><blockquote><p>「消融分析」（Ablative analysis）尝试去解释一些基线表现（通常表现更差）与当前表现的差别。</p><p><strong>消融分析的方法是从最佳表现出发，逐步去除这些特征，观察算法的准确率变化</strong>，目的其实就是为了控制变量。</p></blockquote><h4 id="Baseline-network-design">Baseline network design</h4><h5 id="多任务监督损失">多任务监督损失</h5>$$\mathcal{L}^s(x) = \mathcal{L}^s_r+\alpha \mathcal{L}^s_e + \beta \mathcal{L}^s_c \quad \quad (5)$$<h5 id="多任务一致性损失">多任务一致性损失</h5>$$\mathcal L^c(y) = \mathcal L^c_r + \mathcal L^c_e  + \mathcal L^c_c \quad \quad \quad \quad (7)$$<p>我们执行消融研究实验来评估所提议的多任务监督损失(见公式(5))和多任务一致性损失(参见公式(7)我们的MTMT-Net。这里，我们考虑七个基线网络。</p><p>前四个基线网络是通过重新移除教师模型来构建的。这意味着只有标签数据的监督丢失才能用于MT-CNN的训练。具体地说，第一基线网络(表示为“BASIC”)仅考虑阴影区域检测监督损失($\mathcal L^s_r$ inEq.(5))。第二种(表示为“basic+SE”)是添加阴影边缘检测监督损失($\mathcal L^s_e$ of Eq.(5))，而第三个(表示为“basic+SC”)是添加阴影计数检测监督损失($\mathcal L^s_c$of Eq.(5))。四是将三项任务的监督损失融合在一起。</p><p>另外三个基线网络是建立用于检验在未标注多任务一致性损失。</p><ul><li><p>第一种方法(记为“basic-MT”)只考虑阴影区域任务的Mean teacher模型。,通过融合等式的监督损失($\mathcal L^s_R$of 公式(5))和一致性损失($\mathcal L^c_r $  of 公式(7))。</p></li><li><p>第二种方法(记为“basic-MT+SE-MT”)是将mean teacher模型应用于阴影区域检测和阴影边缘检测，</p>  $$  公式5中的 \mathcal{L}^s_r,\mathcal{L}^s_e，和公式7中的 \mathcal{L}^c_r,\mathcal{L}^c_e  $$  <p>用于训练网络。</p></li><li><p>最后一种方法(记为“basic-MT+SC-MT”)采用平均教师模型进行阴影区域检测和阴影计数检测。换言之，监督损失和和一致性损失用于网络训练。</p>  $$  公式5中的 \mathcal{L}^s_r,\mathcal{L}^s_c 和公式7中的\mathcal{L}^c_r,\mathcal{L}^c_c  $$  </li></ul><p>我们使用SBU训练集和我们的未标记数据对所有七个基线网络进行训练，以获得SBU和UCF的结果。对于ISTD，我们使用ISTD训练集和我们的未标记数据来训练所有四个网络，并使用ISTD测试集对它们进行测试。</p><h4 id="质量对比-2">质量对比</h4><p><img src="https://picture.mulindya.com/Apaper_collect/Mean_Teacher_tab2.png" alt=""></p><p>表2总结了我们的网络和七个基准网络在三个基准数据集上的BER值。结果表明：</p><h5 id="Basis">Basis</h5><p>(i)“BASIC+SE”和“BASIC+SC”比“BASIC”具有更高的误码率，这意味着<strong>阴影边界和阴影计数的检测可以为阴影检测提供有用的信息。</strong></p><p>(ii)“BASIC+三任务”比“BASIC+SE”和“BASIC+SC”具有更好的误码率性能，说明将这三个任务融合在一起进行有监督的阴影检测具有更好的检测性能。</p><p>(iii)“BASIC-MT”比“BASIC”能更准确地检测出阴影像素，因为它的误码率较小。这表明了额外的未标记数据的一致性损失具有更好的阴影检测性能。</p><h5 id="MTMT">MTMT</h5><p>(iv)“BASIC-MT+SE-MT”和“BASIC-MT+SC-MT”比“BASIC-MT”产生的误码率小，说明阴影边缘检测和阴影区域检测有利于阴影检测的mean-teacher模型。</p><p>(v)由于“BASIC-MT+SE-MT”比“BASIC-MT+SC-MT”具有更好的误码率结果，所以<strong>阴影边缘检测比阴影计数检测对我们方法的成功有更大的贡献，这是因为“BASIC-MT+SE-MT”比“BASIC-MT+SC-MT”有更好的误码率。</strong></p><p>(vi)通过设计一个三任务mean teacher模型，我们的MTMT-Net在三个基准上具有最好的误码率性能。</p><h4 id="视觉对比-2">视觉对比</h4><p><img src="https://picture.mulindya.com/Apaper_collect/Mean_Teacher_fig5.png" alt=""></p><p>此外，图(5)直观地比较了我们的MTMT网和七个基线网络生成的阴影图。显然，无论在阴影分割质量还是定位精度上，我们的方法都比所有七个基线网络都能更好地识别阴影。这证明了在一个框架内考虑阴影边缘、阴影计数信息和未标记数据的有效性。</p>]]></content>
    
    
    <categories>
      
      <category>文献</category>
      
      <category>去噪</category>
      
    </categories>
    
    
    <tags>
      
      <tag>文献</tag>
      
      <tag>去噪</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop_Microsoft207 课程表</title>
    <link href="/2022/03/16/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft207/"/>
    <url>/2022/03/16/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft207/</url>
    
    <content type="html"><![CDATA[<blockquote><p>课程表</p></blockquote><h2 id="题目">题目</h2><p>你这个学期必须选修 numCourses 门课程，记为&nbsp;0&nbsp;到&nbsp;numCourses - 1 。</p><p>在选修某些课程之前需要一些先修课程。 先修课程按数组&nbsp;prerequisites 给出，其中&nbsp;prerequisites[i] = [ai, bi] ，表示如果要学习课程&nbsp;ai 则 必须 先学习课程&nbsp; bi 。</p><ul><li>例如，先修课程对&nbsp;[0, 1] 表示：想要学习课程 0 ，你需要先完成课程 1 。<br>请你判断是否可能完成所有课程的学习？如果可以，返回 true ；否则，返回 false 。</li></ul><h3 id="示例-1：">示例 1：</h3><figure class="highlight lua"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs lua">输入：numCourses = <span class="hljs-number">2</span>, prerequisites = <span class="hljs-string">[[1,0]]</span><br>输出：<span class="hljs-literal">true</span><br>解释：总共有 <span class="hljs-number">2</span> 门课程。学习课程 <span class="hljs-number">1</span> 之前，你需要完成课程 <span class="hljs-number">0</span> 。这是可能的。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight lua"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs lua">输入：numCourses = <span class="hljs-number">2</span>, prerequisites = <span class="hljs-string">[[1,0],[0,1]]</span><br>输出：<span class="hljs-literal">false</span><br>解释：总共有 <span class="hljs-number">2</span> 门课程。学习课程 <span class="hljs-number">1</span> 之前，你需要先完成​课程 <span class="hljs-number">0</span> ；并且学习课程 <span class="hljs-number">0</span> 之前，你还应先完成课程 <span class="hljs-number">1</span> 。这是不可能的。<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= numCourses &lt;= 105</li><li>0 &lt;= prerequisites.length &lt;= 5000</li><li>prerequisites[i].length == 2</li><li>0 &lt;= ai, bi &lt; numCourses</li><li>prerequisites[i] 中的所有课程对 互不相同</li></ul><h2 id="题解">题解</h2><p>目标是判断课程安排图是否为有向无环图（DAG）<br>思路是通过拓扑排序判断，原理是对DAG的顶点进行排序，使得每一条有向边（u，v），均有u（在排序记录中比v先出现），也就是就说对于某点v而言，必须其源点都出现了，v才能出现。</p><h4 id="方法一-入度表（广度优先遍历）">方法一: 入度表（广度优先遍历）</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">canFinish</span>(<span class="hljs-params">self, numCourses: <span class="hljs-built_in">int</span>, prerequisites: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]</span>) -&gt; <span class="hljs-built_in">bool</span>:</span><br>        <span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> deque<br>        indegrees = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(numCourses)] <span class="hljs-comment">#每个节点的入度个数记录</span><br>        adjacency = [[] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(numCourses)] <span class="hljs-comment">#邻接表</span><br>        <span class="hljs-keyword">for</span> cur,pre <span class="hljs-keyword">in</span> prerequisites: <span class="hljs-comment">#初始化</span><br>            adjacency[pre].append(cur)<br>            indegrees[cur] += <span class="hljs-number">1</span><br>         <span class="hljs-comment">#寻找开始节点</span><br>        queue = deque()<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(numCourses):<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> indegrees[i]: queue.append(i)<br>        <span class="hljs-comment"># BFS</span><br>        <span class="hljs-keyword">while</span> queue:<br>            pre = queue.popleft() <span class="hljs-comment">#弹出一个入度为0的节点</span><br>            numCourses -= <span class="hljs-number">1</span> <span class="hljs-comment">#弹出一个就可以消减一个</span><br>            <span class="hljs-keyword">for</span> cur <span class="hljs-keyword">in</span> adjacency[pre]: <span class="hljs-comment">#判断此节点是否入度为0</span><br>                indegrees[cur] -= <span class="hljs-number">1</span><br>                <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> indegrees[cur]: queue.append(cur)<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">not</span> numCourses<br></code></pre></td></tr></tbody></table></figure><blockquote><p>在python中队列可以用list实现</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">queue = <span class="hljs-built_in">list</span>() <br>queue.append(num) <span class="hljs-comment">#压入</span><br>queue.pop(<span class="hljs-number">0</span>) <span class="hljs-comment">#弹出，指定下标是0</span><br></code></pre></td></tr></tbody></table></figure><p>栈也可以使用list实现</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">stack = <span class="hljs-built_in">list</span>() <br>stack.append(num) <span class="hljs-comment">#压入</span><br>stack.pop() <span class="hljs-comment">#弹出，默认弹出末尾的节点</span><br></code></pre></td></tr></tbody></table></figure><p>Python中的collentions中有一个<a href="https://so.csdn.net/so/search?q=deque&amp;spm=1001.2101.3001.7020">deque</a>，这个对象类似于list列表，但是使用list存储数据是，按索引访问元素很快，但是插入和删除就很慢了，因为list是线性存储，数据量大的时候，插入和删除效率很低。deque是一个链表结构所以在使用栈或者队列更推荐使用deque来实现。</p><p>deque可以理解为双向队列</p><ul><li><p>append，pop，extend默认从右端操作数据</p></li><li><p>appendleft 在列表左侧插入</p></li><li><p>popleft 弹出列表左侧的值</p></li><li><p>extendleft 在左侧扩展<strong>一组</strong></p></li></ul></blockquote><h4 id="方法二：深度优先遍历">方法二：深度优先遍历</h4><p>原理是通过DFS判断图中是否有环</p><p>借助一个标志列表flags，用于判断每个节点i的状态：</p><ol><li>未被DFS访问时标志为0</li><li>已经被其他节点访问过就无需访问了标志位-1</li><li>被当前的DFS访问标志位1，如果当前路径又访问该节点则说明有环</li></ol><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">canFinish</span>(<span class="hljs-params">self, numCourses: <span class="hljs-built_in">int</span>, prerequisites: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]</span>) -&gt; <span class="hljs-built_in">bool</span>:</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dfs</span>(<span class="hljs-params">i,adjacency,flags</span>):</span><br>            <span class="hljs-keyword">if</span> flags[i] == -<span class="hljs-number">1</span>: <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>            <span class="hljs-keyword">if</span> flags[i] == <span class="hljs-number">1</span>: <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>            flags[i] = <span class="hljs-number">1</span><br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> adjacency[i]:<br>                <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> dfs(j,adjacency,flags): <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span> <span class="hljs-comment">#剪枝</span><br>            flags[i] = -<span class="hljs-number">1</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>        flags = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(numCourses)] <span class="hljs-comment">#每个节点状态</span><br>        adjacency = [[] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(numCourses)] <span class="hljs-comment">#邻接表</span><br>        <span class="hljs-keyword">for</span> cur,pre <span class="hljs-keyword">in</span> prerequisites: <span class="hljs-comment">#初始化</span><br>            adjacency[pre].append(cur)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(numCourses):<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> dfs(i, adjacency, flags): <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br></code></pre></td></tr></tbody></table></figure><p>这两种方法的时间和空间复杂度均为O(M+N)N 和 M 分别为节点数量和临边数量；</p>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>微软</category>
      
      <category>拓扑排序</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>微软</tag>
      
      <tag>拓扑排序</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>外刊阅读--Robots and Jobs</title>
    <link href="/2022/03/15/english/Robots_and_jobs/"/>
    <url>/2022/03/15/english/Robots_and_jobs/</url>
    
    <content type="html"><![CDATA[<blockquote><p>外刊精读：机器人是否会取代人类，文章表明机器人并不会取代人类，在自动化兴起的同时会提供更多的职业需求，就业率反而增长。</p><p><a href="https://paper.mulindya.com/Robots%20And%20Jobs.pdf">https://paper.mulindya.com/Robots And Jobs.pdf</a></p></blockquote><iframe src="/js/pdfjs_old/web/viewer.html?file=https://paper.mulindya.com/Robots%20And%20Jobs.pdf" width="100%" height="600"></iframe>]]></content>
    
    
    <categories>
      
      <category>英语</category>
      
    </categories>
    
    
    <tags>
      
      <tag>英语</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>外刊阅读--Trouble in metaverse</title>
    <link href="/2022/03/14/english/trouble-in-metaverse/"/>
    <url>/2022/03/14/english/trouble-in-metaverse/</url>
    
    <content type="html"><![CDATA[<blockquote><p>外刊精读：关于科技发展中大众的抵触心理，是应该dismiss还是rethink</p><p><a href="https://paper.mulindya.com/Trouble%20In%20Metaverse.pdf">https://paper.mulindya.com/Trouble In Metaverse.pdf</a></p></blockquote><iframe src="/js/pdfjs_old/web/viewer.html?file=https://paper.mulindya.com/Trouble%20In%20Metaverse.pdf" width="100%" height="600"></iframe>]]></content>
    
    
    <categories>
      
      <category>英语</category>
      
    </categories>
    
    
    <tags>
      
      <tag>英语</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Toward Convolutional Blind Denoising of Real Photographs</title>
    <link href="/2022/03/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E5%8E%BB%E5%99%AA/CBDnet/"/>
    <url>/2022/03/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E5%8E%BB%E5%99%AA/CBDnet/</url>
    
    <content type="html"><![CDATA[<blockquote><ul><li><p><a href="https://readpaper.com/pdf-annotate/note?noteId=660745234966142976&amp;pdfId=4544599851060060161">Toward Convolutional Blind Denoising of Real Photographs</a></p><p>主要关注其实验部分：</p><p>数据集的选用，评估和对比的方式，评估噪声水平的标准和引入。</p><p>在噪声数据训练这块，是采用的合成噪声和真实噪声图片混合进行训练</p><p>因此需要明确加噪方法，对不同数据集采取不同的加噪方式。</p></li></ul></blockquote><h1>关于真实照片卷积盲去噪的研究</h1><h2 id="0-Abstract">0. Abstract</h2><p>虽然深度卷积神经网络在加性高斯白噪声的图像去噪上取得了显著成就，但是在真实噪声图像上的效果仍有局限。主要的原因在于在AWGN的图像上模型容易过拟合，导致模型严重偏离了复杂噪声模型。为了提高深度卷积去噪器的泛化能力，我们采用更具真实噪声的模型卷积盲去噪网络–使用真实噪声和干净图像对。一方面，信号相关噪声和相机内的信号处理过程是合成真实噪声图像的来源，另一方面，真实噪声的图像和无噪声图像用于训练CBD网络。为了进一步提供交互式策略来方便矫正去噪结果，我们在CBD网络中嵌入了一个非对称学习的噪声估计子网络用来抑制对噪声水平的低估。在三个真实噪声照片数据集上的广泛实验结果清楚地表明，CBDNet在定量方法和视觉质量方面都优于目前最先进的方法。该代码已在https://github.com/GuoShi28/CBDNet上提供。</p><h2 id="5-Conclusion">5. Conclusion</h2><p>我们提出了一种CBDnet用于真实世界噪声照片的盲去噪。这项工作的主要发现有两个方面：第一，真实噪声模型(包括异源高斯和ISP pipeline ?)是使从合成图像中学习的模型适用于真实世界噪声照片的关键。其次，网络的去噪性能可以通过将合成的和真实的噪声图像结合到训练中来提高。此外，通过在CBDNet中引入噪声估计子网络，我们能够利用非对称损失来提高其对真实世界噪声的生成能力，并且可以方便地进行交互去噪。</p><h2 id="1-Introduction">1. Introduction</h2><h3 id="真实噪声">真实噪声</h3><p>真实噪声的来源：</p><ol><li><p>信号噪声</p><ul><li>暗电流噪声</li><li>短噪声</li><li>热噪声</li></ul></li><li><p>ISP流水线</p><ul><li>去马赛克</li><li>伽马矫正和压缩</li></ul></li></ol><p>这些真实噪声于AWGN大相径庭，并且在现实世界中噪声照片的盲去噪仍然是一个具有挑战性的问题。</p><p><img src="https://picture.mulindya.com/Apaper_collect/CBDnet_fig1.png" alt=""></p><p>从图一当中可以发现，对于AWGN盲去噪的去噪器在应用到真实照片时会显著退化，另一方面，用于非盲AWGN去噪器将在去除真实噪声的同时平滑细节。造成这种现象的原因是过拟合，导致过度适应高斯噪声，对复杂的真实噪声泛化能力较差。</p><h3 id="噪声模型">噪声模型</h3><p>CNN去噪器的成功在很大程度上取决于合成噪声和真实噪声的分布是否匹配。因此，真实感噪声模型是真实照片盲去噪的首要问题。根据文献[14，45]，<strong>泊松-高斯分布可以近似为信号相关噪声分量和站噪声分量的异方差高斯分布，被认为是一种比AWGN更合适的真实原始噪声建模方法</strong>，而且相机内处理会进一步使噪声在空间和色相关，从而增加了噪声的复杂性。因此，<strong>我们在噪声模型中同时考虑了泊松-高斯模型和相机内处理流水线(如去马赛克、伽玛校正和JPEG压缩)</strong>。实验表明，相机内处理流水线在真实噪声建模中起着举足轻重的作用，在DND上比AWGN获得了显著的性能增益</p><blockquote><p>DND。它由 50 对真实噪声图像和相应的ground-truth图像组成，这些图像是用不同传感器尺寸的消费级相机捕获的。对于每一对，使用基本 ISO 级别拍摄参考图像，而使用较高 ISO 和适当调整的曝光时间拍摄嘈杂图像。参考图像经过仔细的后处理，需要进行小的相机移位调整、线性强度缩放和去除低频偏差。后处理的图像作为我们去噪基准的ground-truth。</p></blockquote><h3 id="网络模型">网络模型</h3><p>CBDNet由两个子网络组成，即噪声估计和非盲去噪。由于引入了噪声估计子网络，我们采用了非对称损失，<strong>对噪声水平的低估误差施加更多的惩罚</strong>，使我们的CBDNet在噪声模型与实际噪声不能很好匹配的情况下表现得很好。在NC12[29]、DND[45]和NAM[43]三个真实噪声图像数据集上进行了大量的实验。无论是量化指标还是感知质量，我们的CBDNet与最先进的相比都表现得很好。如图1所示，针对非盲BM3D[12]和盲AWGN的DnCNN[61]都不能对真实世界的噪声照片进行去噪。相比之下，我们的CBDNet通过保留大部分结构和细节，同时去除复杂的现实世界噪声，取得了非常令人满意的去噪效果。</p><h3 id="总结">总结</h3><p>综上所述，本工作的贡献有四个方面：</p><ol><li>通过同时考虑异方差高斯噪声和摄像机内处理流水线，提出了一种逼真的噪声模型，显著提升去噪性能。</li><li>为了更好地刻画真实世界的图像噪声，提高去噪性能，将合成噪声图像和真实噪声照片相结合。</li><li>得益于噪声估计子网，提出了非对称损失来提高对真实噪声的泛化能力，<strong>并通过调整噪声水平图来实现交互去噪</strong>。</li><li>在三个真实世界噪声图像数据集上的实验表明，我们的CBDNet在量化度量和视觉质量方面都达到了最先进的结果。</li></ol><h2 id="2-Related-Work">2. Related Work</h2><h3 id="2-1-Deep-CNN-Denoisers">2.1 Deep CNN Denoisers</h3><p>深度神经网络(DNNs)的出现给高斯去噪带来了很大的改进。直到Burgeret等人。[6]，大多数早期的深度模型不能达到最先进的去噪性能[22，49，57]。随后，CSF[53]和TNRD[11]探索了特有模型领域的优化算法来学习分阶段推理过程。通过结合残差学习[19]和批次归一化[21]，Zhang et al.[61]提出一种去噪CNN(DnCNN)，其性能优于传统的非CNN方法。Noise2Noise[30]在不使用CleanData的情况下也达到了最先进的水平。近年来，RED30[38]、MemNet[55]、BM3D-Net[60]、MWCNN[33]和FFDNet[62]等其他CNN方法也得到了较好的去噪效果。</p><p>研究结果[61，38，55]表明，利用CNNs的建模能力，学习单一模型进行高斯去噪是可行的。</p><h4 id="局限性">局限性</h4><p>这些盲模型可能对AWGN过度拟合，并且不能处理真实噪声。相反，非盲CNN去噪器，例如FFD-NET[62]，通过手动设置适当的或相对较高的噪声水平，可以在大多数真实的噪声图像上获得令人满意的结果。为了利用这一特点，我们的CBDNet包括噪声估计子网络和非对称损失函数，以抑制噪声水平的低估误差。</p><h3 id="2-2-Image-Noise-Modeling">2.2 Image Noise Modeling</h3><p>大多数去噪方法都是针对非盲高斯去噪的。然而，真实图像中的噪声来源繁多(暗电流噪声、短噪声、热噪声等)，而且更为复杂[44]，通过用泊松对光子传感进行建模，并用高斯对静止扰动进行建模，成像传感器的原始数据采用泊松-高斯噪声模型 [14]，对成像传感器的原始数据采用泊松-高斯噪声模型(Poisson-Gaussian Noise Model，简称Poisson-Gaussian Noise Model)。在[14，32]中，还考虑了相机响应函数(CRF)和量化噪声以进行更实际的噪声建模。除了泊松-高斯噪声， Hwang 等[20]提出了一种用于泊松光噪声建模的Skellam分布。此外，当考虑相机内图像处理流水线时，与通道无关的噪声假设可能不成立，并提出了几种跨通道噪声建模方法[25，43]，本文证明了真实噪声模型在基于CNN的真实照片去噪中起着重要作用，泊松-高斯噪声和相机内图像处理流水线都有利于去噪性能。</p><h3 id="2-3-Blind-Denoising-of-Real-Images">2.3 Blind Denoising of Real Images</h3><p>真实含噪图像的盲去噪通常比较有挑战性，可以分为两个阶段，即<strong>噪声估计和非盲去噪</strong>。对于AWGN，已经发展了几种基于PCA的噪声标准差(SD)估计方法[48，34，9]。Rabie[49]将噪声像素建模为异常值，并利用洛伦兹鲁棒估计器进行AWGN估计。对于Poisson-Gauss模型，FOI等人提出了一种两阶段方案，即多个期望/标准差对的局部估计，全局参数模型拟合。</p><p>在大多数盲去噪方法中，将噪声估计与非盲去噪结合使用。Portilla[46，47]采用<strong>高斯混合尺度对每个尺度的小波块进行建模</strong>，并利用<strong>贝叶斯最小二乘估计干净的小波块</strong>。在分段平滑图像模型的基础上，Liu et al.[32]提出了一种统一的色噪声估计和去除框架。Gong et al.[15]将数据拟合项建模为L1和L2范数的加权和，并利用小波域中的稀疏正则化算子处理混合或未知噪声。Lebrun等人[28，29]通过将每个patch组的噪声建模为零均值相关高斯分布，提出了<strong>非局部贝叶斯方法</strong>的扩展[27]。朱等人[63]提出了一种<strong>贝叶斯非参数技术通过低秩混合高斯模型</strong>来去除噪声的方法。Nam等人。[43]将跨信道噪声建模为多元高斯模型，并采用<strong>贝叶斯非局部均值过滤</strong>[24]进行去噪[24].[59]提出了一种利用通道冗余的多通道加权核范数最小化(MCWNNM)模型。他们进一步提出了一种三边加权稀疏编码(TWSC)方法，用于更好地对噪声和图像先验进行建模[58]。除Noise Clinic(NC)[28，29]、MCWNNM[59]和TWSC[58]外，大多数去噪器的代码均不可用。我们的实验表明，它们在去除真实图像中的噪声方面仍然是有限的。</p><h2 id="3-Proposed-Method">3. Proposed Method</h2><p>这一部分介绍了我们的CBDNet，它由一个噪声估计子网和一个非盲去噪子网组成。首先，我们将噪声模型引入合成含噪图像的生成。然后，介绍了网络体系结构和非对称损失。最后，我们解释了如何结合合成图像和真实噪声图像来训练CBDNet。</p><h3 id="3-1-真实噪声模型">3.1.真实噪声模型</h3><p>正如在[39]中所指出的，CNN的推广在很大程度上取决于记忆训练数据的能力。现有的CNN去噪器，例如DnCNN[61]，通常不能很好地处理真实的噪声图像，这主要是因为它们可能对AWGN<strong>过度拟合</strong>，而实际的噪声分布与高斯分布有很大的不同。另一方面，当与真实的噪声模型一起训练时，CNN的记忆能力将有助于使所学习的模型很好地生成真实的照片。因此，噪声模型对保证CNN去噪器的性能起着至关重要的作用。？</p><p>与AWGN不同，实图像噪声通常更复杂且依赖于信号[35，14]。实际上，光子传感产生的噪声可以建模为泊松噪声，剩余的静止扰动可以表示为高斯噪声。因此，泊松-高斯为成像传感器[14]的原始数据提供了一个合理的噪声模型，并且可以进一步用定义为如下的异方差高斯$n(L)∼N(0，σ^2(L))$来近似，<br>$$<br>\sigma^2(L) = L\cdot  \sigma^2_s + \sigma^2_c  \quad \quad (1)<br>$$<br>其中L是原始像素的辐照度图像。$n(L)=n_s(L)+n_c$涉及两个分量:</p><ul><li><p>具有噪声方差$σ^2_c$的平稳噪声分量$n_c$</p></li><li><p>具有空间变异噪声方差$L·σ^2_s$的依赖于信号的噪声分量$n_s$。</p></li></ul><p>然而，实际照片通常是经过相机内处理后获得的，这进一步增加了噪声的复杂性，使其在空间和色度上具有相关性。因此，我们考虑了ISP流水线的两个主要步骤，即去马赛克和伽马校正，得到了真实的噪声模型:<br>$$<br>y=f(DM(L+n(L))) \quad \quad (2) 有噪声的未压缩图像<br>$$<br>其中y表示合成噪声图像，$f(·)$表示从文献[16]提供的201个相机响应函数(CRF)中均匀采样，得到的相机响应函数(CRF)。采用$L=Mf^{-1}(X)$由干净图像生成辐照度图像，$M(·)$表示将sRGB图像转换为Bayer图像的函数，$DM(·)$表示去马赛克函数[37]。请注意，$DM(·)$中的插值涉及不同通道和空间位置的像素。方程中的合成噪声。公式(2)因此是信道和空间相关的。</p><p>此外，为了扩展CBDNet用于处理压缩图像，我们可以在生成合成噪声图像时包括JPEG压缩，<br>$$<br>y = JPEG(f(DM(L + n(L)))) \quad \quad (3) 有噪声的压缩图像<br>$$<br>对于含有噪声的未压缩图像，我们采用公式（2）中的模型生成合成噪声图像。对于有噪声的压缩图像，我们在公式（3）中定义了该模型。(3)。具体地，$σ_s$和$σ_c$分别从[0，0.16]和[0，0.06]范围内均匀采样。在JPEG压缩中，品质因数从范围[60,100]中采样。我们指出，没有考虑量化噪声，因为量化噪声很小，可以忽略，对去噪效果没有任何明显的影响[62]。</p><h3 id="3-2-Network-Architecture">3.2. Network Architecture</h3><p><img src="https://picture.mulindya.com/Apaper_collect/CBDnet1.png" alt=""></p><p>从图中可以看到，CBD网络包含两个部分，一个是噪声估计子网络$CNN_E$，和非盲去噪子网络$CNN_D$；</p><p>$ CNN_E $使用噪声观测y来产生估计噪声电平图$\hat{\sigma}(y) = F_E(y,W_E) $，其中$W_E$表示$CNN_E$的网络参数，我们使$CNN_E$的输出为噪声水平图，因为$CNN_E$的大小与输入y相同，并且可以用完全卷积网络估计。</p><p>$CNND$将y和$\hat{\sigma} (y)$作为输入，得到最终的去噪结果$\hat{x} = F_D(y,\hat{\sigma} (y);W_D)$。$W_D$表示$CNN_D$子网络的网络参数。</p><p>$CNN_E$的引入允许我们在估计噪声水平图$\hat{\sigma} (y)$中放入非盲去噪子网络之前对其调整，在此项工作中，我们提出了简单的交互式去噪策略；即$\hat{\varrho} (y) = \gamma \cdot \hat{\sigma} (y) $</p><h4 id="具体网络结构">具体网络结构</h4><p>我们进一步解释了$CNN_E$和$CNN_D$的网络结构。$CNN_E$采用平坦的五层全卷积网络，不需要合并和批归一化操作。在每一卷积(Conv)层中，设置频率通道数为32个，过滤大小为3×3。在每个卷积(Conv)层之后展开RELU非线性[42]。对于$CNN_D$，我们采用了同时以y和$\hat σ(Y)$作为输入的U-Net[51]结构来预测无噪声干净图像的$\hat x$。在[61]之后，采用残差学习，首先学习残差映射$R(y，\hat σ(Y)；W_D)$，然后预测$\hat x=y+R(y，\hat σ(Y)；W_D)$。图还给出了CNNE的16层U网结构，其中引入了<strong>对称跳跃连接、跨步卷积和转置卷积</strong>，以利用多尺度信息并扩大接收范围。所有过滤的大小都是3×3。除了最后一个之外，每个转换层之后都会应用RELU非线性[42]。此外，我们通过实验发现，批<strong>量归一化对真实感照片的噪声去除几乎没有帮助，部分原因是真实噪声分布与高斯分布有根本的不同</strong>。</p><p>最后，我们注意到，通过学习从噪声观测到干净图像的直接映射来训练单盲CNN去噪器也是可能的。然而，正如文献[62，41]中指出的那样，<strong>同时采用噪声图像和噪声水平图作为输入，有助于将所学习的模型推广到噪声模型之外的图像，从而有利于盲去噪</strong>。实验发现，对于低噪声图像，单盲CNN去噪器的性能与CBDNet相当，而对于高噪声图像，单盲CNN去噪器的性能不如CBDNet。此外，噪声估计子网络的引入也使得交互式去噪和非对称学习成为可能。因此，我们建议在CBDNet中加入噪声估计子网络。（单盲CNN去噪器是指单一噪声形式嘛）</p><h3 id="3-3-Asymmetric-Loss-and-Model-Objective">3.3. Asymmetric Loss and Model Objective</h3><p>当输入噪声为SD时高于ground-truth误差(即高估误差)，CNN和传统的非盲去噪器都表现出很好的去噪性能（当合成的噪声比真实数据的噪声水平更高，则训练的模型都可以很好）。这促使我们采用非对称损失来提高CBDNet的泛化能力。如FFDNet[62]中所述，当输入噪声为SD时和ground-truth是匹配的，BM3D/FFDNet获得最佳结果。当输入噪声SD时低于ground-truth，BM3D/FFDNet的结果包含可察觉的噪声。当输入噪声为SD时高于ground-truth误差(即高估误差)，随着输入噪声SD的增加BM3D/FFDNet通过渐变消除一些低对比度的结构，仍然可以达到令人满意的结果，因此，非盲去噪器对噪声SD的低估误差很敏感，但对高估计误差有较强的鲁棒性。有了这样的特性，BM3D/FFDNnet可以通过设置相对较高的输入噪声SD来用于对真实照片进行去噪，这可能解释了BM3D在非盲设置下在DND基准[45]上的合理性能。</p><p>为了充分利用盲去噪的非对称敏感性，我们提出了一种非对称噪声估计损失，以避免噪声水平图上出现低估误差。给定像素<code>i</code>处的估计噪声水平$\hat σ(Y_i)$和<code>ground-truth</code>$σ(Y_i)$，当$\hat σ(Y_i) &lt; σ(Y_i) $时，<strong>应对它们的MSE施加更多惩罚</strong>。(防止低估噪声水平)因此，我们将噪声估计子网络上的不对称损失定义为</p>$$\mathcal{L_{asymm}} = \sum_i | \alpha- I_{\hat{\sigma}(y_i)-\sigma(y_i)}| \cdot (\hat{\sigma}(y_i)-\sigma(y_i))^2  \quad \quad (4)$$<p><strong>i表示每个像素</strong>，这里当e小于0时$I_e=1$，e大于等于0时$I_e=0$，设置$0 &lt; \alpha &lt; 0.5$,如果低估了噪声水平，则判别式是为真也就是为1，则系数大于0.5，如果是高估了噪声水平，则判别式为0，系数小于0.5，这样求出的损失函数对低估噪声水平的情况会施加更大的处罚。使得模型在真实噪声上泛化能力更强。</p><p>另外，我们引入了总方差（TV）正则项来约束$\sigma(y)$的平滑性</p>$$\mathcal{L_{TV}} = \Vert\nabla_h \hat{\sigma}(y)\Vert_2^2+ \Vert\nabla_v \hat{\sigma}(y)\Vert_2^2  \quad \quad (5)$$<p>这里的$\nabla_h(\nabla_v)$表示水平（垂直）方向的梯度运算符（？这样可以使得噪声估计的曲线偏差不太大，避免过度高估造成过度平滑？还是使得噪声估计曲线更平滑？）</p><p>对于非盲去噪器的输出$\hat{x}$，我们定义重建损失函数为：</p>$$\mathcal{L_{rec}} = \Vert\hat{x} - x\Vert_2^2 \quad \quad (6)$$<p><strong>因此CBDnet总体的目标函数为：</strong></p>$$\mathcal{L} = \mathcal{L_{rec}}+\mathcal{\lambda_{asymm}}\mathcal{L_{asymm}}+\mathcal{\lambda_{TV}}\mathcal{L_{TV}} \quad \quad (7)$$<p><strong>这里的$\mathcal{\lambda_{asymm}},\mathcal{\lambda_{TV}}$分别表示非对称损失函数和TV正则化的折中参数。在我们的实验中，通过最小化上述目标函数，给出了CBDNet的PSNR/SSIM结果。对于视觉质量的定性评价，我们对CBDnet网络进行训练，同时将VGG-6的Relu3_3进一步加入到目标函数公式7中。</strong></p><h3 id="3-4-Training-with-Synthetic-and-Real-Noisy-Images">3.4 Training with Synthetic and Real Noisy Images</h3><p>在3.1节定义的噪声模型可以用于合成任意数量的噪声图像，同时，可以保证干净图像的高质量。尽管如此，噪声模型并不能完全描述真实照片中的噪声，幸运的式，根据文献，通过对同一场景的数百幅噪声图像进行平均，可以得到几乎无噪声的图像，在文献中已经建立了几个数据集。</p><p><strong>缺点</strong></p><p>在这种情况下场景是固定的，获取大量的噪声图像也是昂贵的；</p><p>由于平均效应，干净图像会过度平滑</p><p><strong>因此可以将合成的图像和真实的噪声图像结合起来，一提高对真实照片的泛化能力。</strong></p><p>在这项工作中，我们使用3.1节中的噪声模型生成合成噪声图像，并使用BSD500[40]中的400幅图像、Waterloo[36]中的1600幅图像和MIT-Adobe FiveK数据集[7]中的1600幅图像作为训练数据。具体地说，我们使用rgb图像<code>x</code>来合成干净的原始图像$L=mf^{-1}(X)$作为反向isp过程，并且使用与方程(2)或(3)相同的<code>f</code>来生成噪声图像。其中f是从[16]中随机抽样的CRF，对于真实的噪声图像，我们利用RENOIR数据集中的120幅图像[4]。特别地，我们在训练过程中交替使用了一批合成图像和真实噪声图像，对于一批合成图像，Eqn(7)所有的损失最小化以更新CBDNet。对于一批真实图像，由于无法获得ground-truth噪声水平map，训练时只考虑了$\mathcal{L_{rec}}和\mathcal{L_{TV}}$。实验证明，这种训练方案能有效地提高去噪真实照片的视觉质量。</p><h2 id="4-实验结果">4 实验结果</h2><h3 id="4-1-测试数据集">4.1 测试数据集</h3><p>采用NC12[29]、DND[45]和NAM[43]三个真实噪声图像数据集：</p><ol><li>NC12包括12个噪声图像。无法得到对应的干净图像，我们只报告去噪结果用于定性评估。</li><li>DND包含50对真实的有噪图像和对应的几乎无噪声的图像，DND包含50对真实的有噪图像和对应的几乎无噪声的图像。类似于[4]，通过对低ISO图像进行仔细的后处理，可以获得几乎无噪声的图像。PSNR/SSIM结果是通过在线提交系统获得的。</li><li>NAME包含11个静止场景，对于每个场景，早期的无噪声图像是500JPEG有噪图像的平均值。我们将这些图像裁剪成512×512个patch，并随机选择25个斑块进行评估测试。</li></ol><h3 id="4-2-实现细节">4.2 实现细节</h3>$$\mathcal{L} = \mathcal{L_{rec}}+\mathcal{\lambda_{asymm}}\mathcal{L_{asymm}}+\mathcal{\lambda_{TV}}\mathcal{L_{TV}} \quad \quad (7)$$<p>在公式7中的参数我们设置$\alpha = 0.3,\lambda_1=0.5,\lambda_2=0.05$，注意到来自NAM的噪声图像时JPEG压缩的，而DND的噪声图像时解压缩的，因此，我们使用公式（2）的噪声模型对DND和NC12处理，使用公式（3）对NAM进行处理。</p><p>在训练CBDNet时，采用ADAM，β1=0.9，模型初始化采用[18]中的方法。小批量的大小为32个，每个patch的大小为128×128。对所有模型进行40个周期的训练，其中前20个周期的学习率为$10<sup>{−3}$，然后用$5×10</sup>{−4}$的学习率对模型进行进一步微调。使用MatConvNet包[56]在Nvidia GeForce GTX 1080 Ti GPU上训练我们的CBDNet大约需要三天时间。</p><h3 id="4-3-Comparison-with-State-of-the-arts">4.3 Comparison with State-of-the-arts</h3><p>我们考虑了4个盲去噪方法：NC，NI，MCWNNM，TWSC。NI是一个商业的软件，已经包含在Photoshop和Corel Paintshop中，此外，我们还对比了高斯盲去噪方法（CDnCNN-B），非盲去噪方法（CBM3D，WNNM，FFDNet）。当将非盲去噪器应用于真实照片时，我们利用[9]来估计噪声SD。</p><p><img src="https://picture.mulindya.com/Apaper_collect/CBDnet_fig3.png" alt=""></p><p><strong>NC12</strong>：图3示出了NC12图像的结果。所有竞争的方法在去除黑暗区域的噪声方面都是有限的。相比之下，CBDNet在去除噪声的同时保留了显著的图像结构。</p><p><img src="https://picture.mulindya.com/Apaper_collect/CBDnet_tab1.png" alt=""></p><p><strong>DND</strong>：表1列出了在DND基准网站上发布的PSNR/SSIM结果。毫无疑问，CDnCNN-B[61]不能推广到真实的噪声照片，并且表现得非常差。虽然提供了合成噪声，非盲高斯去噪器比如WNNM[17]、BM3D[12]和FOE[52]等因为真实噪声与AWGN有很大的不同，因此只能获得有效性能。MCWNNM[59]和TWSC[58]是专门为真实照片的盲去噪而设计的，得益于真实噪声模型和与真实噪声图像的结合，也取得了令人满意的结果。我们的CBDNet获得了最高的PSNR/SSIM结果，并且略好于MCWNNM[59]和TWSC[58]。CBDnet的性能明显优于另一个基于CNN的去噪器，即CIMM。对于一幅512×512的图像，CBDNet的运行时间约为0.4s。</p><p><img src="https://picture.mulindya.com/Apaper_collect/CBDnet_fig4.png" alt=""></p><p>图4提供了DND图像的去噪结果。BM3D和CDnCNN-B不能去除真实图像中的大部分噪声，NC、NI、MCWNNM和TWNC仍然不能去除所有噪声，NI也存在过平滑效应。相比之下，我们的CBDNet在平衡去噪和结构保护方面表现出良好性能。</p><p><img src="https://picture.mulindya.com/Apaper_collect/CBDnet_tab2.png" alt=""></p><p><img src="https://picture.mulindya.com/Apaper_collect/CBDnet_fig5.png" alt=""></p><p><strong>Nam</strong>：定量和定性结果如表2和图5所示。CBDNet(JPEG)的性能远远优于CBDNet(即峰值信噪比为1.3dB)，并且与最先进的网络相比取得了最好的性能。</p><h3 id="4-4-消融研究">4.4 消融研究</h3><h4 id="噪声模型的影响">噪声模型的影响</h4><p>我们考虑了非均匀高斯(HG)和相机内处理(ISP)流水线代替AWGN来建模图像噪声。在DND和NAM上，我们实现了四种噪声模型：(I)高斯噪声(CBDNet(G))，(Ii)异质高斯(CBDNet(HG))，(Iii)高斯噪声和ISP(CBD-Net(G+ISP))，以及(Iv)异质高斯和ISP(CBDNet(HG+ISP)，即完整的CBDNet。对于NAM，还包括CBD-NET(JPEG)。表3显示了不同噪声模型的PSNR/SSIM结果。</p><p><img src="https://picture.mulindya.com/Apaper_collect/CBDnet_tab3.png" alt=""></p><h5 id="G与HG">G与HG</h5><p>在没有ISP的情况下，CBDNet(HG)比CBDNet(G)获得了约0.8∼的1dB增益。当包含ISP时，HG的增益适中，即CBDNet(HG+ISP)的性能仅比CBDNet(G+ISP)高0.15dB。</p><h5 id="w-o-ISP">w/o ISP</h5><p>与之相比，<strong>ISP对于真实图像噪声的建模更为关键</strong>。特别地，CBD-Net(G+ISP)的性能比CBDNet(G)高4.88dB，而CBDNet(HG+ISP)的性能比CBDNet(HG)高3.87dbon DND。对于NAM，ISP中包含JPEG压缩进一步带来了1.31dB的增益。</p><h5 id="合成图像和真实图像的结合">合成图像和真实图像的结合</h5><p>(I)CBDNet(Syn)只训练在合成图像上；</p><p>(II)CBDNet(Real)只训练在真实图像上</p><p>并将我们的完整CBDNet重命名为CBDNet(ALL)。</p><p><img src="https://picture.mulindya.com/Apaper_collect/CBDnet_fig7.png" alt=""></p><p><img src="https://picture.mulindya.com/Apaper_collect/CBDnet_tab1.png" alt=""></p><p>图7示出了这三种方法在NC12图像上的去噪结果。即使在大规模合成图像数据集上训练，CBDNet(Syn)仍然不能去除所有的真实噪声，部分原因是噪声模型不能完全刻画真实噪声。CBDNet(Real)可能会过度平滑图像，这部分是由于不够精确的干净噪声影响。比较而言，CBDNet(ALL)在去除真实噪声的同时保持了锐化的边缘，三种模型在DND上的定量结果如表1所示。CBDNet(ALL)获得了比CBDNet(Syn)和CBDNet(Real)更好的PSNR/SSIM结果。</p><h5 id="非对称损失函数">非对称损失函数</h5><p><img src="https://picture.mulindya.com/Apaper_collect/CBDnet_fig8.png" alt=""></p><p>图8比较了具有不同α值的CBDNet的去噪结果，即α=0.5、0.4和0.3。当α=0.5时，CBDNet对低估误差和高估误差施加同等的惩罚，当α&lt;0.5时，对低估误差施加更大的惩罚。由此可见，<strong>较小的α(即0.30)有助于提高CBDNet对未知真实噪声的泛化能力</strong>。</p><h3 id="4-5-交互式图像去噪">4.5 交互式图像去噪</h3><p><img src="https://picture.mulindya.com/Apaper_collect/CBDnet_fig6.png" alt=""></p><p>给定估计的噪声水平图$\hatσ(Y)$，我们引入系数$γ(&gt;0)$来交互地将$\hatσ(Y)$修正为$\hat{\varrho} = \gamma \cdot \hat{\sigma} (y) $。非盲去噪子网络通过允许用户调整$\gamma $，将$\hat{\varrho} $和有噪图像作为输入，得到去噪结果。图6示出了两个真实的DND噪声图像以及使用不同$\gamma$值获得的结果。</p><p>设置第一张图的$\gamma =0.7$，第二张图的$\gamma = 1.3$，CBDNet分别在<strong>保留细节纹理和去除复杂噪声方面</strong>取得了较好的视觉效果。因此，这种交互方案可以为在实际场景中调整去噪结果提供一种方便的手段。</p>]]></content>
    
    
    <categories>
      
      <category>文献</category>
      
      <category>去噪</category>
      
    </categories>
    
    
    <tags>
      
      <tag>文献</tag>
      
      <tag>去噪</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop_Microsoft324 摆动排序Ⅱ</title>
    <link href="/2022/03/10/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft324/"/>
    <url>/2022/03/10/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft324/</url>
    
    <content type="html"><![CDATA[<blockquote><p>摆动排序Ⅱ</p></blockquote><h2 id="题目">题目</h2><p>给你一个整数数组 nums，将它重新排列成 nums[0] &lt; nums[1] &gt; nums[2] &lt; nums[3]… 的顺序。</p><p>你可以假设所有输入数组都可以得到满足题目要求的结果。</p><p>奇数index的数字大于左右的偶数index数字</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight accesslog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">输入：nums = <span class="hljs-string">[1,5,1,1,6,4]</span><br>输出：<span class="hljs-string">[1,6,1,5,1,4]</span><br>解释：<span class="hljs-string">[1,4,1,5,1,6]</span> 同样是符合题目要求的结果，可以被判题程序接受。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight accesslog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">输入：nums = <span class="hljs-string">[1,3,2,2,3,1]</span><br>输出：<span class="hljs-string">[2,3,1,3,1,2]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= nums.length &lt;= 5 * 104</li><li>0 &lt;= nums[i] &lt;= 5000</li><li>题目数据保证，对于给定的输入 nums ，总能产生满足题目要求的结果</li></ul><p>**进阶：**你能用 O(n) 时间复杂度和 / 或原地 O(1) 额外空间来实现吗？</p><h2 id="题解">题解</h2><h3 id="解法一">解法一</h3><h4 id="排序-逆序穿插">排序+逆序穿插</h4><p>首先排序数组，对于排序后的数组的前部分是必然小于等于数组的后部分，中间可能有相等的情况，只需要将数组后半部分插入奇数，前半部分插入偶数位置即可；但是要注意中间相等的部分，使用逆序穿插把中间位置的数字穿插放到两边。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">wiggleSort</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-literal">None</span>:</span><br>        <span class="hljs-string">"""</span><br><span class="hljs-string">        Do not return anything, modify nums in-place instead.</span><br><span class="hljs-string">        """</span><br>        Cnums = <span class="hljs-built_in">sorted</span>(nums)<br>        n = <span class="hljs-built_in">len</span>(nums)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(nums),<span class="hljs-number">2</span>): <span class="hljs-comment">#奇数大于偶数位置 先放置奇数</span><br>            n -= <span class="hljs-number">1</span><br>            nums[i] = Cnums[n]<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,<span class="hljs-built_in">len</span>(nums),<span class="hljs-number">2</span>): <span class="hljs-comment">#后放置偶数 因为中间的数据一部分在数组头，一部分在数组尾部，所以中间出现相等的情况就不会影响</span><br>            n -= <span class="hljs-number">1</span><br>            nums[i] = Cnums[n] <br>        <span class="hljs-keyword">return</span> nums<br></code></pre></td></tr></tbody></table></figure><p>但是实际上不需要排序，因为只需要找到中位数即可，无需保证中位数的左右部分是顺序的。</p><ul><li>首先找到中位数，准确说是第k个数（使用快速排序法）</li><li>使用三分法将数组分成三个部分小于中位数，等于中位数，大于中位数的部分</li><li>逆序穿插</li></ul><p>这样时间复杂度为O(logn)+O(n),即为O(N)</p><h3 id="解法二">解法二</h3><h4 id="总体函数">总体函数</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">wiggleSort</span>(<span class="hljs-params">nums</span>):</span><br>    n = <span class="hljs-built_in">len</span>(nums)<br>    <span class="hljs-keyword">if</span> n&lt;=<span class="hljs-number">1</span>: <span class="hljs-keyword">return</span> nums<br>    k = (n+<span class="hljs-number">1</span>)//<span class="hljs-number">2</span>-<span class="hljs-number">1</span><br>    mid_value = partition(nums, k, <span class="hljs-number">0</span>, n-<span class="hljs-number">1</span>)<br>    three_way_partition(nums, mid_value)<br>    nums0 = nums.copy()<br>    <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>        nums[k] = nums0[(n+<span class="hljs-number">1</span>)//<span class="hljs-number">2</span>-<span class="hljs-number">1</span>-k//<span class="hljs-number">2</span>] <span class="hljs-keyword">if</span> (<span class="hljs-keyword">not</span> k%<span class="hljs-number">2</span>) <span class="hljs-keyword">else</span> nums0[(n-<span class="hljs-number">1</span>)-k//<span class="hljs-number">2</span>]<br></code></pre></td></tr></tbody></table></figure><h4 id="寻找中位数">寻找中位数</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">partition</span>(<span class="hljs-params">nums, k, start, end</span>):</span><br>    key = nums[start]<br>    left, right = start, end<br>    <span class="hljs-comment"># print('nums={}, start={}, end={}'.format(nums,start,end))</span><br>    <span class="hljs-comment"># 循环中的不变量: left&lt;right and nums[right]&gt;=key and nums[left]&lt;=key</span><br>    <span class="hljs-keyword">while</span> left &lt; right:<br>        <span class="hljs-keyword">while</span> left &lt; right <span class="hljs-keyword">and</span> nums[right] &gt;= key:<br>            right = right - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> left &lt; right: nums[left],nums[right] = nums[right],nums[left]<br>        <span class="hljs-keyword">while</span> left &lt; right <span class="hljs-keyword">and</span> nums[left] &lt;= key:<br>            left = left + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> left &lt; right: nums[left],nums[right] = nums[right],nums[left]<br><br>    <span class="hljs-keyword">if</span> left == k:<br>        <span class="hljs-keyword">return</span> nums[left]<br>    <span class="hljs-keyword">elif</span> left &gt; k:<br>        <span class="hljs-keyword">return</span> partition(nums, k, start, left-<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> partition(nums, k, left+<span class="hljs-number">1</span>, end)<br></code></pre></td></tr></tbody></table></figure><h4 id="三分法">三分法</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#三分法实现 {左侧}&lt;=value&lt;={右侧} 为使得左右两侧长度近似</span><br><span class="hljs-comment">#我们取 value = nums的第(n+1)//2 个数 同排序方法中前半段的最后一个数字</span><br><span class="hljs-comment">#参数l, r是小于/大于value的左右下标边界, 即nums[k]&lt;=value for k&lt;=l,nums[k]&gt;=value for k&gt;=r</span><br><span class="hljs-comment">#参数 i 是当前遍历到的数字的下标 根据它和value的关系 我们确定 nums[i]是和 l 还是和 r 交换</span><br><span class="hljs-comment">#两个细节 【1】 while i&lt;=r【2】 只有nums[i]&lt;=value 交换之后i+=1</span><br>nums = [<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>] <span class="hljs-comment"># mid=2</span><br>value = <span class="hljs-number">2</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">three_way_partition</span>(<span class="hljs-params">nums, value</span>):</span><br>    n=<span class="hljs-built_in">len</span>(nums)<br>    l, r = <span class="hljs-number">0</span>, n-<span class="hljs-number">1</span><br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-comment">#不能让i越过r 否则如果nums[l]&lt;=nums[r]&lt;nums[i] 会在下一次中让右侧更大的数字被换到左侧</span><br>    <span class="hljs-keyword">while</span> i&lt;=r: <br>        <span class="hljs-keyword">if</span> nums[i]&lt;value:<br>            nums[l],nums[i]=nums[i],nums[l]<br>            l+=<span class="hljs-number">1</span><br>            i+=<span class="hljs-number">1</span><br>        <span class="hljs-keyword">elif</span> nums[i]&gt;value: <span class="hljs-comment">#在这种情况下i不要移动 因为交换过来的数字nums[r]可能仍是&gt;value</span><br>            nums[r],nums[i]=nums[i],nums[r]<br>            r-=<span class="hljs-number">1</span><br>        <span class="hljs-keyword">else</span>:<br>            i+=<span class="hljs-number">1</span><br></code></pre></td></tr></tbody></table></figure><h4 id="逆序穿插">逆序穿插</h4><p>逆序之后的顺序: (n+1)//2-1 …1 || (n-1)…(n+1)//2<br>穿插之后的顺序: (n+1)//2-1, (n-1), (n+1)//2-1, (n-2),…, 1, (n+1)//2<br>(最后两个元素也可能是(n+1)//2，1）<br>k偶数：ind[0] - ind[k] = k//2 所以 ind[k] = ind[0]-k//2 = (n+1)//2-1-k//2<br>k奇数: ind[1] - ind[k] = k//2 所以 ind[k] = ind[1]-k//2 = (n-1)-k//2</p>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>微软</category>
      
      <category>中位数</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>微软</tag>
      
      <tag>中位数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop_Microsoft56 合并区间</title>
    <link href="/2022/03/08/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft56/"/>
    <url>/2022/03/08/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft56/</url>
    
    <content type="html"><![CDATA[<blockquote><p>合并区间</p></blockquote><h2 id="题目">题目</h2><p>以数组 intervals 表示若干个区间的集合，其中单个区间为 intervals[i] = [starti, endi] 。请你合并所有重叠的区间，并返回 一个不重叠的区间数组，该数组需恰好覆盖输入中的所有区间 。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight prolog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs prolog">输入：intervals = [[<span class="hljs-number">1</span>,<span class="hljs-number">3</span>],[<span class="hljs-number">2</span>,<span class="hljs-number">6</span>],[<span class="hljs-number">8</span>,<span class="hljs-number">10</span>],[<span class="hljs-number">15</span>,<span class="hljs-number">18</span>]]<br>输出：[[<span class="hljs-number">1</span>,<span class="hljs-number">6</span>],[<span class="hljs-number">8</span>,<span class="hljs-number">10</span>],[<span class="hljs-number">15</span>,<span class="hljs-number">18</span>]]<br>解释：区间 [<span class="hljs-number">1</span>,<span class="hljs-number">3</span>] 和 [<span class="hljs-number">2</span>,<span class="hljs-number">6</span>] 重叠, 将它们合并为 [<span class="hljs-number">1</span>,<span class="hljs-number">6</span>].<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight lua"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs lua">输入：intervals = <span class="hljs-string">[[1,4],[4,5]]</span><br>输出：<span class="hljs-string">[[1,5]]</span><br>解释：区间 [<span class="hljs-number">1</span>,<span class="hljs-number">4</span>] 和 [<span class="hljs-number">4</span>,<span class="hljs-number">5</span>] 可被视为重叠区间。<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= intervals.length &lt;= 104</li><li>intervals[i].length == 2</li><li>0 &lt;= starti &lt;= endi &lt;= 104</li></ul><h2 id="题解">题解</h2><p>首先对list排序（根据每个间隔的start）然后使用双指针判断是否合并区间即可。使用<code>key=lambda x:x[0]</code>来指定排序的根据。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">merge</span>(<span class="hljs-params">self, intervals: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]:</span><br>        intervals = <span class="hljs-built_in">sorted</span>(intervals,key=<span class="hljs-keyword">lambda</span> x:x[<span class="hljs-number">0</span>])<br>        result = []<br>        start,end = intervals[<span class="hljs-number">0</span>] <span class="hljs-comment">#可以直接赋值到两个变量</span><br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> intervals:<br>            <span class="hljs-keyword">if</span> item[<span class="hljs-number">0</span>]&lt;=end <span class="hljs-keyword">and</span> item[<span class="hljs-number">1</span>]&gt;end:<br>                end = item[<span class="hljs-number">1</span>]<br>            <span class="hljs-keyword">elif</span> item[<span class="hljs-number">0</span>]&gt;end:<br>                result.append([start,end])<br>                start,end = item[<span class="hljs-number">0</span>],item[<span class="hljs-number">1</span>]<br>        result.append([start,end])<br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>微软</category>
      
      <category>双指针</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>微软</tag>
      
      <tag>双指针</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CodeTop microsoft3 无重复字符的最长子串</title>
    <link href="/2022/03/07/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft3/"/>
    <url>/2022/03/07/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/CodeTop/CodeTop-Microsoft3/</url>
    
    <content type="html"><![CDATA[<blockquote><p>无重复字符的最长子串</p></blockquote><h2 id="题目">题目</h2><p>给定一个字符串 <code>s</code> ，请你找出其中不含有重复字符的 <strong>最长子串</strong> 的长度。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入: s = "abcabcbb"</span><br><span class="hljs-section">输出: 3 </span><br><span class="hljs-section">解释: 因为无重复字符的最长子串是 "abc"，所以其长度为 3。</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入: s = "bbbbb"</span><br><span class="hljs-section">输出: 1</span><br><span class="hljs-section">解释: 因为无重复字符的最长子串是 "b"，所以其长度为 1。</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-3：">示例 3：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入: s = "pwwkew"</span><br><span class="hljs-section">输出: 3</span><br><span class="hljs-section">解释: 因为无重复字符的最长子串是&nbsp;"wke"，所以其长度为 3。</span><br>&nbsp;    请注意，你的答案必须是 子串 的长度，<span class="hljs-string">"pwke"</span>&nbsp;是一个子序列，不是子串。<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><code>0 &lt;= s.length &lt;= 5 * 104</code></li><li><code>s</code> 由英文字母、数字、符号和空格组成</li></ul><h2 id="题解">题解</h2><p>这道题主要用到思路是：滑动窗口</p><ul><li>什么是滑动窗口？</li></ul><p>其实就是一个队列,比如例题中的 abcabcbb，进入这个队列（窗口）为 abc 满足题目要求，当再进入 a，队列变成了 abca，这时候不满足要求。所以，我们要移动这个队列！</p><ul><li>如何移动？</li></ul><p>我们只要把队列的左边的元素移出就行了，直到重复字符之后。</p><p>一直维持这样的队列，找出队列出现最长的长度时候，求出解！</p><blockquote><p>这里要使用到python的set，添加元素使用add，去除元素使用remove，查找元素是否在其中使用in</p></blockquote><p>时间复杂度：O(n)</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lengthOfLongestSubstring</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-comment">#使用滑动窗口</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> s:<span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>        left,maxLength,curLength = <span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span><br>        sset = <span class="hljs-built_in">set</span>()<br>        <span class="hljs-keyword">for</span> right <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(s)):<br>            <span class="hljs-keyword">while</span> s[right] <span class="hljs-keyword">in</span> sset: <span class="hljs-comment">#判断是否在set中O(1)即可，如果在sset中将left移动到重复字符后面所以是while</span><br>                sset.remove(s[left]) <span class="hljs-comment"># 移除该元素</span><br>                left += <span class="hljs-number">1</span><br>                curLength -= <span class="hljs-number">1</span><br>            sset.add(s[right]) <span class="hljs-comment">#添加至set中</span><br>            curLength += <span class="hljs-number">1</span><br>            maxLength = <span class="hljs-built_in">max</span>(maxLength,curLength)<br>        <span class="hljs-keyword">return</span> maxLength<br></code></pre></td></tr></tbody></table></figure><ul><li>什么类型的题目使用滑动窗口呢？</li></ul><p>如果我们依次递增地枚举子串的起始位置，那么子串的结束位置也是递增的；这样一来，我们就可以使用「滑动窗口」来解决这个问题了</p><p>也可以使用<code>defaultdict</code>类，使用<code>from collections import defaultdict</code>,使用<code>defaultdict</code>的好处是如果不在该字典中会返回定义的默认值</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lengthOfLongestSubstring</span>(<span class="hljs-params">self, s</span>):</span><br>        <span class="hljs-string">"""</span><br><span class="hljs-string">        :type s: str</span><br><span class="hljs-string">        :rtype: int</span><br><span class="hljs-string">        """</span><br>        <span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> defaultdict<br>        lookup = defaultdict(<span class="hljs-built_in">int</span>)<br>        start = <span class="hljs-number">0</span><br>        end = <span class="hljs-number">0</span><br>        max_len = <span class="hljs-number">0</span><br>        counter = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">while</span> end &lt; <span class="hljs-built_in">len</span>(s):<br>            <span class="hljs-keyword">if</span> lookup[s[end]] &gt; <span class="hljs-number">0</span>: <span class="hljs-comment">#如果存在多个相同的元素使用counter记录</span><br>                counter += <span class="hljs-number">1</span><br>            lookup[s[end]] += <span class="hljs-number">1</span><br>            end += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">while</span> counter &gt; <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">if</span> lookup[s[start]] &gt; <span class="hljs-number">1</span>:<br>                    counter -= <span class="hljs-number">1</span><br>                lookup[s[start]] -= <span class="hljs-number">1</span><br>                start += <span class="hljs-number">1</span><br>            max_len = <span class="hljs-built_in">max</span>(max_len, end - start)<br>        <span class="hljs-keyword">return</span> max_len<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>CodeTop</category>
      
      <category>微软</category>
      
      <category>滑动窗口</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CodeTop</tag>
      
      <tag>微软</tag>
      
      <tag>滑动窗口</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>外刊寒假小课--Gaming Share the data</title>
    <link href="/2022/03/04/english/gaming-share-the-data/"/>
    <url>/2022/03/04/english/gaming-share-the-data/</url>
    
    <content type="html"><![CDATA[<blockquote><p>寒假小课Gaming Share the data整理</p></blockquote><h2 id="原文">原文</h2><h2 id="单词">单词</h2><p>video games 电子游戏</p><p>makers of video games = video games developers = video game companies 电子游戏公司、电子游戏开发商/制造商。</p><p>addictive 病理性的上瘾，类似毒瘾</p><ul><li>compulsive<ul><li>a compulsive mobile phone user 手机重度用户</li><li>“洁癖”就可以说 compulsively neat and clean.</li><li>有时可以引申为 very interesting/attractive（引人入胜的）</li></ul></li><li>despite  表示“尽管”，注意后面加名词或动名词。</li><li>manual<ul><li>形容词，表示“用手的、体力的”，跟 mental 相对<ul><li>The trend away from manual labor has continued. 体力劳动转为脑力劳动的趋势仍在继续。</li></ul></li><li>“手册、指南”<ul><li>The classification manual explains that by the time the agency declares a famine, the highest category, it will be too late to avert the worst consequences “because many will have died”.这本分类手册解释说，当机构宣布面临饥荒（最高等级的灾难）时，再采取行动为时太晚，因为已经有很多人死亡。</li></ul></li></ul></li><li><strong>sprout</strong><ul><li>动词，本义是指叶子、芽或植株的“发芽、生长”<ul><li>Most seeds can wait out the dry, unwelcoming seasons until conditions are right and they sprout.大多数种子可以熬过干燥、严酷的季节，等待条件适合时发芽。</li></ul></li><li>“发芽、生长”引申出“出现、涌现”的含义<ul><li>Clinics are sprouting around the world 的意思就是诊所在世界各地涌现出来</li></ul></li></ul></li><li><strong>cure</strong><ul><li>“治疗”引申出“矫正、改正(某人的不良行为)”的意思，用法为 cure sb of sth。to stop sb from behaving in a particular way, especially a way that is bad or annoying.<ul><li>Nothing could cure her of her impatience with Anna.她就是改不了对安娜的不耐烦态度。</li></ul></li></ul></li></ul><h2 id="短语">短语</h2><ul><li>welcome  == to be glad to accept something 乐意接纳、欣然接受<ul><li>例句：I’d welcome any suggestions.</li></ul></li><li>happen to sb  指“发生在某人身上”</li><li><strong>多年来</strong><ul><li>地道英语中往往说 for years/ages 会省略many</li></ul></li><li>抱怨  complain 可以和 grumble 替换<ul><li>complain of sth</li><li>complain that+句子。</li></ul></li><li>be addicted to 表示“上瘾”，这里的to是介词，后面加名词或动名词</li><li>come into force 指“生效”，可以同 come into effect 替换。</li></ul><h2 id="句型">句型</h2><ul><li><p>A gains recognition from B “A从B那里获得承认”，即“B承认A”。</p></li><li><p>recognition</p><ul><li>change beyond recognition 表示“巨变”（变得让人认不出来）<ul><li>But in the last ten or fifteen years China has changed beyond all recognition.但在过去10-15年里，中国发生了翻天覆地的变化。</li></ul></li><li>gain recognition from… 就是“从…那里获得承认”<ul><li>He gained recognition from rocket scientists worldwide. 他得到了全球火箭科学家的认可。</li></ul></li></ul></li><li><p>way后面加定语从句，有三种形式：</p><blockquote><p>(1) way + in which + 定语从句</p><p>例如：She was pleased with the way in which he had accepted her criticism.</p><p>(2) way + that +定语从句</p><p>例如：They didn’t do it in the way that we do now.</p><p>(3) way + 定语从句</p><p>例如：He didn’t speak the way I do.</p><p>但一般来说，in which 或 that 往往省略，直接说「way+定语从句」，这样更加简练。</p></blockquote></li></ul>]]></content>
    
    
    <categories>
      
      <category>英语</category>
      
    </categories>
    
    
    <tags>
      
      <tag>英语</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>收集近年去噪资料</title>
    <link href="/2022/03/03/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E6%80%BB%E7%BB%93/collect-papersOfACPDnet/"/>
    <url>/2022/03/03/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E6%80%BB%E7%BB%93/collect-papersOfACPDnet/</url>
    
    <content type="html"><![CDATA[<blockquote><p>基于<a href="https://readpaper.com/pdf-annotate/note?noteId=652422328685277184&amp;pdfId=630634874308022272"><strong>Adaptive Consistency Prior based Deep Network for Image Denoising</strong></a>论文出发，从引用文献查找2020，2021年份发表的论文，以及被引用的论文。整理其摘要，结论，和其他重要图表。</p></blockquote><h2 id="引用-🎵">引用 🎵</h2><p>[5] Meng Chang, Qi Li, Huajun Feng, and Zhihai Xu. Spatial-adaptive network for single image denoising. In EuropeanConference on Computer Vision (ECCV), pages 171–187,Sep. 2020.</p><p>[24] Yoonsik Kim, Jae Woong Soh, Gu Yong Park, and Nam IkCho. Transfer learning from synthetic to real-noise denoisingwith adaptive instance normalization. In IEEE Conferenceon Computer Vision and Pattern Recognition (CVPR), pages3482–3492, Jun. 2020. 1, 2, 8</p><p>[29] Xiaoyao Li, Yicong Zhou, Jing Zhang, and Lianhong Wang.Multipatch unbiased distance non-local adaptive means withwavelet shrinkage. IEEE Transactions on Image Processing,29:157–169, 2020. 1</p><p>[49] Chunwei Tian, Yong Xu, Zuoyong Li, Wangmeng Zuo,Lunke Fei, and Hong Liu. Attention-guided cnn for imagedenoising. Neural Networks, 124:117–129, 2020. 7, 8</p><p>[50] Chunwei Tian, Yong Xu, and Wangmeng Zuo. Image de-noising using deep cnn with batch renormalization. NeuralNetworks, 121:461–473, 2020. 7, 8</p><p>[54] Ting Xie, Shutao Li, and Bin Sun. Hyperspectral images de-noising via nonconvex regularized low-rank and sparse ma-trix decomposition. IEEE Transactions on Image Process-ing, 29:44–56, 2020. 1</p><p><a href="https://readpaper.com/paper/3090412929">Spatial-Adaptive Network for Single Image Denoising</a></p><p><a href="https://readpaper.com/paper/3008207168">Transfer Learning from Synthetic to Real-Noise Denoising with Adaptive Instance Normalization</a></p><p><a href="https://readpaper.com/paper/2963279247">Multipatch Unbiased Distance Non-Local Adaptive Means With Wavelet Shrinkage</a></p><p><a href="https://readpaper.com/paper/2999653953">Attention-guided CNN for image denoising.</a></p><p><a href="https://readpaper.com/paper/2971719842">Image denoising using deep CNN with batch renormalization.</a></p><p><a href="https://readpaper.com/paper/2959148625">Hyperspectral Images Denoising via Nonconvex Regularized Low-Rank and Sparse Matrix Decomposition</a></p><h2 id="被引用-🍃">被引用 🍃</h2><p><a href="https://readpaper.com/paper/3213415572">CAR - Cityscapes Attributes Recognition A Multi-category Attributes Dataset for Autonomous Vehicles.</a></p><p><a href="https://readpaper.com/paper/3212228063">Restormer: Efficient Transformer for High-Resolution Image Restoration.</a></p><p><a href="https://readpaper.com/paper/3199857585">Dynamic Attentive Graph Learning for Image Restoration</a></p><h2 id="总结-🐾">总结 🐾</h2><h3 id="问题">问题</h3><ol><li>卷积神经网络去噪方法会产生过平滑伪影。更深层次的网络结构可以缓解这些问题，但代价是额外的计算开销。</li><li>真实噪声的统计量不服从正态分布，并且在空间和时间上都是变化的，因此真实噪声的去噪是一项具有挑战性的任务。</li><li>深卷积神经网络研究通常致力于通过极深的CNN来提高去噪性能，但随着深度的增加，浅层对深层的影响会减弱。</li><li>深卷积神经网络(CNNs)在图像去噪领域存在两个缺点：(1)用于去噪任务的深层CNN训练非常困难；(2)大部分深层CNN存在性能饱和问题。</li><li>虽然Transformer模型缓解了CNN的缺点(即接收范围有限，对输入内容不适应)，但其计算复杂度随空间分辨率呈二次曲线增长，<strong>因此不适用于大多数涉及高分辨率图像的图像恢复任务。</strong></li><li>自然图像的非局部自相似性已被证明是图像恢复的有效先验。然而，大多数现有的深度非局部方法为每个查询项分配固定数量的邻居，忽略了非局部相关性的动态性。而且，非局部相关通常是基于像素的，容易受到图像退化的影响而产生偏差。</li></ol><h3 id="解决方案">解决方案</h3><p>对应的解决方案如下：</p><ol><li>空间自适应去噪网络，设计了一种残差空间自适应块，并引入可变形卷积对空间相关特征进行采样加权。采用上下文块的编解码器结构来捕获多尺度信息。通过从粗到细进行去噪处理。</li><li>一种泛化良好的去噪结构和一种迁移学习方案；采用自适应实例归一化方法构建去噪器，对特征图进行规则化，防止网络过度拟合到训练集。我们还介绍了一种迁移学习方案，它将从合成噪声数据中学习到的知识转移到真实噪声去噪器上。</li><li>一种注意力引导的去噪卷积神经网络(AD-Net)，主要包括稀疏block(SB)、特征增强block(FEB)、关注度block(AB)和重构block(RB)。</li><li>提出了一种被称为批处理-重整化去噪网络(BRDNet)的新型网络的设计。具体地说，我们结合两个网络来增加网络的宽度，从而获得更多的特征。由于批量重整化被融合到BRDNet中，可以解决内部协变量移位和小批量问题。为了便于网络训练，还采用了整体剩余学习的方式。利用膨胀卷积来提取更多的信息用于去噪任务。</li><li>在这项工作中，我们提出了一种有效的Transformer模型，它在构建模块(多头处理和前馈网络)中进行了几个关键设计，以便在捕获远距离像素交互的同时，仍然适用于大图像。我们的模型名为Restoration Transformer(Restormer)；</li><li>本文提出了一种动态注意力图学习模型(DAGL)来探索图像恢复中斑块级的动态非局部性。</li></ol><h2 id="文献具体分析-📢">文献具体分析 📢</h2><h3 id="Spatial-Adaptive-Network-for-Single-ImageDenoising">Spatial-Adaptive Network for Single ImageDenoising</h3><h4 id="摘要">摘要</h4><p>卷积神经网络在图像去噪任务中可以取得较好的效果。但是，由于受局部刚性卷积运算的限制，这些方法会产生过平滑伪影。更深层次的网络结构可以缓解这些问题，但代价是额外的计算开销。本文提出了一种新的空间自适应去噪网络(SAD-NET)，用于有效地去除单幅图像的盲噪。为了适应空间纹理和边缘的变化，设计了一种残差空间自适应块，并引入可变形卷积对空间相关特征进行采样加权。采用上下文块的编解码器结构来捕获多尺度信息。通过从粗到细进行去噪处理，得到了高质量的无噪声图像，并将该方法应用于合成图像和真实含噪图像数据，实验结果表明，该方法在定量和视觉上都优于目前最先进的去噪方法。</p><h4 id="结论">结论</h4><p>在本文中，我们提出了一种空间自适应去噪网络来进行有效的去噪。该网络由多尺度残差空间自适应块构成，根据图像的内容和纹理特征抽取相关特征进行加权。在此基础上，引入上下文block来捕捉多尺度信息，并实现偏移量传递，以更准确地估计采样位置。我们发现，空间自适应能力的引入可以在强噪声下的复杂场景中存储更丰富的细节。所提出的SADNet在合成和真实噪声图像上都实现了最先进的性能，并且具有适中的运行时间。</p><h4 id="提炼">提炼</h4><h5 id="问题-2">问题</h5><p>由于受局部刚性卷积运算的限制，卷积神经网络去噪方法会产生过平滑伪影。更深层次的网络结构可以缓解这些问题，但代价是额外的计算开销。</p><h5 id="方法">方法</h5><p>提出了一种新的<strong>空间自适应去噪网络</strong>(SAD-NET)，用于有效地去除单幅图像的盲噪。为了适应空间纹理和边缘的变化，设计了一种残差空间自适应块，并引入可变形卷积对空间相关特征进行采样加权。采用上下文块的编解码器结构来捕获多尺度信息。通过从粗到细进行去噪处理，得到了高质量的无噪声图像。</p><h5 id="细节">细节</h5><p><img src="https://picture.mulindya.com/Apaper_collect/paper-collect1_1.png" alt=""></p><p><img src="https://picture.mulindya.com/Apaper_collect/paper-collect1_2.png" alt=""></p><h5 id="成果">成果</h5><p>该方法应用于合成图像和真实含噪图像数据，实验结果表明，该方法在定量和视觉上都优于目前最先进的去噪方法。我们发现，空间自适应能力的引入可以在强噪声下的复杂场景中存储更丰富的细节。SADNet在合成和真实噪声图像上都实现了最先进的性能，并且具有适中的运行时间。</p><h3 id="Transfer-Learning-from-Synthetic-to-Real-Noise-Denoising-with-Adaptive-Instance-Normalization-⭐️">Transfer Learning from Synthetic to Real-Noise Denoising with Adaptive Instance Normalization  ⭐️</h3><h4 id="摘要-2">摘要</h4><p>由于真实噪声的统计量不服从正态分布，并且在空间和时间上都是变化的，因此真实噪声的去噪是一项具有挑战性的任务。为了应对各种复杂的真实噪声，我们提出了一种泛化良好的去噪结构和一种迁移学习方案。具体地说，我们采用自适应实例归一化方法构建去噪器，对特征图进行规则化，防止网络过度拟合到训练集。我们还介绍了一种迁移学习方案，它将从合成噪声数据中学习到的知识转移到真实噪声去噪器上。从所提出的转移学习中，合成噪声去噪器可以从各种合成噪声数据中学习一般特征，而真实噪声去噪器可以从真实数据中学习真实噪声特征。实验结果表明，本文提出的去噪方法具有很强的泛化能力，在已发表的Darmstadt噪声数据集(DND)去噪方法中，用合成噪声训练的网络取得了最好的去噪效果。我们还可以看到，所提出的转移学习方案通过使用很少的标记数据进行学习，对真实噪声图像具有很强的鲁棒性。</p><h4 id="结论-2">结论</h4><p>在本文中，我们提出了一种新的RN去噪的消噪器和迁移学习方案。该去噪器采用AIN对网络进行正则化处理，同时防止网络过拟合到SN。迁移学习主要是利用RN数据更新AIN模块，调整数据分布。从实验结果可以看出，提出的去噪方案即使用SN训练，也能很好地推广到RN上。并且，该传递学习方案可以有效地使SN消噪器适应RN消噪器，并且几乎不需要用实数噪声对进行额外的训练。我们将在https://github.com/terryoo/AINDNet上公开我们的代码，以供进一步研究和比较。</p><h4 id="提炼-2">提炼</h4><h5 id="问题-3">问题</h5><p>由于真实噪声的统计量不服从正态分布，并且在空间和时间上都是变化的，因此真实噪声的去噪是一项具有挑战性的任务。</p><h5 id="方法-2">方法</h5><p>为了应对各种复杂的真实噪声，我们提出了一种泛化良好的去噪结构和一种迁移学习方案。具体地说，我们采用自适应实例归一化方法构建去噪器，对特征图进行规则化，防止网络过度拟合到训练集。我们还介绍了一种迁移学习方案，它将从合成噪声数据中学习到的知识转移到真实噪声去噪器上。从所提出的转移学习中，合成噪声去噪器可以从各种合成噪声数据中学习一般特征，而真实噪声去噪器可以从真实数据中学习真实噪声特征。</p><h5 id="细节-2">细节</h5><p><img src="https://picture.mulindya.com/Apaper_collect/paper-collect2_1.png" alt=""></p><p>去噪器的图示。噪声水平估计器和重构网络都是基于U网的结构，因此特征图通过平均池/转置卷积进行降/升采样。我们将每个尺度温度图表示为1/s，其中s可以是1、2和4。重建网络中表示的所有卷积都是3×3核，除最后一次卷积外具有64S个特征图。噪声电平估计器的特征表示也由32个通道的3×3卷积组成，噪声电平映射由3个通道输出的3×3卷积得到。总参数为1370万。</p><p><img src="https://picture.mulindya.com/Apaper_collect/paper-collect2_2.png" alt=""></p><p>所建议的具有相应核大小(K)、特征尺度(S)和特征数目(N)的AIN-ResBlock的图示。注意，n根据s线性增加。Leaky RELU用于激活函数。规范(红色)block表示信道方式的空间归一化block。Average-Pool将σ(Y)的大小调整为与h的大小相同。</p><p><img src="https://picture.mulindya.com/Apaper_collect/paper-collect2_3.png" alt=""></p><p>迁移学习模式图示，AIN模块、噪声电平估计器和上次卷积仅在学习RN数据时更新。为了更好地可视化，我们在此图中省略了噪声级估计器。</p><h5 id="成果-2">成果</h5><p>实验结果表明，本文提出的去噪方法具有很强的泛化能力，在已发表的Darmstadt噪声数据集(DND)去噪方法中，用合成噪声训练的网络取得了最好的去噪效果。我们还可以看到，所提出的转移学习方案通过使用很少的标记数据进行学习，对真实噪声图像具有很强的鲁棒性。从实验结果可以看出，提出的去噪方案即使用SN训练，也能很好地推广到RN上。并且，该传递学习方案可以有效地使SN消噪器适应RN消噪器，并且几乎不需要用实数噪声对进行额外的训练。</p><h2 id="Multipatch-Unbiased-Distance-Non-Local-Adaptive-Means-With-Wavelet-Shrinkage">Multipatch Unbiased Distance Non-Local Adaptive Means With Wavelet Shrinkage</h2><h4 id="摘要-3">摘要</h4><p>现有的许多非局部均值方法或者使用欧氏距离来度量面片之间的相似性，或者只计算权$ω_{ij}$一次并在随后的去噪迭代中保持不变，或者只利用去噪图像的结构信息来更新权$ω_{ij}$。这可能导致去噪性能有限。针对这些问题，本文提出了一种非局部自适应神经网络(NLAM)图像去噪方法。NLAM将权重$ω_{ij}$作为优化变量，迭代更新其值，引入像素-像素、面片-面片和耦合无偏距离三种无偏距离。与欧几里德距离相比，这些无偏距离在度量图像像素/块相似性方面更为稳健。利用耦合无偏距离，提出了无偏距离非局部自适应神经网络(UD-NLAM)。由于UD-NLAM只使用单个块大小来计算权重$ω_{ij}$，因此我们引入了多块UD-NLAM(MUD-NLAM)来适应不同的噪声水平。为了进一步提高去噪性能，提出了一种新的小波收缩去噪方法MUD-NLAM(MUD-NLAM-WS)，实验结果表明，MUD-NLAM、UD-NLAM和MUD-NLAM的去噪性能均优于现有的NLM方法，其中MUD-NLAM-WS的去噪效果优于现有的去噪方法。</p><h4 id="结论-3">结论</h4><p>本文介绍了非局部自适应方法(NLAM)在图像去噪中的应用。该算法将权重$ω_{ij}$作为一个自适应于图像内容的优化变量，通过测量图像块的相似度，在每次去噪迭代中更新权重ωij。然后定义了三种无偏距离，即像素-像素无偏距离、块-块无偏距离和耦合无偏距离。由于这些距离包含了噪声图像和去噪图像在每次迭代中的结构信息，因此比传统的欧几里德距离具有更强的鲁棒性来度量图像像素/块的相似性。利用耦合的无偏距离，提出了无偏距离非局部自适应均值(UD-NLAM)，并将UD-NLAM扩展到其多面体版本，以适应不同的噪声水平，提出了多面体UD-NLAM(MUD-NLAM)。在综合小波收缩的基础上，进一步提出了一种新的去噪方法–MUD-NLAM加小波收缩去噪方法(MUD-NLAM-WS)。我们与现有的几种去噪方法进行了大量的对比实验，定量评价和视觉比较表明，NLAM方法优于现有的一些基于NLM的去噪方法。UD-NLAM和MUD-NLAM进一步提高了NLAM的去噪性能，MUD-NLAM-WS在去噪和细节保护两个方面都优于与之竞争的最先进的去噪方法。由于所提出的方法侧重于灰度图像去噪，因此我们的下一步工作将研究如何将所提出的方法扩展到彩色图像去噪。例如，我们将引入一种新的距离准则来度量两个彩色图像像素/块之间的相似性。此外，将外地方法融入深度学习框架也是值得探索的。</p><h4 id="提炼-3">提炼</h4><h5 id="问题-4">问题</h5><p>现有的许多非局部均值方法或者使用欧氏距离来度量面片之间的相似性，或者只计算权$ω_{ij}$一次并在随后的去噪迭代中保持不变，或者只利用去噪图像的结构信息来更新权$ω_{ij}$。这可能导致去噪性能有限。</p><h5 id="方法-3">方法</h5><p>本文提出了一种非局部自适应神经网络(NLAM)图像去噪方法。NLAM将权重$ω_{ij}$作为优化变量，迭代更新其值，引入像素-像素、面片-面片和耦合无偏距离三种无偏距离。与欧几里德距离相比，这些无偏距离在度量图像像素/块相似性方面更为稳健。利用耦合无偏距离，提出了无偏距离非局部自适应神经网络(UD-NLAM)。由于UD-NLAM只使用单个块大小来计算权重$ω_{ij}$，因此我们引入了多块UD-NLAM(MUD-NLAM)来适应不同的噪声水平。为了进一步提高去噪性能，提出了一种新的小波收缩去噪方法MUD-NLAM(MUD-NLAM-WS)</p><h5 id="成果-3">成果</h5><p>实验结果表明，MUD-NLAM、UD-NLAM和MUD-NLAM的去噪性能均优于现有的NLM方法，其中MUD-NLAM-WS的去噪效果优于现有的去噪方法。</p><h3 id="Attention-guided-CNN-for-image-denoising-⭐️">Attention-guided CNN for image denoising. ⭐️</h3><h4 id="摘要-4">摘要</h4><p>深卷积神经网络(CNNs)在低级计算机视觉领域引起了人们极大的兴趣。研究通常致力于通过极深的CNN来提高去噪性能，但随着深度的增加，浅层对深层的影响会减弱。受此启发，我们提出了一种注意力引导的去噪卷积神经网络(AD-Net)，主要包括稀疏block(SB)、特征增强block(FEB)、关注度block(AB)和重构block(RB)。具体地说，SB通过使用膨胀卷积和普通卷积来消除噪声，从而在性能和效率之间进行折衷。FEB通过长路径综合全局和局部特征信息，增强了去噪模型的表达能力。AB用于精细提取隐藏在复杂背景中的噪声信息，对于复杂的噪声图像，特别是真实的噪声图像，结合去噪是非常有效的。此外，FEB与AB相结合，提高了训练去噪模型的效率，降低了训练的复杂度。最后，RB的目标是通过得到的噪声映射和给定的噪声图像来构造干净的图像。此外，综合实验表明，所提出的Adnet在三个任务(即合成和真实噪声图像以及盲去噪)中都有很好的性能，无论是定量评估还是定性评估都是如此。Adnet的代码可以在http://www.yongxu.org/lunwen.html.上访问</p><h4 id="结论-4">结论</h4><p>在本文中，我们提出了一种注意力引导的CNN去噪方法和ADNET图像去噪方法。Adnet的主要组件扮演以下角色。SB基于膨胀卷积和普通卷积，可以在去噪性能和效率之间进行折衷；FEB通过全局信息和局部信息的协同作用来增强模型对含噪图像的表示能力。AB算法能够提取隐藏在复杂背景中的潜在噪声信息，对复杂噪声图像，如含盲噪声图像和真实噪声图像都是非常有效的。在执行完上述组件后，执行RB以获得所得到的干净图像。由于采用AB对FEB进行合并，因此可以提高训练去噪模型的效率和复杂度。实验结果表明，本文提出的Adnet算法在图像去噪方面具有很好的定性和定量评价效果。</p><h4 id="提炼-4">提炼</h4><h5 id="问题-5">问题</h5><p>深卷积神经网络(CNNs)在低级计算机视觉领域引起了人们极大的兴趣。研究通常致力于通过极深的CNN来提高去噪性能，但随着深度的增加，浅层对深层的影响会减弱。</p><h5 id="方法-4">方法</h5><p>我们提出了一种注意力引导的去噪卷积神经网络(AD-Net)，主要包括稀疏block(SB)、特征增强block(FEB)、关注度block(AB)和重构block(RB)。具体地说，SB通过使用膨胀卷积和普通卷积来消除噪声，从而在性能和效率之间进行折衷。FEB通过长路径综合全局和局部特征信息，增强了去噪模型的表达能力。AB用于精细提取隐藏在复杂背景中的噪声信息，对于复杂的噪声图像，特别是真实的噪声图像，结合去噪是非常有效的。此外，FEB与AB相结合，提高了训练去噪模型的效率，降低了训练的复杂度。最后，RB的目标是通过得到的噪声映射和给定的噪声图像来构造干净的图像。</p><h5 id="细节-3">细节</h5><p><img src="https://picture.mulindya.com/Apaper_collect/paper-collect4_1.png" alt=""></p><p>Adnet的主要组件扮演以下角色。SB基于膨胀卷积和普通卷积，可以在去噪性能和效率之间进行折衷；FEB通过全局信息和局部信息的协同作用来增强模型对含噪图像的表示能力。AB算法能够提取隐藏在复杂背景中的潜在噪声信息，对复杂噪声图像，如含盲噪声图像和真实噪声图像都是非常有效的。在执行完上述组件后，执行RB以获得所得到的干净图像。由于采用AB对FEB进行合并，因此可以提高训练去噪模型的效率和复杂度。</p><h5 id="成果-4">成果</h5><p>综合实验表明，所提出的Adnet在三个任务(即合成和真实噪声图像以及盲去噪)中都有很好的性能，无论是定量评估还是定性评估都是如此。</p><h3 id="Image-denoising-using-deep-CNN-with-batch-renormalization">Image denoising using deep CNN with batch renormalization.</h3><h4 id="摘要-5">摘要</h4><p>深卷积神经网络(CNNs)在图像去噪领域引起了极大的关注。然而，存在两个缺点：(1)用于去噪任务的深层CNN训练非常困难；(2)大部分深层CNN存在性能饱和问题。在这篇论文中，我们提出了一种被称为批处理-重整化去噪网络(BRDNet)的新型网络的设计。具体地说，我们结合两个网络来增加网络的宽度，从而获得更多的特征。由于批量重整化被融合到BRDNet中，我们可以解决内部协变量移位和小批量问题。为了便于网络训练，还采用了整体剩余学习的方式。利用膨胀卷积来提取更多的信息用于去噪任务。大量的实验结果表明，BRD-Net的去噪效果优于目前最先进的图像去噪方法。BRDnet的代码可以在http://www.yongxu.org/lunwen.html.上访问</p><h4 id="结论-5">结论</h4><p>在本文中，我们提出了一种新的基于模型的CNN去噪器BRDNet，它结合了两种不同的网络来提高图像去噪性能。此外，BRDNet使用BRN、RL和膨胀卷积来提高去噪性能，使模型更容易训练。BRN不仅用于加速BRDNet的收敛，而且用于解决小批量问题。在BRDNet中，RL被用来分离噪声和有噪图像，并获得潜在的干净图像。扩张的卷积可以扩大接受范围以获得更多的上下文信息。实验结果表明，该方法与其它图像去噪方法相比，具有很好的性能。在未来，我们计划使用具有先验知识的CNN来处理更复杂的真实噪声图像去噪，例如微光图像和模糊图像。</p><h4 id="提炼-5">提炼</h4><h5 id="问题-6">问题</h5><p>深卷积神经网络(CNNs)在图像去噪领域引起了极大的关注。然而，存在两个缺点：(1)用于去噪任务的深层CNN训练非常困难；(2)大部分深层CNN存在性能饱和问题。</p><h5 id="方法-5">方法</h5><p>提出了一种被称为批处理-重整化去噪网络(BRDNet)的新型网络的设计。具体地说，我们结合两个网络来增加网络的宽度，从而获得更多的特征。由于批量重整化被融合到BRDNet中，我们可以解决内部协变量移位和小批量问题。为了便于网络训练，还采用了整体剩余学习的方式。利用膨胀卷积来提取更多的信息用于去噪任务。</p><h5 id="细节-4">细节</h5><p><img src="https://picture.mulindya.com/Apaper_collect/paper-collect5_1.png" alt=""></p><p>提出了一种新的基于模型的CNN去噪器BRDNet，它结合了两种不同的网络来提高图像去噪性能。此外，BRDNet使用BRN、RL和膨胀卷积来提高去噪性能，使模型更容易训练。BRN不仅用于加速BRDNet的收敛，而且用于解决小批量问题。在BRDNet中，RL被用来分离噪声和有噪图像，并获得潜在的干净图像。扩张的卷积可以扩大接受范围以获得更多的上下文信息。</p><h5 id="成果-5">成果</h5><p>大量的实验结果表明，BRD-Net的去噪效果优于目前最先进的图像去噪方法。</p><h5 id="展望">展望</h5><p>在未来，我们计划使用具有先验知识的CNN来处理更复杂的真实噪声图像去噪，例如微光图像和模糊图像。</p><h3 id="Hyperspectral-Images-Denoising-via-Nonconvex-Regularized-Low-Rank-and-Sparse-Matrix-Decomposition">Hyperspectral Images Denoising via Nonconvex Regularized Low-Rank and Sparse Matrix Decomposition</h3><h4 id="摘要-6">摘要</h4><p>高光谱图像在成像过程中经常受到各种噪声的影响，包括高斯噪声、脉冲噪声、条纹噪声等，这些复杂的噪声会困扰后续的高光谱图像处理。通常，大多数HSI去噪方法都是用凸范数约束来描述稀疏优化问题，这会过度惩罚较大的向量输入，并可能导致有偏解。本文提出了一种非凸正则低秩稀疏矩阵分解(NonRLRS)方法用于HSIS去噪，它能同时去除高斯噪声、脉冲噪声、死线和条纹。非RLRS的目的是将退化的HSI分解成具有鲁棒性的低秩稀疏成分，并以矩阵的形式表示。为了增强固有低阶结构和稀疏破坏的稀疏性，提出了一种新的非凸正则化子–归一化罚函数，它可以自适应地收缩每个条目。此外，还提出了一种基于优化最小化(MM)的有效算法来求解由此产生的非凸优化问题。具体地说，MM算法在每次迭代中首先用代理上界替换非凸目标函数，然后将构造的代理函数最小化，从而使非凸问题能够在重加权技术的框架下求解。仿真数据和实际数据的实验结果表明了该方法的有效性。</p><h4 id="结论-6">结论</h4><p>本文提出了一种新的非RLRS算法，用于在HSI去噪应用中同时检测干净的HSI低阶结构和稀疏腐蚀。在非ε中引入了自适应收缩每个条目的非归一化RLRS惩罚，使其能够更准确地从受多种类型噪声污染的退化HSI中提取低秩稀疏成分。此外，采用基于MM的算法有效地解决了所提出的非RLRS问题。MM算法是迭代实现的，它首先用目标函数的非凸分量的上界替换目标函数的非凸分量，然后最小化构造的代理。实验结果表明，该方法可以同时去除高斯噪声、脉冲噪声、死线和条带，</p><h5 id="展望-2">展望</h5><p>在未来的工作中，我们将把该方法扩展到其他类型的应用，如背景提取、目标检测、压缩感知等。此外，施加在HSI像素上的空间谱约束将被用于HSI去噪</p><h4 id="提炼-6">提炼</h4><h5 id="问题-7">问题</h5><p>高光谱图像在成像过程中经常受到各种噪声的影响，包括高斯噪声、脉冲噪声、条纹噪声等，这些复杂的噪声会困扰后续的高光谱图像处理。通常，大多数HSI去噪方法都是用凸范数约束来描述稀疏优化问题，这会过度惩罚较大的向量输入，并可能导致有偏解。</p><h5 id="方法-6">方法</h5><p>本文提出了一种非凸正则低秩稀疏矩阵分解(NonRLRS)方法用于HSIS去噪，它能同时去除高斯噪声、脉冲噪声、死线和条纹。非RLRS的目的是将退化的HSI分解成具有鲁棒性的低秩稀疏成分，并以矩阵的形式表示。为了增强固有低阶结构和稀疏破坏的稀疏性，提出了一种新的非凸正则化子–归一化罚函数，它可以自适应地收缩每个条目。此外，还提出了一种基于优化最小化(MM)的有效算法来求解由此产生的非凸优化问题。具体地说，MM算法在每次迭代中首先用代理上界替换非凸目标函数，然后将构造的代理函数最小化，从而使非凸问题能够在重加权技术的框架下求解。</p><h5 id="成果-6">成果</h5><p>仿真数据和实际数据的实验结果表明了该方法的有效性。</p><h3 id="CAR-Cityscapes-Attributes-Recognition-A-Multi-category-Attributes-Dataset-for-Autonomous-Vehicles">CAR - Cityscapes Attributes Recognition A Multi-category Attributes Dataset for Autonomous Vehicles.</h3><h4 id="摘要-7">摘要</h4><p>自动驾驶汽车是交通运输的未来。随着这一领域的进步，世界越来越接近安全道路，几乎没有发生事故的可能性，并消除了人为错误。然而，要达到健壮性水平，还需要进行大量的研究和开发。一个重要的方面是充分理解一个场景，包括所有细节。因为场景中物体的某些特征(属性)(例如驾驶员的行为)对于正确的决策是必不可少的。然而，目前的算法存在属性丰富、质量不高的问题。因此，本文提出了一种新的属性识别数据集–城市景观属性识别(CAR)。新数据集通过在每个图像中添加对象属性的附加但重要的注释层来扩展众所周知的数据集CiteScenes。目前，我们已经注释了超过32000个不同类别的实例(车辆、Pedes-Trians等)。该数据集具有结构化和定制的税收经济，其中每个类别都有其自己的一组可能的属性。量身定做的分类集中在最有利于开发更好的自动驾驶算法的属性上，这些算法依赖于准确的计算机视觉和场景理解。我们还为数据集创建了API，以方便CAR的使用。该接口可通过以下方式访问https://github.com/kareem-metwaly/CAR-API</p><h4 id="结论-7">结论</h4><p>在本文中，我们讨论了一个新的数据集，称为Cityscapes Attributes Recognition(CAR)。CAR通过向数据集的每个图像中的每个对象添加属性来补充已经存在的城市景观数据集。这导致了对场景的完整理解，这在自动驾驶汽车的某些情况下是至关重要的。例如，无人驾驶车辆需要了解附近行人的预期行为。数据集包含32,729个实例。数据集被划分为拥有更大的属性预测数据集，这些数据集只关注与驾驶相关的类别，这对于自动驾驶汽车领域是必不可少的。此外，它还将为计算机视觉带来更可持续、更可靠的算法。</p><h4 id="提炼-7">提炼</h4><h5 id="问题-8">问题</h5><p>自动驾驶汽车是交通运输的未来。随着这一领域的进步，世界越来越接近安全道路，几乎没有发生事故的可能性，并消除了人为错误。然而，要达到健壮性水平，还需要进行大量的研究和开发。一个重要的方面是充分理解一个场景，包括所有细节。因为场景中物体的某些特征(属性)(例如驾驶员的行为)对于正确的决策是必不可少的。然而，目前的算法存在属性丰富、质量不高的问题。</p><h3 id="Restormer-Efficient-Transformer-for-High-Resolution-Image-Restoration-⭐️">Restormer: Efficient Transformer for High-Resolution Image Restoration ⭐️</h3><h4 id="摘要-8">摘要</h4><p>由于卷积神经网络(CNNs)在从大规模数据中学习可推广的图像先验知识方面表现出色，这些模型已被广泛应用于图像恢复和相关任务。最近，另一类神经结构，Transformer，在自然语言和高级视觉任务上表现出显著的性能提升。虽然Transformer模型缓解了CNN的缺点(即接收范围有限，对输入内容不适应)，但其计算复杂度随空间分辨率呈二次曲线增长，因此不适用于大多数涉及高分辨率图像的图像恢复任务。在这项工作中，我们提出了一种有效的Transformer模型，它在构建模块(多头处理和前馈网络)中进行了几个关键设计，以便在捕获远距离像素交互的同时，仍然适用于大图像。我们的模型名为(Restormer)，实现了图像去噪、单图像运动去模糊、散焦去模糊(单像素和双像素数据)和图像去噪(高斯灰度/彩色去噪和真实图像去噪)等几个图像恢复任务的最新成果。源代码和预先培训的模型可在https://github.com/swz30/Restormer获得。</p><h4 id="结论-8">结论</h4><p>我们提出了一种图像恢复Transformer模型Restormer，该模型在处理高分辨率图像时计算效率很高。我们对Transformer block的核心部件进行了关键设计，以改进功能聚合和转换。具体地说，我们的多Dconv头部转置注意(MDTA)模块通过应用跨频道的自我注意而不是空间维度来隐含地建模全局上下文，因此具有线性复杂度而不是二次复杂度。此外，提出的门控DConv前馈网络(GDFN)引入了一种门控机制来实现受控的特征变换。为了将CNN的强度融入到Transformer模型中，MDTA和GDFN模型都包括用于编码空间局部上下文的深度卷积。在16个基准数据集上的广泛实验表明，Restormer在众多图像恢复任务中实现了最先进的性能。</p><h4 id="提炼-8">提炼</h4><h5 id="问题-9">问题</h5><p>由于卷积神经网络(CNNs)在从大规模数据中学习可推广的图像先验知识方面表现出色，这些模型已被广泛应用于图像恢复和相关任务。最近，另一类神经结构，Transformer，在自然语言和高级视觉任务上表现出显著的性能提升。虽然Transformer模型缓解了CNN的缺点(即接收范围有限，对输入内容不适应)，但其计算复杂度随空间分辨率呈二次曲线增长，<strong>因此不适用于大多数涉及高分辨率图像的图像恢复任务。</strong></p><h5 id="方法-7">方法</h5><p>在这项工作中，我们提出了一种有效的Transformer模型，它在构建模块(多头处理和前馈网络)中进行了几个关键设计，以便在捕获远距离像素交互的同时，仍然适用于大图像。我们的模型名为Restoration Transformer(Restormer)；</p><p><img src="https://picture.mulindya.com/Apaper_collect/paper-collect8_1.png" alt=""></p><p>用于高分辨率图像恢复的Restormer架构。我们的恢复器由多尺度分层设计组成，增加了高效的Transformer模块。Transformer block的核心模块是：(A)多DConv头部转置注意力，其执行(空间丰富的)跨通道的查询-关键特征交互，而不是在空间维度上；以及(B)门控-DConv前馈网络，其执行受控的特征变换，即允许有用信息进一步传播。</p><h5 id="成果-7">成果</h5><p>实现了图像去噪、单图像运动去模糊、散焦去模糊(单像素和双像素数据)和图像去噪(高斯灰度/彩色去噪和真实图像去噪)等几个图像恢复任务的最新成果。源代码和预先培训的模型可在https://github.com/swz30/Restormer获得。在16个基准数据集上的广泛实验表明，Restormer在众多图像恢复任务中实现了最先进的性能。</p><h3 id="Dynamic-Attentive-Graph-Learning-for-Image-Restoration">Dynamic Attentive Graph Learning for Image Restoration</h3><h4 id="摘要-9">摘要</h4><p>自然图像的非局部自相似性已被证明是图像恢复的有效先验。然而，大多数现有的深度非局部方法为每个查询项分配固定数量的邻居，忽略了非局部相关性的动态性。而且，非局部相关通常是基于像素的，容易受到图像退化的影响而产生偏差。针对这些不足，本文提出了一种动态注意力图学习模型(DAGL)来探索图像恢复中斑块级的动态非局部性。具体地说，我们提出了一种改进的图模型来执行逐块图卷积，每个节点的邻域数目是动态的和自适应的。这样，图像内容可以通过其连通邻域的数目自适应地平衡过光滑和过尖锐的伪影，而逐块的非局部相关性可以增强消息的传递过程。在合成图像去噪、真实图像去噪、图像去马赛克和压缩伪影减少等各种图像恢复任务上的实验结果表明，我们的DAGL可以产生最先进的结果，具有较高的精度和视觉质量。源代码可以在https://github.com/jianzhangcs/DAGL.上找到。</p><h4 id="结论-9">结论</h4><p>本文提出了一种改进的用于图像恢复的图注意模型。与以往的非局部图像恢复方法不同，该模型可以为每个查询项分配一定数量的邻域，并基于特征块构造远程相关关系。此外，我们提出的动态注意图学习可以很容易地扩展到其他计算机视觉任务。扩展实验表明，该模型在合成图像去噪、真实图像去噪、图像去马赛克和压缩伪影减少等广泛的图像恢复任务中取得了最好的性能。</p><h4 id="提炼-9">提炼</h4><h5 id="问题-10">问题</h5><p>自然图像的非局部自相似性已被证明是图像恢复的有效先验。然而，大多数现有的深度非局部方法为每个查询项分配固定数量的邻居，忽略了非局部相关性的动态性。而且，非局部相关通常是基于像素的，容易受到图像退化的影响而产生偏差。</p><h5 id="方法-8">方法</h5><p>本文提出了一种动态注意力图学习模型(DAGL)来探索图像恢复中斑块级的动态非局部性。具体地说，我们提出了一种改进的图模型来执行逐块图卷积，每个节点的邻域数目是动态的和自适应的。这样，图像内容可以通过其连通邻域的数目自适应地平衡过光滑和过尖锐的伪影，而逐块的非局部相关性可以增强消息的传递过程。</p><p><img src="https://picture.mulindya.com/Apaper_collect/paper-collect10_1.png" alt=""></p><p>提出了动态注意力图学习模型(DAGL)。特征提取模块(FEM)利用残差分块来提取深层特征。基于图的特征聚集模块(GFAM)构建具有动态连接的图，并进行面片状的图卷积。具有多个头的广义FAM(M-GFAM)联合聚集来自不同表示子空间的信息。</p><h5 id="成果-8">成果</h5><p>在合成图像去噪、真实图像去噪、图像去马赛克和压缩伪影减少等各种图像恢复任务上的实验结果表明，我们的DAGL可以产生最先进的结果，具有较高的精度和视觉质量。源代码可以在https://github.com/jianzhangcs/DAGL.上找到。</p>]]></content>
    
    
    <categories>
      
      <category>文献</category>
      
      <category>总结</category>
      
    </categories>
    
    
    <tags>
      
      <tag>文献</tag>
      
      <tag>总结</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer55-2 平衡二叉树</title>
    <link href="/2022/03/02/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer55-2/"/>
    <url>/2022/03/02/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer55-2/</url>
    
    <content type="html"><![CDATA[<blockquote><p>平衡二叉树</p></blockquote><h2 id="题目">题目</h2><p>输入一棵二叉树的根节点，判断该树是不是平衡二叉树。如果某二叉树中任意节点的左右子树的深度相差不超过1，那么它就是一棵平衡二叉树。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight livescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs livescript">给定二叉树 [<span class="hljs-number">3</span>,<span class="hljs-number">9</span>,<span class="hljs-number">20</span>,<span class="hljs-literal">null</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">15</span>,<span class="hljs-number">7</span>]<br><br>    <span class="hljs-number">3</span><br>   / <span class="hljs-string">\</span><br>  <span class="hljs-number">9</span>  <span class="hljs-number">20</span><br>    /  <span class="hljs-string">\</span><br>   <span class="hljs-number">15</span>   <span class="hljs-number">7</span><br>返回 <span class="hljs-literal">true</span> 。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight livescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs livescript">给定二叉树 [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>,<span class="hljs-literal">null</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">4</span>,<span class="hljs-number">4</span>]<br><br>       <span class="hljs-number">1</span><br>      / <span class="hljs-string">\</span><br>     <span class="hljs-number">2</span>   <span class="hljs-number">2</span><br>    / <span class="hljs-string">\</span><br>   <span class="hljs-number">3</span>   <span class="hljs-number">3</span><br>  / <span class="hljs-string">\</span><br> <span class="hljs-number">4</span>   <span class="hljs-number">4</span><br>返回&nbsp;<span class="hljs-literal">false</span> 。<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><code>0 &lt;= 树的结点个数 &lt;= 10000</code></li></ul><h2 id="题解">题解</h2><p>中序遍历的思想得到一棵树的深度为<code>max(left,right)+1</code>，首先得到左右子树的深度，在此基础上取最大值加一即为此根的树深度。同时注意剪枝！</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for a binary tree node.</span><br><span class="hljs-comment"># class TreeNode:</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.left = None</span><br><span class="hljs-comment">#         self.right = None</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">isBalanced</span>(<span class="hljs-params">self, root: TreeNode</span>) -&gt; <span class="hljs-built_in">bool</span>:</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">func</span>(<span class="hljs-params">root</span>):</span> <span class="hljs-comment">#判断深度，如果子树不平衡就返回-1</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root:<span class="hljs-keyword">return</span> <span class="hljs-number">0</span> <span class="hljs-comment">#为空时深度为0</span><br>            left = func(root.left)<br>            <span class="hljs-keyword">if</span> left==-<span class="hljs-number">1</span>:<span class="hljs-keyword">return</span> -<span class="hljs-number">1</span> <span class="hljs-comment">#剪枝</span><br>            right = func(root.right)<br>            <span class="hljs-keyword">if</span> right == -<span class="hljs-number">1</span>: <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span> <span class="hljs-comment">#剪枝</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(left,right)+<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> <span class="hljs-built_in">abs</span>(left-right)&lt;=<span class="hljs-number">1</span> <span class="hljs-keyword">else</span> -<span class="hljs-number">1</span><br>        <br>        <span class="hljs-keyword">if</span> func(root)==-<span class="hljs-number">1</span>:<span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>        <span class="hljs-keyword">else</span>:<span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>树</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Deep learning on image denoising--An overview</title>
    <link href="/2022/03/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E7%BB%BC%E8%BF%B0/%E8%87%AA%E7%84%B6%E5%9B%BE%E5%83%8F%E5%8E%BB%E5%99%AA%E7%BB%BC%E8%BF%B0/"/>
    <url>/2022/03/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E7%BB%BC%E8%BF%B0/%E8%87%AA%E7%84%B6%E5%9B%BE%E5%83%8F%E5%8E%BB%E5%99%AA%E7%BB%BC%E8%BF%B0/</url>
    
    <content type="html"><![CDATA[<blockquote><p>有关自然图像去噪的一篇综述Deep learning on image denoising–An overview.在此记录和总结此篇论文的要点；聚焦于图像去噪的方法，成果，区别，动机和展望。</p></blockquote><h1>Deep learning on image denoising</h1><p>2020发表 156被引用</p><h2 id="摘要">摘要</h2><h4 id="深度学习去噪">深度学习去噪</h4><p>基于深度学习的判别学习可以很好地解决高斯噪声问题。基于深度学习的优化模型对真实噪声的估计是有效的。</p><h4 id="分类方法">分类方法</h4><p>1，对加性白噪声图像的深层卷积神经网络(CNN)</p><p>2，真实噪声图像的深层卷积神经网络(CNN)</p><p>3，盲去噪图像的深层卷积神经网络(CNN)</p><p>4，混合噪声图像的深层卷积神经网络(CNN)。</p><p>它们分别<strong>代表</strong>了噪声图像、模糊图像和低分辨率图像的组合。然后，我们分析了不同类型深度学习方法的<strong>动机和原理</strong>。从定量和定性分析两个方面对公开数据集去噪的最新方法进行了<strong>比较</strong>。</p><h4 id="关注点">关注点</h4><ul><li>定性定量的依据是什么？</li><li>如何表示？对应关系如何？</li></ul><h2 id="结论">结论</h2><h3 id="文章总结">文章总结</h3><p>本文对用于图像去噪的深度网络进行了比较、研究和总结。</p><ul><li>深度学习用于图像去噪的<strong>基本框架</strong>。</li><li>分析<strong>噪声任务</strong>的深度学习技术，包括加性白噪声图像、盲去噪、真实噪声图像和混合噪声图像；</li><li>针对每一类噪声任务，分析了网络去噪的<strong>动因和原理</strong>。</li><li>比较不同网络在基准数据集上的去噪效果、效率和视觉<strong>效果</strong>；</li><li>不同类型的噪声下，对不同类型的图像去噪方法进行了<strong>交叉比较</strong>。</li><li>有待进一步研究的领域，讨论图像去噪面临的<strong>挑战</strong>。</li></ul><h3 id="挑战与展望">挑战与展望</h3><p>在过去的几年里，高斯噪声图像去噪技术已经取得了很大的成功，特别是在高斯噪声是规则的情况下。</p><h4 id="现实条件">现实条件</h4><ul><li><p>噪声是复杂和不规则的。（改进硬件设备，以便更好地抑制噪声，以获取高质量的图像非常重要）</p></li><li><p>获取的图像可能会出现模糊、低分辨率和损坏的情况。</p></li></ul><h4 id="挑战">挑战</h4><ul><li>如何有效地从叠加的噪声图像中恢复出潜在的干净图像是至关重要的。</li><li>使用深度学习技术来学习特征需要ground-truth，但获得的真实噪声图像没有ground-truth。</li></ul><h2 id="引入">引入</h2><h3 id="近50年的发展">近50年的发展</h3><p><strong>探索阶段</strong>（传统）：非线性和非自适应滤波器被用于图像应用。与线性滤波器不同，非线性滤波器可以保留边缘信息以抑制噪声。自适应非线性滤波器依赖于局部信噪比来导出适当的加权因子，用于从被加性随机、信号相关、脉冲噪声和加性随机噪声的组合所污染的图像中去除噪声。非自适应滤波器可以同时使用边缘信息和信噪比信息来估计噪声。</p><p><strong>机器学习</strong>：机器学习方法，如基于稀疏的方法，被成功地应用于图像去噪。一种非局部集中式稀疏表示方法利用非局部自相似性对稀疏方法进行优化，获得了较高的图像去噪性能；降低成本：采用字典学习方法快速过滤去噪。恢复潜在clean图像细节信息：先验知识(即总变异正则化)可以平滑噪声图像，以处理受污染的图像。</p><p><strong>更多补充</strong>：马尔可夫随机场（MRF），加权核范数最小化（WNNM），学习同时稀疏编码（LSSC），收缩场级联（CSF），可训练非线性反应扩散（TNRD）和梯度直方图估计和保存（GHEP)</p><h5 id="缺点">缺点</h5><p>上述大多数方法在图像去噪方面都取得了相当好的性能，但它们也存在一些缺点，包括需要测试阶段的优化方法、手动设置参数以及针对单个去噪任务的特定模型。</p><h3 id="深度学习">深度学习</h3><p>提出的去噪工作首先使用具有已知<strong>移位不变模糊函数和加性噪声</strong>的神经网络来恢复潜在的干净图像。</p><p>后续使用加权因子去除复杂噪声，为了降低计算代价，使用<em><strong>前馈网络</strong></em>折中去噪效果和性能。前馈神经网络利用Kuwahara filters对图像进行平滑处理（类似卷积），还证明均方误差(MSE)是ALOS函数，并不是神经网络所特有的。</p><h4 id="优化算法">优化算法</h4><p>随后，使用更多的优化算法来加速训练网络的收敛，提高去噪性能</p><ul><li>最大熵和原对偶La-grangian乘性因子相结合来<strong>增强神经网络的表达能力</strong>；</li><li>将贪婪算法和异步算法应用到神经网络中，设计了一种新的网络结构，通过增加深度或改变激活函数来消除噪声来<strong>权衡速度和效果</strong>；</li><li>CENNs主要利用带有模板的节点来求取平均函数，有效地抑制噪声。但需要手动设置模板参数。为了解决这个问题，发展了<strong>梯度下降法</strong>。</li></ul><h5 id="缺点-2">缺点</h5><p>网络不允许添加新的插件，这限制了它们在现实世界中的应用</p><h4 id="卷积神经网络">卷积神经网络</h4><h5 id="瓶颈">瓶颈</h5><ol><li>深层CNN会产生消失的梯度。</li><li>激活函数如Sigmoid和tanh导致较高的计算成本。</li><li>硬件平台不支持复杂网络。</li></ol><h5 id="转折">转折</h5><p>在2012年发生了变化，AlexNet在当年的ImageNet大规模视觉识别挑战(ILSVRC)。此后，深度网络结构(如VGG和GoogLeNet)被广泛应用于图像、视频、自然语言处理和语音处理等领域，尤其是低级计算机视觉。</p><h5 id="引入图像去噪">引入图像去噪</h5><p>深度网络在2015年首次应用于图像去噪。所提出的网络不需要手动设置用于消除噪声的参数。此后，深度网络被广泛应用于语音、视频和图像恢复。</p><p>采用多次卷积和反卷积的方法抑制噪声，恢复高分辨率图像。为了通过模型处理多个低层任务，提出了一种由卷积、批归一化(BN)、校正线性单元(RELU)和残差学习(RL)组成的去噪CNN(DnCNN)来处理图像去噪、超分辨率和JPEG图像去块。考虑到去噪性能和速度的折衷。</p><h6 id="彩色图像噪声">彩色图像噪声</h6><p>彩色非局部网络(CNLNet)将非局部自相似性(NLSS)和CNN相结合，有效地去除了彩色图像噪声。</p><p>DnCNN：<a href="https://readpaper.com/paper/2508457857">https://readpaper.com/paper/2508457857</a> （2017年发表，3793被引用）</p><p>CNLNet：<a href="https://readpaper.com/paper/2550616896%EF%BC%882016%E5%B9%B4%E5%8F%91%E8%A1%A8%EF%BC%8C9%E8%A2%AB%E5%BC%95%E7%94%A8%EF%BC%89">https://readpaper.com/paper/2550616896（2016年发表，9被引用）</a></p><h5 id="blind-denoising">blind denoising</h5><p>一种快速灵活的去噪CNN(FFDNet)提出了不同的噪声水平，并将含噪图像块作为去噪网络的输入，以提高去噪速度，<strong>进行blind去噪</strong>。</p><h6 id="不成对的噪声图像">不成对的噪声图像</h6><ul><li><p>为了处理不成对的噪声图像，生成对抗网络(GAN)CNN盲去噪器(GCBD)解决了这一问题，它首先生成ground-truth，然后将获得的ground-truth输入到GAN中训练去噪器。</p></li><li><p>卷积盲去噪网络(CBDNet)通过两个子网络来去除给定的真实噪声图像中的噪声，其中一个子网络负责估计真实含噪图像的噪声，另一个子网络负责获取潜在的干净图像。</p></li><li><p>对于更复杂的受污染图像，发展了一种深度即插即用超分辨率(DPSR)方法来估计模糊kenel和噪声，并恢复高分辨率图像。</p></li></ul><p>FFDNet：<a href="https://readpaper.com/paper/2764207251">https://readpaper.com/paper/2764207251</a> （2018年发表 899被引用）</p><p>GCBD：<a href="https://readpaper.com/paper/2798278116">https://readpaper.com/paper/2798278116</a> （2018年发表 294被引用）</p><p>CBDNet：<a href="https://readpaper.com/paper/2832157980">https://readpaper.com/paper/2832157980</a> （2018年发表 9被引用）</p><p>DPSR：<a href="https://readpaper.com/paper/2929525177">https://readpaper.com/paper/2929525177</a> （2019年发表 0被引用）</p><h4 id="论文组织">论文组织</h4><ul><li><p>第二部分讨论了流行的图像应用的深度学习框架;(<a href="#%E5%8E%BB%E5%99%AA%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6">Fundamental frameworks of deep learning methods for image denoising</a>)</p></li><li><p>第三部分介绍了深度学习在图像去噪中的主要分类，并对这些方法进行了比较分析;(<a href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%9C%AF%E5%9C%A8%E5%9B%BE%E5%83%8F%E5%8E%BB%E5%99%AA%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8">Deep learning techniques in image denoising</a>)</p></li><li><p>第四节提供了这些去噪方法的性能比较;(Experimental results)</p></li><li><p>第五节讨论了仍然存在的挑战和潜在的研究方向;(Discussion)</p></li><li><p>第六节给出了作者的结论;(<a href="#%E7%BB%93%E8%AE%BA">Conclusion</a>)</p></li></ul><h2 id="去噪基础框架">去噪基础框架</h2><p>这一部分讨论深度学习，包括它背后的思想、主要的网络框架(技术)以及硬件和软件，这是本调查涵盖的深入学习图像去噪技术的基础。</p><h3 id="机器学习">机器学习</h3><p>机器学习方法分为监督学习方法、半监督学习方法和非监督学习方法。</p><ul><li><p>有监督学习方法使用给定的标签使获得的特征更接近目标，以便学习参数和训练去噪模型。<br>$$<br>y=x+\mu \<br>x:干净图像，y:噪声图像，\mu：标准差为\sigma的AWGN<br>$$</p><ul><li>通过上述公式和贝叶斯知识，学习降噪模型的参数依赖于配对${x_k,y_k}^N_{k=1}$，$x_k$和$y_k$分别代表第k个干净图像和噪声图像，N是总数。处理可以表示为$x_k=f(y_k,\theta,m)，其中\theta是参数，m是给定的噪声等级$。</li></ul></li><li><p>无监督学习方法使用给定的训练样本，寻找pattern（而不是标签匹配），并完成特定任务，诸如对真实的低分辨率图像进行解配对。最近提出的循环内循环GaN(CinCGAN)算法首先估计高分辨率图像作为标签，然后利用获得的标签和损失函数训练超分辨率模型。</p></li><li><p>半监督学习方法将给定数据分布中的模型应用于构建学习器来标记未标记的样本。<strong>这种机制在小样本任务(如医学诊断)中更受青睐</strong>。半监督学习<strong>正弦图</strong>恢复网络(SLSR-NET)可以通过监督网络从成对的正弦图中学习特征分布，然后通过无监督网络将所获得的特征分布从未标记的低剂量正弦图转换为高保真正弦图。</p></li></ul><p>有监督学习方法：</p><p><strong><a href="https://readpaper.com/paper/2592929672">A survey on deep learning in medical image analysis</a></strong>（2017发表 6840被引用）</p><p>A Local Consensus Index Scheme for Random-Valued Impulse Noise Detection Systems （2021发表 13被引用 ）</p><p><a href="https://readpaper.com/paper/2946875605">Shared Linear Encoder-Based Multikernel Gaussian Process Latent Variable Model for Visual Classification</a> （2021发表 10被引用 ）</p><p>无监督学习方法：</p><p><a href="https://readpaper.com/paper/2605205826">Unsupervised holistic image generation from key local patches</a> （2018发表 8被引用）</p><p><a href="https://readpaper.com/paper/2962903125">Unsupervised Image Super-Resolution Using Cycle-in-Cycle Generative Adversarial Networks</a>（2018发表 210被引用）</p><p>半监督学习方法：</p><p><a href="https://readpaper.com/paper/2979557921">Semi-Supervised Learning for Low-Dose CT Image Restoration with Hierarchical Deep Generative Adversarial Network</a> (HD-GAN) （2019发表 6被引用）</p><p><a href="https://readpaper.com/paper/3011790227">Semi-supervised learned sinogram restoration network for low-dose CT image reconstruction</a>（2020发表 4被引用）</p><h3 id="神经网络">神经网络</h3><p>如果一个神经网络的层数超过三层，它也被称为深度神经网络，堆叠自动编码器(SARS)和深度信念网络(DBN)是典型的深度神经网络。他们在无监督的情况下使用叠加层对模型进行训练，取得了良好的性能。然而，这些网络的实现并不简单，需要大量的人工设置才能实现最佳模型。正因为如此，提出了端到端的连接网络（特别是CNN）。CNNs在图像处理，特别是图像去噪领域有着广泛的应用。</p><h4 id="卷积神经网络-2">卷积神经网络</h4><h5 id="AlexNet">AlexNet</h5><p>提出的AlexNet是深度学习的里程碑。它的成功有几个原因。</p><ol><li>图形处理单元(GPU)提供了强大的计算能力。</li><li>随机裁剪(即丢弃)解决了过拟合问题；</li><li>Relu提高了随机梯度下降(SGD)的速度，而不是Sigmoid。</li><li>数据增强方法进一步解决了过拟合问题。</li></ol><p><strong>缺点：</strong></p><p>虽然AlexNet取得了很好的性能，但由于其庞大的卷积内核，它需要大量的内存。这限制了它在现实世界中的应用，比如在智能相机中。在此之后，在2014-2016年间，为了提高性能和降低计算成本，更倾向于采用具有小过滤器的更深层次的网络体系结构。</p><h5 id="GoogLeNet">GoogLeNet</h5><p>随着更深层次网络的成功，研究转向增加它们的<strong>宽度</strong>。GoogLeNet增加了宽度以提高图像应用程序的性能。此外，GoogLeNet还将一个较大的卷积核变换为两个较小的卷积核，以减少参数数量和计算量。GoogLeNet还使用了Inistation模块和Inception模块。</p><h5 id="ResNet">ResNet</h5><p>VGG和GoogLeNet方法对于图像应用是有效的，但它们有两个缺点：如果网络很深，可能会导致梯度消失或爆炸；以及如果网络很深，可能会导致梯度消失或爆炸；如果网络过宽，可能会出现过度拟合的现象。</p><p>为了克服这些问题，2016年提出Resnet。每个block通过在ResNet中加入残差学习操作来提高图像识别性能。</p><h4 id="总结">总结</h4><p>自2014年以来，深度网络已广泛应用于真实世界的图像应用，例如面部识别和医疗诊断。</p><p>然而，在许多应用中，捕获的图像(例如真实的噪声图像)是不够的，并且深层CNN在图像应用中的性能往往很差。为此，Gans应运而生。GANS由两个网络组成：生成性网络和鉴别性网络。产生式网络(也称为生成器)用于根据输入样本生成样本。判别网络(也称为鉴别器)用于判断输入样本和生成样本的真实性。这两个网络是对抗性的。请注意，如果鉴别器能够准确区分真实样本并从生成器生成样本，则认为训练的模型已完成。图6中可以看到GaN的网络结构。由于其构建补充训练样本的能力，GaN对于小样本任务非常有效，例如面部识别和复杂噪声图像去噪。这些CNN是图像去噪的基本网络。</p><h3 id="软硬件使用">软硬件使用</h3><h4 id="硬件">硬件</h4><p>深度学习成功的一个原因是GPU。GPU采用CUDA、OpenCL和cuDNN平台，增强了并行计算能力，速度比CPU快10~30倍。GPU由NVIDIA显卡(即GTX 680、GTX 980、GTX 1070、GTX 1070Ti、GTX1080、GTX 1080Ti、RTX2070、RTX 2080、RTX 2080Ti、Tesla K40c、Tesla K80、Quadro M6000、Quadro GP100、QuadroP6000和Tesla V100)和AMD(即Radeon Vega 64)组成。</p><h4 id="软件">软件</h4><p>深度学习软件可以提供调用GPU的接口。目前流行的软件包有：</p><p>(1) 基于C<ins>的Caffe，提供C</ins>、Python和Matlab接口，既可以在CPU上运行，也可以在GPU上运行。它被广泛用于目标检测任务。然而，它要求开发人员掌握C++。</p><p>(2) Theano是一个用于处理大规模神经网络的数学表达式编译器。Theano提供了Python接口，用于图像的超分辨率、去噪和分类。</p><p>(3) MatConvernet提供了Matlab接口。它可用于图像分类、去噪和超分辨率，以及视频跟踪。但这需要掌握Matlab。</p><p>(4) TensorFlow是一个相对高阶的机器学习库。它比Theanofor编译速度更快。TensorFlow提供C++和Python接口，用于目标检测、图像分类、去噪和超分辨率。</p><p>(5) 基于TensorFlow和Theano的KERAS在Python中实现，并提供Python接口。它可以用于图像分类、目标检测、图像分辨率、图像去噪和动作识别。</p><p>(6) PyTorch是用Python实现的，并提供了Python接口。它应用于图像分类、目标检测、图像分割、动作识别、图像超分辨率、图像去噪和视频跟踪。</p><h2 id="深度学习技术在图像去噪中的应用">深度学习技术在图像去噪中的应用</h2><h3 id="加性白噪声图像去噪的深度学习技术">加性白噪声图像去噪的深度学习技术</h3><p>由于真实噪声图像的不足，加性白噪声图像(AWNI)被广泛用于训练去噪模型。AWNI包括高斯、泊松、椒盐、胡椒和乘性噪声图像。用于AWNI去噪的深度学习技术有几种，包括CNN/NN、CNN/NN与普通特征提取方法的结合以及优化方法与CNN/NN的结合。</p><h4 id="CNN-NN-在AWNI去噪中的应用">CNN/NN 在AWNI去噪中的应用</h4><p>自动特征提取方法可以在降低图像应用的计算成本方面发挥重要作用。为此，已开发出用于图像去噪的CNN，Zhang提出DnCNN来解决多个低级视觉任务，即通过CNN的图像去噪、超分辨率和去块、批归一化和残差学习技术。Wang等人还提出了用于图像去噪的更深层CNN的残差学习。然而，更深层的CNN技术依赖于更深的层，而不是浅层，这导致了长期的依赖问题。为了解决这个问题，人们提出了几种基于信号的方法。Tai 提出利用递归和门单元自适应地挖掘更精确的特征并恢复清晰的图像。受低阶Hankel矩阵的启发，Ye et al提供了卷积框架，通过卷积局部基和非局部基来解释信号处理和深度学习之间的联系。为了解决不充分的噪声图像(即高光谱图像和医学图像)，最近的一些工作试图通过使用改进的CNN来提取更多有用的信息。例如，袁等人将深度CNN、残差学习和多尺度知识相结合，对高光谱噪声图像进行去噪处理。然而，这些建议的CNN导致了计算成本和内存消耗的增加，这不利于现实世界的应用。为了解决这一现象，Gholizadeh等人在不增加CT图像去噪成本的情况下，利用膨胀卷积来扩大接收范围和减小网络深度。Lian等人提出了一种基于多尺度交叉路径级联的残差网络来抑制噪声。上述方法大多依赖于改进的CNN来处理噪声。因此，设计网络架构对于图像去噪非常重要。</p><p>改变网络架构包含下列方法：</p><ul><li>从一个CNN的多个输入融合特征<ul><li>同一个样本的不同部分作为输入</li><li>同一个样本的不同视角作为输入</li><li>同一个样本的不同通道作为输入</li></ul></li><li>改变损失函数——根据自然图像的特征设计不同的损失函数提取更鲁棒的特征<ul><li>Chen et al. [34]结合欧式和感知损失函数挖掘更多边缘信息</li></ul></li><li>提升CNN的深度或宽度<ul><li>增加网络深度</li><li>增加网络宽度</li></ul></li><li>增加一些辅助插件<ul><li>激活函数</li><li>扩张卷积</li><li>全连接层</li><li>池化</li></ul></li><li>引入跳连或者级联操作<ul><li>skip connection</li><li>cascade operation</li></ul></li></ul><p>具体地说，</p><ol><li>第一种方法包括三种类型：一个样本的不同部分作为来自不同网络的多个输入；一个样本作为输入的不同视角，例如多尺度；以及CNN的不同频道作为输入。</li><li>第二种方法是根据自然图像的特点设计不同的损失函数，以提取更稳健的特征。例如，Chen等人联合EU-CLIEDINE函数和感知损失函数，挖掘更多的边缘信息，用于图像去噪。</li><li>第三种方法通过增加网络的深度或宽度来增大接收野的大小以提高去噪性能。</li><li>第四种方法利用插件，如激活函数、膨胀卷积、全连接层和合并操作来增强CNN的表达能力。</li><li>第五种方法利用跳跃连接或级联操作来为CNN中的深层提供补充信息。</li></ol><p>表1提供了用于AWNI去噪的CNN的概述。</p><p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_1.png" alt=""></p><h4 id="CNN-NN和常用特征提取的AWNI的去噪方法">CNN/NN和常用特征提取的AWNI的去噪方法</h4><p>特征提取在图像处理中用来表示整幅图像，对机器学习非常重要。然而，由于深度学习技术是黑盒技术，它们不允许选择特征，因此不能保证所获得的特征是最健壮的。受问题的启发，<strong>研究了将常用特征提取方法嵌入到神经网络中</strong>，以达到图像去噪的目的。他们这样做的原因有五个：</p><ol><li>弱边缘信息噪声图像</li><li>非线性噪声图像</li><li>高维噪声图像</li><li>不显著噪声图像，</li><li>较高的计算代价。</li></ol><ul><li><p>对于弱边缘信息噪声图像，关等人提出了基于变换域的CNN方法。然而，它们在消除噪音方面并不有效。具体地说，在文献<strong>Multi-level Wavelet-CNN for Image Restoration</strong>中，提出的方法使用小波方法和U-网来消除膨胀卷积的网格效应，以扩大图像恢复的接收范围。</p></li><li><p>对于非线性噪声图像，带有核方法的CNN被证明是有用的。这些方法主要包括三个步骤。第一步使用CNN进行特征提取。第二步利用核方法将得到的非线性特征转化为线性特征。第三步利用残差学习构造潜在的干净图像。</p></li><li><p>对于高维噪声图像，提出了CNN与降维相结合的方法。例如，Khaw等人采用基于主成分分析(PCA)的细胞神经网络(CNN)进行图像去噪。这包括三个步骤。第一步采用卷积运算提取特征。第二步利用主成分分析对所获得的特征进行降维。第三步采用卷积的方法对PCA得到的特征进行处理，重建出干净的图像。</p></li><li><p>对于噪声不明显的图像，信号处理可以指导CNN提取显著特征[94,103,174，2]。具体地说，跳过连接是信号处理的典型操作。</p></li><li><p>对于涉及高计算成本的任务，具有图像像素关系性质的CNN在降低复杂度方面非常有效。例如，Ahn等人采用具有非局部自相似性的细胞神经网络(CNN)对噪声进行过滤去噪，其中给定噪声图像的相似特征可以加快特征提取的速度，降低计算成本.</p></li></ul><p>关于这些方法的更多详细信息可以见表2。</p><p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_2.png" alt=""></p><h4 id="最优化方法与CNN-NN相结合的AWNI去噪">最优化方法与CNN/NN相结合的AWNI去噪</h4><p>机器学习使用优化技术和判别性学习方法来处理图像应用。虽然优化方法在不同的低层视觉任务上都有很好的性能，但是这些方法需要手动设置参数，非常耗时。判别性学习方法图像恢复速度快，但对低水平视觉任务不灵活。为了在效率和灵活性之间实现折衷，提出了一种基于判别学习优化的图像应用方法，如图像去噪。<strong>基于正则项损失函数的先验知识CNN是图像去噪中常用的方法，可分为提高去噪速度和改善去噪性能两大类。</strong></p><p>为了提高去噪速度，利用CNN的优化方法是快速找到图像去噪最优解的有效工具。例如，采用最大后验概率(MAP)方法的GaN被用来估计噪声和处理其他任务，如图像修复和超分辨率。基于经验的贪婪算法和使用CNN的迁移学习策略可以加速遗传算法以获得干净的图像。噪声图像和噪声级映射是CNN的输入，在预测噪声方面执行速度更快。</p><p>为提高去噪性能，采用神经网络(CNN)组合优化方法对含噪图像进行平滑处理。具有全变差去噪的CNN降低了噪声像素的影响。将分裂Bregman迭代算法与CNN相结合，可以通过图像深度对像素进行增强，得到一幅潜在的干净图像。具有特征匹配的两阶段CNN可以更好地恢复干净图像的细节信息，特别是噪声图像。采用最近邻算法的GAN在过滤干净图像中的噪声图像方面是有效的。一种组合的CNN使用波前编码通过变换域来增强潜在清洁图像的像素。文献显示了其他有效的去噪方法。表3显示了优化方法和CNN/NN在AWNI去噪中组合的详细信息。</p><p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_3.png" alt=""></p><h3 id="真实噪声图像去噪中的深度学习技术">真实噪声图像去噪中的深度学习技术</h3><p>用于图像去噪的深度学习技术主要有两种：单一的端到端CNN和先验知识与CNN的结合。</p><p>对于第一种方法，改变网络结构是从给定的真实损坏图像中去除噪声的有效方法。多尺度知识是图像去噪的有效方法。例如，由卷积、REU和RL组成的CNN采用不同的相位特征来增强微光图像去噪模型的表达能力。为了克服模糊和虚假的图像伪影，提出了一种具有跳跃连接的双U网用于CT图像重建。为了解决资源约束问题，等人提出了解决方案使用具有批量重整化、RL和膨胀卷积的双重CNN来处理真实的噪声图像。基于光图像的性质，两个CNN利用各向异性视差分析来生成真实噪声图像的结构视差信息。在弱光条件下使用CNN解析遥感和医学图像被证明是有效的。为了提取更详细的信息，循环连接被用来增强对真实世界中的损坏图像的表示能力。为了处理未知的噪声图像，利用残差结构来促进低频特征，然后可以应用注意机制从通道中提取更多潜在的特征。为了产生含噪图像，有一种技术使用模拟摄像管道来构建退化模型，以便过滤(Alipay)获得真实的含噪图像。为了解决含噪图像无配对的无噪声图像的问题，一种嵌入无监督学习方法到cnn中的方法在图像去噪上是有效的。自洽的GaN首先使用一个CNN来估计给定噪声图像的噪声作为一个标签，然后应用另一个CNN和所得到的标签来去除其他噪声图像的噪声。这一概念也已扩展到一般的CNN。Noise2InversemMethod使用CNN根据周围的噪音像素预测噪音像素的值。**合并到3D自监督网络中的注意机制可以提高从医学噪声图像中去除噪声的效率。**有关上述研究的更详细资料参见表4。</p><p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_4.png" alt=""></p><p>将CNN和先验知识相结合的方法可以更好地处理真实噪声图像中的速度和复杂噪声任务。张等人提出了利用半二次分裂(HQS)和细胞神经网络(CNN)对给定的真实含噪图像进行噪声估计的方法。Guo等人提出了一种三阶段去噪方法。</p><ol><li>第一阶段使用高斯噪声和相机内处理流水线来合成噪声图像。将合成的噪声图像和真实的噪声图像进行融合，以更好地表示真实的噪声图像。</li><li>第二阶段采用具有非对称总变分损失的子网络来估计真实含噪图像的噪声。</li><li>第三阶段利用原始含噪图像，估计噪声，恢复潜在的干净图像。</li></ol><p>为了解决不成对噪声图像的问题，以半监督的方式发展了CNN和先验知识的组合。分层深层GaN(HD-GAN)首先使用聚类算法对每个患者的CT进行多类别分类，然后通过收集不同患者的同一类别的图像来构建数据集。最后，使用GaN对获得的数据集进行处理，以进行图像去噪和分类。类似的方法在3D映射中表现良好。</p><p>具有信道先验知识的CNN对于微光图像增强是有效的，表5显示了关于上述研究的详细信息。</p><p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_5.png" alt=""></p><h3 id="深度学习技术在盲降噪中的应用">深度学习技术在盲降噪中的应用</h3><p>在现实世界中，图像很容易被破坏，噪声也很复杂。因此，盲去噪技术非常重要。FFDNet使用噪声电平和噪声作为CNN的输入来训练未知噪声图像的去噪器。随后，提出了几种解决盲去噪问题的方法。Kenzo等人提出的一种成像器件机构。利用软性收缩调整噪声水平进行盲去噪。对于未配对的噪声图像，使用CNN估计噪声被证明是有效的。Yang等人使用已知的噪声水平训练去噪器，然后利用该去噪器来估计噪声水平。为了解决随机噪声衰减的问题，采用具有RL的细胞神经网络对过滤复合噪声进行处理。改变网络结构可以提高盲去噪的去噪性能。马琼达·埃塔尔提出对撞击未知噪声采用自动编码器。对于混合噪声，级联神经网络能有效去除加性高斯白噪声(AWGN)和脉冲噪声。表6显示了有关这些去噪方法的更多信息。</p><p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_6.png" alt=""></p><h3 id="混合噪声图像去噪的深度学习技术">混合噪声图像去噪的深度学习技术</h3><p>在现实世界中，捕获的图像会受到复杂环境的影响。受此启发，几位研究人员提出了混合噪声图像去噪技术。Li等人提出将CNN与翘曲导引相结合来解决噪声、模糊和JPEG压缩问题。张等人使用一种模型来处理噪声、模糊核和低分辨率图像等多种退化问题。为了增强原始传感器数据，Kokkinos等人提出了一种基于残差细胞神经网络的图像去马赛克和去噪迭代算法。为了处理任意模糊核，张等人提出采用级联去模糊和单幅图像超分辨率(SISR)网络来恢复即插即用超分辨率图像。表7给出了这些混合噪声图像去噪方法。</p><p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_7.png" alt=""></p><h4 id="突发噪声">突发噪声</h4><p>值得注意的是，图像携带的信息是有限的，这在实际应用中是不利的。为了解决这个问题，突发技术被开发出来。然而，爆裂受到噪声和相机抖动的影响，增加了实施实际任务的难度。最近，用于突发图像去噪的深度学习技术引起了人们的极大兴趣，即逐帧去除噪声。递归全卷积深度神经网络可以对任意长度序列中所有帧的噪声进行过滤去噪，将细胞神经网络与核方法相结合可以提高突发噪声图像的去噪性能。针对复杂背景噪声图像，提出了一种结合核和CNN的注意力机制来增强关键特征对突发图像去噪的效果，加快了训练速度。对于微光条件，使用CNN将给定的突发噪声图像映射到sRGB输出可以获得多帧去噪图像序列。为了降低网络复杂性，具有残差学习的CNN直接训练去噪模型，而不是显式的对齐过程。表8列出了这些突发去噪方法。</p><p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_8.png" alt=""></p><h4 id="视频噪声">视频噪声</h4><p>类似于突发图像，视频检测被分解到每一帧中。因此，加性白噪声图像去噪、实噪声图像去噪、盲去噪、混合噪声图像去噪等深入研究技术也适用于视频去噪。重现的神经网络利用端到端的CNN从被破坏的视频中去除噪声。为了提高视频去噪效果，降低视频冗余度是一种有效的方法。一种非局部拼接融合的CNN可以有效地抑制视频和图像去噪的噪声。在视频去噪中，CNN结合时间信息在性能和训练效率之间进行权衡。对于盲视频去噪，两级CNN被证明是一个很好的选择。第一阶段通过微调预先训练的AWGN去噪网络来训练视频去噪模型。第二阶段利用得到的视频去噪模型得到潜在的干净视频。这些视频去噪方法如表9所示。</p><p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_9.png" alt=""></p><h2 id="实验结果">实验结果</h2><h3 id="数据集">数据集</h3><h4 id="训练集">训练集</h4><p>训练集划分为两类：灰度噪声和彩色噪声图像。</p><p>灰度噪声图像数据集可用于训练高斯去噪器和盲去噪器。包括BSD400和Waterloo Exploration Database。BSD400由400张.png格式的图像组成，并裁剪到180*180用于训练一个去噪模型。Waterloo Exploration Database由4744个.png格式的自然图像组成。</p><p>彩色噪声图像包括BSD432，Waterloo Exploration Database和polyU-Real-World-Noisy-Images数据集。polyU-Real-World-Noisy-Images由100个真实噪声图像组成，尺寸2784*1856，由5个摄影机获得：Nikon D800，Canon 5D Mark Ⅱ，Sony A7 Ⅱ， Canon 80D和Canon 600D。</p><h4 id="测试集">测试集</h4><p>测试集包含灰度噪声和彩色噪声图像数据集。</p><p>灰度噪声数据集由Set12和BSD68组成。Set12包含12个场景。BSD68包含68个自然图像。它们用于测试高斯去噪器和盲噪声去噪器。</p><p>彩色噪声数据集包含CBSD68，Kodak24，McMaster，cc，DND，NC12，SIDD和Nam。Kodak24和McMaster分别包含24和18个彩色噪声图像。cc包含15个不同ISO（1600，3200，6400）的真实噪声图像。DND包含50个真实噪声图像，干净图像由低ISO捕获图像。NC12包含12个噪声图像并且没有groud-truth干净图像。SIDD包含来自智能手机的真实噪声图像，由320个噪声、ground-truch图像对构成。Nam包含11个场景，以JPEG格式保存。</p><h3 id="实验结果-2">实验结果</h3><p>为了验证一些方法的去噪表现，在Set12, BSD68, CBSD68, Kodak24, McMaster, DND, SIDD, Nam, cc和NC12数据集上进行了定量定性评估。定量评估主要使用不同去噪器的PSNR值来测试去噪效果。此外，我们利用去噪一张图像的时间来支持PSNR的定量评估。定性评估采用直观的图形表示恢复后的干净图像。</p><h4 id="加性白噪声图像去噪的深度学习技巧">加性白噪声图像去噪的深度学习技巧</h4><p>去噪方法的对比应该考虑加性白噪声，包括：高斯、泊松、微光噪声和盐、胡椒噪声，所有这些的噪声水平都有很大的不同。另外，很多方法使用不同的工具，对去噪结果影响很大。基于这些原因，选择<strong>典型高斯噪声</strong>来测试去噪表现。此外，大多数方法使用PSNR作为定量指标。所以，使用 BSD68, Set12, CBSD68, Kodak24和McMaster数据集来测试对于加性白噪声深度学习技巧的去噪表现。</p><p>【具有不同噪声水平的不同网络用于灰度加法白噪声图像去噪的PSNR值。ELDRN[165]表现最好】</p><p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_17_Table_10.png" alt=""></p><p>【为理解不同方法的去噪表现，使用FSIM（feature similarity index，特征相似性指数）作为视觉质量指标来进行在BSD68上不同噪声水平的实验】</p><p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_17_Table_11.png" alt=""></p><p>【为测试不同网络处理单个灰度加性白噪声图像的能力，在Set12上进行实验】</p><p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_19_Table_12.png" alt=""></p><p>【不同去噪方法对彩色加性白噪声图像的去噪表现】</p><p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_20_Table_13.png" alt=""></p><p>【不同方法图像去噪的效率】</p><p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_20_Table_14.png" alt=""></p><p>对于定性分析，对不同方法放大潜在干净图像的一个区域。观察得越清晰，说明去噪效果越好。</p><h4 id="真实噪声图像去噪的深度学习技巧">真实噪声图像去噪的深度学习技巧</h4><p>基于DND,SIDD,Nam,CC数据集。不使用NC12数据集的原因是NC12的ground-truth干净图像不可获得。</p><p>为了帮助更好理解这些方法，增加了一些传统去噪方法，比如BM3D作为比较方法。</p><p>从表15、16可看出，<strong>DRDN在DND和SSID上对真实噪声去噪获得了最好结果。</strong></p><p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_23_Table_15.png" alt=""></p><p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_24_Table_16.png" alt=""></p><p>从表17看出，<strong>对于压缩噪声图像，AGAN获得了很好的表现。</strong></p><p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_24_Table_17.png" alt=""></p><p>从表18看出，<strong>对于不同ISO值的真实噪声图像，SDNet和BRDNet获得了最佳和此佳去噪表现。</strong></p><p><img src="https://picture.mulindya.com/Apaper_collect/review_denoise_18.png" alt=""></p><h4 id="盲去噪的深度学习技巧">盲去噪的深度学习技巧</h4><p>众所周知，噪声在现实世界中是复杂的，不受规则的约束。这就是为什么盲去噪技术，特别是深度学习技术被开发出来的原因。比较不同深度学习技术的去噪性能是非常有用的。</p><p>实验采用DnCNN、FFDNet、Adnet、SCNN和G2G1等先进的去噪方法在BSD68和Set12上进行实验设计。</p><p><strong>FFDNet和Adnet在盲去噪方面优于其他方法</strong>，分别如表19和表20所示。</p><p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_24_Table_19.png" alt=""></p><p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_25_Table_20.png" alt=""></p><h4 id="混合噪声去噪的深度学习技巧">混合噪声去噪的深度学习技巧</h4><p>在现实世界中，损坏的图像可能包含不同种类的噪声，这使得恢复潜在的干净图像非常困难。为了解决这个问题，人们提出了基于深度学习技术的多退化思想。如表21所示，<strong>WarpNet与其他流行方法对比（如DnCNN和MemNet），有很强的竞争力。</strong></p><p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/64bef38470b7fc1bb5a95a95938c2ac5_25_Table_21.png" alt=""></p><h2 id="Discussion">Discussion</h2><p>指出未来研究的潜在区域和一些目前未解决的问题。</p><p>基于深度学习技术的图像去噪主要是为了<strong>提高去噪性能和效率，完成复杂的去噪任务</strong>。</p><p>改善去噪<strong>性能</strong>的解决方案包括以下几个方面：</p><ol><li><strong>增大感受野</strong>可以捕获更多上下文信息。增大感受野可以通过扩大网络深度和宽度完成。但这会导致高计算代价和更多内存消耗。一个解决方法是<strong>膨胀卷积</strong>，不仅可以获得更好的表现和效率，还可以有效地挖掘更多边缘信息。</li><li>使用CNN的同时还<strong>使用额外信息（也称先验知识）<strong>是便于获取更精确特征的有效方法。通过</strong>设计损失函数</strong>实现。</li><li><strong>结合局部和全局信息</strong>可以增强深层对浅层的记忆能力，从而更好地对抗噪声。两个解决方法是<strong>残差操作和递归操作</strong>。</li><li>可以使用<strong>单一的处理方法</strong>来抑制噪声。将单一的加工技术融合到深度CNN中，可以获得优异的性能。<strong>例如，小波技术</strong>被聚集到U-Net中来处理图像恢复[137]。</li><li><strong>数据增强</strong>，如水平翻转、垂直翻转和颜色抖动，可以帮助去噪方法学习更多类型的噪声，从而增强去噪模型的表达能力。另外，利用GAN构造虚拟噪声图像也有利于图像去噪。</li><li><strong>迁移学习、图搜索和神经结构搜索</strong>等方法可以获得较好的去噪效果。</li><li><strong>改进硬件或摄像机制</strong>可以降低噪声对采集图像的影响。</li></ol><p><strong>压缩深度神经网络</strong>在提高去噪<strong>效率</strong>方面取得了很大的成功。<strong>减小深层神经网络的深度或宽度</strong>可以降低这些网络在图像去噪中的复杂度。此外，使用<strong>小卷积核和分组卷积</strong>可以减少参数的数量，从而加快训练速度。<strong>与降维方法的融合</strong>，比如CNN与PCA的结合，也可以提高去噪效率。</p><p>对于<strong>复杂的含噪图像</strong>，<strong>分步处理</strong>是一种非常流行的方法。例如，使用两步机制是处理低分辨率噪声图像的一种方式，第一步涉及由CNN恢复高分辨率图像。第二步，用另一个新的CNN过滤来消除高分辨率图像的噪声。在上面的示例中，两个CNN通过级联操作实现。这种两步机制是<strong>无监督噪声任务</strong>的理想选择，例如真实噪声图像和盲去噪。也就是说，第一步依赖于具有优化算法的CNN，即最大后验，以估计噪声为地面事实(称为标签)。第二步，利用另一种CNN，获得地面真实情况，训练去噪模型，用于真噪声图像去噪或盲去噪；第二步，利用另一种CNN，训练去噪模型，用于真噪声图像去噪或盲去噪。<strong>融合到CNN中的自监督学习</strong>是<strong>真实噪声图像去噪或盲去噪</strong>的一个很好的选择。</p><p>虽然深度学习技术在这三种场景中都取得了很大的成功，但在图像去噪领域仍然存在<strong>挑战</strong>。这些措施包括：</p><ol><li>更深的网络需要<strong>更多的内存</strong>资源</li><li><strong>训练更深的去噪网络</strong>对于真实噪声图像、无配对的噪声图像、多降质任务<strong>不是一个稳定的解决方法</strong></li><li>真实噪声图像不是容易捕捉的，<strong>训练样本不足</strong></li><li>深度CNNs<strong>很难解决无监督</strong>去噪任务</li><li>需要<strong>更精确的</strong>去噪任务<strong>指标</strong>，PSNR、SSIM是流行的图像恢复指标。<strong>峰值信噪比(PSNR)存在过度平滑的问题，很难识别难以区分的图像。SSIM依赖于亮度、对比度和结构，因此不能准确地评价图像的感知质量。</strong></li></ol>]]></content>
    
    
    <categories>
      
      <category>文献</category>
      
      <category>综述</category>
      
    </categories>
    
    
    <tags>
      
      <tag>文献</tag>
      
      <tag>综述</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RuntimeError--expected dtype Double but got dtype Float</title>
    <link href="/2022/02/25/%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3/buildnet-runerror1/"/>
    <url>/2022/02/25/%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3/buildnet-runerror1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>在搭建去噪网络训练的时候出现RuntimeError: expected dtype Double but got dtype Float</p></blockquote><h2 id="问题描述-⛅️">问题描述 ⛅️</h2><p>利用<a href="https://so.csdn.net/so/search?q=Pytorch&amp;spm=1001.2101.3001.7020">Pytorch</a>框架自己构建网络结构，在程序运行到“loss.backward()”的时候报错：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">RuntimeError: expected dtype Double but got dtype Float<br></code></pre></td></tr></tbody></table></figure><p>通过查询资料得知，该错误来自于输入数据的<a href="https://so.csdn.net/so/search?q=%E7%B1%BB%E5%9E%8B&amp;spm=1001.2101.3001.7020">类型</a>和模型参数类型不一致。因此最好在程序开始统一数据类型。</p><h2 id="解决方案-🔅">解决方案 🔅</h2><h3 id="统一为DoubleTensor">统一为DoubleTensor</h3><p>Pytorch里的<a href="https://so.csdn.net/so/search?q=tensor&amp;spm=1001.2101.3001.7020">tensor</a>创建时默认是Torch.FloatTensor类型（torch.float32),</p><p>可通过在import语句后增加语句</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.set_default_tensor_type(torch.DoubleTensor)<br></code></pre></td></tr></tbody></table></figure><p>这样之后创建的变量类型都是<a href="https://so.csdn.net/so/search?q=Double&amp;spm=1001.2101.3001.7020">Double</a>类型(torch.float64)。不过这样也有些占用内存开销。</p><h3 id="统一为FloatTensor">统一为FloatTensor</h3><p>如果想要创建变量类型都是<a href="https://so.csdn.net/so/search?q=Float&amp;spm=1001.2101.3001.7020">Float</a>类型，在import后增加语句</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.set_default_tensor_type(torch.FloatTensor)<br></code></pre></td></tr></tbody></table></figure><p>但是这样卷积操作也会报错，这是因为numpy的默认数据类型为float64，这样创建的tensor还是为double类型，还是会导致类型不一致的情况。</p><p>因此如果想要项目中<a href="https://so.csdn.net/so/search?q=%E5%8F%82%E6%95%B0&amp;spm=1001.2101.3001.7020">参数</a>类型都为Float类型，不仅要加</p><figure class="highlight elm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-title">torch</span>.set_default_tensor_<span class="hljs-keyword">type</span>(torch.<span class="hljs-type">FloatTensor</span>)<br></code></pre></td></tr></tbody></table></figure><p>还要将数据转化为float32的格式：</p><p>转化为tensor类型时：</p><figure class="highlight reasonml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">images = torch.<span class="hljs-constructor">Tensor(<span class="hljs-params">images</span>)</span>.<span class="hljs-built_in">float</span><span class="hljs-literal">()</span> #增加.<span class="hljs-built_in">float</span><span class="hljs-literal">()</span><br></code></pre></td></tr></tbody></table></figure><p>在训练数据时：</p><figure class="highlight sqf"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sqf">inputs, <span class="hljs-built_in">targets</span> = inputs.<span class="hljs-keyword">to</span>(device).<span class="hljs-keyword">to</span>(torch.float32), <span class="hljs-built_in">targets</span>.<span class="hljs-keyword">to</span>(device, non_blocking=<span class="hljs-literal">True</span>).<span class="hljs-keyword">to</span>(torch.float32)<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>报错解决</category>
      
    </categories>
    
    
    <tags>
      
      <tag>报错解决</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>机器学习中的相关概念</title>
    <link href="/2022/02/24/machine_learning/%E7%9B%91%E7%9D%A3%E6%A6%82%E5%BF%B5/"/>
    <url>/2022/02/24/machine_learning/%E7%9B%91%E7%9D%A3%E6%A6%82%E5%BF%B5/</url>
    
    <content type="html"><![CDATA[<blockquote><p>机器学习中大体可以把任务分为监督学习，无监督学习。在我们的学习和资料查阅中会出现，半监督，自监督，弱监督这样的词汇，让人心生疑惑，在此进行一个梳理。以上各个概念的分类并不是严格互斥的。</p></blockquote><h2 id="监督和无监督-🎵">监督和无监督 🎵</h2><ul><li>有监督：用有标签的数据训练；</li><li>无监督：用无标签的数据训练；</li></ul><blockquote><p>这两者其最主要的区别在于模型在训练时是否需要人工标注的标签信息。监督学习利用大量的标注数据来训练模型，模型的预测和数据的真实标签产生损失后进行反向传播，通过不断的学习，最终可以获得识别新样本的能力。<br>无监督学习不依赖任何标签值，通过对数据内在特征的挖掘，找到样本间的关系，比如聚类相关的任务。</p></blockquote><ul><li>半监督：同时用有标签和无标签的数据进行训练。也就是数据集中小部分数据是带标签的；先前通常是两阶段的训练，先用（较小规模的）有标签数据训练一个Teacher模型，再用这个模型对（较大规模的）无标签数据预测伪标签，作为Student模型的训练数据；目前已经有很多直接end-to-end地训练，大大减少半监督训练的工作；</li></ul><h2 id="自监督学习-☁️">自监督学习 ☁️</h2><ul><li><p>自监督：在无标注数据上训练，通过一些方法让模型学习到数据的inner representation，再接下游任务，例如加一个mlp作为分类器等。但接了下游任务之后还是需要在特定的有标签数据上finetune，只是有时候可以选择把前面的层完全固定，只finetune后面接的网络的参数。</p><p>自监督学习是监督学习的一个特例，它与众不同，值得单独分为一类。自监督学习是没有人工标注标签的监督学习，可以将它看作没有人类参与的监督学习。标签仍然存在（因为总要有什么东西来监督学习过程），但它们是从输入数据中生成的，通常使用启发式算法生成的。</p></li></ul><blockquote><p>和无监督学习不同，自监督学习主要是利用辅助任务（pretext）从大规模的无监督数据中挖掘自身的监督信息，通过这种构造的监督信息对网络进行训练，从而可以学习到对下游任务有价值的表征。换句话说自监督学习的监督信息不是人工标注的，而是算法在大规模无监督数据中自动构造监督信息，来进行监督学习或训练。</p></blockquote><h2 id="弱监督学习-🎐">弱监督学习 🎐</h2><ul><li>弱监督：用包含噪声的有标签数据训练。弱监督学习是机器学习领域中的一个分支，与传统的监督学习相比，其使用有限的、含有噪声的或者标注不准确的数据来进行模型参数的训练。</li></ul><p>也就是说这种监督学习的数据的缘故，是一种有限有瓶颈的学习。来描述一个任务比较困难，并在这种学习任务中将其统称为弱监督学习。</p><p>按照数据的标注程度可以分为以下三类：不完全监督、不确切监督、不准确监督。</p><p><strong>1．不完全监督</strong><br>若样本中存在部分数据具有标注信息，而剩余部分则不具备有效的标注，这种为不完全监督。进一步，如果对于选定的未标注数据，存在一个系统能够给出数据的正确标签，即具备查询功能，则为不完全监督中的主动学习，其余的可划分为半监督学习的范围。<br>在半监督学习中，对于数据的分布存在两种基本假设：聚类假设和流行假设。前者假设样本空间存在内在的聚类结构，因此同一聚类中样本的标签应该相同；而后者则认为数据分布在一个流行上，在流行上相近的样本具有相似的预测结果。</p><p><strong>2．不确切监督</strong><br>当数据只具有粗粒度的标签时，被称为不确切监督。例如在人脸识别任务中，只对样本中是否含有人脸进行说明，但不提供人脸的具体位置，便是一种典型的不确切监督的问题。</p><p><strong>3．不准确监督</strong><br>即样本虽有具有标签，但并不准确。造成这种现象的原因有很多，例如标注难度大、标注人员自身水平有限等。</p><p><strong>弱监督学习在医学影像中的应用</strong></p><p>医学影像因标注要求高、数据收集困难等特点，很难收集具有大量有效标注的医学影像，因此很多医学影像分析的工作均采用弱监督学习的思路尝试解决问题。弱监督学习在标签有限的情况下，进行医学影像的处理，进而实现疾病的分类、病灶的定位及分割多种任务。</p><h2 id="强化学习-📠">强化学习 📠</h2><ul><li>强化学习一直以来被人们所忽视，但随着google的DeepMind公司将其成功应用于学习玩Atari游戏（以及后来学习下围棋并达到最高水平），机器学习的这一分支开始受到大量关注。</li></ul><p>在强化学习中，智能体（agent）接收有关环境的信息，并学会选择使某种奖励最大化的行动。例如，神经网络会“观察”视频游戏的屏幕，并输出游戏操作，目的是尽可能得高分，这种神经网络可以通过强化学习来训练。</p>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>praticalML第八章笔记--迁移学习</title>
    <link href="/2022/02/23/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PracticeML8/"/>
    <url>/2022/02/23/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PracticeML8/</url>
    
    <content type="html"><![CDATA[<blockquote><p>斯坦福2021秋季的实用机器学习上线啦~ 😉 跟着沐神复习机器学习冲冲冲！ 记录一下笔记和重点，不一定很全哦~，只是记录自我感觉的重点。本章的内容包括迁移学习，对视觉，NLP两个方面的微调。</p></blockquote><h1>第八章</h1><h2 id="8-1-迁移学习-💧">8.1 迁移学习 💧</h2><p>• Motivation<br>• Exploit a model trained on one task for a related task<br>• Popular in deep learning as DNNs are data hungry and training cost is high<br>• Approaches<br>• Feature extraction (e.g. Word2Vec, ResNet-50 feature, I3D feature)<br>• Train a model on a related task and reuse it<br>• Fine-tuning from a pertained model (focus of this lecture)<br>• Related to<br>• Semi-supervised learning  半监督学习<br>• In the extreme, zero-shot / few-shot learning<br>• Multi-task learning, where some labeled data is available for each task 多任务学习</p><ul><li>途径：<ul><li>训练好模型作为特征抽取的模块</li><li>在相关任务上训练一个模型，直接在另外一个任务上使用该模型</li><li>对预训练模型进行微调</li></ul></li></ul><h2 id="8-2-计算机视觉上的应用-🌼">8.2 计算机视觉上的应用 🌼</h2><h3 id="8-2-1-Transferring-Knowledge">8.2.1 Transferring Knowledge</h3><p>• There exists large-scale labeled CV datasets<br>• Especially for image classification, the cheapest one to label<br>• Transfer knowledge from models trained on these datasets to your CV applications (with 10-100X smaller data)</p><p>比如：ImageNet有120万图片1000类图片</p><h3 id="8-2-2-预训练模型">8.2.2 预训练模型</h3><ul><li>Partition a neural network into:<br>• A feature extractor (encoder) maps raw pixels into linearly separable features<br>• A linear classifier (decoder) makes decisions</li><li>Pre-trained model<br>• a neural network trained on a large-scale and general enough dataset</li><li>The feature extractor may generalize well to<br>• other datasets (e.g. medical/satellite images)<br>• other tasks (e.g. object detection, segmentation)</li></ul><p>可以把神经网络分成两块 encoder + decoder，这是一种抽象的概念。</p><p>encoder就是一种特征提取器，把原始像素转换为语义空间中线性可分的特征（浅表示/语义表示）；</p><p>decoder 是对编码器的表示进行一些决策转化为标号空间；</p><p><img src="https://picture.mulindya.com/Blog_PracticeML/pML8-1.png" alt=""></p><p>比如说上图这个网络结构，可以把下面的L-1层作为encocder，最后一层可以作为decoder。</p><p>预训练模型可以理解为在大型数据集上训练过的，因此是具有一定分泛化能力的。在imagenet上训练好的神经网络具有一定的特征提取能力，虽然它是自然图片，但是换到医学数据，卫星图片也是有一定帮助的。</p><h3 id="8-2-3-Fine-Tuning">8.2.3 Fine-Tuning</h3><p>一种简单的方法是将预训练模型只进行特征提取，也就是encoder部分。</p><ul><li>Initialize the new model:<br>• Initialize the feature extractor with the feature extractor parameters of a pre-trained model<br>• Randomly initialize the output layer<br>• Start the parameter optimization near a local minimal</li><li>Train with a small learning rate with just a few epochs<br>•   Regularize the search space</li></ul><p>微调比直接替换encoder更有效。</p><p>在新的任务上构建新的模型，但是他的架构和预训练模型有一致的地方，再去初始化模型；</p><p>初始化表示的是把预训练好的模型权重复制到那些一致的地方，而对decoder部分随机初始化，如下图所示；</p><p><img src="https://picture.mulindya.com/Blog_PracticeML/pML8-2.png" alt=""></p><p>然后再进行训练，对于如何训练也有一些技巧，通过初始化encoder权重，可以使得自己的权重值已经比较接近最优解了，这个时候训练可以<strong>使用比较小的学习率，采用更小的epoch，或者冻结部分层</strong>，使得搜索空间更小，避免梯度偏离。因为泛化误差和训练误差是不一样的，我们要让泛化误差更好。</p><h3 id="8-2-4-Freeze-Bottom-Layers">8.2.4 Freeze Bottom Layers</h3><ul><li>Neural networks learn hierarchical features<br>• Low-level features are universal, generalize well, e.g. curves /edges / blobs<br>• High-level features are more task and dataset specific, e.g. classification labels</li><li>Freeze bottom layers during fine tuning Train the top layers from scratch<br>• Keep low-level universal features intact<br>• Focus on learning task specific features<br>• A strong regularizer</li></ul><p>限制搜索空间也可以使用冻结的方法，在下面的层是学习像素底层的特征，比如颜色，纹理，这种特征提取是可以冻结的，越往上越靠近语义相关的特征.</p><p><img src="https://picture.mulindya.com/Blog_PracticeML/pML8-3.png" alt=""></p><p>对于神经网络是一个很平滑的过程从下而上慢慢学习任务；也就是说对下面几层可以固定住；如果应用和预训练数据差别比较大，可以少固定几层。</p><h3 id="8-2-5-find-Pre-trained-Models">8.2.5 find Pre-trained Models</h3><p>• Tensorflow Hub: <a href="https://tfhub.dev/">https://tfhub.dev/</a><br>• Tensorflow models submitted by users<br>• TIMM:  <a href="https://github.com/rwightman/pytorch-image-models">https://github.com/rwightman/pytorch-image-models</a>  最近比较流行，整理比较清晰，但是模型性能一般般<br>• PyTorch models collected by Ross Wightman</p><p>也有modelhub modelzoo</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> timm<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br>model = timm.creat_model(<span class="hljs-string">'resnet18'</span>,pretrained=<span class="hljs-literal">True</span>) <span class="hljs-comment">#模型和预训练模型权重</span><br>model.fc = nn.Linear(model.fc.in_features,n_classes) <span class="hljs-comment">#修改最后一层 个人数据集n_classes 默认随机初始化</span><br><span class="hljs-comment"># Train model as a normal training job </span><br><span class="hljs-comment">#固定层就是对其学习率改成0</span><br></code></pre></td></tr></tbody></table></figure><h3 id="8-2-6-应用">8.2.6 应用</h3><ul><li>Fine-tuning pre-trained models (on ImageNet) is widely used in various CV applications:<br>• Detection/segmentation (similar images but different targets)<br>• Medical/satellite images (same task but very different<br>images)</li><li>Fine-tuning accelerates convergence</li><li>Though not always improve accuracy<br>• Training from scratch could get a similar accuracy, especially when the target dataset is also large</li></ul><p><img src="https://picture.mulindya.com/Blog_PracticeML/pML8-4.png" alt=""></p><p>微调加速了收敛，对任务不同，数据集不同都能得到不错的效果；当数据集和预训练数据集差别非常大不一定会提升精度，但是不会变差。</p><h3 id="8-2-7-总结">8.2.7 总结</h3><p>• Pre-train models on large-scale datasets (often image classification)<br>• Initialize weights with pre-trained models for down-stream tasks<br>• Fine-tuning accelerates converges and (sometimes) improves<br>accuracy</p><p>在大型数据集上预训练模型，引入到自身的任务中，再进行微调。计算机视觉中对此有较好的应用性。</p><h2 id="8-3-NLP中的微调-⛳️">8.3 NLP中的微调 ⛳️</h2><h3 id="8-3-1-自监督预训练">8.3.1 自监督预训练</h3><p>• No large-scale labeled NLP dataset<br>• Large quantities of unlabeled documents<br>• Wikipedia, ebooks, crawled webpages<br>• Self-supervised pre-training<br>• Generate “pseudo label” and use supervised learning task<br>• Common tasks for NLP<br>• Language model (LM): predict next word. e.g. I like your hat  预测下一个词<br>• Masked language model (MLM): random masked word prediction. e.g. I like your hat 类似完型填空（更容易）</p><p>在NLP中不存在大型数据集预训练模型，存在大量的无标注的文档。在NLP一般会使用自监督来产生伪标号。</p><p>可以使用LM（语言模型）和MLM（带掩码的语言模型）来生成标号。</p><h3 id="8-3-2-预训练模型">8.3.2 预训练模型</h3><p><img src="https://picture.mulindya.com/Blog_PracticeML/pML8-5.png" alt=""></p><ul><li>词嵌入（比较旧），在一个文档中挑一个y，用左右的词来预测y，窗口大小为n，y用u来表示，上下文用v表示。得到y和上下文的关系。在预测时使用词典中的y取最大化CBOW；也可以使用中心词来预测周围词。向量空间可以一定程度上反映词的相似度。可以使用某个词周围的词放入公式得到该词作为中心词的特征向量表示。</li><li>基于Transformer的预训练模型（最近火热）<ul><li><strong>BERT：Transformer的编码器，训练时使用带掩码的词预测。编码器时双向的模型，所以需要带掩码；</strong></li><li><strong>GPT：解码器时一个从左对右的模型，可以用于预测下一个词；</strong></li><li><strong>T5：基于编码器和解码器的架构。</strong></li></ul></li></ul><h3 id="8-3-3-BERT">8.3.3 BERT</h3><p><img src="https://picture.mulindya.com/Blog_PracticeML/pML8-6.png" alt=""></p><p>使用两个训练任务：</p><ul><li>使用masked token盖住部分词来预测；</li><li>一次处理两个句子，可以相连为正例，无相连关系为负例。</li></ul><p>每个词会得到向量表示，还有一个分类cls来分类两个句子是否相连</p><h3 id="8-3-4-BERT微调">8.3.4 BERT微调</h3><p><img src="https://picture.mulindya.com/Blog_PracticeML/pML8-7.png" alt=""></p><p>得到预训练模型之后可以进行微调了，微调的方法和CV比较相似。把BERT的最后一层来微调，他是根据任务的不同而不同。将最后一层随机初始化，再使用小的学习率微调。</p><h3 id="8-3-5-实践">8.3.5 实践</h3><p>• BERT fine-tuning on small datasets can be unstable<br>• BERT removed bias correction steps in Adam<br>• Too few (=3) epochs<br>• Randomly initializing some top transformer layers help<br>• Features learned by top layers are too specific to the pre-training tasks<br>• The cutoff depends on downstream tasks</p><p>BERT微调结果很不稳定，是由于Adam在模型前期的系数估计不准确，这个参数对BERT无伤大雅，因为数据量庞大，但是在自己的小数据集上使用时使用完整版的Adam，BERT默认对任务时训练3次，但是在实际没有收敛，微调时建议多训练几轮。</p><p>对于Transformer和CNN没有本质区别，对于底层时语义层次信息，越向上和标注空间会更相似。所以同样将下面的层冻结，训练上面的层。</p><h3 id="8-3-6-寻找NLP预训练模型">8.3.6 寻找NLP预训练模型</h3><p>• HuggingFace: a collection of pre-trained transformer models on<br>both PyTorch and TensorFlow</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer <br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification <br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">"bert-base-cased"</span>) <br>inputs = tokenizer(sentences, padding=<span class="hljs-string">"max_length"</span>, truncation=<span class="hljs-literal">True</span>) <br>model = AutoModelForSequenceClassification.from_pretrained( <br>“bert-base-cased<span class="hljs-string">", num_labels=2) </span><br><span class="hljs-string"># Train model on inputs as a normal training job </span><br><span class="hljs-string"></span><br></code></pre></td></tr></tbody></table></figure><p>目前常见的NLP模型比较主流的是HuggingFace的transformers包。</p><p>NLP<strong>关键点</strong>：如何把文档表示为一个个的词/词元/token.这一步取决于模型。不同的模型有不同的表示方法，需要把对应的字典用相同的方式表示，否则无法对应，并且任务不同也对应的不同。</p><h3 id="8-3-7-应用">8.3.7 应用</h3><p>• “(BERT) obtains new state-of-the-art results on eleven natural language processing tasks”, including<br>• If a sequence of words is a grammatical English sentence<br>• Sentiment of sentences from movie reviews<br>• Sentences/questions in a pair are semantically equivalent, or similar<br>• If the premise entails the hypothesis<br>• Find the span of the answer for a question<br>• “(T5) achieve state-of-the-art results on many benchmarks covering<br>summarization, question answering, text classification, and more”</p><p>BERT是编码器的架构，所以有一定的局限性，比如input为一段话生成一段新的句子就比较难实现。</p><p>适合于：</p><ul><li><p>判断句子句法是否正确；</p></li><li><p>电影的评论为正面还是负面；</p></li><li><p>两句话或是两个问题是否语义等价；</p></li><li><p>假设和结论之间是否存在加强关系；</p></li><li><p>在问题中是否可以找到答案的范围；</p></li></ul><h3 id="8-3-8-总结">8.3.8 总结</h3><p>• Self-supervised pre-training for NLP models<br>• A common task is (masked) language model<br>• BERT is a giant transformer encoder<br>• Downstream tasks fine-tune BERT with a consistent manner</p><p>NLP的预训练使用自监督来完成。</p><ul><li><strong>BERT：Transformer的编码器，训练时使用带掩码的词预测。编码器时双向的模型，所以需要带掩码；</strong></li><li><strong>GPT：解码器时一个从左对右的模型，可以用于预测下一个词；</strong></li><li><strong>T5：基于编码器和解码器的架构。</strong></li></ul>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>李沐</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer61 扑克牌中的顺子</title>
    <link href="/2022/02/21/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer61/"/>
    <url>/2022/02/21/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer61/</url>
    
    <content type="html"><![CDATA[<blockquote><p>扑克牌中的顺子</p></blockquote><h2 id="题目">题目</h2><p>从若干副扑克牌中随机抽 5 张牌，判断是不是一个顺子，即这5张牌是不是连续的。2～10为数字本身，A为1，J为11，Q为12，K为13，而大、小王为 0 ，可以看成任意数字。A 不能视为 14。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入: [1,2,3,4,5]</span><br><span class="hljs-section">输出: True</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入: [0,0,1,2,5]</span><br><span class="hljs-section">输出: True</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>数组长度为 5</li><li>数组的数取值为 [0, 13]</li></ul><h2 id="题解">题解</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">isStraight</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">bool</span>:</span><br>        new_nums = <span class="hljs-built_in">sorted</span>(nums)<br>        target = -<span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>            <span class="hljs-keyword">if</span> new_nums[i]!=<span class="hljs-number">0</span> <span class="hljs-keyword">and</span> target==-<span class="hljs-number">1</span>: <span class="hljs-comment">#更新0个数 也是起始非0index</span><br>                target = i<br>            <span class="hljs-keyword">if</span> i&gt;<span class="hljs-number">0</span> <span class="hljs-keyword">and</span> new_nums[i]!=<span class="hljs-number">0</span> <span class="hljs-keyword">and</span> new_nums[i]==new_nums[i-<span class="hljs-number">1</span>]:<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>        need = (new_nums[<span class="hljs-number">4</span>]-new_nums[target]-(<span class="hljs-number">5</span>-target)+<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> need&lt;=target<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>数组</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>数组</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>机器学习公式推导--Introduction</title>
    <link href="/2022/02/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%99%BD%E6%9D%BF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/1.Intro_Math/"/>
    <url>/2022/02/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%99%BD%E6%9D%BF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/1.Intro_Math/</url>
    
    <content type="html"><![CDATA[<blockquote><p>记录机器学习公式推导的文档，好好学数学哦~<br>参考视频：<a href="https://www.bilibili.com/video/BV1aE411o7qd?p=2&amp;spm_id_from=pageDriver">https://www.bilibili.com/video/BV1aE411o7qd?p=2&amp;spm_id_from=pageDriver</a><br>语雀文档：<a href="https://www.yuque.com/books/share/f4031f65-70c1-4909-ba01-c47c31398466/hu0291">https://www.yuque.com/books/share/f4031f65-70c1-4909-ba01-c47c31398466/hu0291</a></p></blockquote><h1>Introduction</h1><p>对概率的诠释有两大学派，一种是频率派另一种是贝叶斯派。后面我们对观测集采用下面记号：</p>$$X_{N\times p}=(x_{1},x_{2},\cdots,x_{N})^{T},x_{i}=(x_{i1},x_{i2},\cdots,x_{ip})^{T}$$ <p>这个记号表示有 $N$ 个样本，每个样本都是 $p$ 维向量。其中每个观测都是由 $p(x|\theta)$ 生成的。</p><h2 id="频率派的观点">频率派的观点</h2><p>$p(x|\theta)$ 中的 $\theta$ 是一个未知常量。对于 $N$ 个观测来说观测集的概率为</p>$$p(X|\theta)\mathop{=}\limits _{iid}\prod\limits _{i=1}^{N}p(x_{i}|\theta))$$<p>为了求 $\theta$ 的大小，我们采用最大对数似然MLE的方法：</p>$$\theta_{MLE}=\mathop{argmax}\limits _{\theta}\log p(X|\theta)\mathop{=}\limits _{iid}\mathop{argmax}\limits _{\theta}\sum\limits _{i=1}^{N}\log p(x_{i}|\theta)$$<p>假设每个样本$x_i$都是独立同分布(iid)于$p(x_i| \theta)$,那么有$P(X| \theta) = \prod_{i=1}^N p(x_i| \theta)$,对两边取对数连乘就变成连加。</p><p>频率派模型演化为统计机器学习，关键是优化问题，如设计模型，loss function，algorithm。</p><h2 id="贝叶斯派的观点">贝叶斯派的观点</h2><p>贝叶斯派认为 $p(x|\theta)$ 中的 $\theta$ 不是一个常量**。这个 $\theta$ 满足一个预设的分布 $\theta\sim p(\theta)$** ，这个预设的分布就是先验，而这个先验是可以通过贝叶斯公式由后验得到。于是根据贝叶斯定理依赖观测集参数的后验可以写成：</p>$$p(\theta|X)=\frac{p(X|\theta)\cdot p(\theta)}{p(X)}=\frac{p(X|\theta)\cdot p(\theta)}{\int\limits _{\theta}p(X|\theta)\cdot p(\theta)d\theta}$$<p>为了求 $\theta$ 的值，我们要最大化这个参数后验MAP（最大后验概率估计）：</p>$$\theta_{MAP}=\mathop{argmax}\limits _{\theta}p(\theta|X)=\mathop{argmax}\limits _{\theta}p(X|\theta)\cdot p(\theta)$$<p>其中第二个等号是由于分母和 $\theta$ 没有关系。求解这个 $\theta$ 值后计算</p>$$\frac{p(X|\theta)\cdot p(\theta)}{\int\limits _{\theta}p(X|\theta)\cdot p(\theta)d\theta}$$<p>，就得到了参数的后验概率。其中 $p(X|\theta)$ 叫似然，是我们的模型分布。得到了参数的后验分布后，我们可以将这个分布用于预测贝叶斯预测：</p>$$p(x_{new}|X)=\int\limits _{\theta}p(x_{new}|\theta)\cdot p(\theta|X)d\theta$$ <p>其中积分中的被乘数是模型，乘数是后验分布。</p><p>贝叶斯模型进而发展为概率图模型，关键就是求积分（比如常用的MCMC，蒙特卡洛方法）。</p><h2 id="小结">小结</h2><p>频率派和贝叶斯派分别给出了一系列的机器学习算法。频率派的观点导出了一系列的统计机器学习算法而贝叶斯派导出了概率图理论。在应用频率派的 MLE 方法时最优化理论占有重要地位。而贝叶斯派的算法无论是后验概率的建模还是应用这个后验进行推断时积分占有重要地位。因此采样积分方法如 MCMC 有很多应用。</p><h1>MathBasics</h1><h2 id="高斯分布">高斯分布</h2><h3 id="一维情况-MLE">一维情况 MLE</h3><p>高斯分布在机器学习中占有举足轻重的作用。在 MLE 方法中：</p>$$\theta=(\mu,\Sigma)=(\mu,\sigma^{2}),\theta_{MLE}=\mathop{argmax}\limits _{\theta}\log p(X|\theta)\mathop{=}\limits _{iid}\mathop{argmax}\limits _{\theta}\sum\limits _{i=1}^{N}\log p(x_{i}|\theta)$$<p>一般地，高斯分布的概率密度函数写为：</p>$$p(x|\mu,\Sigma)=\frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}}e^{-\frac{1}{2}(x-\mu)^{T}\Sigma^{-1}(x-\mu)}  $$<p>其中 $\Sigma$表示分布的协方差矩阵，在一维的情况其协方差矩阵即为该方差的1X1矩阵。</p><p>带入 MLE 中我们考虑一维的情况</p>$$\log p(X|\theta)=\sum\limits _{i=1}^{N}\log p(x_{i}|\theta)=\sum\limits _{i=1}^{N}\log\frac{1}{\sqrt{2\pi}\sigma}\exp(-(x_{i}-\mu)^{2}/2\sigma^{2})$$<p>首先对 $\mu$ 的极值可以得到 ：</p>$$\mu_{MLE}=\mathop{argmax}\limits _{\mu}\log p(X|\theta)=\mathop{argmax}\limits _{\mu}\sum\limits _{i=1}^{N}(x_{i}-\mu)^{2}$$ <p>于是：</p>$$\frac{\partial}{\partial\mu}\sum\limits _{i=1}^{N}(x_{i}-\mu)^{2}=0\longrightarrow\mu_{MLE}=\frac{1}{N}\sum\limits _{i=1}^{N}x_{i}$$<p>就可以得到$\mu$的估计值。</p><p>其次对 $\theta$ 中的另一个参数 $\sigma$ ，有：</p>$$\begin{align}\sigma_{MLE}=\mathop{argmax}\limits _{\sigma}\log p(X|\theta)&amp;=\mathop{argmax}\limits _{\sigma}\sum\limits _{i=1}^{N}[-\log\sigma-\frac{1}{2\sigma^{2}}(x_{i}-\mu)^{2}]\nonumber\\&amp;=\mathop{argmin}\limits _{\sigma}\sum\limits _{i=1}^{N}[\log\sigma+\frac{1}{2\sigma^{2}}(x_{i}-\mu)^{2}]\end{align}$$<p>于是：</p>$$\frac{\partial}{\partial\sigma}\sum\limits _{i=1}^{N}[\log\sigma+\frac{1}{2\sigma^{2}}(x_{i}-\mu)^{2}]=0\longrightarrow\sigma_{MLE}^{2}=\frac{1}{N}\sum\limits _{i=1}^{N}(x_{i}-\mu)^{2}$$<p>值得注意的是，上面的推导中，首先对 $\mu$ 求 MLE， 然后利用这个结果求 $\sigma_{MLE}$ ，因此可以预期的是对数据集求期望时 $\mathbb{E}<em>{\mathcal{D}}[\mu</em>{MLE}]$ 是无偏差的：</p>$$\mathbb{E}_{\mathcal{D}}[\mu_{MLE}]=\mathbb{E}_{\mathcal{D}}[\frac{1}{N}\sum\limits _{i=1}^{N}x_{i}]=\frac{1}{N}\sum\limits _{i=1}^{N}\mathbb{E}_{\mathcal{D}}[x_{i}]=\mu$$<p>但是当对 $\sigma_{MLE}$ 求 期望的时候由于使用了<strong>单个数据集</strong>的 $\mu_{MLE}$,其方差会比真实的方差更小，因此对所有数据集求期望的时候我们会发现 $\sigma_{MLE}$ 是 有偏的：</p>$$\begin{align}\mathbb{E}_{\mathcal{D}}[\sigma_{MLE}^{2}]&amp;=\mathbb{E}_{\mathcal{D}}[\frac{1}{N}\sum\limits _{i=1}^{N}(x_{i}-\mu_{MLE})^{2}]=\mathbb{E}_{\mathcal{D}}[\frac{1}{N}\sum\limits _{i=1}^{N}(x_{i}^{2}-2x_{i}\mu_{MLE}+\mu_{MLE}^{2})\nonumber\\&amp;=\mathbb{E}_{\mathcal{D}}[\frac{1}{N}\sum\limits _{i=1}^{N}x_{i}^{2}-\mu_{MLE}^{2}]=\mathbb{E}_{\mathcal{D}}[\frac{1}{N}\sum\limits _{i=1}^{N}x_{i}^{2}-\mu^{2}+\mu^{2}-\mu_{MLE}^{2}]\nonumber\\&amp;= \mathbb{E}_{\mathcal{D}}[\frac{1}{N}\sum\limits _{i=1}^{N}x_{i}^{2}-\mu^{2}]-\mathbb{E}_{\mathcal{D}}[\mu_{MLE}^{2}-\mu^{2}]=\sigma^{2}-(\mathbb{E}_{\mathcal{D}}[\mu_{MLE}^{2}]-\mu^{2})\nonumber\\&amp;=\sigma^{2}-(\mathbb{E}_{\mathcal{D}}[\mu_{MLE}^{2}]-\mathbb{E}_{\mathcal{D}}^{2}[\mu_{MLE}])=\sigma^{2}-Var[\mu_{MLE}]\nonumber\\&amp;=\sigma^{2}-Var[\frac{1}{N}\sum\limits _{i=1}^{N}x_{i}]=\sigma^{2}-\frac{1}{N^{2}}\sum\limits _{i=1}^{N}Var[x_{i}]=\frac{N-1}{N}\sigma^{2}\end{align}$$<p>所以：</p>$$\hat{\sigma}^{2}=\frac{1}{N-1}\sum\limits _{i=1}^{N}(x_{i}-\mu)^{2}$$]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>公式推导</category>
      
    </categories>
    
    
    <tags>
      
      <tag>公式推导</tag>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文中的各种加噪方式</title>
    <link href="/2022/02/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E5%8E%BB%E5%99%AA/paper-noise/"/>
    <url>/2022/02/16/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E5%8E%BB%E5%99%AA/paper-noise/</url>
    
    <content type="html"><![CDATA[<blockquote><p>整理论文中的加噪方式</p><p>参考论文具体如下：</p><p><strong>Adaptive Consistency Prior based Deep Network for Image Denoising</strong><br>Paper：<a href="https://readpaper.com/pdf-annotate/note?noteId=652422328685277184&amp;pdfId=630634874308022272">https://readpaper.com/pdf-annotate/note?noteId=652422328685277184&amp;pdfId=630634874308022272</a> (笔记)<br>Code：<a href="https://github.com/chaoren88/DeamNet/tree/827c736dec2fe675e7bf4de06c3f026d9aaf4dbf">https://github.com/chaoren88/DeamNet/tree/827c736dec2fe675e7bf4de06c3f026d9aaf4dbf</a></p><p><strong>Unpaired Learning of Deep Image Denoising</strong><br>Paper：<a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123610732.pdf">https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123610732.pdf</a><br>Code：<a href="https://github.com/majedelhelou/SFM">https://github.com/majedelhelou/SFM</a></p><p><strong>Learning Graph-Convolutional Representations for Point Cloud Denoising</strong><br>Paper：<a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123650103.pdf">https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123650103.pdf</a><br>Code：<a href="https://github.com/diegovalsesia/GPDNet">https://github.com/diegovalsesia/GPDNet</a></p><p><strong>Spatial-Adaptive Network for Single Image Denoising</strong><br>Paper：<a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123750171.pdf">https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123750171.pdf</a><br>Code:<a href="https://github.com/JimmyChame/SADNet">https://github.com/JimmyChame/SADNet</a></p></blockquote><h2 id="1，Adaptive-Consistency-Prior-based-Deep-Network-for-Image-Denoising">1，Adaptive Consistency Prior based Deep Network for Image Denoising</h2><h4 id="实验部分">实验部分</h4><p>分为对合成噪声数据集和真实数据集上去噪两个模块。</p><p><strong>噪声类型</strong>： 加性高斯白噪声AWGN(Additive White Gaussian Noise)  （在论文中提到的强度对比 15, 25 and 50.）</p><ul><li>训练部分</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">parser.add_argument(<span class="hljs-string">"--noiseL"</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">25</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'noise level'</span>)<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span>(<span class="hljs-params">epoch</span>):</span><br>    epoch_loss = <span class="hljs-number">0</span><br>    model.train()<br>    <span class="hljs-keyword">for</span> iteration, batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(training_data_loader, <span class="hljs-number">1</span>):<br>        target = Variable(batch)<br>        noise = torch.FloatTensor(target.size()).normal_(mean=<span class="hljs-number">0</span>, std=opt.val_noiseL / <span class="hljs-number">255.</span>)<br>        <span class="hljs-built_in">input</span> = target + noise<br>        .....<br></code></pre></td></tr></tbody></table></figure><ul><li>测试部分（合成）</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">parser.add_argument(<span class="hljs-string">"--test_noiseL"</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">15</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'noise level used on test set'</span>) <span class="hljs-comment">#噪声强度</span><br>opt = parser.parse_args()<br><br>ISource = torch.Tensor(Img)    <br><span class="hljs-comment"># noise</span><br>noise = torch.FloatTensor(ISource.size()).normal_(mean=<span class="hljs-number">0</span>, std=opt.test_noiseL / <span class="hljs-number">255.</span>) <span class="hljs-comment">#高斯噪声</span><br><span class="hljs-comment"># noisy image</span><br>INoisy = ISource + noise <span class="hljs-comment">#加性</span><br>ISource, INoisy = Variable(ISource.cuda()), Variable(INoisy.cuda())<br></code></pre></td></tr></tbody></table></figure><p>真实数据集</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span>(<span class="hljs-params">self, index</span>):</span><br>    clean = Image.<span class="hljs-built_in">open</span>(self.path[index])<br><br>    <span class="hljs-keyword">if</span> self.transform:<br>        clean = self.transform(clean)<br><br>    noise = torch.randn(clean.size()).mul_(self.sigma/<span class="hljs-number">255.0</span>) <span class="hljs-comment">#噪声？</span><br>    noisy = clean + noise<br>    noisy = torch.clamp(noisy, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>)<br>    <span class="hljs-keyword">return</span> noisy, clean<br></code></pre></td></tr></tbody></table></figure><blockquote><p>这里加噪代码存疑</p><p>论文中对真实数据集的去噪细节中写道：</p><p>由于真实噪声通常是信号相关的，并且随着摄像机内管线的不同，真实图像去噪通常是一项极具挑战性的任务，为了进一步展示DeamNet对真实噪声的泛化能力，选择DND基准、SIDD基准和RNI15数据集作为测试数据集。请注意，对于DND和SIDD基准，几乎无噪音的图像不是公开的，但PSNR/SSIM结果可以通过他们的在线服务器获得。而对于RNI15，只有噪声图像可用。</p></blockquote><h4 id="合成噪声数据集（重点关注）">合成噪声数据集（重点关注）</h4><p><strong>训练数据集</strong>包括：</p><ol><li><p>the Berke-ley Segmentation Dataset (BSD)  是为图像分割和边界检测的研究提供经验基础的数据集，包含来自 30 个人类受试者的 1000 个手工标记的 1000 个 Corel 数据集图像的分割，其中一半的分割是通过向主体呈现彩色图像而获得的; 另一半来自呈现灰度图像。</p></li><li><p>Div2K：数据集有1000张高清图(2K分辨率)，其中800张作为训练，100张作为验证，100 张作为测试。</p></li></ol><p>三个标准<strong>基线数据集</strong>进行了评估 （指标：PSNR and SSIM）</p><ol><li><p>Set12：数字图像处理常用数据集Set12，12张灰度图（含lena，cameraman，house，pepper，fishstar，monarch，airplane，parrot，barbara，ship，man，couple），01-07是256*256,08-12是512*512.</p></li><li><p>BSD68  数字图像处理常用数据集BSD68，68张灰度图，大小不一。</p></li><li><p>Urban100  ：一个用于超分辨率和图像重建的数据集 Urban100，总计100张建筑高清图片，同时对应了100张降低分辨率的图片。</p></li></ol><h4 id="真实噪声数据集">真实噪声数据集</h4><h5 id="训练数据集">训练数据集</h5><ol><li>SIDD：智能手机图像去噪数据集（SIDD）使用5个具有代表性的智能手机摄像头，从10个场景中提取约30000个噪声图像，并生成它们真实的场景图像。</li><li>RENOIR：一个真实的图像降噪数据集，包含了3个子数据集，分别是Xiaomi Mi3，Canon S90，Canon T3i拍摄，拥有低噪和高噪对比图。</li></ol><h5 id="测试数据集">测试数据集</h5><ul><li><p>DND：是由50幅真实世界的噪声图像组成的，但没有几乎没有噪声的对应图像。通常，可以通过将去噪图像上传到DND网站来获得PSNR/SSIM结果。</p></li><li><p>SIDD：提供320对噪声图像和近无噪声图像用于训练，1280个图像patch用于验证。PSNR/SSIM结果可以通过将去噪图像提交到SIDD网站获得。</p></li><li><p>RNI15：提供了15幅真实噪声图像。不幸的是，地面真实的干净图像不可用，因此我们只展示RNI15的视觉结果。</p></li></ul><h4 id="数据增强">数据增强</h4><p>我们将这些训练图像对随机裁剪成大小为128×128的小块。为了增加训练样本，采用了180度的旋转和水平翻转。</p><h4 id="对比网络">对比网络</h4><ul><li><p>TNRD</p></li><li><p>DnCNN</p></li><li><p>FFDNet</p></li><li><p>RED</p></li><li><p>MemNet</p></li><li><p>UNLNet</p></li><li><p>CFSNet</p></li><li><p>N3Net</p></li><li><p>ADNet</p></li><li><p>BRDNet</p></li><li><p>RIDNet</p></li></ul><h5 id="合成数据集效果">合成数据集效果</h5><p><img src="https://picture.mulindya.com/deamnet1.png" alt=""></p><h5 id="真实数据集效果">真实数据集效果</h5><p><img src="https://picture.mulindya.com/deamnet2.png" alt=""></p><h2 id="2，Unpaired-Learning-of-Deep-Image-Denoising">2，Unpaired Learning of Deep Image Denoising</h2><ul><li><p>AWGN                                       (代码中为gaussian)</p></li><li><p>heteroscedastic Gaussian  （代码中为poisson_gaussian）</p><ul><li>参数 $\alpha$  和$\sigma$  分别表示混合噪声中Poisson分量和Gaussian分量的强度。</li></ul></li><li><p>multivariate Gaussian        （代码中为multivariate_gaussian）多元高斯分布</p></li></ul><h3 id="代码">代码</h3><p>路径：DBSN/dbsn_cocor/data/dn_dataset.py</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DnDataset</span>(<span class="hljs-params">BaseDataset</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, opt, split, dataset_name, noiseL</span>):</span><br>        <span class="hljs-built_in">super</span>(DnDataset, self).__init__(opt, split, dataset_name)        <br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(noiseL) == <span class="hljs-number">1</span>:<br>            self.noiseL = noiseL[<span class="hljs-number">0</span>]<br>            self.get_noiseL = self._get_noiseL_1<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">len</span>(noiseL) == <span class="hljs-number">2</span>:<br>            <span class="hljs-keyword">if</span> self.noise_type.lower==<span class="hljs-string">'gaussian'</span>:<br>                self.noiseL = noiseL<br>                self.get_noiseL = self._get_noiseL_2<br>            <span class="hljs-keyword">else</span>:<br>                self.noiseL = noiseL<br>                self.get_noiseL = self._get_noiseL_1<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">len</span>(noiseL) == <span class="hljs-number">3</span>:<br>            self.noiseL_p = [noiseL[<span class="hljs-number">0</span>], noiseL[<span class="hljs-number">1</span>]]<br>            self.noiseL_g = [noiseL[<span class="hljs-number">0</span>], noiseL[<span class="hljs-number">2</span>]]<br>            self.get_noiseL_p = self._get_noiseL_p<br>            self.get_noiseL_g = self._get_noiseL_g<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">'noiseL should have one or two or three values'</span>)<br></code></pre></td></tr></tbody></table></figure><h4 id="AWGN">AWGN</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_add_noise_gaussian</span>(<span class="hljs-params">self, img</span>):</span><br>    <span class="hljs-keyword">if</span> self.split == <span class="hljs-string">'val'</span>:<br>        np.random.seed(seed=<span class="hljs-number">0</span>)<br>    noise = np.random.normal(<span class="hljs-number">0</span>, self.get_noiseL()/<span class="hljs-number">255.</span>,<br>                            img.shape).astype(np.float32) <br>    <span class="hljs-keyword">return</span> img + noise <br></code></pre></td></tr></tbody></table></figure><h4 id="heteroscedastic-Gaussian">heteroscedastic Gaussian</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_add_noise_poisson_gaussian</span>(<span class="hljs-params">self, img</span>):</span><br>    <span class="hljs-comment"># implemented in paper</span><br>    noiseLevel = [v/<span class="hljs-number">255.</span> <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> self.get_noiseL()]<br>    sigma_s = noiseLevel[<span class="hljs-number">0</span>]<br>    sigma_c = noiseLevel[<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">if</span> self.split == <span class="hljs-string">'val'</span>:<br>        np.random.seed(seed=<span class="hljs-number">0</span>)<br>    n1 = np.random.randn(*img.shape)*sigma_s*img<br>    <span class="hljs-keyword">if</span> self.split == <span class="hljs-string">'val'</span>:<br>        np.random.seed(seed=<span class="hljs-number">0</span>)<br>    n2 = np.random.randn(*img.shape)*sigma_c<br>    noise = (n1 + n2).astype(np.float32)<br>    <span class="hljs-keyword">return</span> img + noise <br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_add_noise_poisson_gaussian_blind</span>(<span class="hljs-params">self, img</span>):</span><br>    <span class="hljs-keyword">if</span> self.split == <span class="hljs-string">'val'</span>:<br>        np.random.seed(seed=<span class="hljs-number">0</span>)<br>    sigma_s = [v/<span class="hljs-number">255.</span> <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> self.get_noiseL_p()]<br>    sigma_c = [v/<span class="hljs-number">255.</span> <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> self.get_noiseL_g()]<br>    noiseL = np.sqrt((sigma_s**<span class="hljs-number">2</span>)*img+(sigma_c**<span class="hljs-number">2</span>))<br>    noise = (np.random.randn(*img.shape)*noiseL).astype(np.float32)<br>    <span class="hljs-keyword">return</span> img + noise <br></code></pre></td></tr></tbody></table></figure><h4 id="multivariate-Gaussian">multivariate Gaussian</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_add_noise_multivariate_gaussian</span>(<span class="hljs-params">self, img</span>):</span><br>    _,H,W=img.shape<br>    L=<span class="hljs-number">75</span>/<span class="hljs-number">255</span><br>    <span class="hljs-keyword">if</span> self.split == <span class="hljs-string">'val'</span>:<br>        np.random.seed(seed=<span class="hljs-number">0</span>)<br>        D=np.diag(np.random.rand(<span class="hljs-number">3</span>))<br>        np.random.seed(<span class="hljs-number">0</span>)<br>        U=orth(np.random.rand(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>))<br>    <span class="hljs-keyword">else</span>:<br>        D=np.diag(np.random.rand(<span class="hljs-number">3</span>))<br>        U=orth(np.random.rand(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>))<br>    tmp = np.matmul(D, U)<br>    tmp = np.matmul(U.T,np.matmul(D, U))<br>    tmp = (L**<span class="hljs-number">2</span>)*tmp<br>    noiseSigma=np.<span class="hljs-built_in">abs</span>(tmp)<br>    <span class="hljs-keyword">if</span> self.split == <span class="hljs-string">'val'</span>:<br>        np.random.seed(<span class="hljs-number">0</span>)<br>    noise = np.random.multivariate_normal([<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>], noiseSigma, (H,W)).astype(np.float32)<br>    noise = noise.transpose(<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> img + noise    <br></code></pre></td></tr></tbody></table></figure><h2 id="3，Stochastic-Frequency-Masking-to-Improve-Super-Resolution-and-Denoising-Networks">3，Stochastic Frequency Masking to Improve Super-Resolution and Denoising Networks</h2><h3 id="噪声类型">噪声类型</h3><p>论文中的提到的两种噪声**AWGN(强度 10 20 30 40 50 60 70 80 90 100 )Poisson-Gaussian **</p><h3 id="训练代码中加噪">训练代码中加噪</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># ADD Noise</span><br>img_train = data<br>            <br>noise = torch.zeros(img_train.size())<br>noise_level_train = torch.zeros(img_train.size())<br>stdN = np.random.uniform(noiseL_B[<span class="hljs-number">0</span>], noiseL_B[<span class="hljs-number">1</span>], size=noise.size()[<span class="hljs-number">0</span>])<br>sizeN = noise[<span class="hljs-number">0</span>,:,:,:].size()<br>            <br><span class="hljs-comment"># Noise Level map preparation (each step)</span><br><span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(noise.size()[<span class="hljs-number">0</span>]):<br>    noise[n,:,:,:] = torch.FloatTensor(sizeN).normal_(mean=<span class="hljs-number">0</span>, std=stdN[n]/<span class="hljs-number">255.</span>)<br>    noise_level_value = stdN[n] / noiseL_B[<span class="hljs-number">1</span>]<br>    noise_level_train[n,:,:,:] = torch.FloatTensor( np.ones(sizeN) )<br>    noise_level_train[n,:,:,:] = noise_level_train[n,:,:,:] * noise_level_value<br>noise_level_train = Variable(noise_level_train.cuda())<br><br><span class="hljs-comment"># Modifying the frequency content of the added noise (Low or High only)</span><br><span class="hljs-keyword">if</span> opt.mask_train_noise <span class="hljs-keyword">in</span>([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]):<br>    noise_mask = get_mask_low_high(w=sizeN[<span class="hljs-number">1</span>], h=sizeN[<span class="hljs-number">2</span>], radius_perc=<span class="hljs-number">0.5</span>, mask_mode=opt.mask_train_noise)<br>    <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(noise.size()[<span class="hljs-number">0</span>]):<br>        noise_dct = dct(dct(noise[n,<span class="hljs-number">0</span>,:,:].data.numpy(), axis=<span class="hljs-number">0</span>, norm=<span class="hljs-string">'ortho'</span>), axis=<span class="hljs-number">1</span>, norm=<span class="hljs-string">'ortho'</span>)<br>        noise_dct = noise_dct * noise_mask<br>        noise_numpy = idct(idct(noise_dct, axis=<span class="hljs-number">0</span>, norm=<span class="hljs-string">'ortho'</span>), axis=<span class="hljs-number">1</span>, norm=<span class="hljs-string">'ortho'</span>)<br>        noise[n,<span class="hljs-number">0</span>,:,:] = torch.from_numpy(noise_numpy)<br><span class="hljs-keyword">elif</span> opt.mask_train_noise == <span class="hljs-number">3</span>: <span class="hljs-comment">#Brownian noise</span><br>    <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(noise.size()[<span class="hljs-number">0</span>]):<br>        noise_numpy = gaussian_filter(noise[n,<span class="hljs-number">0</span>,:,:].data.numpy(), sigma=<span class="hljs-number">3</span>)<br>        noise[n,<span class="hljs-number">0</span>,:,:] = torch.from_numpy(noise_numpy)<br></code></pre></td></tr></tbody></table></figure><h3 id="test代码中加噪">test代码中加噪</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_varying_noise</span>(<span class="hljs-params">image_size, noise_std_min, noise_std_max</span>):</span><br>    <span class="hljs-string">''' outputs a noise image of size image_size, with varying noise levels, ranging from noise_std_min to noise_std_max</span><br><span class="hljs-string">    the noise level increases linearly with the number of rows in the image '''</span><br>    noise = torch.FloatTensor(image_size).normal_(mean=<span class="hljs-number">0</span>, std=<span class="hljs-number">0</span>).cuda()<br><br>    row_size = torch.Size([image_size[<span class="hljs-number">0</span>], image_size[<span class="hljs-number">1</span>], image_size[<span class="hljs-number">2</span>]])<br>    <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(image_size[<span class="hljs-number">3</span>]):<br>        std_value = noise_std_min + (noise_std_max-noise_std_min) * (row/(image_size[<span class="hljs-number">3</span>]*<span class="hljs-number">1.0</span>-<span class="hljs-number">1</span>))<br>        noise[:,:,:,row] = torch.FloatTensor(row_size).normal_(mean=<span class="hljs-number">0</span>, std=std_value/<span class="hljs-number">255.</span>).cuda()<br><br>    <span class="hljs-keyword">return</span> noise<br>后续图片加上噪声<br></code></pre></td></tr></tbody></table></figure><h2 id="4，Spatial-Adaptive-Network-for-Single-Image-Denoising">4，Spatial-Adaptive Network for Single Image Denoising</h2><h3 id="合成噪声">合成噪声</h3><p>测试数据集：BSD68，KODAK24</p><p><strong>噪声：在间隙中加入不同噪声水平的AWGN 噪声强度取值30 50 70</strong></p><p>方法：</p><p>​传统：BM3D和CBM3D</p><p>​cnn：DnCNN[35]、MemNet[27]、FFDNet[36]、RNaN[37]和RIDNet[4]， SADNet（论文提出的方法）</p><h3 id="真实噪声">真实噪声</h3><p>测试数据集：DND[25]、SIDD[1]和NAM[22]</p>]]></content>
    
    
    <categories>
      
      <category>文献</category>
      
      <category>去噪</category>
      
    </categories>
    
    
    <tags>
      
      <tag>文献</tag>
      
      <tag>去噪</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>精读Adaptive Consistency Prior based Deep Network for Image Denoising</title>
    <link href="/2022/02/14/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E9%98%85%E8%AF%BB%E6%96%B9%E6%B3%95/paperer-DeamNet/"/>
    <url>/2022/02/14/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E9%98%85%E8%AF%BB%E6%96%B9%E6%B3%95/paperer-DeamNet/</url>
    
    <content type="html"><![CDATA[<blockquote><p>这是一篇2021年发表在cvpr期刊上的文章，老师说可以多关注他的加噪方式和文章的实验对比方法，正好以此为例，来精读此文章以作讲解。</p><p>灰常nice！ 阅读pdf文章的网站https://readpaper.com/</p></blockquote><h3 id="第一遍">第一遍</h3><p><strong>重点：标题-&gt; 摘要 -&gt; 结论的顺序； 目的是大概了解文章，做出取舍；</strong></p><p><strong>tips：可以大概看看图表，了解关键的方法。</strong></p><h4 id="预览">预览</h4><ol><li><p>标题：Adaptive Consistency Prior based Deep Network for Image Denoising</p><p>​基于自适应一致性先验的深度网络图像去噪</p></li><li><p>摘要：</p><p><strong>总结</strong> :作者提出了ACP+Deam 可以在合成噪声和真实噪声的图片降噪上取得好的结果。</p><p><strong>问题现状</strong>：如何将传统方法融入到网络设计中同时提高可解释性，仍然是一个悬而未决的问题。</p><p><strong>方法</strong> :提出了一种新的基于模型的去噪方法来指导去噪网络的设计，首先，通过在传统的一致性先验中引入非线性滤波算子、可靠性矩阵和高维特征变换函数，提出了一种新的自适应一致性先验(ACP)。其次，通过将ACP项引入最大后验框架，提出了一种基于模型的去噪方法，并将该方法用于指导网络设计，得到了一种新的端到端可训练、可解释的深度去噪网络。</p></li><li><p>结论：</p><p><strong>总结</strong> :提出了Deamnet深度网络来图像去噪。</p><p><strong>创新点</strong> :与现有的大多数深度网络去噪方法不同，我们将新的ACP项（传统方法）引入到优化问题中，然后利用unfolding策略利用优化过程来指导深度网络的设计。</p><p><strong>成果</strong> :在一定程度上提高了可解释性。实验结果表明，该网络具有领先的去噪性能。</p></li><li><p>其他</p><p>查看他的图表可以发现他的工作非常的详细，对各种网络，各种数据集进行了各种效果的对比，从图像，数据集，噪声强度，PSNR，SSIM，运行时间，参数大小各个方面进行对比，值得学习。</p></li></ol><h4 id="思路">思路</h4><p>文章的思路：<strong>将传统的降噪方法和深度学习网络结合</strong></p><ul><li>在传统的一致性先验中引入非线性滤波算子、可靠性矩阵和高维特征变换函数，提出了一种新的自适应一致性先验(ACP)</li><li>通过将ACP项引入最大后验框架，提出了一种基于模型的去噪方法，并将该方法用于指导网络设计，得到去噪网络。</li></ul><h4 id="思考">思考</h4><p>关注点：思考噪声是怎么加的，用了哪几种噪声？</p><h3 id="第二遍">第二遍</h3><p><strong>重点：从头到尾读，不用关注得太细节，主要目的是清晰了解图表含义。</strong></p><p><strong>tips：圈出感兴趣的文献。</strong></p><h4 id="Introduce">Introduce</h4><p>如果对这个领域不是非常了解，就可以好好看看Introduce中的内容，一般会对该领域研究问题进行总结和梳理。可以标记出感兴趣的文献。</p><p>在Introduce中提出的几种去噪方法，对这三种方法的含义和相关算法简要介绍：</p><ul><li><p>filtering-based methods</p><ul><li><p>原理：由于图像中有很多相似物，可以使用非局部相似块来去除噪声，比如NLM和BM3D，各种非局部滤波方法应运而生。</p></li><li><p>问题：输出模糊，去噪方法中的超参数难以调整。</p></li></ul></li><li><p>model-based methods</p><ul><li><p>原理：基于模型的方法通常将去噪任务描述为基于后验I(MAP)的最大优化问题，其性能主要取决于图像先验。</p></li><li><p>前提：在假设图像块可以用适当的基函数稀疏表示的前提下。</p></li><li><p>方法：提出稀疏先验，最近，提出了一种基于三边加权稀疏编码的真实图像去噪方法。根据自然图像中非局部相似块构成的矩阵具有低秩的特点，提出了很多基于低秩先验的图像去噪方法，还有IR的加权核范数最小化(WNNM)方法。此外还有图的正则化方法。</p></li><li><p>好处：基于模型的方法具有很强的数学推导能力。</p></li><li><p>问题：1，在恢复强噪声下的纹理结构时，性能会明显下降。2，由于迭代优化的高度复杂性，它们通常很耗时。</p></li></ul></li><li><p>learning-based methods</p><ul><li>定义：基于学习的方法侧重于从噪声图像到干净图像的潜在映射学习，可分为传统的基于学习的方法和基于深度网络的方法。</li><li>评价：由于基于深度网络的去噪方法比基于滤波、基于模型和基于传统学习的方法取得了更好的去噪效果，它们已成为<strong>主流</strong>的去噪方法。</li><li>问题：大多数深度网络方法的体系结构都是经验性设计的，没有充分考虑传统算法的成果，在一定程度上面临着可解释性较弱的问题。</li></ul></li><li><p>最近，也有人提出了用深度网络展开来实现一些传统的方法。</p></li></ul><p>作者主要工作是提出一种新的基于模型的去噪方法，并深入研究该方法的推理过程，为其去噪CNN(DeamNet)的设计提供参考。</p><blockquote><p>这里我对作者提出的方法有一些疑问，基于模型和基于学习的去噪方法的本质区别在哪里，作者的工作”去噪的CNN设计提供参考“涉及到卷积神经网络，为什么还是基于模型的去噪方法呢？</p><p>在 Proposed Method部分作者阐述了自己的设计思想，这一部分涉及的公式很多，其实对作者所提出的方法和我自身的研究内容不是非常的契合，所以这部分可以简要看看，我主要的目的还是对它的实验中噪声和数据部分更加感兴趣。</p></blockquote><h4 id="设计思想">设计思想</h4><ul><li><p>Adaptive Consistency Prior for Denoising</p><ul><li>自适应一致性先验算法在去噪中的应用,本文提出了一种端到端的可训练展开网络，该网络能够自适应地学习这些算子。</li></ul></li><li><p>Deep Unfolding Denoising Network</p><ul><li>DeamNet的体系结构。它由特征域(FD)模块、重构模块、基于非线性运算(NLO)子网络的K个迭代阶段和双元素注意机制(DEAM)模块组成.</li><li>在高维FD中进行去噪具有以下优点：1)可以将原始的噪声空间潜在地变换到FD空间，在FD空间中可以更容易地降低噪声，从而获得比像素域更精细的图像细节。“补充材料”中的实验详细说明了这一点；2）使用高维FD模块还可以增加特征通道数并且增强神经网络中的信息流传输来得到更高的性能。相比之下，传统的深度展开网络在低维图像空间进行迭代去噪；3)通过将地面真实图像与退化图像之间的残差视为待降噪的部分，该策略还可以使网络更适用于其他红外应用。</li><li>在传统的注意机制中，低频分支的重要性在很大程度上被忽视了。相反，如果低频分支对潜在特征的描述不理想，则DEAM可以自适应地增加残留分支的特征权重，反之亦然。此外，DEAM中的初始特征信息可用性和跨层特征交互可以进一步增强网络的表达能力。</li></ul></li></ul><h4 id="实验部分">实验部分</h4><p>分为对合成噪声数据集和真实数据集上去噪两个模块。</p><p><strong>噪声类型</strong>： 加性高斯白噪声AWGN(Additive White Gaussian Noise)  （在论文中提到的强度对比 15, 25 and 50.）</p><ul><li>训练部分</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">parser.add_argument(<span class="hljs-string">"--noiseL"</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">25</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'noise level'</span>)<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span>(<span class="hljs-params">epoch</span>):</span><br>    epoch_loss = <span class="hljs-number">0</span><br>    model.train()<br>    <span class="hljs-keyword">for</span> iteration, batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(training_data_loader, <span class="hljs-number">1</span>):<br>        target = Variable(batch)<br>        noise = torch.FloatTensor(target.size()).normal_(mean=<span class="hljs-number">0</span>, std=opt.val_noiseL / <span class="hljs-number">255.</span>)<br>        <span class="hljs-built_in">input</span> = target + noise<br>        .....<br></code></pre></td></tr></tbody></table></figure><ul><li>测试部分（合成）</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">parser.add_argument(<span class="hljs-string">"--test_noiseL"</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">15</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'noise level used on test set'</span>) <span class="hljs-comment">#噪声强度</span><br>opt = parser.parse_args()<br><br>ISource = torch.Tensor(Img)    <br><span class="hljs-comment"># noise</span><br>noise = torch.FloatTensor(ISource.size()).normal_(mean=<span class="hljs-number">0</span>, std=opt.test_noiseL / <span class="hljs-number">255.</span>) <span class="hljs-comment">#高斯噪声</span><br><span class="hljs-comment"># noisy image</span><br>INoisy = ISource + noise <span class="hljs-comment">#加性</span><br>ISource, INoisy = Variable(ISource.cuda()), Variable(INoisy.cuda())<br></code></pre></td></tr></tbody></table></figure><p>真实数据集</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span>(<span class="hljs-params">self, index</span>):</span><br>    clean = Image.<span class="hljs-built_in">open</span>(self.path[index])<br><br>    <span class="hljs-keyword">if</span> self.transform:<br>        clean = self.transform(clean)<br><br>    noise = torch.randn(clean.size()).mul_(self.sigma/<span class="hljs-number">255.0</span>) <span class="hljs-comment">#噪声？</span><br>    noisy = clean + noise<br>    noisy = torch.clamp(noisy, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>)<br>    <span class="hljs-keyword">return</span> noisy, clean<br></code></pre></td></tr></tbody></table></figure><blockquote><p>这里加噪代码存疑</p><p>论文中对真实数据集的去噪细节中写道：</p><p>由于真实噪声通常是信号相关的，并且随着摄像机内管线的不同，真实图像去噪通常是一项极具挑战性的任务，为了进一步展示DeamNet对真实噪声的泛化能力，选择DND基准、SIDD基准和RNI15数据集作为测试数据集。请注意，对于DND和SIDD基准，几乎无噪音的图像不是公开的，但PSNR/SSIM结果可以通过他们的在线服务器获得。而对于RNI15，只有噪声图像可用。</p></blockquote><h4 id="合成噪声数据集（重点关注）">合成噪声数据集（重点关注）</h4><p><strong>训练数据集</strong>包括：</p><ol><li><p>the Berke-ley Segmentation Dataset (BSD)  是为图像分割和边界检测的研究提供经验基础的数据集，包含来自 30 个人类受试者的 1000 个手工标记的 1000 个 Corel 数据集图像的分割，其中一半的分割是通过向主体呈现彩色图像而获得的; 另一半来自呈现灰度图像。</p></li><li><p>Div2K：数据集有1000张高清图(2K分辨率)，其中800张作为训练，100张作为验证，100 张作为测试。</p></li></ol><p>三个标准<strong>基线数据集</strong>进行了评估 （指标：PSNR and SSIM）</p><ol><li><p>Set12：数字图像处理常用数据集Set12，12张灰度图（含lena，cameraman，house，pepper，fishstar，monarch，airplane，parrot，barbara，ship，man，couple），01-07是256*256,08-12是512*512.</p></li><li><p>BSD68  数字图像处理常用数据集BSD68，68张灰度图，大小不一。</p></li><li><p>Urban100  ：一个用于超分辨率和图像重建的数据集 Urban100，总计100张建筑高清图片，同时对应了100张降低分辨率的图片。</p></li></ol><h4 id="真实噪声数据集">真实噪声数据集</h4><h5 id="训练数据集">训练数据集</h5><ol><li>SIDD：智能手机图像去噪数据集（SIDD）使用5个具有代表性的智能手机摄像头，从10个场景中提取约30000个噪声图像，并生成它们真实的场景图像。</li><li>RENOIR：一个真实的图像降噪数据集，包含了3个子数据集，分别是Xiaomi Mi3，Canon S90，Canon T3i拍摄，拥有低噪和高噪对比图。</li></ol><h5 id="测试数据集">测试数据集</h5><ul><li><p>DND：是由50幅真实世界的噪声图像组成的，但没有几乎没有噪声的对应图像。通常，可以通过将去噪图像上传到DND网站来获得PSNR/SSIM结果。</p></li><li><p>SIDD：提供320对噪声图像和近无噪声图像用于训练，1280个图像patch用于验证。PSNR/SSIM结果可以通过将去噪图像提交到SIDD网站获得。</p></li><li><p>RNI15：提供了15幅真实噪声图像。不幸的是，地面真实的干净图像不可用，因此我们只展示RNI15的视觉结果。</p></li></ul><h4 id="数据增强">数据增强</h4><p>我们将这些训练图像对随机裁剪成大小为128×128的小块。为了增加训练样本，采用了180度的旋转和水平翻转。</p><h4 id="对比网络">对比网络</h4><ul><li><p>TNRD</p></li><li><p>DnCNN</p></li><li><p>FFDNet</p></li><li><p>RED</p></li><li><p>MemNet</p></li><li><p>UNLNet</p></li><li><p>CFSNet</p></li><li><p>N3Net</p></li><li><p>ADNet</p></li><li><p>BRDNet</p></li><li><p>RIDNet</p></li></ul><h5 id="合成数据集效果">合成数据集效果</h5><p><img src="https://picture.mulindya.com/deamnet1.png" alt=""></p><h5 id="真实数据集效果">真实数据集效果</h5><p><img src="https://picture.mulindya.com/deamnet2.png" alt=""></p><h3 id="第三遍">第三遍</h3><p><strong>重点：详细了解文章，并且拓展到自己，给自己设置问题，学会“脑补”</strong>。</p><p><strong>tips: 在文章最后作者会提到文章有一些没有继续研究的地方，可以记录自己的思考。</strong></p>]]></content>
    
    
    <categories>
      
      <category>文献</category>
      
      <category>阅读方法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>文献</tag>
      
      <tag>阅读方法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>光子计数CT重建算法</title>
    <link href="/2022/02/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/CT/%E5%85%89%E5%AD%90%E8%AE%A1%E6%95%B0CT%E9%87%8D%E5%BB%BA%E7%AE%97%E6%B3%95/"/>
    <url>/2022/02/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/CT/%E5%85%89%E5%AD%90%E8%AE%A1%E6%95%B0CT%E9%87%8D%E5%BB%BA%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<blockquote><p>查找相关论文，整理其思想。</p></blockquote><h1>光子计数CT重建算法</h1><h2 id="一，光子计数CT与传统CT的区别">一，光子计数CT与传统CT的区别</h2><p><strong>传统X线CT</strong>系统利用电荷积分探测器进行信号检测，<strong>光子权重与其能量成正比，较高能量的光子被赋予较大的权重</strong>。然而，重建图像的对比度主要取决于较低能量的光子，因此<strong>电荷积分探测方式将导致重建图像对比度下降</strong>。</p><p>近期研发的<strong>光子计数探测器</strong>具有能量分辨能力，它由半导体探测器及快速专用集成电路组成，在医学诊断X线能量范围内具有较高的量子效率，<strong>可灵活设置能量阈值，并可消除低能电子学噪声的干扰，通过对被检物体的一次扫描可以同时获得多个能量段的光子计数</strong>。</p><p><strong>传统CT</strong> 采用积分式探测器采集投影数据 ，反映的是<strong>物体的平均衰减特性</strong> ，会在一定程度上造成信息损失 ，无法对物体进行较好的定性定量测量。</p><p><strong>基于光子计数探测器的能谱CT</strong> 通过设定多个能量响应阈值能够探测不同能量范围内的X射线光子 ，采集更多被测物体的物质组成信息 ，有助于识别不同物理特性的材料 ，基于此 ，<strong>能谱CT 被广泛的应用于小病灶、低对比度结构以及微细结构的成像。</strong></p><p>PCD技术消除了电子噪声，提供了比传统CT探测器<strong>更高的信噪比</strong>。</p><p>然而，PCD技术仍然存在两个主要的问题，首先，<strong>单个能量通道只包含总光子的一小部分</strong>；其次，<strong>大部分PCD 只能承受有限的计数率，<strong>所以从PCD 获得的多通道投影通常包含</strong>非常强的泊松噪声</strong>。</p><h2 id="二，文献查找来源">二，文献查找来源</h2><ul><li><p><a href="https://www.cttacn.org.cn/">CT理论与应用研究</a></p></li><li><p><a href="http://www.diagnoschina.com/newest/zazhi_id-2">中国CT和MRI杂志</a></p></li><li><p><a href="http://lcfsx.chinabidingnews.cn/">临床放射学杂志</a></p></li><li><p><a href="http://ywlc.chinajournal.net.cn/WKB3/WebPublication/wkTextContent.aspx?colType=4&amp;tp=gklb">中国药物与临床</a></p></li><li><p>东南大学学报</p></li><li><p>光谱学与光谱分析</p></li><li><p>光电工程</p></li><li><p>中国医学物理学杂志</p></li></ul><h2 id="三，针对光子计数CT重建算法">三，针对光子计数CT重建算法</h2><p><img src="https://picture.mulindya.com/CT_paper6.png" alt=""></p><h3 id="3-1-投影加权重建">3.1 投影加权重建</h3><p>从投影正弦图中提取噪声信息，构造关于权重的对比噪声比（CNR）优化函数，求解最优权重，利用权重进行投影加权图像重建。</p><ul><li>基于<strong>投影加权</strong>的多能光子计数X线CT全能谱图像重建改进方法[1]</li></ul><p>针对包含不同对比材料的3种模体进行投影仿真–&gt;获得包含泊松和高斯噪声的投影正弦图–&gt;从投影正弦图中提取噪声信息–&gt;构造关于权重的<strong>对比噪声比</strong>优化函数–&gt;求解使对比噪声比最优的权重–&gt;利用该权重进行投影加权图像重建</p><p>噪声来源：与 Ｘ线相关的噪声，包括Ｘ线光子数随机变化引起的噪声、Ｘ 线进行光电转换时产生的噪声等，这些噪声服从泊松随机分布，称为泊松噪声；此外，还存在与 Ｘ 线无关的噪声，如成像系统中探测器单元的电子噪声、探测器读出电路的读出噪声等，这部分噪声的幅度服从高斯概率密度分布，称为高斯噪声。</p><h3 id="3-2-图像加权重建">3.2 图像加权重建</h3><p>利用某一种重建算法将各能量段投影数据转换为图像，对图像进行加权求和。</p><ul><li>基于<strong>图像加权</strong>的多能光子计数X线CT全能谱图像重建改进方法[2]</li></ul><p>对每个能量段的投影数据采用<strong>最大后验概率（MAP）统计重建算法</strong>进行图像重建–&gt;对各能量段图像进行优化加权求和，获得全能谱图像。</p><p>MAP统计重建算法可显著提高全能谱重建图像的对比噪声比（CNR）。</p><p>根据每个能量段图像中对比材料和背景材料衰减系数差异构造权重，然后将权重赋予每个能量段图像进行加权求和，得到全能谱重建图像，这种方法被称为<strong>图像加权成像法</strong>。</p><ul><li>多能光子计数X-CT能量加权图像重建方法[3]</li></ul><p>对各能量段投影进行<strong>FBP</strong>重建，并将各FBP重建图像加权求和获得最终的重建图像。</p><h3 id="3-3-正则化约束项的迭代类重建">3.3 正则化约束项的迭代类重建</h3><ul><li>多通道联合的广义总变分能谱CT重建[4]</li></ul><p>压缩感知理论的出现，使<strong>正则化约束项的迭代类重建算法</strong>发挥出巨大的潜力。能谱 CT 重建中，正则化约束项以<strong>先验图像引导和稀疏性条件</strong>为主。先验图像引导以 Yu 采用全光谱图像作为先验图像的压缩感知(prior image constrained compressed sensing，PICCS)算法为代表，稀疏性条件包括全变分、紧框架、小波和字典学习等已被应用于 CT 重建，并取得了不同程度的成功。受空间域信息相关性的启发，Zhang等将总变分与能谱均值相结合，提高重建图像的质量。Li 等提出一种能谱非局部均值的方法，利用图像相关性来抑制噪声和条纹伪影。Hu 等利用张量字典块的稀疏性表示来提高重建质量。陈佩君等提出一种总变分与传统张量字典学习结合的重建算法，可进一步恢复图像的微小结构，有效抑制噪声。为了更好地利用能谱 CT 在能量轴方向的信息相关性，Rigie等将总变分向矢量延伸，提出了总核变分(total nuclear variation，TNV)正则化方法，可以更好地保存图像特征。Niu 等提出了一种alpha 发散约束的广义总变分(total generalized variation，TGV)方法用于稀疏视角X 射线CT 图像重建，有效地消除总变分正则化中经常出现的阶梯状和斑片状伪影。</p><p>在重建过程中，通道数的增加会造成单通道中光子数减少，从而导致重建图像质量下降，难以满足实际需求。</p><p>本文从能谱 CT 重建的角度出发，将广义总变分向矢量延伸，利用奇异值的稀疏性，促进图像梯度的线性依赖，提出一种**基于核范数的多通道联合TGV（广义总变分）**的能谱 CT 重建算法。</p><ul><li>光子探测器CT低流速低剂量CTPA图像质量的客观评估[5]</li></ul><h3 id="3-4-基于深度学习的重建">3.4 基于深度学习的重建</h3><p>神经网络直接提取图像中噪声的特征信息，通过与标准图像作对比抑制训练图像中的噪声。</p><ul><li>基于全卷积金字塔残差网络的能谱 CT 图像降噪研究[6]</li></ul><p>将全卷积网络和金字塔残差网络结合为全卷积金字塔残差网络（FCPRN）</p><p>利用能谱CT 在不同的能量范围扫描小鼠样本 ，使用 FDK 算法和基于压缩感知的Split-Bregman算法进行重建并分别作为训练数据和标签数据训练全卷积金字塔残差网络。</p><p>与DNCN、REDCNN进行对比。</p><p>模型对FDK算法重建出的图像进行降噪，由此提高能谱CT图像降噪效率，保证能谱CT重建图像的质量。</p><p>在能谱CT 图像降噪研究方面 ，现多采用迭代重建算法对投影数据进行重建以抑制噪声。例如 Clark等结合图像的稀疏特性和能谱CT 图像相关性以构建重建目标函数 ，提高了能谱CT 图像重建效果。 Rigie和 Riviere等提出了一种基于矢量全变分（TV）的能谱CT 重建算法。上述图像重建降噪算法可以较好的抑制能谱CT 重建图像中的噪声 ，但算法复杂度较高、计算时间较长。</p><p>近年来 ，深度学习在 CT 图像降噪领域中得到了广泛应用。神经网络可以直接提取图像中噪声的特征信息 ，进而通过与标准图像作对比抑制训练图像中的噪声。例如 Chen等研究一种 CT 图像去噪的浅层卷积神经网络模型 ，基于该网络提出了残差编码器-解码器卷积神经网络 ，并使用反卷积网络和快捷连接以增强网络降噪性能。</p><h2 id="四，光子计数CT重建与传统CT重建的区别">四，光子计数CT重建与传统CT重建的区别</h2><h3 id="4-1-投影">4.1 投影</h3><ul><li><p>传统CT：通过对投影数据进行预处理，包括自适应滤波、均方的滤波 ，基于图像 K-L 变换的加权最小均方和噪声分离滤波等。近来的研究重点在于学习型稀疏表示方法。</p></li><li><p>光子计数CT：从投影正弦图中提取噪声信息，构造关于权重的对比噪声比（CNR）优化函数，求解最优权重，利用权重进行投影加权图像重建。</p></li></ul><h3 id="4-2-图像">4.2 图像</h3><ul><li><p>传统CT：</p><ul><li>传统：基于非局部均值（NLM）。从高质量CT图像中提取有效的特征信息，为低质量的CT图像处理提供先验指导。</li><li>基于深度学习：网络框架改进（CNN、GAN、RNN），功能模块设计（注意力模块），训练策略改进（有监督、无监督）</li></ul></li><li><p>光子计数CT：</p><ul><li>利用某一种重建算法将各能量段投影数据转换为图像，对图像进行加权求和。</li><li>神经网络直接提取图像中噪声的特征信息，通过与标准图像作对比抑制训练图像中的噪声。类似于传统CT中基于深度学习的方法。</li></ul></li></ul><h3 id="4-3-迭代重建">4.3 迭代重建</h3><ul><li><p>传统CT：</p><ul><li><p>传统：</p><ul><li><p>解析重建：FBP、FDK</p></li><li><p>迭代重建：</p><ul><li><p>代数迭代</p></li><li><p>统计迭代（SIR，重建效果最好）</p><p>与稀疏学习表示约束结合，最常用的是TV（总变分）约束迭代重建和基于特征字典学习进行稀疏表示。</p></li></ul></li></ul></li><li><p>基于深度学习：学习FBP、学习正则项、学习迭代求解</p></li></ul></li><li><p>光子计数CT:</p><ul><li>正则化约束项的迭代重建<ul><li>先验图像引导</li><li>稀疏性条件：总变分、紧框架、小波、字典学习</li></ul></li></ul></li></ul><h2 id="五，光子计数CT临床应用">五，光子计数CT临床应用</h2><h3 id="5-1-能谱纯化结合迭代重建算法">5.1  能谱纯化结合迭代重建算法</h3><p>2022 年 2 月武汉市肺科医院放射科发表的一篇文章[7]</p><ul><li><p>目的：探讨基于能谱纯化结合迭代重建算法在继发性肺结核患者低剂量CT检查中的应用。</p></li><li><p>方法：选取2019年4月至6月武汉市肺科医院确诊的70例继发性肺结核患者作为研究对象。初检采用常规剂量组：管电压110 kV，参考管电流52 mAs，滤波反投影（FBP）重建图像；复检采用低剂量组（能谱纯化）：管电压Sn 110 kV，参考管电流73 mAs，正弦图迭代重建（SAFIRE）。比较两组图像主观评分、升主动脉CT值、图像噪声、SNR及辐射剂量差异。</p></li><li><p>结果：两组图像主观评分相比无差异，满足临床诊断要求。两组升主动脉CT值无差异；低剂量组图像SNR低于常规剂量组。低剂量组ED（0.36±0.15）mSv与常规剂量组（2.35±0.73）mSv相比降低约84.7％。</p></li><li><p><strong>结论：能谱纯化结合迭代重建算法在继发性肺结核患者检查中能够显著降低患者所受辐射剂量，同时图像质量也能满足临床诊断要求。</strong></p></li></ul><h3 id="5-2-光子探测器CT低流速低剂量CTPA图像质量的客观评估">5.2 光子探测器CT低流速低剂量CTPA图像质量的客观评估</h3><p>2021年中国医学科学院北京协和医学院北京协和医院放射科[5]</p><ul><li>目的：客观评估应用光子探测器CT行低流速低剂量对比剂CT肺动脉造影(CTPA)不同单能谱下的图像质量，探究CTPA的最佳单能谱图像。</li><li>方法：纳入行CTPA检查的患者47例， 所有患者均用光子探测器CT进行CTPA扫描，扫描范围自胸廓入口至膈肌水平，以10 keV间距重建9个单能谱图像，分别为40、50、60、70、80、90、100、110、120 keV的图像。在肺动脉主干(PA)、右肺动脉主干(RP)、左肺动脉主干(LP)、右肺上叶动脉(URP)、右肺下叶动脉(LRP)、左肺上叶动脉(ULP)、左肺下叶动脉(LLP)勾画20 mm2感兴趣区，记录各个感兴趣区及右主气管、背阔肌组织的CT值和标准差，计算不同能谱等级下图像的信噪比(SNR)、对比噪声比(CNR)。采用Wilcoxon秩和检验对比不同单能谱等级的CT值、SNR和CNR。</li><li>结果：单能谱40 keV时肺动脉主干CT值594. 17 HU(434.16～829.52) HU、SNR16.88(7.35 ～30.12)和CNR 15.63 (6.7 ～ 26.54)，均显著高于50 ～ 120 keV能级组，Z( PA、LA、RA)=5.968，P＜0.05差异具有统计学意义。单能谱40 keV时RP、LP、URP、LRP、ULP、LLP的CT值均显著高于50 ～ 120 keV组，Z(URP、LRP、ULP、LLP) =5.968，P＜0.05差异具有统计学意义。</li><li><strong>结论：应用光子探测器CT行低流速低剂量对比剂CTPA，可获得高对比度、高信噪比的图像，最佳单能谱等级为40 keV。应用光子探测器CT可弥补肺动脉强化不佳导致无法诊断的难题，能进一步减少对比剂不良事件的发生，值得临床推广应用。</strong></li></ul><h2 id="参考文献">参考文献</h2><p>[1] 周正东,管绍林,余子丽,等. 基于投影加权的多能光子计数X线CT全能谱图像重建改进方法[J]. 东南大学学报（自然科学版）,2016,46(6):1126-1131. DOI:10.3969/j.issn.1001-0505.2016.06.003.</p><p>[2] 周正东,管绍林,涂佳丽,等. 基于图像加权的多能光子计数X线CT全能谱图像重建改进方法[J]. 东南大学学报（自然科学版）,2017,47(5):892-896. DOI:10.3969/j.issn.1001-0505.2017.05.009.</p><p>[3] 余子丽,周正东,张雯雯,等. 多能光子计数X-CT能量加权图像重建方法[J]. 中国医学物理学杂志,2016,33(2):141-145. DOI:10.3969/j.issn.1005-202X.2016.02.007.</p><p>[4] 连祥媛,孔慧华,潘晋孝,等. 多通道联合的广义总变分能谱CT重建[J]. 光电工程,2021(9). DOI:10.12086/oee.2021.210211.</p><p>[5] 杜华阳,宋伟,隋昕,等. 光子探测器CT低流速低剂量CTPA图像质量的客观评估[J]. 临床放射学杂志,2021,40(3):470-475.</p><p>[6] 任学智,何鹏,龙邹荣,等. 基于全卷积金字塔残差网络的能谱CT图像降噪研究[J]. 光谱学与光谱分析,2021(9). DOI:10.3964/j.issn.1000-0593(2021)09-2950-06.</p><p>[7] 姜一, 田葵, 沙晋璐, 等. 基于能谱纯化结合迭代重建算法在继发性肺结核患者低剂量CT检查中的应用[J]. CT理论与应用研究, 2022, 31(1): 95-101. DOI: 10.15953/j.1004-4140.2022.31.01.11</p>]]></content>
    
    
    <categories>
      
      <category>文献</category>
      
      <category>CT</category>
      
    </categories>
    
    
    <tags>
      
      <tag>文献</tag>
      
      <tag>CT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>研究新意度和论文思路方法</title>
    <link href="/2022/02/11/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E9%98%85%E8%AF%BB%E6%96%B9%E6%B3%95/how-output-paper/"/>
    <url>/2022/02/11/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E9%98%85%E8%AF%BB%E6%96%B9%E6%B3%95/how-output-paper/</url>
    
    <content type="html"><![CDATA[<blockquote><p>参考李沐的相关视频</p><p><a href="https://www.bilibili.com/video/BV1ea41127Bq?spm_id_from=333.999.0.0">研究新意度的五大误解</a></p><p><a href="https://www.bilibili.com/video/BV1qq4y1z7F2?spm_id_from=333.999.0.0">如何找论文思路1–打补丁法</a></p></blockquote><h2 id="文章的新意度​-🔎">文章的新意度​ 🔎</h2><p>可能在发表文章的时候，经常会被吐槽文章的新意度不够。</p><p>$研究价值=新意度 \times 有效性 \times 问题大小$</p><p>有效性可以用实验结果的好坏衡量，问题大小可以在研究领域中有多少研究者，发表了多少篇论文来大致衡量。</p><p>查阅一位学术大佬Michael Black的一篇博客 科学中的新意度 （<a href="https://perceiving-systems.blog/en/news/novelty-in-science">Novelty in Science</a>）他的副标题是A guide for reviewers 给审稿人的指南。</p><p><img src="https://picture.mulindya.com/read_paper-1.png" alt=""></p><p>I see reviewers regularly mistake <strong>complexity</strong>, <strong>difficulty</strong>, and <strong>technicality</strong> for <strong>novelty</strong>. In science reviewing, novelty seems to imply these things. We might be better served by removing the word “novelty” from the review instructions and replacing it with <em><strong>beauty</strong></em>.</p><p>审稿人经常会把复杂度，困难度和技术度与新意度搞混，他建议在评审时把新意度拿掉，换成<em>优美</em>。</p><p>对于理论研究者而言，之前所说的判断价值的方法就失效了哦~，对理论研究的判断一般会使用两个词，深刻和优美，深刻就是说是否揭示了本质的东西，优美是指定理的本身和其相关的证明是否有美感，优美的好处是把技术性和复杂性剥除</p><p>来看看审稿人对于novelty的误区</p><h3 id="Novelty-as-complexity"><strong>Novelty as complexity</strong></h3><p>The simplicity of an idea is often confused with a lack of novelty when exactly the opposite is often true.  A common review critique is</p><p><em>The idea is very simple. It just changes one term in the loss and everything else is the same as prior work.</em></p><p><strong>If nobody thought to change that one term, then it is <em>ipso facto</em> novel.</strong> The inventive insight is to realize that a small change could have a big effect and to formulate the new loss.</p><p>Such reviews lead my students to say that we should make an idea appear more complex so that reviewers will find it of higher value.  <strong>I value simplicity over unnecessary complexity; the simpler the better.</strong> Taking an existing network and replacing one thing is better science than concocting a whole new network just to make it look more complex.</p><p>误区一：用复杂度衡量新意度；应该是大道至简！</p><h3 id="Novelty-as-difficulty"><strong>Novelty as difficulty</strong></h3><p>It’s hard to get a paper into a top conference, therefore reviewers often feel that the ideas and technical details must be difficult.  The authors have to shed blood, sweat, and tears to deserve a paper. Inexperienced reviewers, in particular, like to see that the authors have really worked hard.</p><p>Formulating a simple idea means stripping away the unnecessary to reveal the core of something. This is one of the most useful things that a scientist can do.</p><p><strong>A simple idea can be important. But it can also be trivial</strong>（显然的）. This is where reviewers struggle. A trivial idea is an unimportant idea. If a paper has a simple idea that works better than the state of the art, then it is most likely not trivial.  The authors are onto something and the field will be interested.</p><p>误区二：用困难度衡量新意度；简单有效证明最核心的东西。方法简单但非常有效</p><h3 id="Novelty-as-surprise"><strong>Novelty as surprise</strong></h3><p>Novelty and surprise are closely related. A novel idea is a surprising one by definition – it’s one that nobody in the field thought of.  But there is a flip side to this as surprise is a fleeting emotion. If you hear a good idea, there is a moment of surprise and then, the better it is, the more obvious it may seem. A common review:</p><p><em>The idea is obvious because the authors just combined two well known ideas.</em></p><p>Obvious is the opposite of novelty. So, if an idea is obvious <em>after</em> you’ve heard it, reviewers quickly assume it isn’t novel.  The novelty, however, must be evaluated <em>before</em> the idea existed. The inventive novelty was to have the idea in the first place.  If it is easy to explain and obvious in hindsight, this in no way diminishes the creativity (and novelty) of the idea.</p><p>误区三：用惊讶程度衡量新意度；A，B被提出，不能说A+B有效果就不够创新了。</p><h3 id="Novelty-as-technical-novelty"><strong>Novelty as technical novelty</strong></h3><p>The most common misconception of reviewers is that novelty pertains to technical details. Novelty (and value) come in many forms in papers. A new dataset can be novel if it does something no other dataset has done, even if all the methods used to generate the dataset are well known. A new use of an old method can be novel if nobody ever thought to use it this way. Replacing a complex algorithm with a simple one provides insight.</p><p>Novelty reveals itself in as many ways as beauty. Before critiquing a paper for a lack to technical novelty ask yourself if the true novelty lies elsewhere.</p><p>误区四：技术新意代表新意度；老方法用在新领域就是有创新;</p><h3 id="Novelty-as-usefulness-or-value"><strong>Novelty as usefulness or value</strong></h3><p>Not all novel ideas are useful. Just the property of being new does not connote value.  We want new ideas that lead us somewhere.  Here, reviewers need to be very careful.  It’s very hard to know where a new idea wi</p><p>ll take the field because any predictions that we make are based on the field as it is today.</p><p>A common review I get is</p><p><em>The authors describe a new method but I don’t know why anyone needs this.</em></p><p>Lack of utility is indeed an issue but it is very hard to assess with a new idea. Reviewers should be careful here and aware that we all have limited imagination.</p><p>误区五：用有效性或价值来衡量新意度；</p><h4 id="作者见解">作者见解</h4><p>新意度不等于  复杂度，困难度，惊讶度，技术新意，有效性</p><p>新意度 约等于 优美</p><p>要懂得欣赏</p><h2 id="如何寻找研究想法-💡">如何寻找研究想法 💡</h2><h3 id="打补丁法">打补丁法</h3><p>在读论文的时候，读的是一个完整的故事，在自己探索idea的时候，就需要把原文章的东西提炼，改进它的不足之处，再讲好一个故事，勇于尝试。可能会产生很多想法，关键在于验证，做实验去看哪一个效果最好，很多时候思考理论得出的直觉在做实验的时候发现并不是那么回事，但是通过观察实验结果，可以得到一些新的想法，然后再开始做实验，可以再实验中发现一些想法。很多时候，其实每个idea对自己最后都有一定的贡献，把这些东西糅合起来，也可以形成一篇文章。</p><p>好处是比较好上手，门槛不太高。</p><p>比如说何恺明21年11月份MAE这篇文章，就是糅合了两个东西，缺少一个效果都会大打折扣；这些补丁的作用就是让最后的效果有提升。</p><p>MAE</p><ul><li>基于VIT+BERT<ul><li>遮住更多的图片块<ul><li>编码时只处理没有遮住的</li></ul></li></ul></li><li>用Transfomer来输出（解码）</li></ul><p>但是也要注意不要在一个问题上打上太多补丁，如果杂乱的填充会显得idea不够优雅。最好在打补丁的时候，可以有一个故事将自己的想法串起来。也就是要有逻辑，讲好故事，不要有太强的违和感。</p><p>难点是：这种方法对写作是一个考验，有时可以把不太重要的补丁拿掉，在最后选择哪些论文打补丁也是很有讲究的，选择的论文要新，空间要大。如果一篇论文本身就是打了补丁，再去改进就很难有很好的成就，因为作者在进行自己的改进就可能试过很多方法了。最好是选一些脑洞比较打的论文，比如说VIT刚出来，马上就有很多人去跟进做实验，因为VIT的思想比较新，里面没有做过的想法很多，这种方法对硬件要求也比较高，对财力要求较高。</p><p>反过来来讲，也可以去做一些比较新的模型，进行一些改进使得训练更快，转换思路让训练更快更便宜，而不是执着于精度。</p>]]></content>
    
    
    <categories>
      
      <category>文献</category>
      
      <category>阅读方法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>文献</tag>
      
      <tag>阅读方法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何读论文</title>
    <link href="/2022/02/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E9%98%85%E8%AF%BB%E6%96%B9%E6%B3%95/read-paper/"/>
    <url>/2022/02/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E9%98%85%E8%AF%BB%E6%96%B9%E6%B3%95/read-paper/</url>
    
    <content type="html"><![CDATA[<blockquote><p>导师说希望我们可以发一篇质量很好的论文，以后不免会经常看文献，有的时候看论文抓不住重点，花费很久很久的时间可能都不能对这个问题有清晰的了解。或者最后发现这篇论文并不是我真正需要的；对于精读和略读的方法也会有所疑惑。来看看学术大佬沐神，他推荐是怎么去读论文叭~学习一下下嘿嘿。</p></blockquote><blockquote><p>参考吴恩达，李沐的相关视频</p><p>cs230 <a href="https://www.bilibili.com/video/BV195411Y7ms/?spm_id_from=333.788.recommend_more_video.11">如何读论文</a></p><p>沐神：</p><p><a href="https://www.bilibili.com/video/BV1H44y1t75x?spm_id_from=333.999.0.0">如何读论文</a></p><p><a href="https://www.bilibili.com/video/BV1oL411c7Us?spm_id_from=333.999.0.0">如何判断研究工作的价值</a></p></blockquote><h2 id="如何查找文献🔍">如何查找文献🔍</h2><p>谷歌学术，顶刊，arXiv，Medium posts，Github post</p><h2 id="读论文的步骤-📮">读论文的步骤 📮</h2><p>编制论文清单 （arXiv，Medium posts，Github post）</p><p>随机开始阅读</p><p>随机几篇论文开始，快速浏览并理解每篇论文的10%，然后挑选到值得阅读的文章花时间继续阅读并理解整篇文章，在此基础上，可能在参考文献中找到继续研究的论文继续阅读。阅读的同时，回顾充实前面的文章。再随机挑选论文，…,以此循环。</p><p>这样就可以慢慢掌握想要学习的研究主题。</p><p>5-20 papers      对该研究领域有基本的了解，可以做一些工作，应用一些算法。</p><p>50-100 papers  足以对该领域有很好的理解，足以进行研究或是处于前沿。</p><h2 id="论文的构成-📙">论文的构成 📙</h2><ul><li><strong>TITLE</strong>  标题</li><li><strong>ABSTRACT</strong> 摘要</li><li><strong>INDEX TERMS</strong> 关键词</li><li><strong>INTRODUCTION</strong> 导言</li><li><strong>MATERIALS AND METHODS</strong>  提出的算法</li><li><strong>EXPERIENCE</strong> 实验</li><li><strong>CONCLUSION</strong> 结论</li></ul><p>绝大多数的文章都是这种格式，相当于是一个八股文的结构。</p><h2 id="读文献的方法-✏️">读文献的方法 ✏️</h2><p>当然你是可以从头读到尾，但是这个世界上论文有这么多，如果都是从头读到尾的话，时间上是不值当的，并且你要找的文章可能就是一小部分，要快速的筛选出你自己需要的文章，然后对他进行精度。</p><p>这里给大家介绍一个方法，如何花三遍来读一遍论文！</p><p><strong>原则：从高效信息内容出发，然后再去延申。</strong></p><h3 id="第一遍">第一遍</h3><p><strong>重点：标题-&gt; 摘要 -&gt; 结论的顺序； 目的是大概了解文章，做出取舍；</strong></p><p><strong>tips：可以大概看看图表，了解关键的方法。</strong></p><p>这个时候只需要关注标题和摘要，读完摘要之后直接跳到结论部分；</p><ul><li><p>首先了解这个文章的<strong>标题</strong>是什么，和我们要查找的内容是不是相关的。</p></li><li><p>然后呢，再看一眼<strong>摘要</strong>，摘要就是比较精炼的介绍一下这篇文章。</p></li><li><p>最后直接跳到<strong>结论</strong>，结论通常来说，是和摘要一样的，但是会把摘要里面提出的一两个问题用一些实际的结论，实际的数字来证明一下。</p></li></ul><p>当你读完这三个部分，就可以大致知道这篇文章是在讲述什么内容了，看是否符合自己的诉求。再可以跳到实验部分，看一下一些关键的图和表；还可以跳到方法的图表看看这篇文章的关键方法。</p><p>这一遍通常需要10分钟的时间可以<strong>大概了解这篇文章大概在讲什么</strong>，质量如何，结果怎么样，方法看上去怎么样。最重要的是，这篇文章是否适合自己，确定要不要继续读下去。或者这篇文章质量不高，和自己没有太多关系，内容不感兴趣，就可以放到一边。</p><p>试着回答：（前两项即可）</p><p>作者试图完成什么？</p><p>关键要素是什么？</p><p>你可以用到什么？</p><p>有哪些参考文献可以继续学习？</p><h3 id="第二遍">第二遍</h3><p><strong>重点：从头到尾读，不用关注得太细节，主要目的是清晰了解图表含义。</strong></p><p><strong>tips：不要停留在数学上，只需继续阅读，略读数学，圈出感兴趣的文献</strong></p><p>对整个文章过一遍，可以沿着标题读到最后，这一遍不用注意太多细节，比如公式证明或者很细节的部分可以忽略，主要是搞清楚<strong>重要的图表</strong>，要清楚每个字，知道他到底是在干什么。比如方法中的流程图是什么样子，算法的图是什么结构，细致到实验中图的x轴，y轴是什么，每个点的含义是什么。作者提出的方法是如何和其他人方法对比的，它们之间的差距有多大。</p><p>这一遍读完之后可能还是对文章很模糊，没有特别搞懂它在干什么，但是没有关系，因为已经对整个论文的各个部分有了大概的了解。同时，在这一遍阅读时，可以把相关的文献圈出来，比如说作者在阐述某个问题，这个问题是某某之前提出来的，作者又是在某某的方法上改进的，如果你发现这些引用的重要的文献你没有读过，不太了解，就把他圈出来。</p><p>这时候你已经知道作者解决了什么问题，结果怎么样，大概用了什么方法，但是这个文章你觉得太难了，读不太懂得话，可以选择去读他引用的那些文章，之前的一些工作可能门槛更低一些，读完之后再回过来读这篇文章。</p><p>另外，如果觉得自己不需要了解得那么深，做的方向跟这个不太一样，不需要完全搞懂论文，那么读到这里就可以了。如果这篇文章比较关键，想要充分阅读，就可以进行第三遍阅读。</p><p>再次试着回答：</p><p>作者试图完成什么？</p><p>关键要素是什么？</p><p>你可以用到什么？</p><p>有哪些参考文献可以继续学习？</p><h3 id="第三遍">第三遍</h3><p><strong>重点：详细了解文章，并且拓展到自己，给自己设置问题，学会“脑补”</strong></p><p><strong>tips: 在文章最后作者会提到文章有一些没有继续研究的地方，可以记录自己的思考</strong></p><p>最详细的一遍，对每一句话，每一段了解清楚，可以想象自己去实现这篇文章。比如说，作者说提出了什么问题，用什么方法来解决这个问题。你可以带入角色，如果是我来做这件事情应该怎么办，我可以用什么方法来实现这个目的，主动给自己设置问题。作者在阐述实验的过程，你也可以问自己，如果是自己我应该怎么做，能不能比他做得更好。在文章最后作者会提到文章有一些没有继续研究的地方，留到了以后，可以拓展到自己，有没有什么方法可以往前继续推进成果。</p><p>最佳状态是：看完之后就好像是自己做过一遍一样，这样，对这篇文章的细节就了解的非常清楚啦！关上文章也可以回忆出很多细节的地方。</p><p>再基于他做研究，或者之后再向大家提到这篇文章的时候，可以详细和别人复述一遍了</p><h3 id="总结">总结</h3><p>第一遍的花时最少，也就是进行海选；</p><p>第二遍对论文做精选；</p><p>第三步是重点研读论文；</p><h2 id="什么是好的研究工作-🏆">什么是好的研究工作 🏆</h2><p>我们自己在做研究的时候，会思考现在的结果是否足够发表一篇论文，能够投什么级别的期刊或者会议，在写论文的时候，也会思考应该怎么样去讲述自己的故事使得读者更容易看到研究工作的意义。</p><p>所以如何去判断一个工作的意义呢？又如何写好一个故事呢？</p><p>核心：</p><p>用有<strong>新意</strong>的方法</p><p><strong>有效</strong>的解决一个</p><p><strong>研究</strong>问题</p><ul><li><strong>研究</strong></li></ul><p>这里关注技术类问题，可以分为两大类 研究类和工程类问题。</p><p>绝大部分问题属于工程问题，什么是工程问题？</p><p>比如说</p><p>算法很占内存，在计算资源上无法满足。</p><p>想法：那么第一个解决方案是 能不能买内存，第二是能不能优化算法，使得在不改变关键算法的同时节省内存。</p><p>模型的精度不够。</p><p>想法：是否可以多标一些数据来解决问题，或者在采样数据的时候用更好的传感器。</p><p>在遇到问题时，如果可以提出几个方案，而且这些方案在没有尝试的时候，就可以确定这些方案是可以一定程度上可以解决问题。那么这种问题是工程类问题</p><p>对于研究问题而言，是更加困难的问题，你是完全不知道怎么样解决它，或者是你有一些想法和方案，但是在真正尝试之前，你不知道这个想法是否可行。而一般的研究问题，前面所说的那些想法通常是不可行的。</p><ul><li><strong>有效</strong></li></ul><p>有效是一个相对的概念，不是一个绝对的概念；有效性是指的相比之前的工作，解决某个问题的有效性有所提升。</p><ul><li><strong>新意</strong></li></ul><p>这个也是一个相对的概念，因为就算是一个很有新意的东西，提出被大家熟知之后就不再有新意了。所以新意指的是在研究社区里面，对大多数研究者而言，你的想法是有新意的。这里并不要求所提出的方法，之前都没有人提到过，很有可能在很多年前别人已经用过的，只是目前大家没有关注了；另外在别的领域研究者提出的方法，但是在你所在的研究领域大家对这个方法并不是非常了解。这也可以作为论文的新意。</p><p>这三个方面可以衡量一篇文章的意义。</p><p>在写文章的时候，研究工作应该总结成这么一句话：使用了…方法，…有效的解决了…研究问题。</p><p>具体来说，在摘要部分，要引出 解决什么研究问题 ； 方法的新意在哪里；结果如何；</p><h3 id="价值">价值</h3><p>一个研究工作的$研究价值=新意度 \times 有效性 \times 问题大小$</p><p>不过反过来而言，价值是仁者见仁智者见智，很难准确定义一项研究成果的价值有多少。</p><h4 id="问题大小档次">问题大小档次</h4><ul><li><p>1        小      比如在前面工作的某一个点上进行改进</p></li><li><p>10      中等  比如在计算机视觉领域某一个视觉的子任务做出成果</p></li><li><p>100    大      比如提升机器对图片的理解，机器随文字的理解</p></li><li><p>…</p></li><li><p>10000  更大  比如解决通用的人共智能</p></li></ul><h4 id="有效性档次">有效性档次</h4><ul><li><p>1     小        比如模型精度比之前的研究好一点点</p></li><li><p>10   中等    比如一项长期的工作在一年之内在某一数据集上的精度向前推进了10个点，本篇论文的工作向前推进了1个点</p></li><li><p>100  高       比如一项工作就像研究将精度提升了5个点或者10个点</p></li></ul><p>对于问题的不同，有效性的定义也不同，但对于技术问题而言，通常指关心三个问题</p><ol><li>精度高，效果好</li><li>规模大，成本降低</li><li>安全， 比如数据隐私，模型隐私，联邦学习就是追求安全提出来的</li></ol><h4 id="新意度档次">新意度档次</h4><ul><li><p>1       表示大家对此方法没有很意外 比如提出的方法大家都了解，也可以预料到使用到它的结果如何</p></li><li><p>10    有一定的新意度，比如用某个技术解决了还不错的问题</p></li><li><p>100  使用的技术其他研究者不太熟悉，大家会觉得打开了新世界的大门</p></li></ul><p>对技术类工作来讲，很难有一个技术之前从来没有出现过，新意度只是对于该领域的读者而言，文章的新意度有多高。</p><h4 id="实际现实">实际现实</h4><p>在人工智能这个方面，</p><p>$研究价值=新意度 \times 有效性 \times 问题大小$</p><p>很多时候，一篇文章很难把三个方面都做得特别好，甚至把两个方面做到高水平都是很难的事情；所以通常情况下，在一两个指标上，做到差不多的水平也很好了。如果要发表在一流的会议或杂志上，研究价值需要达到1000；如果有两个10，也值得写文章发表，也可以练习写作。</p>]]></content>
    
    
    <categories>
      
      <category>文献</category>
      
      <category>阅读方法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>文献</tag>
      
      <tag>阅读方法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>praticalML第七章笔记</title>
    <link href="/2022/02/09/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PracticeML7/"/>
    <url>/2022/02/09/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PracticeML7/</url>
    
    <content type="html"><![CDATA[<blockquote><p>斯坦福2021秋季的实用机器学习上线啦~ 😉 跟着沐神复习机器学习冲冲冲！ 记录一下笔记和重点，不一定很全哦~，只是记录自我感觉的重点。这一章主要是讲神经网络中的归一化，残差连接以及注意力机制。</p></blockquote><h1>第七章 ​归一化💜</h1><h2 id="7-1-深度学习-🎶">7.1 深度学习 🎶</h2><p>Deep Network Tuning<br>• DL is a programming language to extract information from data<br>• Some values will be filled by data later<br>• Differentiable<br>• Various design patterns, from layers to network architecture<br>• Here we talk about some of them</p><p>定义一个模板，模板中的参数是根据数据和目标学习得到的，因此其有很多模式。</p><h2 id="7-2-Batch-Normalization（批量归一化）-🌊">7.2 Batch Normalization（批量归一化） 🌊</h2><p>• Standardizing data makes the loss smother for linear methods<br>•Smooth: $ ∥∇f(x)− ∇f(y)∥^2 ≤ β∥x−y∥^2 $<br>•A smaller $β$  allows a larger learning rate</p><p>​• Does not help deep NN</p><p>• Batch Normalization (BN) standards inputs for internal layers</p><p>​• Improves the smoothness to make training easier</p><p>• (Still controversial why BN works)</p><p>对于线性回归而言标准化的作用是使得数据均值为0，方差为1；作用是使得损失函数更加平滑，平滑就是$ ∥∇f(x)− ∇f(y)∥^2 ≤ β∥x−y∥^2 $​​​​​​ ，意味着在优化时求梯度更新时更稳定，可以调整使得学习率稍微大。但是对于神经网络而言，由于神经网络存在隐藏层，存在非线性就不能对中间层起到作用，可能只能对最后一层线性层有帮助。</p><p>因此需要BN层来对中间层进行数据标准化，使得函数更容易收敛。其实BN层的论文提出并不是此作用，存在争议，但是现在研究领域发现BN层的作用实际上就说数据标准化。</p><h2 id="7-3-具体机制-🐝">7.3 具体机制 🐝</h2><p><img src="https://picture.mulindya.com/ParacticeML7-1.png" alt=""></p><p>可以将其拆解为4步。</p><p>第一步是reshape：如果输出不是2D就将其转化为2D矩阵，比如说n,c,w,h就会转化为nwh乘以c，可以理解c为特征数，每个通道识别不同的模式，可以将样本压到一维。</p><p>第二步是Normalize：也就是标准化，对每一列的数据标准化。（总共有c列）</p><p>第三步是Recovery：对刚刚做完的标准化的数据进行反标准化，通过可学习的参数$\gamma \ \beta$ 来进行一些调整，起到一定程度上的还原。</p><p>第四步是将得到的结果的维度还原到原始维度。</p><p>这里严谨来说应该是Batch Standardization，因为就统计上而言是标准化。</p><h2 id="7-4-具体代码-🍃">7.4 具体代码 🍃</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">batch_norm</span>(<span class="hljs-params">X, gamma, beta, moving_mean, moving_var, eps, momentum</span>):</span> <br>    <span class="hljs-comment">#X是二维或者4维的向量 gamma和beta是可学的向量 moving_mean，moving_var是存着后续预测使用 eps是为了避免除零 momentum是全局的冲量</span><br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> torch.is_grad_enabled(): <span class="hljs-comment"># In prediction mode 没有梯度是预测模式 这里使用的是训练过程中存的全局均值和方差</span><br>    X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps) <br><span class="hljs-keyword">else</span>: <br><span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(X.shape) <span class="hljs-keyword">in</span> (<span class="hljs-number">2</span>, <span class="hljs-number">4</span>) <br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(X.shape) == <span class="hljs-number">2</span>:<br>        mean = X.mean(dim=<span class="hljs-number">0</span>) <span class="hljs-comment">#对每一列求均值</span><br>            var = ((X - mean)**<span class="hljs-number">2</span>).mean(dim=<span class="hljs-number">0</span>) <br>        <span class="hljs-keyword">else</span>: <br>        mean = X.mean(dim=(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), keepdim=<span class="hljs-literal">True</span>) <br>        var = ((X - mean)**<span class="hljs-number">2</span>).mean(dim=(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), keepdim=<span class="hljs-literal">True</span>) <br>        X_hat = (X - mean) / torch.sqrt(var + eps) <br>        moving_mean = momentum * moving_mean + (<span class="hljs-number">1.0</span> - momentum) * mean<br>        moving_var = momentum * moving_var + (<span class="hljs-number">1.0</span> - momentum) * var<br>    Y = gamma * X_hat + beta<br>    <span class="hljs-keyword">return</span> Y, moving_mean, moving_var<br></code></pre></td></tr></tbody></table></figure><h2 id="7-5-Layer-Normalization（层归一化）-🎁">7.5 Layer Normalization（层归一化） 🎁</h2><p>• If apply to RNN, BN needs maintain separated moving statistics for each time step</p><p>​• Problematic for very long sequences during inference</p><p>• Layer normalization reshapes input  $ X∈ ℝ^{n×p}→X′∈ ℝ^{p×n} $​ or $ X∈ ℝ^{n×c×w×h}→X′∈ ℝ^{cwh×n}$​ , rest is same with BN</p><p>​• Normalizing within each example, up to current time step</p><p>​ • Consistent between training and inference</p><p>​• Popularized by Transformers</p><p>主要是用于循环神经网络</p><p>假设句子长度是p，进行p次mlp，每个时间步骤是把当前的矩阵（样本乘以特征）以及放入mlp，每个句子也是不等长的，在每一个时间步需要用均值方差和参数$\gamma  \beta$​​​​​​,而在不同时间步他们的差别是比较大的，​​但是BN应该是对当前的数据进行稳定的方差估计，如果均值方差抖动比较大的话，就失去了标准化的意义，并且在预测的时候如果出现长度更长的句子，效果就不好了。层归一化就是对每一个小单元做标准化。比如说一个句子，一张图像。在预测的时候无须全局的信息，在RNN和Transformer中效果很好，在CNN上可能没有什么效果。</p><h2 id="7-6-更多归一化-🔑">7.6 更多归一化 🔑</h2><p>More Normalizations• Modify “reshape”, e.g</p><p>.•InstanceNorm:$ n \times c \times w \times h \to wh \times cn$​ 每一个位置</p><p>•GroupNorm: $ n \times c \times w \times h \to swh \times gn $​  with $ c = sg$​  对c分组​</p><p>• CrossNorm: swap mean/std between a pair of features 交换mean和std</p><p>• Modify “normalize”: e.g. whitening  使用白化，不仅仅使得均值为0方差为1，而且使得特征之间没有关系，也就是进行PCA降维</p><p>•Modify “recovery”: e.g.  $\gamma \ \beta$​​​​ replace  with a dense layer 可以把参数改成线性层甚至mlp去还原</p><p>• Apply to weights or gradients （Normalizations主要对层的输入中，也可以对权重w或者梯度来标准化）</p><p>最近发现在GAN，Adversarial Attack中使用BN效果不好，针对不同的问题要选择合适的Normalizations的技术。</p><h2 id="7-7-Summary-📧">7.7 Summary 📧</h2><p>• Normalizing inputs of internal layers makes deep NNs easier to train</p><p>• A normalization layer performs three steps: r<strong>eshape input, normalize data, recovery with learnable parameters</strong>  通用步骤</p><p>​• Notable examples include Batch Normalization for CNNs, Layer Normalization for Transformers 现在很多人发现在CNN上不用BN也是没有什么问题的。</p><p>Normalizing 可以把中间层的数值更稳定，使得损失函数更加平滑，使得网络的训练更加容易，一般来说，对准确率没有太大影响，但是可以让曲线更加稳定平滑。其实神经网络并不一定需要使用BN，可以进行一些其他的操作，比如对梯度进行Clipping，使其不要太大。并且其实BN在计算上，在实现上会带来很大的问题。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>李沐</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指27 移除元素</title>
    <link href="/2022/02/08/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode27/"/>
    <url>/2022/02/08/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode27/</url>
    
    <content type="html"><![CDATA[<blockquote><p>移除元素</p></blockquote><h2 id="题目">题目</h2><p>给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。</p><p>不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。</p><p>元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。</p><p>说明:</p><p>为什么返回数值是整数，但输出的答案是数组呢?</p><p>请注意，输入数组是以「引用」方式传递的，这意味着在函数里修改输入数组对于调用者是可见的。</p><p>你可以想象内部操作如下:</p><figure class="highlight go"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// nums 是以“引用”方式传递的。也就是说，不对实参作任何拷贝</span><br><span class="hljs-keyword">int</span> <span class="hljs-built_in">len</span> = removeElement(nums, val);<br><br><span class="hljs-comment">// 在函数里修改输入数组对于调用者是可见的。</span><br><span class="hljs-comment">// 根据你的函数返回的长度, 它会打印出数组中 该长度范围内 的所有元素。</span><br><span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-built_in">len</span>; i++) {<br>&nbsp; &nbsp; <span class="hljs-built_in">print</span>(nums[i]);<br>}<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-1：">示例 1：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">nums</span> = [<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>], <span class="hljs-attr">val</span> = <span class="hljs-number">3</span><br>输出：<span class="hljs-number">2</span>, <span class="hljs-attr">nums</span> = [<span class="hljs-number">2</span>,<span class="hljs-number">2</span>]<br>解释：函数应该返回新的长度 <span class="hljs-number">2</span>, 并且 nums 中的前两个元素均为 <span class="hljs-number">2</span>。你不需要考虑数组中超出新长度后面的元素。例如，函数返回的新长度为 <span class="hljs-number">2</span> ，而 <span class="hljs-attr">nums</span> = [<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>] 或 <span class="hljs-attr">nums</span> = [<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]，也会被视作正确答案。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight dns"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs dns">输入：nums = [<span class="hljs-number">0,1,2,2</span>,<span class="hljs-number">3,0,4,2</span>], val = <span class="hljs-number">2</span><br>输出：<span class="hljs-number">5</span>, nums = [<span class="hljs-number">0,1,4,0</span>,<span class="hljs-number">3</span>]<br>解释：函数应该返回新的长度 <span class="hljs-number">5</span>, 并且 nums 中的前五个元素为 <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">4</span>。注意这五个元素可为任意顺序。你不需要考虑数组中超出新长度后面的元素。<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><code>0 &lt;= nums.length &lt;= 100</code></li><li><code>0 &lt;= nums[i] &lt;= 50</code></li><li><code>0 &lt;= val &lt;= 100</code></li></ul><h2 id="题解">题解</h2><p>只需记录当前该元素出现的次数，在遍历过程中调整位置即可。最后返回的是剩下的数组长度。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">removeElement</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], val: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        x = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(nums)):<br>            <span class="hljs-keyword">if</span> nums[i]== val: x += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>: nums[i-x] = nums[i]<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(nums)-x<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>数组</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>数组</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>超低剂量高分辨率成像算法</title>
    <link href="/2022/02/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/CT/CT-paper/"/>
    <url>/2022/02/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/CT/CT-paper/</url>
    
    <content type="html"><![CDATA[<blockquote><p>查找相关论文，整理其思想。</p></blockquote><h2 id="一，-目的">一， 目的</h2><h3 id="超低剂量X射线显微CT系统研制">超低剂量X射线显微CT系统研制</h3><p>设计并研制超低剂量现验CT成像系统及核心部件，明确纵向成像不同电离辐射对动物各组织器官结构与功能的影响，实现低辐射剂量条件下的高分辨率成像。</p><h2 id="二，-文献查找来源">二， 文献查找来源</h2><ul><li><a href="https://www.cttacn.org.cn/">CT理论与应用研究</a></li><li><a href="http://www.diagnoschina.com/newest/zazhi_id-2">中国CT和MRI杂志</a></li><li><a href="http://lcfsx.chinabidingnews.cn/">临床放射学杂志</a></li><li>IEEE</li><li>Nature</li><li><a href="https://linkspringer.53yu.com/">Springer</a></li><li><a href="https://www.sciencedirect.com/">sciencedirect</a></li></ul><h2 id="三，低剂量CT成像算法">三，低剂量CT成像算法</h2><p>已有的研究工作大体可归结为三大类：投影数据处理，迭代重建算法和图像后处理方法。</p><p><img src="https://picture.mulindya.com/CT_paper1.png" alt=""></p><p><img src="https://picture.mulindya.com/CT_paper5.png" alt=""></p><h2 id="四，CT成像应用进展">四，CT成像应用进展</h2><p>为提高低剂量扫描条件下的成像质量，科研界和工业界的研究人员对 CT 成像算法链中的各个部分进行了相应研究，提出大量有效的算法。目前针对 CT 成像中的噪声伪影抑制问题，已有的研究工作大体可归结为三大类：投影数据处理，迭代重建算法和图像后处理方法 。特征学习方法在医学图像处理领域中得到了越来越多的应用，成为近年来医学图像处理的重要方法之一，并且已经逐步地应用在 CT 成像研究中，大大加速了 CT 成像技术的发展，主要表现在稀疏表示学习 CT 成像技术和深度学习 CT 成像技术两方面。以下我们将重点从 3 种高质量 CT 成像方法介入，分析现阶段的 CT 成像研究现状。</p><h3 id="4-1-投影数据预处理">4.1 投影数据预处理</h3><p>​在低剂量扫描条件下（低管电流、管电压，有限角度），投影数据会受到噪声干扰，出现伪影，甚至缺失等现象。投影数据的预处理通常就是采用数据去噪、复原等手段，对扫描后的原始数据进行一系列的处理，以尽可能提高投影数据的一致性，进而提高重建图像质量，该类算法又被称作重建前“预处理算法”。</p><p>​<strong>早期</strong>，人们提出了大量的投影数据预处理方法，如<strong>自适应滤波，加权最小均方的滤波 ，基于图像 K-L 变换的加权最小均方和噪声分离滤波</strong>等。随着研究的深入，学习型稀疏表示方法在投影数据预处理方面已有一定的应用，例如Shtok 等利用 K-SVD 字典对低剂量投影数据进行稀疏表示进而去噪，可实现减少低剂量重建图像中伪影的目的。Stojanovic 等将投影弦图平滑技术和学习型字典稀疏表示相互结合，来降低投影数据噪声从而提高重建效果。Li 等将字典学习方法应用于投影图修补，可以有效地减少稀疏角度成像中的伪影。Shen 等提出了一种近似的稀疏学习及表示模型，实现了快速弦图修补，在不影响重建图像分辨率的情况下提高重建效果。Zhang 等根据噪声特性进一步提出了投影域的字典学习方法来降低噪声提高低剂量 CT 成像质量。Karimi 等基于三维投影数据的相似性，构建联合稀疏表示，对锥束投影数据进行预处理，得到了较好的去噪效果。Liu 等 从保持投影数据一致性出发，提出一种投影数据区别性特征表示的方法，有效地降低了投影数据中的噪声并提高了数据的一致性。深度学习方面，Park 等提出了基于弦图一致性的学习模型，可有效地降低重建图像中的射束硬化伪影现象。随后，该团队在这一基础上，进一步应用于金属伪影的去除，取得了明显的效果。Lee 等将投影角度间差值和深度卷积神经网络相结合，可以进一步提高稀疏角度重建图像质量。Anirudh 等通过设计一种有效的二维卷积神经网络来修复有限角度扫描下的投影数据缺失，通过将有限角度扫描的投影数据补全的策略来提高成像质量。</p><p>​一般来说，这类方法直接对原始投影数据进行处理，将噪声抑制和图像重建看作两个相互独立的过程，便于系统集成，投影域预处理方法的计算复杂度小于迭代重建方法，相比于迭代重建算法具有较大优势，并且容易集成入成像算法链中。但是投影域处理过程容易出现数据不一致、欠校正、过校正等现象，从而使得重建图像失真，或者出现新的伪影和噪声等。因此，根据投影数据中的噪声特性来设计快速有效而保持数据一致性的算法，十分重要。</p><h3 id="4-2-图像重建">4.2 图像重建</h3><p>​由于计算机运算能力的提高，迭代算法的实用性越来越强。与解析重建相比，迭代重建具有对噪声不敏感，物理模型准确、易于添加正则项等优点，使得它在低剂量扫描条件下更具有优势。迭代重建算法中，将先验信息作为正则项，并引入目标函数可以抑制噪声和保持结构信息，提高求解稳定性。因此，<strong>基于正则项的统计迭代重建算法是目前的一个研究重点。</strong></p><h4 id="4-2-1-传统的重建方法">4.2.1 传统的重建方法</h4><p>​CT 成像技术的核心是重建算法，<strong>典型的重建算法包括解析法和迭代法</strong>。由于具备算法简单、计算速度快等的优点，**解析法中的FBP 与FDK（feldkamp-daivs-kress）分别成为了二维和三维 CT 系统的主流选择。**然而，解析法对投影数据的完备性要求较高，且对噪声非常敏感，在稀疏角度或有限角度扫描条件下的重建结果往往会受到严重的伪影和噪声污染。迭代法将待重建图像作为未知量，在图像域建立目标函数，并通过迭代求解来获取待重建图像。根据目标函数建立的方式不同，<strong>迭代算法可分为代数迭代法和统计迭代重建算法</strong>（statistical iterative reconstruction，SIR）。代数迭代法能够节省内存且重建速度快，然而重建后的图像质量并不理想。与传统的解析法和代数迭代法相比，<strong>SIR的重建效果更好。</strong></p><p>​伴随着压缩感知理论的发展，研究发现统计重建算法可以与稀疏学习表示的约束很好地结合起来，从而能够有效提高重建图像的质量。在这类方法中，最常用的稀疏表示方法是 TV 约束迭代重建，它可以在一定程度上减少 CT 图像中的噪声伪影。但是 TV 约束迭代重建难以有效处理具有复杂结构信息的图像，该方法在低剂量 CT 图像重建中会不可避免地引入块状伪影和丢失细节。另外，基于特征字典学习进行稀疏表示的方法也已经应用于医学图像重建过程中，相比于 TV 约束，特征字典学习方法可以有效地处理图像局部细节，能够获得更高质量图像。例如 Xu 等首次将全局字典以及自适应学习应用于低剂量 CT重建中，得到了较高的图像质量并且保持了较好的细节。随后出现了一些改进研究，例如Lu 等提出对偶字典、Bai 等提出的多尺度字典等都在一定程度上提高了 CT 图像重建效果。Chen 等根据人体组织结构和噪声伪影之间的特征不一致性，提出了基于区别性特征表示的低剂量 CT 图像处理算法，该算法使用含有解剖结构特征和噪声伪影特征的混合字典，通过竞争性的区别性稀疏表示实现了对噪声和伪影的有效去除，实验证明该区别性特征表示算法既能通过图像空间后处理，也能通过投影空间前处理来提高低剂量 CT 图像质量，具有较好的扩展性。最近，Liu 等使用字典学习的三维特征来约束迭代重建，可大幅度的提高重建图像质量。</p><h4 id="4-2-2-基于深度学习的重建方法">4.2.2 基于深度学习的重建方法</h4><p><img src="https://picture.mulindya.com/CT_paper2.png" alt=""></p><p>​第Ⅰ类方法将深度学习用于实现解析重建中的滤波反投影操作，主要研究如何采用卷积神经网络（convolutional neural network，CNN）实现投影域与图像域的直接映射。此类方法一般采用网络训练的方式实现解析重建中的滤波与反投影操作，它们可以分为投影域网络 + BP 和投影域网络 + BP + 图像域网络两类。</p><p>​第Ⅱ类方法将深度学习用于实现 SIR 中的正则项功能。与传统 SIR 算法需要人工设计正则化项不同，此类方法中能够反映 CT 图像先验信息的正则项是可学习的。根据网络模型是否需要预先训练，可将这类方法分为 model-based 类重建方法和 plug-and-play 类重建方法。</p><p>​第 Ⅲ类方法是基于 CNN 的迭代展开类算法，主要研究如何采用深度学习网络模块通过网络训练的方式实现 SIR 中的迭代求解过程。 ① 一部分研究者致力于研究采用端到端的训练方式实现迭代求解过程可学习。</p><p>​Hammernik 等提出了一种深度学习的重建网络架构，能在一定程度上提高有限角度 CT 图像重建质量。Kelly 等通过<strong>深度特征学习</strong>，来引导不完全投影数据的重建，能有效地减少不完全投影重建带来的伪影。Zhao 等提出了一种轻量化的卷积神经网络架构，通过联合优化各层网络参数，来实现稀疏角度 CT 图像重建，取得了较传统的特征字典效果更好的图像。Gjesteby 等通过采用深度神经网络的方式，学习高质量的 CT 图像特征以引导 CT 图像重建，抑制重建过程中的金属伪影。Ramesh 等 通过卷积神经网络来提取高质量 CT 图像的中的先验信息，并将其用于重建中，该先验信息具有良好的自适应性，在噪声伪影抑制和图像细节保持方面取得较好的平衡。Ye 等通过设计含有串联的 ReLU 激活函数结构的卷积神经网络，来探索深度学习在逆问题求解中的通用框架，并将其应用于医学图像重建中。Chen 等将统计迭代重建中的先验项替换为多个级联的残差网络，设计出一种学习专家评估的重建网络 LEARN，并用于稀疏角度 CT 重建，实验结果表明在 50 个迭代级联后，能有效地减少重建伪影提高图像质量。Adler 等利用对偶关系，将重建问题转换为一个近似的对偶问题，并用神经网络来替代对偶的求解，提出了一种原始对偶重建方法，仿真实验结果表明在噪声抑制和细节保持上要优于 TV 重建算法，并且能在仅 10 倍 FBP 重建时间下取得良好的图像质量，具有一定的应用前景。基于正则化项的统计迭代类算法，它从投影数据的统计特性以及 CT 图像的特定先验信息的角度出发，通过优化重建逆问题的目标函数，可以获得质量较好的重建图像。但是这类算法面临的主要问题有：超参数多，难以自适应优化；算法复杂度高，需要重复进行迭代计算；先验信息具有不稳定性，无法获得统一框架下的正则项等，使得迭代重建在实际临床应用场景难以充分发挥其价值。这些都是未来研究的重要方向及热点。</p><h3 id="4-3-图像后处理">4.3 图像后处理</h3><p>​在图像域，以抑制图像中噪声和伪影为研究目标，直接对重建图像进行处理的方法称为后处理方法。由于其在图像域进行操作，不依赖于原始投影数据，可移植性较强，便于推广，后处理方法已经成为 LDCT 成像领域的热点研究方向。后处理算法主要分为两类：<strong>传统后处理算法与基于深度学习的后处理方法。</strong></p><h4 id="4-3-1-传统后处理算法">4.3.1 传统后处理算法</h4><p>​在深度学习被广泛应用之前，LDCT 图像伪影抑制主要通过传统后处理方法来实现。经典算法中，由于能够有效利用图像像素之间的结构相似性，<strong>基于非局部均值（non-localmeans，NLM）及其改进形式的方法</strong>取得了较好的降噪效果。</p><p>​这些方法的主要思想都是从**高质量 CT 图像中提取有效的特征信息，为低质量的 CT 图像处理提供先验指导，服务于成像。**其中，基于特征字典的稀疏学习表示技术结合了图像的先验信息，及非局部处理算法的优势，取得了优异的效果。Chen 等提出的基于大尺度邻域非局部均值滤波的LDCT 伪影抑制方法，考虑了大尺度窗口内像素结构的相似性，伪影抑制效果较好。此外，也有许多在变换域进行 LDCT 图像降噪的探索，如基于多尺度奇异点检测的 LDCT 图像小波去噪算法、在小波域对 NLM 方法进行改进的三维块匹配滤波算法和基于稀疏表示和字典学习的方法也是LDCT 图像降噪领域近年的研究热点。传统方法还包括自适应多尺度全变分 LDCT 图像降噪方法、基于Curvelet 双线性插值的 LDCT 图像降噪方法等。这些传统算法主要运用数学分析、现代信号处理与数字图像处理等理论来解决 CT 图像降噪问题，算法原理过于依赖人工设计难以灵活调整，其性能有较大的局限性。</p><h4 id="4-3-2-基于深度学习的-LDCT-图像后处理方法">4.3.2 基于深度学习的 <strong>LDCT</strong> 图像后处理方法</h4><p>​近年，研究者们尝试采用深度学习解决 LDCT 图像伪影噪声抑制问题。学者们的研究热点主要集中在网络框架改进、训练策略改进及功能模块设计等方面。</p><p><img src="https://picture.mulindya.com/CT_paper3.png" alt=""></p><p>​随着深度学习技术在工业界及学术界的蓬勃发展，在 CT 图像处理领域也得到了初步应用。最早，Harmeling 等提出利用多层感知机网络学习含噪声伪影的图像与高质量图像之间的映射关系，实现对自然图像进行噪声抑制，其处理结果呈现与 BM3D 算法相接近的效果。低剂量 CT 成像领域中，Chen 等提出将三维卷积神经网络用于低剂量 CT 图像后处理过程中来降低图像噪声，取得了优异的成绩；随后该团队中 Yang 等在此基础上采用残差网络架构来进一步提高低剂量 CT 图像质量；Wu 等提出级联多个卷积神经网络来提高图像质量；Kang 等提出利用方向波变换对低剂量 CT 图像进行预处理，再输入到 U-net 进行训练的策略，可进一步提高低剂量 CT 图像的降噪效果；Chen 等 将自编码神经网络应用于低剂量 CT 图像降噪，提出残差编码解码网络结构，能在保持图像细节的同时有效降低噪声。</p><p>​Wolterink 等将生成对抗网络应用于低剂量心脏 CT 降噪中，发现生成对抗网络能够产生与常规剂量 CT 纹理接近的图像；Yang 等在神经网络的目标函数中使用感知损失函数（Perceptual Loss），而非传统的均方误差损失函数，并比较用卷积神经网络和生成对抗网络对低剂量 CT 图像降噪的效果，发现该损失函数能保留了更多的关键细节，可进一步提升处理图像的对比度。Würfl 等提出 FBP 重建算法以及迭代重建算法可以等价地用神经网络来表示，表明使用神经网络来实现从投影数据直接到图像的可行性。Han 等提出了一种基于持续性同源分析的残差学习方法来处理压缩感知的 CT 重建图像。Yin 等通过设计不同的神经网络从投影域和图像域两方面同时进行处理，能极大程度地抑制低剂量 CT 中的噪声，并保留更多的解剖细节信息。研究表明，CT 图像中的噪声和伪影分布情况较为复杂，不同设备之间的差异较大，对其进行精确的分析和建模具有一定的困难。因此，从 CT 图像噪声、伪影、正常结构以及病灶区域等角度出发，来设计相应的处理网络仍然将是深度学习在低剂量 CT 成像领域的研究重点。</p><h3 id="4-4-总结">4.4 总结</h3><p><img src="https://picture.mulindya.com/CT_paper4.png" alt=""></p><p>​针对低剂量 CT 成像所面临的图像质量下降问题，目前基础性的成像算法研究工作主要包括投影数据预处理、重建算法改进和后处理三个方面。</p><p>​其中投影域相关方法与图像重建是相互独立过程，有利于并行化的集成，但投影空间数据处理易导致数据过校正的现象；基于统计迭代算法考虑了投影数据的统计特性和 CT 图像特定的先验信息，但算法复杂度高、超参数多、先验信息不稳定性、计算成本大等，难以满足实际临床需求；</p><p>​图像后处理算法处理速度快，可移植性较强，但处理能力有限。目前，稀疏学习处理模型求解方法虽然能够提供比传统重建算法或图像处理方法更好的噪声抑制效果，但对强度较大的噪声或伪影抑制往往效果欠佳（强度较大的噪声或伪影特征往往关联比较大的系数，难以在稀疏系数求解中被抑制）。另外，对于原子数量较多的字典情况下求解字典中原子稀疏系数时计算复杂度较大。同时字典表示中对图像空间分辨率的影响仍然有待更深入的研究。</p><p>​深度学习的主要缺点是其处理不透明的“黑盒子”特性，一般通过反复经验性的“试错”和“试对”来设计搭建网络，在低剂量 CT 成像中的应用还主要集中在图像后处理或者以先验特征形式引入迭代重建这两个方面，其在图像后处理中的效果受制于已经严重退化的低剂量 CT 图像，而在迭代重建中的应用受到迭代重建类算法所需的计算复杂度的制约。随着计算能力的提升和学习模型理论的完善，基于特征学习类的高质量 CT 成像算法研究必将成为本领域研究的热点方向。迄今为止，许多研究团队和 CT 研发制造商已经在深度特征学习的成像方面开展进行了初步的研究和探索，验证了其在临床 CT 成像中的潜力和价值。</p><h2 id="五，具体阐述方法">五，具体阐述方法</h2><h3 id="5-1-能谱纯化结合迭代重建算法">5.1 能谱纯化结合迭代重建算法</h3><p>此为2022 年 2 月武汉市肺科医院放射科发表的一篇文章。</p><ul><li><p>目的：探讨基于能谱纯化结合迭代重建算法在继发性肺结核患者低剂量CT检查中的应用。</p></li><li><p>方法：选取2019年4月至6月武汉市肺科医院确诊的70例继发性肺结核患者作为研究对象。初检采用常规剂量组：管电压110 kV，参考管电流52 mAs，滤波反投影（FBP）重建图像；复检采用低剂量组（能谱纯化）：管电压Sn 110 kV，参考管电流73 mAs，正弦图迭代重建（SAFIRE）。比较两组图像主观评分、升主动脉CT值、图像噪声、SNR及辐射剂量差异。</p></li><li><p>结果：两组图像主观评分相比无差异，满足临床诊断要求。两组升主动脉CT值无差异；低剂量组图像SNR低于常规剂量组。低剂量组ED（0.36±0.15）mSv与常规剂量组（2.35±0.73）mSv相比降低约84.7％。</p></li><li><p><strong>结论：能谱纯化结合迭代重建算法在继发性肺结核患者检查中能够显著降低患者所受辐射剂量，同时图像质量也能满足临床诊断要求。</strong></p></li></ul><p>​    文献报道证实采用<strong>迭代重建技术</strong>在<strong>低剂量 CT 扫描</strong>时可显著降低图像噪声，提高图像质量。以往大多数医院研究低剂量 CT 扫描采用<strong>降低管电压或管电流技术</strong>的方法，而对于采用<strong>能谱纯化技术</strong>的方法来研究低剂量 CT 扫描却鲜有报道。</p><p>​    以往大部分研究学者采用降低管电压或管电流的方法来达到降低辐射剂量的目的，而本研究低剂量组采用西门子公司独创研制的能谱纯化技术，该技术原理是用特殊锡滤过板放置于 X 线球管前方，将 X 线的辐射能量频谱图中低能量部分的截止能量提高，从而使 X 线能谱变窄，能量增加，使之更接近 CT 成像理论要求的光子能量的均一性，有效提高 X 线的利用率，从而减少患者所受辐射剂量。</p><p>​    低剂量 CT 扫描虽显著降低患者所受辐射剂量，但同时也增加图像噪声，图像分辨率下降，导致图像质量无法达到临床诊断要求。传统的 FBP 是目前临床应用较为广泛的一种重建算法，它对重建数据要求较高，通过对每组投影值进行校准、滤波、加权及反投影，但是当辐射剂量降低时，人体成像所需的 X 线光子数目会减少，图像噪声就会相应地增加。<strong>因此低剂量扫描采用 FBP 重建算法来保证图像质量的方法是不可行的。</strong></p><p>​     近年，迭代重建算法所具有降低噪声和保证图像质量的特点而逐渐被临床及放射专家认可。有关研究表明在儿内科患儿胸部 CT 检查中应用 ASIR 技术可在确保图像质量的同时降低辐射剂量；256 层 iCTIMR 重建技术在肺动脉 CTA 检查中图像质量能够满足临床诊断需求，同时有效地降低患者辐射剂量。</p><p>​    本研究采用正弦图确定迭代重建算法(sinogram affirmed iterative reconstruction，SAFIRE)，SAFIRE是迭代重建算法之一，比传统滤波反投影算法(FBP)有更优的降噪效果，对低kV扫描的图像进行重建，可以一定程度上使噪声降低，从而保证图像质量。它属于近年来出现的一种新型的基于原始数据的重建算法，该算法可以将原始数据中的噪声投射到图像中，利用反复插入方法去除噪声，通过多次迭代来去除伪影、减少噪声，提高图像分辨率。</p><h3 id="5-2-自适应统计迭代重建技术在儿内科患儿胸部CT检查中的应用">5.2 自适应统计迭代重建技术在儿内科患儿胸部CT检查中的应用</h3><p>自适应统计迭代重建(ASIR)技术是基于图像数据空间与投影数据空间的一种新型CT重建算法，与传统的滤波反投影(FBP)技术比较，可在保证CT重建后图像质量及不影响临床诊断的前提下，大幅降低辐射剂量。</p><p>CT检查方法：  患儿取仰卧位，平静呼吸下进行扫描，扫描范围自胸廓入口至膈肌水平。对于无法配合的低龄患儿，检查前给予10%水合氯醛(0.5mL/kg)口服。研究组采用美国GE公司宝石能谱CT(Discovery  CT750HD)扫描仪，扫描参数：管电压120kV，螺距1.375:1，转速0.8s/r，自动管电流调节技术(ATCM)设置管电流10～350mA。根据患儿年龄设置噪声指数(NI)，1～12个月NI值11，1～3岁NI值13，4～6岁NI值15。所得原始数据通过30%  ASIR与70% FBP混合重建图像。对照组采用美国GE公司Lightspeed  VCT扫描仪，扫描范围、参数同研究组，噪声指数8HU。所得原始数据采用FBP技术重建图像。</p><h3 id="5-3-基于特征学习的低剂量CT成像算法">5.3 基于特征学习的低剂量CT成像算法</h3><p>​在影像大数据环境下，基于特征学习方法的低剂量 CT 成像有着更广阔的发展空间。基于特征学习的低剂量 CT 成像算法可大致分为学习浅层特征的稀疏学习算法和学习深层特征的深度学习算法。稀疏学习在特征识别、纹理分类和图像去噪等领域中受到广泛关注，该方法是通过一定的方式从样本数据中构造的过完备字典，并利用字典中的特征原子，对待表示数据进行稀疏编码。而深度学习的方法是设计一个多层的深度卷积网络来实现对数据的高效信息特征抽取，分析和处理。通过学习训练建立样本数据与标签数据特征集的映射关系。稀疏学习和深度学习的方法在低剂量 CT 成像方面都得到了一定的应用。</p><h2 id="参考文献">参考文献</h2><p>[1] 姜一, 田葵, 沙晋璐, 等. 基于能谱纯化结合迭代重建算法在继发性肺结核患者低剂量CT检查中的应用[J]. CT理论与应用研究, 2022, 31(1): 95-101. DOI: 10.15953/j.1004-4140.2022.31.01.11</p><p>[2] 刘进, 赵倩隆, 尹相瑞, 顾云波, 康季槐, 陈阳. 基于特征学习的低剂量CT成像算法研究进展[J]. CT理论与应用研究, 2019, 28(3): 393-406. doi: 10.15953/j.1004-4140.2019.28.03.14</p><p>[3] 马桂娜,江奇琦,韩萍,等. SAFIRE重建联合CARE kV技术在主动脉CT低剂量成像中的临床应用[J]. 临床放射学杂志,2018,37(10):1755-1759.</p><p>[4] 胡光玉,童和平,叶永灿,等. 自适应统计迭代重建技术在儿内科患儿胸部CT检查中的应用[J]. 中国CT和MRI杂志,2020(11). DOI:10.3969/j.issn.1672-5131.2020.11.019.</p><p>[5] 刘进,赵倩隆,尹相瑞,等. 基于特征学习的低剂量CT成像算法研究进展[J]. CT理论与应用研究,2019,28(3):393-406. DOI:10.15953/j.1004-4140.2019.28.03.14.</p><p>[6] 韩泽芳, 上官宏, 张雄, 等. 基于深度学习的低剂量CT成像算法研究进展[J]. CT理论与应用研究, 2022, 31(1): 117-134. DOI: 10.15953/j.1004-4140.2022.31.01.14</p>]]></content>
    
    
    <categories>
      
      <category>文献</category>
      
      <category>CT</category>
      
    </categories>
    
    
    <tags>
      
      <tag>文献</tag>
      
      <tag>CT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer68-1 二叉搜索树的最近公共祖先</title>
    <link href="/2022/02/06/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer68-1/"/>
    <url>/2022/02/06/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer68-1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>二叉搜索树的最近公共祖先</p></blockquote><h2 id="题目">题目</h2><p>给定一个二叉搜索树, 找到该树中两个指定节点的最近公共祖先。</p><p>百度百科中最近公共祖先的定义为：“对于有根树 T 的两个结点 p、q，最近公共祖先表示为一个结点 x，满足 x 是 p、q 的祖先且 x 的深度尽可能大（一个节点也可以是它自己的祖先）。”</p><p>例如，给定如下二叉搜索树:  root = [6,2,8,0,4,7,9,null,null,3,5]</p><figure class="highlight livescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs livescript">    <span class="hljs-number">6</span><br>  /   <span class="hljs-string">\</span> <br> <span class="hljs-number">2</span>     <span class="hljs-number">8</span><br>/ <span class="hljs-string">\</span>   / <span class="hljs-string">\</span><br><span class="hljs-number">0</span>  <span class="hljs-number">4</span>  <span class="hljs-number">7</span>  <span class="hljs-number">9</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-1：">示例 1：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入: <span class="hljs-attr">root</span> = [<span class="hljs-number">6</span>,<span class="hljs-number">2</span>,<span class="hljs-number">8</span>,<span class="hljs-number">0</span>,<span class="hljs-number">4</span>,<span class="hljs-number">7</span>,<span class="hljs-number">9</span>,<span class="hljs-literal">null</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">3</span>,<span class="hljs-number">5</span>], <span class="hljs-attr">p</span> = <span class="hljs-number">2</span>, <span class="hljs-attr">q</span> = <span class="hljs-number">8</span><br>输出: <span class="hljs-number">6</span> <br>解释: 节点 <span class="hljs-number">2</span> 和节点 <span class="hljs-number">8</span> 的最近公共祖先是 <span class="hljs-number">6</span>。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入: <span class="hljs-attr">root</span> = [<span class="hljs-number">6</span>,<span class="hljs-number">2</span>,<span class="hljs-number">8</span>,<span class="hljs-number">0</span>,<span class="hljs-number">4</span>,<span class="hljs-number">7</span>,<span class="hljs-number">9</span>,<span class="hljs-literal">null</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">3</span>,<span class="hljs-number">5</span>], <span class="hljs-attr">p</span> = <span class="hljs-number">2</span>, <span class="hljs-attr">q</span> = <span class="hljs-number">4</span><br>输出: <span class="hljs-number">2</span><br>解释: 节点 <span class="hljs-number">2</span> 和节点 <span class="hljs-number">4</span> 的最近公共祖先是 <span class="hljs-number">2</span>, 因为根据定义最近公共祖先节点可以为节点本身。<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>所有节点的值都是唯一的。</li><li>p、q 为不同节点且均存在于给定的二叉搜索树中。</li></ul><h2 id="题解">题解</h2><p>这里是二叉搜索树，只需要这两个节点在左右即可，如果两个在左子树就搜索左子树，如果两个节点在右子树就搜索右子树。只用根据大小比较即可。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for a binary tree node.</span><br><span class="hljs-comment"># class TreeNode:</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.left = None</span><br><span class="hljs-comment">#         self.right = None</span><br></code></pre></td></tr></tbody></table></figure><ul><li>定义闭包函数来查找root。</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lowestCommonAncestor</span>(<span class="hljs-params">self, root: <span class="hljs-string">'TreeNode'</span>, p: <span class="hljs-string">'TreeNode'</span>, q: <span class="hljs-string">'TreeNode'</span></span>) -&gt; 'TreeNode':</span><br>        x,y = p.val,q.val<br>        <span class="hljs-keyword">if</span> x&gt;y:<br>            x,y = y,x<br>        self.parent = <span class="hljs-number">0</span><br>        self.find = <span class="hljs-literal">False</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">func</span>(<span class="hljs-params">root</span>):</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root <span class="hljs-keyword">or</span> self.find:<span class="hljs-keyword">return</span><br>            <span class="hljs-keyword">if</span> (root.val==x <span class="hljs-keyword">or</span> root.val==y) <span class="hljs-keyword">or</span> (x&lt;root.val <span class="hljs-keyword">and</span> y&gt;root.val):<br>                self.parent = root<br>                self.find = <span class="hljs-literal">True</span><br>                <span class="hljs-keyword">return</span> <br>            <span class="hljs-built_in">print</span>()<br>            <span class="hljs-keyword">if</span> x&gt;root.val:func(root.right)<br>            <span class="hljs-keyword">else</span>:func(root.left)<br>        func(root)<br>        <span class="hljs-keyword">return</span> self.parent<br></code></pre></td></tr></tbody></table></figure><ul><li>直接使用递归</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lowestCommonAncestor</span>(<span class="hljs-params">self, root: <span class="hljs-string">'TreeNode'</span>, p: <span class="hljs-string">'TreeNode'</span>, q: <span class="hljs-string">'TreeNode'</span></span>) -&gt; 'TreeNode':</span><br>        <span class="hljs-keyword">if</span> root.val &lt; p.val <span class="hljs-keyword">and</span> root.val &lt; q.val:<br>            <span class="hljs-keyword">return</span> self.lowestCommonAncestor(root.right, p, q)<br>        <span class="hljs-keyword">if</span> root.val &gt; p.val <span class="hljs-keyword">and</span> root.val &gt; q.val:<br>            <span class="hljs-keyword">return</span> self.lowestCommonAncestor(root.left, p, q)<br>        <span class="hljs-keyword">return</span> root<br></code></pre></td></tr></tbody></table></figure><ul><li>使用循环函数</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lowestCommonAncestor</span>(<span class="hljs-params">self, root: <span class="hljs-string">'TreeNode'</span>, p: <span class="hljs-string">'TreeNode'</span>, q: <span class="hljs-string">'TreeNode'</span></span>) -&gt; 'TreeNode':</span><br>        <span class="hljs-keyword">if</span> p.val &gt; q.val: p, q = q, p <span class="hljs-comment"># 保证 p.val &lt; q.val</span><br>        <span class="hljs-keyword">while</span> root:<br>            <span class="hljs-keyword">if</span> root.val &lt; p.val: <span class="hljs-comment"># p,q 都在 root 的右子树中</span><br>                root = root.right <span class="hljs-comment"># 遍历至右子节点</span><br>            <span class="hljs-keyword">elif</span> root.val &gt; q.val: <span class="hljs-comment"># p,q 都在 root 的左子树中</span><br>                root = root.left <span class="hljs-comment"># 遍历至左子节点</span><br>            <span class="hljs-keyword">else</span>: <span class="hljs-keyword">break</span><br>        <span class="hljs-keyword">return</span> root<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>树</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer54 二叉搜索树的第k大节点</title>
    <link href="/2022/02/04/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer54/"/>
    <url>/2022/02/04/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer54/</url>
    
    <content type="html"><![CDATA[<blockquote><p>二叉搜索树的第k大节点</p></blockquote><h2 id="题目">题目</h2><p>给定一棵二叉搜索树，请找出其中第 <code>k</code> 大的节点的值。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight livescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs livescript">输入: root = [<span class="hljs-number">3</span>,<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">2</span>], k = <span class="hljs-number">1</span><br>   <span class="hljs-number">3</span><br>  / <span class="hljs-string">\</span><br> <span class="hljs-number">1</span>   <span class="hljs-number">4</span><br>  <span class="hljs-string">\</span><br>   <span class="hljs-number">2</span><br>输出: <span class="hljs-number">4</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight livescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs livescript">输入: root = [<span class="hljs-number">5</span>,<span class="hljs-number">3</span>,<span class="hljs-number">6</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-literal">null</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">1</span>], k = <span class="hljs-number">3</span><br>       <span class="hljs-number">5</span><br>      / <span class="hljs-string">\</span><br>     <span class="hljs-number">3</span>   <span class="hljs-number">6</span><br>    / <span class="hljs-string">\</span><br>   <span class="hljs-number">2</span>   <span class="hljs-number">4</span><br>  /<br> <span class="hljs-number">1</span><br>输出: <span class="hljs-number">4</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 ≤ k ≤ 二叉搜索树元素个数</li></ul><h2 id="题解">题解</h2><p>按照中序遍历可以得到二叉搜索树的顺序的序列，这里用全局遍历res来记录序号，因为这里是第K大因此是先遍历右子树再遍历左子树。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for a binary tree node.</span><br><span class="hljs-comment"># class TreeNode:</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.left = None</span><br><span class="hljs-comment">#         self.right = None</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">kthLargest</span>(<span class="hljs-params">self, root: TreeNode, k: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        self.res = <span class="hljs-number">0</span><br><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">funcMid</span>(<span class="hljs-params">root</span>):</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root <span class="hljs-keyword">or</span> self.res&gt;=k :<span class="hljs-keyword">return</span><br>            funcMid(root.right)<br>            self.res += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> self.res==k:self.result = root.val<br>            funcMid(root.left)<br>        <span class="hljs-comment">#中序遍历 得到有顺序的序列</span><br>        <br>        self.result = <span class="hljs-number">0</span><br>        funcMid(root)<br>        <span class="hljs-keyword">return</span> self.result<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>树</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>praticalML第六章笔记 Tuning</title>
    <link href="/2022/02/02/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PracticeML6/"/>
    <url>/2022/02/02/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PracticeML6/</url>
    
    <content type="html"><![CDATA[<blockquote><p>斯坦福2021秋季的实用机器学习上线啦~ 😉 跟着沐神复习机器学习冲冲冲！ 记录一下笔记和重点，不一定很全哦~，只是记录自我感觉的重点。这一章的内容主要是对建立的模型进行Tuning，包括模型调参，超参数优化，网络架构搜索。</p></blockquote><h1>第六章</h1><h2 id="6-1-模型调参-🐾">6.1 模型调参 🐾</h2><h3 id="6-1-1-Manual-Hyperparameter-Tuning">6.1.1 Manual Hyperparameter Tuning</h3><ul><li><p>Start with a good baseline, e.g. default settings in high-quality toolkits, values reported in papers</p></li><li><p>Tune a value, retrain the model to see the changes</p></li><li><p>Repeat multiple times to gain insights about</p><p>• Which hyperparameters are important 哪些参数比较重要</p><p>• How sensitive the model to hyperparameters 敏感度</p><p>• What are the good ranges  找寻好的区间</p></li></ul><p>一般来说，会从一个好的基线开始，找寻工具包有一个大致的参数，或者参考相关论文中，相关数据集中的参数设置，再在验证集上对比结果。</p><p>当SGD调参调的比较好的时候通常比Adam要更好，但是Adam对学习率不那么敏感，更好调参。</p><h4 id="参数的记录和保存">参数的记录和保存</h4><ul><li><p>Needs careful experiment management</p></li><li><p>Save your training logs and hyperparameters to compare, share and reproduce later</p></li></ul><p>• The simplest way is saving logs in text and put key metrics in Excel</p><p>• Better options exist, e.g. <strong>tenesorboard and weights &amp; bias</strong></p><ul><li><p>Reproducing is hard, it relates to</p><p>• Environment (hardware &amp; library)</p><p>• Code</p><p>• Randomness (seed)</p></li></ul><p>最好记录好自己的训练日志，各种参数设置利于重复。</p><p>推荐的工具：tenesorboard and weights &amp; bias（wandb）</p><p>重复实验是比较难实现，因为实验和硬件，包环境，代码，<strong>随机种子</strong>相关。实在做不到的重复实验，想要达到效果可以使用多个模型进行Ensemble融合起来。</p><h3 id="6-1-2-机器调参">6.1.2 机器调参</h3><p><img src="https://picture.mulindya.com/ParacticeML6-1.png" alt=""></p><p>在小的任务上可以使用机器调参。</p><h4 id="AutoML">AutoML</h4><p><img src="https://picture.mulindya.com/ParacticeML6-2.png" alt=""></p><p>在模型选择这一块，AutoML有所发展。</p><h3 id="6-1-3-总结">6.1.3 总结</h3><p>• Hyperparameter tuning aims to find a set of good values</p><p>• It’s time consuming as data preprocessing</p><p>• There is a trend to use algorithm for tuning</p><p>调整参数的目的是找一组好的参数值，现在更倾向于使用算法来Tuning。</p><h2 id="6-2-超参数优化-🌻">6.2 超参数优化 🌻</h2><p><img src="https://picture.mulindya.com/ParacticeML6-3.png" alt=""></p><h3 id="6-2-1-HPO-algorithms-Black-box-or-Multi-fidelity">6.2.1 HPO algorithms: Black-box or Multi-fidelity</h3><ul><li>Black-box: treats a training job as a black-box in HPO； 黑盒</li></ul><p>​• Completes the training process for each trial</p><ul><li>Multi-fidelity: modifies the training job to speed up the search</li></ul><p>• Train on subsampled datasets</p><p>• Reduce model size (e.g less #layers, #channels)</p><p>• Stop bad configuration earlier</p><p>调参的trick：在小数据集，减少模型的size，训练的时候减少epoch；</p><p>这样可以很快的对参数的效果有一些比较和对比。</p><p><img src="https://picture.mulindya.com/ParacticeML6-4.png" alt=""></p><h3 id="6-2-2-常见的HPO策略">6.2.2 常见的HPO策略</h3><ol><li><p>网格搜索 Grid Search</p><p>暴力穷举，把所有的组合过一遍得到最好的结果</p></li><li><p>随机搜索 Random Search</p><p>循环n次，随机选择超参数的组合，在没有很好的头绪的时候可以先选择随机搜索来确定参数值</p></li></ol><p><img src="https://picture.mulindya.com/ParacticeML6-5.png" alt=""></p><h3 id="6-2-3-（BO）-Bayesian-Optimization">6.2.3 （BO） Bayesian Optimization</h3><p>•<strong>BO</strong>: Iteratively learn a mapping from HP to objective function.  Based on previous trials. Select the next trial based on the current estimation.</p><p>•<strong>Surrogate model</strong></p><p>​• Estimate how the objective function depends on HP</p><p>​• Probabilistic regression models: Random forest, Gaussian process, …</p><p>贝叶斯优化，目前应用得不太广泛，了解一下</p><h3 id="6-2-4-Successive-Halving-（SH算法）">6.2.4 Successive Halving （SH算法）</h3><p><img src="https://picture.mulindya.com/ParacticeML6-6.png" alt=""></p><p>有很多超参数得选择，首先选择n组个超参数，训练m个epoch，淘汰n/2组超参数，然后再训练更多一点epoch 2m次epoch，这样每一次的选取计算开销是差不多的。</p><h3 id="6-2-5-Hyperband（实际中可用）">6.2.5 Hyperband（实际中可用）</h3><p><img src="https://picture.mulindya.com/ParacticeML6-7.png" alt=""></p><p>SH中选大的n，小的m。Hyperband实际上是将多个SH结合起来，然后在前面选取的超参数中选取减半n数目的比较好的参数组合，双倍m，目的是多跑一跑，给第一次在少量epoch的参数再次确认的机会。这样在n和m的选取上就不会那么敏感了。</p><h3 id="6-2-6-总结">6.2.6 总结</h3><ul><li><p>Black-box HPO: grid/<strong>random search</strong>, bayesian optimization</p></li><li><p>Multi-fidelity HPO: Successive Halving, <strong>Hyperband</strong></p></li><li><p>In practice, start with random search</p></li><li><p>Beware there are <strong>top performers</strong></p><p>• You can find them by mining your training logs, or what common configurations used in paper/code</p></li></ul><p>再次说明调参的trick：在小数据集，减少模型的size，训练的时候减少epoch；</p><p>这样可以很快的对参数的效果有一些比较和对比。</p><p>总有几个模型几组参数在所有的数据集任务都表现得比较好，在论文和比赛中记录下比较好得参数组合，只用试试这些参数即可。</p><h2 id="6-3-神经架构搜索（NAS）🍄">6.3 神经架构搜索（NAS）🍄</h2><h3 id="6-3-1-概念">6.3.1 概念</h3><p>模型架构的搜索Neural Architecture Search (NAS)</p><ul><li>A neural network has different types of hyperparameters:</li></ul><p>• Topological structure: resnet-ish, mobilenet-ish, #layers</p><p>• Individual layers: kernel_size, #channels in convolutional layer, #hidden_outputs in dense/recurrent layers</p><ul><li>NAS automates the design of neural network</li></ul><p>​• How to specify the search space of NN</p><p>​• How to explore the search space</p><p>​• Performance estimation</p><p><img src="https://picture.mulindya.com/ParacticeML6-8.png" alt=""></p><p>NAS的工作是尽量使得模型架构的选择自动化</p><h3 id="6-3-2-使用强化学习来NAS">6.3.2 使用强化学习来NAS</h3><p><img src="https://picture.mulindya.com/ParacticeML6-9.png" alt=""></p><p>使用RNN来生成模型的架构，得到的反馈是模型的精度，但是强化学习很贵，实际上不太适用。</p><h3 id="6-3-3-One-shot方法（更实用）">6.3.3 One-shot方法（更实用）</h3><ul><li><p>Combines the learning of architecture and model params</p></li><li><p>Construct and train a single model presents a wide variety of architectures</p></li><li><p>Evaluate candidate architectures</p><p>• Only care about the candidate ranking</p><p>• Use a proxy metric: the accuracy after a few epochs</p></li><li><p>Re-train the most promising candidate from scratch</p></li></ul><p>同时学习网络架构的参数和其中的超参数，训练一个巨大的模型，每个子模型的架构和超参数也可以得到。实际上只需要得到模型对前面得模型有提升即可。</p><h4 id="例子-Differentiable-Architecture-Search">例子 Differentiable Architecture Search</h4><p><img src="https://picture.mulindya.com/ParacticeML6-10.png" alt=""></p><p>使用softmax来判定子路，每一层有很多候选层，比如L层的第i个候选输出为$O_i<sup>l$然后通过对权重参数a通过softmax可以获得${\alpha}</sup>l$​​​加权求和得到​​值赋值m份给到L，通过训练之后得到的a可以来选择好的单元（单元对应的a越大越好）</p><h3 id="6-3-4-Scaling-CNNs（更简单实用）">6.3.4 Scaling CNNs（更简单实用）</h3><p><img src="https://picture.mulindya.com/ParacticeML6-11.png" alt=""></p><p>EfficientNet就是这样的方法搜索出来的，但是Scaling CNNs这个方法有一定的局限性，只对于小部分的神经网络使用，具体是对于卷积神经网络。</p><p>调节网络的三个方法：</p><p>更多层，更多channel，更大的输入分辨率；</p><p>Efficientnet建议组合调节这三个部分，当网络深度变深时通道数也可以相应变多，同样resolution也对应变多。通过4个参数来调节这三个部分。</p><h3 id="6-3-5-研究方向">6.3.5 研究方向</h3><ul><li><p>Explainability of NAS result</p></li><li><p>Search architecture to fit into edge devices</p><p>• Edge devices are more and more powerful, data privacy concerns</p><p>• But they are very diverse (CPU/GPU/DSP, 100x performance difference) and have power constraints</p></li></ul><p>• Minimize both model loss and hardware latency</p><p>​•E.g. minimize $ loss×log(latency)^β $​</p><ul><li>To what extend can we automates the entire ML workflow?</li></ul><h3 id="6-3-6-总结">6.3.6 总结</h3><ul><li>NAS searches a NN architecture for a customizable goal</li></ul><p>​ • Maximize accuracy or meet latency constraints on particular hardware</p><ul><li>NAS is practical to use now:</li></ul><p>​• Compound depth, width, resolution scaling</p><p>​• Differentiable one-hot neural network</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>李沐</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer48 最长不含重复字符的子字符串</title>
    <link href="/2022/01/25/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer48/"/>
    <url>/2022/01/25/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer48/</url>
    
    <content type="html"><![CDATA[<blockquote><p>最长不含重复字符的子字符串</p></blockquote><h2 id="题目">题目</h2><p>请从字符串中找出一个最长的不包含重复字符的子字符串，计算该最长子字符串的长度。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入: "abcabcbb"</span><br><span class="hljs-section">输出: 3 </span><br><span class="hljs-section">解释: 因为无重复字符的最长子串是 "abc"，所以其长度为 3。</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入: "bbbbb"</span><br><span class="hljs-section">输出: 1</span><br><span class="hljs-section">解释: 因为无重复字符的最长子串是 "b"，所以其长度为 1。</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-3：">示例 3：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入: "pwwkew"</span><br><span class="hljs-section">输出: 3</span><br><span class="hljs-section">解释: 因为无重复字符的最长子串是&nbsp;"wke"，所以其长度为 3。</span><br>&nbsp;    请注意，你的答案必须是 子串 的长度，<span class="hljs-string">"pwke"</span>&nbsp;是一个子序列，不是子串。<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><code>s.length &lt;= 40000</code></li></ul><h2 id="题解">题解</h2><p>使用动态规划+哈希表的方法</p><ul><li><strong>哈希表 dic 统计：</strong> 指针 j遍历字符 s，哈希表统计字符 s[j]<strong>最后一次出现的索引</strong> 。</li><li>更新左指针 i ： 根据上轮左指针 i 和 dic[s[j]]，每轮更新左边界 i ，保证区间 [i + 1, j]内无重复字符且最大。</li><li><strong>更新结果 res：</strong> 取上轮 res和本轮双指针区间 [i + 1,j]的宽度（即 j - i）中的最大值。</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lengthOfLongestSubstring</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        dic, res, i = {}, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(s)):<br>            <span class="hljs-keyword">if</span> s[j] <span class="hljs-keyword">in</span> dic:<br>                i = <span class="hljs-built_in">max</span>(dic[s[j]], i) <span class="hljs-comment"># 更新左指针 i</span><br>            dic[s[j]] = j <span class="hljs-comment"># 哈希表记录</span><br>            res = <span class="hljs-built_in">max</span>(res, j - i) <span class="hljs-comment"># 更新结果</span><br>        <span class="hljs-keyword">return</span> res<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>动态规划</category>
      
    </categories>
    
    
    <tags>
      
      <tag>动态规划</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer53-Ⅱ 0~n-1种缺少的数字</title>
    <link href="/2022/01/24/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer53-2/"/>
    <url>/2022/01/24/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer53-2/</url>
    
    <content type="html"><![CDATA[<blockquote><p>0~n-1种缺少的数字</p></blockquote><h2 id="题目">题目</h2><p>一个长度为n-1的递增排序数组中的所有数字都是唯一的，并且每个数字都在范围0～n-1之内。在范围0～n-1内的n个数字中有且只有一个数字不在该数组中，请找出这个数字。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入: [0,1,3]</span><br><span class="hljs-section">输出: 2</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight dns"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs dns">输入: [<span class="hljs-number">0,1,2,3</span>,<span class="hljs-number">4,5,6,7</span>,<span class="hljs-number">9</span>]<br>输出: <span class="hljs-number">8</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= 数组长度 &lt;= 10000</li></ul><h2 id="题解">题解</h2><p>使用二分法来查找就好啦~，如果是出现在缺失数字之前的数字就会和下标相同，如果是在缺失数字之后就会比下标要大1，根据这一特性来查找这个缺失数字。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">missingNumber</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        i,j = <span class="hljs-number">0</span>,<span class="hljs-built_in">len</span>(nums)-<span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> i&lt;=j:<br>            m = (i+j)//<span class="hljs-number">2</span><br>            <span class="hljs-keyword">if</span> nums[m]==m:i = m+<span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>: j = m-<span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> i <span class="hljs-comment">#返回i下标即可</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>查找</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>二分法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>praticalML第五章笔记</title>
    <link href="/2022/01/24/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PracticeML5/"/>
    <url>/2022/01/24/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PracticeML5/</url>
    
    <content type="html"><![CDATA[<blockquote><p>斯坦福2021秋季的实用机器学习上线啦~ 😉 跟着沐神复习机器学习冲冲冲！ 记录一下笔记和重点，不一定很全哦~，只是记录自我感觉的重点。这一章的中心是模型融合，也就是Model Combination，主要讲解方差和偏差，bagging，boosting，stacking的慨念和算法！</p></blockquote><h1>第五章</h1><h2 id="5-1-方差和偏差-🌖">5.1 方差和偏差 🌖</h2><h3 id="5-1-1-概念">5.1.1 概念</h3><p>统计学习中使用方差和偏差来衡量模型。</p><p><img src="https://picture.mulindya.com/ParacticeML5-1.png" alt=""></p><p>训练的模型对于样本得到的预测值，采样5次数据训练5个模型的到的5个结果值，黄色区域是容忍的区域；</p><p>偏差是学习到的模型和真实的模型得到的解的差距；</p><p>方差是每次学习到的东西的差别有多大。</p><h3 id="5-1-2-重要公式">5.1.2 重要公式</h3><p><img src="https://picture.mulindya.com/ParacticeML5-2.png" alt=""></p><p>Bias为第一项，Var为第三项，可以需要使得模型的方差和偏差尽可能的小。这个公式灰常重要🔎！</p><h3 id="5-1-3-模型优化方法">5.1.3 模型优化方法</h3><p><img src="https://picture.mulindya.com/ParacticeML5-3.png" alt=""></p><p>随着模型越复杂，偏差会递减，而方差会递增，因为会过拟合，模型对于小的扰动会对结果扰动很大。</p><p>如果要得到好的模型，增强泛化能力，就需要把偏差，方差，噪声都降低。</p><p><img src="https://picture.mulindya.com/ParacticeML5-4.png" alt=""></p><ul><li><p>降低偏差：复杂模型，boosting，Stacking；</p></li><li><p>降低方差：简单模型，正则化参数，Bagging，Stacking；</p></li><li><p>降低噪音：增强数据质量；</p></li></ul><p>其中Boosting，Stacking,Bagging是Ensemble Learning也就是集成学习。<strong>核心思想是使用多个模型来提升预测性能~</strong></p><h3 id="5-1-4-总结">5.1.4 总结</h3><ul><li>Decompose model generalization error into bias,variance and intrinsic error</li><li>Ensemble learning combines mutiple models to reduce both bias and variance</li></ul><p>将模型的泛化误差分解成方差，偏差的平方，采集数据误差。</p><p>可以使用集成模型来降低方差和偏差。</p><h2 id="5-2-Bagging-🔮">5.2 Bagging 🔮</h2><h3 id="5-2-1-概念">5.2.1 概念</h3><p>Bagging是生产词，来自于Bootstrap Aggrgrating</p><ul><li><p>Learn  base learners in parallel, combine to reduce model variance</p></li><li><p>Each base learner is trained on a bootstrap sample<br>•Given a dataset of  examples, create a sample by randomly sampling examples with replacement<br>•Around 公式1 unique examples will be sampled use the out-of-bag examples for validation</p>   $$  公式1: \ 1-\frac{1}{e} \approx 63\%  $$   </li><li><p>Combine learners by averaging the outputs (regression) or majority voting (classification)</p></li><li><p>Random forest: bagging with decision trees<br>• usually select random subset of features for each bootstrap sample</p></li></ul><p>将n个模型做预测，回归可以得到的结果做平均，分类可以使用n个模型得到的结果来投票取最大统计数的结果。</p><p>bootstrap采样 也就是随机放回采样得到训练的模型，这样的采样方式大概含有了63%的原始样本，剩下的37%是重复样本，out of bag剩下没有采样的原始样本可以作为验证集。</p><h3 id="5-2-2-代码">5.2.2 代码</h3><p><img src="https://picture.mulindya.com/ParacticeML5-5.png" alt=""></p><p><code>__init__</code>方法是初始化n个学习器：<code>clone</code>可以把一个<code>base_learner</code>复制n次，因为模型不是share权重的，是独立的，不能直接使用<code>[base_learner for _ in range(n_leaners)]</code>。</p><p><code>fit</code>方法是训练学习器：<code>fit</code>中的<code>example</code>是在m个样本中又有放回随机选择m个样本。然后训练n个训练模型。</p><p><code>predict</code>方法是：预测是给x来得到pred，存到一个数组中，转为array在第一个维度求均值。</p><h3 id="5-2-3-本质">5.2.3 本质</h3><p><img src="https://picture.mulindya.com/ParacticeML5-6.png" alt=""></p><p>Baggin降低了模型的方差，尤其是不稳定的学习器，因此泛化能力会增强，大方差的模型可以称作Unstable Learner。</p><p>下面公式中的$f(x)$不是随机变量是确定的，因此是可以化成$\hat{f}(x)^2$​​,这里没有看懂😵，单个小于等于多个f的期望。</p><h3 id="5-2-4-Unstable-Learners">5.2.4 Unstable Learners</h3><p>随机森林也就是降低了方差，但是没有增加偏差和噪声；</p><p>在使用bagging的时候使用不稳定的Learner会有显著提升泛化性能的效果，决策树不是稳定的模型，数据一旦发生变化，那么选取哪些特征切开分支会很不一样，线性回归相对是比较稳定的模型，协方差矩阵（最小特征值和最大特征值的比）比较好的模型相对比较稳定</p><p><img src="https://picture.mulindya.com/ParacticeML5-7.png" alt=""></p><h3 id="5-2-5-总结">5.2.5 总结</h3><ul><li><p>Bagging train multiple learner on data by bootstrap sampling(随机放回采样)</p></li><li><p>Bagging reduce variance,especially for unstable learners</p><p>对于不稳定的模型，比如决策树效果最佳，比如随机森林</p></li></ul><h2 id="5-3-Boosting">5.3 Boosting</h2><h3 id="5-3-1-定义">5.3.1 定义</h3><p><img src="https://picture.mulindya.com/ParacticeML5-14.png" alt=""></p><p>Boosting是为了降低模型的偏差，Bagging是为了降低模型的方差。</p><p>Boosting是将偏差比较大的模型（weak learners）将其组合成一个比较强的模型</p><h3 id="5-3-2-Gradient-Boosting">5.3.2 Gradient Boosting</h3><p><img src="https://picture.mulindya.com/ParacticeML5-15.png" alt=""></p><p>这里注意是在残差上学习，也就是样本本身，特征不变化，只有标号变了，标号为$y_i-H_t(s_i)$​,也就是前面模型没有学够的部分然后加到当前的模型中继续Boosting，在加入新的$\hat{h_t}_(x)$​(上面公式中的f是沐神笔误了)时前有一个$\eta$​​​作为正则项​避免过拟合，<strong>可以将$ \eta $​​​​​设置为0.1或者0.几，避免一次性拟合太过。</strong></p><p>残差等于求损失对函数梯度的负方向，拟合等价与 每次学习一个新的ht是去拟合负梯度的方向，以前的梯度下降是使用负的导数梯度乘以学习率加到权重中，由于这里是学习的函数，在这里不是加到权重中，而是加到函数中。不同的L可采取不同的Boosting的算法。</p><h3 id="5-3-3-实现代码">5.3.3 实现代码</h3><p><img src="https://picture.mulindya.com/ParacticeML5-16.png" alt=""></p><p><code>fit</code>方法是首先将y copy到residual中，然后训练模型（X,residual）,然后更新残差形式；</p><p><code>predict</code>时需要求和乘以学习率时为了加权每个弱学习器的结果。</p><h4 id="5-3-4-Gradient-Boosting-Decision-Trees-GBDT">5.3.4 Gradient Boosting Decision Trees(GBDT)</h4><p><img src="https://picture.mulindya.com/ParacticeML5-17.png" alt=""></p><p>Boosting容易过拟合，所以需要一些正则化；我们需要一些弱模型，可以使用少层的决策树（或其他模型）或者在少量的特征上学习的模型。这里没有过拟合一个是取得模型都是很弱，另外学习率取为0.1.</p><h3 id="5-3-5-总结">5.3.5 总结</h3><ul><li><p>Boosting combines weak learners into a strong one to reduce bias</p></li><li><p>Gradient Boosting learns weak learners by fitting the residuals</p><p>弱模型组合成强模型降低偏差</p></li></ul><h2 id="5-4-Stacking-🔋">5.4 Stacking 🔋</h2><h3 id="5-4-1-定义">5.4.1 定义</h3><p><img src="https://picture.mulindya.com/ParacticeML5-8.png" alt=""></p><p>可以融合<strong>不同种</strong>模型，然后Concat结果再进行线性组合也就是全连接层，既可以降低偏差，也可以降低方差，在竞赛中常用此方法。</p><h4 id="对比Bagging">对比Bagging</h4><ul><li><p>类似Bagging组合模型投票，但是这里是不同种类的模型来融合。</p></li><li><p>不需要Bootstrap来获取多样性因为模型本身就具有多样性；</p></li><li><p>模型不一样在特征提取也会不一样。</p></li></ul><h3 id="5-4-2-Stacking-result">5.4.2 Stacking result</h3><p><img src="https://picture.mulindya.com/ParacticeML5-9.png" alt=""></p><p>需要注意模型的选取。</p><h3 id="5-4-3-多层Stacking">5.4.3 多层Stacking</h3><p>之前的stacking主要是降低方差，也可以使用多层的方法降低偏差</p><p><img src="https://picture.mulindya.com/ParacticeML5-10.png" alt=""></p><p>下一层的模型是上一层的输出结果，原始特征加上模型输出结果来concat。多层的stacking很容易过拟合，容易过度注意噪音，需要减轻过拟合。</p><h3 id="5-4-4-减轻过拟合">5.4.4 减轻过拟合</h3><p><img src="https://picture.mulindya.com/ParacticeML5-11.png" alt=""></p><h4 id="不重复数据">不重复数据</h4><p>可以把数据分成两块A，B，在A上训练第一层的模型，在B得到预测的结果在加上B的本身用于第二层模型的训练。这样每一层数据的训练集是不耦合的，缺点是每一层只能使用一半的数据。</p><h4 id="重复K折Bagging">重复K折Bagging</h4><p>类似交叉验证将数据分成K份，在k-1上训练，在i上做验证，这样可以训练k个模型，将得到的结果可以组成和原始数据一样的大小，但是预测都是没有再次参与当前模型训练的，再进入到下一层训练，同时下一层可以看到整个样本的预测同时都没有参加，训练n次就一层之中的小模型可以看到所有数据，这样实际上就训练了k*n个模型，也就是说n个模型并排成为一层，然后使用k成交叉，使得每一次训练小模型看到的数据不同。然后再求平均输出到下一层。</p><h3 id="5-4-5-代码实例">5.4.5 代码实例</h3><p><img src="https://picture.mulindya.com/ParacticeML5-12.png" alt=""></p><h3 id="5-4-6-总结">5.4.6 总结</h3><ul><li><p>Stacking combine multiple learners to reduce variance</p></li><li><p>Stacking learners in multiple levels to reduce bias</p><ul><li>Repeated K-fold bagging:fully utilize data and alleviate overfitting</li></ul><p>多层减轻偏差，多个模型减轻方差</p></li></ul><h2 id="5-5-模型融合总结-📫">5.5 模型融合总结 📫</h2><ul><li>集成学习的方法来降低偏差和方差</li></ul><p><img src="https://picture.mulindya.com/ParacticeML5-13.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>李沐</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer58-2 左旋转字符串</title>
    <link href="/2022/01/23/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer58-2/"/>
    <url>/2022/01/23/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer58-2/</url>
    
    <content type="html"><![CDATA[<blockquote><p>左旋转字符串</p></blockquote><h2 id="题目">题目</h2><p>字符串的左旋转操作是把字符串前面的若干个字符转移到字符串的尾部。请定义一个函数实现字符串左旋转操作的功能。比如，输入字符串"abcdefg"和数字2，该函数将返回左旋转两位得到的结果"cdefgab"。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入: <span class="hljs-attr">s</span> = <span class="hljs-string">"abcdefg"</span>, <span class="hljs-attr">k</span> = <span class="hljs-number">2</span><br>输出: <span class="hljs-string">"cdefgab"</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入: <span class="hljs-attr">s</span> = <span class="hljs-string">"lrloseumgh"</span>, <span class="hljs-attr">k</span> = <span class="hljs-number">6</span><br>输出: <span class="hljs-string">"umghlrlose"</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><code>1 &lt;= k &lt; s.length &lt;= 10000</code></li></ul><h2 id="题解">题解</h2><p>直接使用切片</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reverseLeftWords</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span>, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">str</span>:</span><br>        <span class="hljs-keyword">return</span> s[n:]+s[:n]<br></code></pre></td></tr></tbody></table></figure><p>如果不允许使用切片可以使用字符串的拼接</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reverseLeftWords</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span>, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">str</span>:</span><br>        res = <span class="hljs-string">""</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n, <span class="hljs-built_in">len</span>(s)):<br>            res += s[i]<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            res += s[i]<br>        <span class="hljs-keyword">return</span> res<br></code></pre></td></tr></tbody></table></figure><p>代码简洁可以直接求余运算</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reverseLeftWords</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span>, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">str</span>:</span><br>        res = <span class="hljs-string">""</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n, n + <span class="hljs-built_in">len</span>(s)):<br>            res += s[i % <span class="hljs-built_in">len</span>(s)]<br>        <span class="hljs-keyword">return</span> res<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>方法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>方法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer53-1 在排序数组中查找数字Ⅰ</title>
    <link href="/2022/01/22/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer53-1/"/>
    <url>/2022/01/22/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer53-1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>在排序数组中查找数字Ⅰ</p></blockquote><h2 id="题目">题目</h2><p>统计一个数字在排序数组中出现的次数。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入: nums = [5,7,7,8,8,10], target = 8</span><br><span class="hljs-section">输出: 2</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入: nums = [5,7,7,8,8,10], target = 6</span><br><span class="hljs-section">输出: 0</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>0 &lt;= nums.length &lt;= 105</li><li>-109&nbsp;&lt;= nums[i]&nbsp;&lt;= 109</li><li>nums&nbsp;是一个非递减数组</li><li>-109&nbsp;&lt;= target&nbsp;&lt;= 109</li></ul><h2 id="题解">题解</h2><p>第一种方法是直接遍历：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        result = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> nums:<br>            <span class="hljs-keyword">if</span> item==target:<br>                result += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> result<br><br></code></pre></td></tr></tbody></table></figure><p>注意到这里是排序好的数组可以直接找寻两个数字的最左边或者最右边再求差</p><p>求最左侧的index，可以用<code>func(target)- func(target-1)</code></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-comment">#二分法</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">func</span>(<span class="hljs-params">tar</span>):</span><br>            i, j = <span class="hljs-number">0</span>,<span class="hljs-built_in">len</span>(nums)-<span class="hljs-number">1</span><br>            <span class="hljs-keyword">while</span> i&lt;=j: <span class="hljs-comment">#当数组只有一个数字时 [1] 找寻0 </span><br>                m = (i+j)//<span class="hljs-number">2</span><br>                <span class="hljs-keyword">if</span> nums[m]&lt;=tar: <span class="hljs-comment">#找寻最右点</span><br>                    i = m+<span class="hljs-number">1</span><br>                <span class="hljs-keyword">else</span>:j = m-<span class="hljs-number">1</span>  <br>            <span class="hljs-built_in">print</span>(i,j) <br>            <span class="hljs-keyword">return</span> j<br>        <span class="hljs-keyword">return</span> func(target)- func(target-<span class="hljs-number">1</span>)<br><br></code></pre></td></tr></tbody></table></figure><p>注意模板，<code>i&lt;=j</code>,返回<code>j</code></p><p>求最右侧的index，可以用<code>func(target+1)- func(target)</code></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-comment">#二分法</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">func</span>(<span class="hljs-params">tar</span>):</span><br>            i, j = <span class="hljs-number">0</span>,<span class="hljs-built_in">len</span>(nums)-<span class="hljs-number">1</span><br>            <span class="hljs-keyword">while</span> i&lt;=j: <span class="hljs-comment">#当数组只有一个数字时 [1] 找寻0 </span><br>                m = (i+j)//<span class="hljs-number">2</span><br>                <span class="hljs-keyword">if</span> nums[m]&lt;=tar: <span class="hljs-comment">#找寻最右点</span><br>                    i = m+<span class="hljs-number">1</span><br>                <span class="hljs-keyword">else</span>:j = m-<span class="hljs-number">1</span>  <br>            <span class="hljs-built_in">print</span>(i,j) <br>            <span class="hljs-keyword">return</span> j<br>        <span class="hljs-keyword">return</span> func(target)- func(target-<span class="hljs-number">1</span>)<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>查找</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>二分法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer52 两个链表的第一个公共节点</title>
    <link href="/2022/01/21/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer52/"/>
    <url>/2022/01/21/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer52/</url>
    
    <content type="html"><![CDATA[<blockquote><p>两个链表的第一个公共节点</p></blockquote><h2 id="题目">题目</h2><p>输入两个链表，找出它们的第一个公共节点。</p><p><img src="https://picture.mulindya.com/leetcode-offer52-1.png" alt=""></p><p>在节点 c1 开始相交。</p><h3 id="示例-1：">示例 1：</h3><p><img src="https://picture.mulindya.com/leetcode-offer52-2.png" alt=""></p><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">intersectVal</span> = <span class="hljs-number">8</span>, <span class="hljs-attr">listA</span> = [<span class="hljs-number">4</span>,<span class="hljs-number">1</span>,<span class="hljs-number">8</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>], <span class="hljs-attr">listB</span> = [<span class="hljs-number">5</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">8</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>], <span class="hljs-attr">skipA</span> = <span class="hljs-number">2</span>, <span class="hljs-attr">skipB</span> = <span class="hljs-number">3</span><br>输出：Reference of the node <span class="hljs-keyword">with</span> <span class="hljs-attr">value</span> = <span class="hljs-number">8</span><br>输入解释：相交节点的值为 <span class="hljs-number">8</span> （注意，如果两个列表相交则不能为 <span class="hljs-number">0</span>）。从各自的表头开始算起，链表 A 为 [<span class="hljs-number">4</span>,<span class="hljs-number">1</span>,<span class="hljs-number">8</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>]，链表 B 为 [<span class="hljs-number">5</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">8</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>]。在 A 中，相交节点前有 <span class="hljs-number">2</span> 个节点；在 B 中，相交节点前有 <span class="hljs-number">3</span> 个节点。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><p><img src="https://picture.mulindya.com/leetcode-offer52-3.png" alt=""></p><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">intersectVal</span>&nbsp;= <span class="hljs-number">2</span>, <span class="hljs-attr">listA</span> = [<span class="hljs-number">0</span>,<span class="hljs-number">9</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>], <span class="hljs-attr">listB</span> = [<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>], <span class="hljs-attr">skipA</span> = <span class="hljs-number">3</span>, <span class="hljs-attr">skipB</span> = <span class="hljs-number">1</span><br>输出：Reference of the node <span class="hljs-keyword">with</span> <span class="hljs-attr">value</span> = <span class="hljs-number">2</span><br>输入解释：相交节点的值为 <span class="hljs-number">2</span> （注意，如果两个列表相交则不能为 <span class="hljs-number">0</span>）。从各自的表头开始算起，链表 A 为 [<span class="hljs-number">0</span>,<span class="hljs-number">9</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>]，链表 B 为 [<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>]。在 A 中，相交节点前有 <span class="hljs-number">3</span> 个节点；在 B 中，相交节点前有 <span class="hljs-number">1</span> 个节点。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-3：">示例 3：</h3><p><img src="https://picture.mulindya.com/leetcode-offer52-4.png" alt=""></p><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">intersectVal</span> = <span class="hljs-number">0</span>, <span class="hljs-attr">listA</span> = [<span class="hljs-number">2</span>,<span class="hljs-number">6</span>,<span class="hljs-number">4</span>], <span class="hljs-attr">listB</span> = [<span class="hljs-number">1</span>,<span class="hljs-number">5</span>], <span class="hljs-attr">skipA</span> = <span class="hljs-number">3</span>, <span class="hljs-attr">skipB</span> = <span class="hljs-number">2</span><br>输出：<span class="hljs-literal">null</span><br>输入解释：从各自的表头开始算起，链表 A 为 [<span class="hljs-number">2</span>,<span class="hljs-number">6</span>,<span class="hljs-number">4</span>]，链表 B 为 [<span class="hljs-number">1</span>,<span class="hljs-number">5</span>]。由于这两个链表不相交，所以 intersectVal 必须为 <span class="hljs-number">0</span>，而 skipA 和 skipB 可以是任意值。<br>解释：这两个链表不相交，因此返回 <span class="hljs-literal">null</span>。<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>如果两个链表没有交点，返回 null.</li><li>在返回结果后，两个链表仍须保持原有的结构。</li><li>可假定整个链表结构中没有循环。</li><li>程序尽量满足 O(n) 时间复杂度，且仅用 O(1) 内存。</li><li>本题与主站 160 题相同：<a href="https://leetcode-cn.com/problems/intersection-of-two-linked-lists/">https://leetcode-cn.com/problems/intersection-of-two-linked-lists/</a></li></ul><h2 id="题解">题解</h2><p>这道题刚拿到觉得很简单，可以把数字用数组存下来，然后从后向前找寻公共节点。但是有一项要求<code>程序尽量满足 O(n) 时间复杂度，且仅用 O(1) 内存。</code>很难满足。</p><p>看大佬的题解真是妙不可言，甚至还被虐了</p><blockquote><p>《你的名字》</p><p>你变成我，走过我走过的路。<br>我变成你，走过你走过的路。<br>然后我们便相遇了…</p></blockquote><p>使用双指针A，B；当他们同时开始运动，A遍历完headA链表就遍历headB链表，而B遍历完headB链表就遍历A链表。A和B总会相遇要么是空，要么是公共节点。</p><p>背后的原理是：假设A链表的长度为a，B链表长度为b，公共部分为c；那么在相遇之前A会走a+b-c步，B会走b+a-c步，他们走的步数是相同的，所以只要他们同时开始运动，A指针按照A链表B链表，B指针按照B链表A链表，就会在节点处相遇！</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode:</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.next = None</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getIntersectionNode</span>(<span class="hljs-params">self, headA: ListNode, headB: ListNode</span>) -&gt; ListNode:</span><br>        <span class="hljs-comment"># 公共节点不仅值相等，实际上就是同一节点</span><br>        A,B = headA,headB<br>        <span class="hljs-keyword">while</span>(A!=B):<br>            A = A.<span class="hljs-built_in">next</span> <span class="hljs-keyword">if</span> A <span class="hljs-keyword">else</span> headB<br>            B = B.<span class="hljs-built_in">next</span> <span class="hljs-keyword">if</span> B <span class="hljs-keyword">else</span> headA<br>        <span class="hljs-keyword">return</span> A<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>双指针</category>
      
    </categories>
    
    
    <tags>
      
      <tag>双指针</tag>
      
      <tag>剑指</tag>
      
      <tag>idea</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer46 把数字翻译成字符串</title>
    <link href="/2022/01/20/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer46/"/>
    <url>/2022/01/20/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer46/</url>
    
    <content type="html"><![CDATA[<blockquote><p>把数字翻译成字符串</p></blockquote><h2 id="题目">题目</h2><p>给定一个数字，我们按照如下规则把它翻译为字符串：0 翻译成 “a” ，1 翻译成 “b”，……，11 翻译成 “l”，……，25 翻译成 “z”。一个数字可能有多个翻译。请编程实现一个函数，用来计算一个数字有多少种不同的翻译方法。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight 1c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs 1c">输入: <span class="hljs-number">12258</span><br>输出: <span class="hljs-number">5</span><br>解释: <span class="hljs-number">12258</span>有<span class="hljs-number">5</span>种不同的翻译，分别是<span class="hljs-string">"bccfi"</span>, <span class="hljs-string">"bwfi"</span>, <span class="hljs-string">"bczi"</span>, <span class="hljs-string">"mcfi"</span>和<span class="hljs-string">"mzi"</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><code>0 &lt;= num &lt; 231</code></li></ul><h2 id="题解">题解</h2><p>使用动态规划，record记录num的对应位的翻译数目，动态规划的转移方程如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">record[i+<span class="hljs-number">1</span>] = record[i] <span class="hljs-keyword">if</span> tempnum&gt;<span class="hljs-number">25</span> <span class="hljs-keyword">or</span> tempnum&lt;<span class="hljs-number">10</span> <span class="hljs-keyword">else</span> record[i]+record[i-<span class="hljs-number">1</span>]<br></code></pre></td></tr></tbody></table></figure><p><code>tempnum</code>表示此位和前一位组成的数字，注意<code>tempnum</code>的范围，如果小于10，则还是等于前一位的record。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">translateNum</span>(<span class="hljs-params">self, num: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-keyword">if</span> num&lt;<span class="hljs-number">10</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>        record = [<span class="hljs-number">1</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">32</span>)]<br>        s = <span class="hljs-built_in">str</span>(num)<br>        <span class="hljs-keyword">for</span> i,x <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(s):<br>            <span class="hljs-keyword">if</span> i==<span class="hljs-number">0</span>: <span class="hljs-keyword">continue</span><br>            temp = s[i-<span class="hljs-number">1</span>]+s[i]<br>            tempnum = <span class="hljs-built_in">int</span>(temp)<br>            record[i+<span class="hljs-number">1</span>] = record[i] <span class="hljs-keyword">if</span> tempnum&gt;<span class="hljs-number">25</span> <span class="hljs-keyword">or</span> tempnum&lt;<span class="hljs-number">10</span> <span class="hljs-keyword">else</span> record[i]+record[i-<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">return</span> record[<span class="hljs-built_in">len</span>(s)]<br></code></pre></td></tr></tbody></table></figure><p>瞻仰一下大佬的代码：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">translateNum</span>(<span class="hljs-params">self, num: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        s = <span class="hljs-built_in">str</span>(num)<br>        a = b = <span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>, <span class="hljs-built_in">len</span>(s) + <span class="hljs-number">1</span>):<br>            a, b = (a + b <span class="hljs-keyword">if</span> <span class="hljs-string">"10"</span> &lt;= s[i - <span class="hljs-number">2</span>:i] &lt;= <span class="hljs-string">"25"</span> <span class="hljs-keyword">else</span> a), a<br>        <span class="hljs-keyword">return</span> a<br></code></pre></td></tr></tbody></table></figure><p>实际上只需要两个信息就可以推断当前的record，a表示当前信息，b为前一位信息，使用a，b来更新后续信息。</p>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>动态规划</category>
      
    </categories>
    
    
    <tags>
      
      <tag>动态规划</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据分析笔记--神经网络</title>
    <link href="/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis11/"/>
    <url>/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis11/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本科实训的时候记录的数据分析的笔记，感觉还挺全面的，部署到博客中，今后对数据分析的应用可以方便回顾。😶</p></blockquote><blockquote><p>本篇主要内容是神经网络，简要介绍概念和反向传播，后面是sklearn ​来​建模​哈​。☀️</p></blockquote><h1>1 神经网络 ⏳</h1><h2 id="1-1-BP神经网络">1.1 BP神经网络</h2><p><img src="https://picture.mulindya.com/image-20210128233510841.png" alt=""></p><p>根据真实值，对于偏置和权重进行更新</p><p><img src="https://picture.mulindya.com/image-20210129000757438.png" alt=""></p><h2 id="1-2-计算">1.2 计算</h2><blockquote><p>神经元4：0.332</p><p>神经元5：0.525</p><p>神经元6：0.474</p><p>Err6 = 0.1311 Err4 = -0.0087 Err5 = -0.0065</p><p>学习率为：0.9</p><p>更新：</p><p>权重更新：</p><p>w46 = -0.3 + 0.9*0.1311*0.332 = -0.261          w56 = -0.2 + 0.9*0.1311*0.525 = 0.138</p><p>w14 = -0.2 + 0.9*-0.0087*1 = 0.192                 w15 = -0.3 + 0.9*-0.0065* = -0.306</p><p>w24 = -0.4 + 0.9*-0.0087*0 = -0.4                    w25 = -0.1 + 0.9*-0.0065*0 = 0.1</p><p>w34 = -0. + 0.9*-0.0087*1 = -0.508                  w35 = 0.2 + 0.9*-0.0065*1 = 0.194</p><p>偏置项更新：</p><p>θ6 = 0.1+0.9*0.1311 = 0.218                              θ5 = 0.2+0.9*-0.0065 = 0.194</p><p>θ4 = -0.4+0.9*-0.0087 = -0.408</p></blockquote><h1>2 案例分析 🔆</h1><h2 id="2-1-切分特征值和目标值">2.1 切分特征值和目标值</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">feature = data.loc[:,<span class="hljs-string">'gender'</span>:]<br><span class="hljs-built_in">print</span>(feature.head())<br>label = data[<span class="hljs-string">'churn'</span>]<br><span class="hljs-built_in">print</span>(label.head())<br></code></pre></td></tr></tbody></table></figure><h2 id="2-2-将数据集进行切分">2.2 将数据集进行切分</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br>X_train,X_test,y_train,y_test = train_test_split(feature,label)<br></code></pre></td></tr></tbody></table></figure><p>#神经网络需要对数据进行极差标准化 是一个黑盒模型<br>#变量是连续变量，分类变量 一般数据处理要求进行极差标准化 分类变量需要转换为虚拟变量<br>#但是也可以特殊处理 多分类名义变量必须转化为寻变量 等级变量和二分类变量可以不转换当作连续变量处理</p><h2 id="2-3-利用数据进行训练转换器">2.3 利用数据进行训练转换器</h2><p>应用训练集x数据的固有属性，将其应用于训练集和测试集</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> MinMaxScaler<br>scaler = MinMaxScaler()<br>scaler.fit(X_train)<br><span class="hljs-comment">#得到数据转化之后的数据</span><br>scaler_train_data = scaler.transform(X_train)<br>scaler_test_data = scaler.transform(X_test)<br></code></pre></td></tr></tbody></table></figure><h2 id="2-4-构建感知器模型">2.4 构建感知器模型</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#设置一个隐藏层 和10个神经元</span><br><span class="hljs-keyword">from</span> sklearn.neural_network <span class="hljs-keyword">import</span> MLPClassifier<br>mlp = MLPClassifier(hidden_layer_sizes=(<span class="hljs-number">10</span>,),activation=<span class="hljs-string">'logistic'</span>)<br>mlp.fit(scaler_train_data,y_train)<br></code></pre></td></tr></tbody></table></figure><h2 id="2-5-预测模型">2.5 预测模型</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">y_predict = mlp.predict(scaler_test_data)<br></code></pre></td></tr></tbody></table></figure><h2 id="2-6-评估模型">2.6 评估模型</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sklearn.metrics <span class="hljs-keyword">as</span> metrics<br><span class="hljs-built_in">print</span>(metrics.classification_report(y_test,y_predict))<br><span class="hljs-comment">#混淆矩阵</span><br><span class="hljs-built_in">print</span>(metrics.confusion_matrix(y_test,y_predict,labels=[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>]))<br><span class="hljs-comment">#平均准确率</span><br>mlp.score(scaler_test_data,y_test)<br></code></pre></td></tr></tbody></table></figure><h2 id="2-7-寻找最优参数">2.7 寻找最优参数</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 寻找最优参数</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> GridSearchCV<br>param ={<br>    <span class="hljs-string">'hidden_layer_sizes'</span>:[(<span class="hljs-number">10</span>,),(<span class="hljs-number">20</span>,)],<br>    <span class="hljs-string">'activation'</span>:[ <span class="hljs-string">'logistic'</span>, <span class="hljs-string">'tanh'</span>, <span class="hljs-string">'relu'</span>],<br>    <span class="hljs-string">'alpha'</span>:[<span class="hljs-number">0.001</span>,<span class="hljs-number">0.1</span>,<span class="hljs-number">0.01</span>]<br>}<br>newmlp = MLPClassifier(max_iter=<span class="hljs-number">1000</span>)<br><span class="hljs-comment">#cv=5表示5折交叉验证</span><br>gsc = GridSearchCV(estimator=newmlp,param_grid=param,scoring=<span class="hljs-string">'roc_auc'</span>,cv=<span class="hljs-number">5</span>)<br>gsc.fit(scaler_train_data,y_train)<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数据分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>数据分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据分析笔记--朴素贝叶斯</title>
    <link href="/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis10/"/>
    <url>/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis10/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本科实训的时候记录的数据分析的笔记，感觉还挺全面的，部署到博客中，今后对数据分析的应用可以方便回顾。😶</p></blockquote><blockquote><p>本篇主要内容是朴素贝叶斯，也是一个分类模型​，​具体​貌似用的而不太多​，​所以我好像不是特别清楚，看后续是否需要再了解一下。☀️</p></blockquote><h1>1 朴素贝叶斯 🔔</h1><h2 id="1-1-定义">1.1 定义</h2><p>分类模型，构造基础贝叶斯理论</p><p>朴素贝叶斯是基于贝叶斯定理和全概率公式，可以计算在自变量一定取值条件下，因变量的条件概率限制了自变量的取值类型（<strong>分类变量</strong>），并且自变量<strong>相互独立</strong>；</p><h2 id="1-2-公式">1.2 公式</h2><h3 id="1-2-1-全概率公式">1.2.1 全概率公式</h3><p><img src="https://picture.mulindya.com/image-20210128105624694.png" alt=""></p><h3 id="1-2-2-贝叶斯公式">1.2.2 贝叶斯公式</h3><p><img src="https://picture.mulindya.com/image-20210128105642741.png" alt=""></p><h3 id="1-2-3-高斯模型">1.2.3 高斯模型</h3><table><thead><tr><th>模型</th><th>头文件</th><th>说明</th></tr></thead><tbody><tr><td>高斯模型</td><td>from sklearn.naive_bayes import GaussianNB</td><td>有些特征可能是连续型变量</td></tr><tr><td>伯努利模型</td><td>from sklearn.naive_bayes import BernoulliNB</td><td>使用特征为全局特征，在伯努利模型中，每个特征的特征是布尔类型</td></tr><tr><td>多项式模型</td><td>from sklearn.naive_bayes import MultinomialNB</td><td>常用文本分类 特征是单词值出现的次数</td></tr></tbody></table><h2 id="1-3-拉普拉斯平滑系数">1.3 拉普拉斯平滑系数</h2><p>出现原因：在训练样本过程中，可能出现一些特征的缺失，某些特征出现的次数为0,以此方式计算时可能最终结果为0；<br>$$<br>p(x1,x2,x3,…|yi) = p(x1|yi)p(x2|yi)p(x3|yi)<br>$$</p><p>$$<br>pi = (Ni+a)/(N+a*m)<br>$$</p><p>a：平滑系数；m：特征值向量个数；a=1时称为拉普拉斯平滑</p><h1>2 文本特征提取 🎐</h1><p>用于文档分类 垃圾邮件分类 新闻分类 文本分类是通过词是否存在或者词的重要性（概率）来表示</p><h2 id="2-1-文档中词的出现">2.1 文档中词的出现</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> CountVectorizer<br>data2 = [<br>    <span class="hljs-string">'i love python'</span>,<br>    <span class="hljs-string">'life is short,i use python'</span>,<br>    <span class="hljs-string">'i dislike python'</span><br>]<br>cv = CountVectorizer()<br>cv.fit_transform(data2).toarray()<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">array([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>       [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>       [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]], dtype=int64)<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">cv.get_feature_names()<br>结果为：[<span class="hljs-string">'dislike'</span>, <span class="hljs-string">'is'</span>, <span class="hljs-string">'life'</span>, <span class="hljs-string">'love'</span>, <span class="hljs-string">'python'</span>, <span class="hljs-string">'short'</span>, <span class="hljs-string">'use'</span>]<br></code></pre></td></tr></tbody></table></figure><h2 id="2-2-文章中词的重要性">2.2 文章中词的重要性</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> TfidfVectorizer<br>tv = TfidfVectorizer(stop_words=<span class="hljs-string">'english'</span>)<br>tv.fit_transform(data2).toarray()<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">array([[<span class="hljs-number">0.</span>        , <span class="hljs-number">0.</span>        , <span class="hljs-number">0.861037</span>  , <span class="hljs-number">0.50854232</span>, <span class="hljs-number">0.</span>        ,<br>        <span class="hljs-number">0.</span>        ],<br>       [<span class="hljs-number">0.</span>        , <span class="hljs-number">0.54645401</span>, <span class="hljs-number">0.</span>        , <span class="hljs-number">0.32274454</span>, <span class="hljs-number">0.54645401</span>,<br>        <span class="hljs-number">0.54645401</span>],<br>       [<span class="hljs-number">0.861037</span>  , <span class="hljs-number">0.</span>        , <span class="hljs-number">0.</span>        , <span class="hljs-number">0.50854232</span>, <span class="hljs-number">0.</span>        ,<br>        <span class="hljs-number">0.</span>        ]])<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">tv.vocabulary_<br>结果是 {<span class="hljs-string">'love'</span>: <span class="hljs-number">2</span>, <span class="hljs-string">'python'</span>: <span class="hljs-number">3</span>, <span class="hljs-string">'life'</span>: <span class="hljs-number">1</span>, <span class="hljs-string">'short'</span>: <span class="hljs-number">4</span>, <span class="hljs-string">'use'</span>: <span class="hljs-number">5</span>, <span class="hljs-string">'dislike'</span>: <span class="hljs-number">0</span>}<br>tv.get_feature_names()<br>结果是 [<span class="hljs-string">'dislike'</span>, <span class="hljs-string">'life'</span>, <span class="hljs-string">'love'</span>, <span class="hljs-string">'python'</span>, <span class="hljs-string">'short'</span>, <span class="hljs-string">'use'</span>]<br></code></pre></td></tr></tbody></table></figure><h2 id="2-3-关于中文文章进行分析的问题">2.3 关于中文文章进行分析的问题</h2><h3 id="2-3-1-结巴分词">2.3.1 结巴分词</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> jieba<br>data3 = [<br>    <span class="hljs-string">'因为在实际的训练中，训练的结果对于训练集的拟合程度通常还是挺好的'</span>,<br>    <span class="hljs-string">'但是对于训练集之外的数据的拟合程度通常就不那么令人满意了。'</span>,<br>    <span class="hljs-string">'因此我们通常并不会把所有的数据集都拿来训练'</span><br>]<br>datalist=[]<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(data3)):<br>    newlist=[]<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> jieba.cut(data3[i]):<br>        newlist.append(j)<br>    content = (<span class="hljs-string">' '</span>).join(newlist)<br>    datalist.append(content)<br>ch_tf = TfidfVectorizer(stop_words=[<span class="hljs-string">'的'</span>,<span class="hljs-string">'（'</span>,<span class="hljs-string">'）'</span>,<span class="hljs-string">'，'</span>,<span class="hljs-string">'。'</span>,<span class="hljs-string">'了'</span>])<br>ch_tf.fit_transform(datalist).toarray() <br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">array([[<span class="hljs-number">0.</span>        , <span class="hljs-number">0.</span>        , <span class="hljs-number">0.</span>        , <span class="hljs-number">0.</span>        , <span class="hljs-number">0.32927047</span>,<br>        <span class="hljs-number">0.</span>        , <span class="hljs-number">0.32927047</span>, <span class="hljs-number">0.25041868</span>, <span class="hljs-number">0.</span>        , <span class="hljs-number">0.</span>        ,<br>        <span class="hljs-number">0.25041868</span>, <span class="hljs-number">0.</span>        , <span class="hljs-number">0.</span>        , <span class="hljs-number">0.25041868</span>, <span class="hljs-number">0.32927047</span>,<br>        <span class="hljs-number">0.58341732</span>, <span class="hljs-number">0.32927047</span>, <span class="hljs-number">0.19447244</span>, <span class="hljs-number">0.</span>        , <span class="hljs-number">0.</span>        ],<br>       [<span class="hljs-number">0.</span>        , <span class="hljs-number">0.37766105</span>, <span class="hljs-number">0.37766105</span>, <span class="hljs-number">0.37766105</span>, <span class="hljs-number">0.</span>        ,<br>        <span class="hljs-number">0.</span>        , <span class="hljs-number">0.</span>        , <span class="hljs-number">0.28722096</span>, <span class="hljs-number">0.</span>        , <span class="hljs-number">0.</span>        ,<br>        <span class="hljs-number">0.28722096</span>, <span class="hljs-number">0.</span>        , <span class="hljs-number">0.28722096</span>, <span class="hljs-number">0.28722096</span>, <span class="hljs-number">0.</span>        ,<br>        <span class="hljs-number">0.2230527</span> , <span class="hljs-number">0.</span>        , <span class="hljs-number">0.2230527</span> , <span class="hljs-number">0.37766105</span>, <span class="hljs-number">0.</span>        ],<br>       [<span class="hljs-number">0.37072514</span>, <span class="hljs-number">0.</span>        , <span class="hljs-number">0.</span>        , <span class="hljs-number">0.</span>        , <span class="hljs-number">0.</span>        ,<br>        <span class="hljs-number">0.37072514</span>, <span class="hljs-number">0.</span>        , <span class="hljs-number">0.</span>        , <span class="hljs-number">0.37072514</span>, <span class="hljs-number">0.37072514</span>,<br>        <span class="hljs-number">0.</span>        , <span class="hljs-number">0.37072514</span>, <span class="hljs-number">0.28194602</span>, <span class="hljs-number">0.</span>        , <span class="hljs-number">0.</span>        ,<br>        <span class="hljs-number">0.21895624</span>, <span class="hljs-number">0.</span>        , <span class="hljs-number">0.21895624</span>, <span class="hljs-number">0.</span>        , <span class="hljs-number">0.37072514</span>]])<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python">ch_tf.get_feature_names()<br>结果是 [<span class="hljs-string">'不会'</span>,<br> <span class="hljs-string">'之外'</span>,<br> <span class="hljs-string">'令人满意'</span>,<br> <span class="hljs-string">'但是'</span>,<br> <span class="hljs-string">'因为'</span>,<br> <span class="hljs-string">'因此'</span>,<br> <span class="hljs-string">'实际'</span>,<br> <span class="hljs-string">'对于'</span>,<br> <span class="hljs-string">'我们'</span>,<br> <span class="hljs-string">'所有'</span>,<br> <span class="hljs-string">'拟合'</span>,<br> <span class="hljs-string">'拿来'</span>,<br> <span class="hljs-string">'数据'</span>,<br> <span class="hljs-string">'程度'</span>,<br> <span class="hljs-string">'结果'</span>,<br> <span class="hljs-string">'训练'</span>,<br> <span class="hljs-string">'还是'</span>,<br> <span class="hljs-string">'通常'</span>,<br> <span class="hljs-string">'那么'</span>,<br> <span class="hljs-string">'集都'</span>]<br></code></pre></td></tr></tbody></table></figure><h1></h1>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数据分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>数据分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据分析笔记--KNN</title>
    <link href="/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis9/"/>
    <url>/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis9/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本科实训的时候记录的数据分析的笔记，感觉还挺全面的，部署到博客中，今后对数据分析的应用可以方便回顾。😶</p></blockquote><blockquote><p>本篇主要内容是KNN，是一个分类算法；注意点是距离的选取方式。这里的案例分析值得学习一下，可以学习sklearn的相关用法。☀️</p></blockquote><h1>1 KNN 🎅</h1><h2 id="1-1-k近邻">1.1 k近邻</h2><p>最近邻域法：属于惰性算法</p><p>特点：不必事先创建全局的判别公式或者规则</p><h2 id="1-2-k近邻的算法">1.2 k近邻的算法</h2><ol><li>为了判别未知数据的类别，以所有已知的类别实例作为参考</li><li>重要步骤:计算未知实例与所有已知实例的距离</li><li>选择参考的实例参数k</li><li>根据少数服从多数的原则，让未知的实例归类于k个最近邻样本中最多数的类别（投票法则）</li></ol><h2 id="1-3-距离的算法选择">1.3 距离的算法选择</h2><h3 id="1-3-1-欧氏距离">1.3.1 欧氏距离</h3><p>欧几里得度量（euclidean metric）（也称欧氏距离）是一个通常采用的距离定义，指在m维空间中两个点之间的真实距离，或者向量的自然长度（即该点到原点的距离）。在二维和三维空间中的欧氏距离就是两点之间的实际距离。<br>$$<br>\rho = \sqrt{(x_2-x_1)<sup>2+(y_2-y_1)</sup>2}<br>$$</p><h3 id="1-3-2-闵可夫斯基距离：">1.3.2 闵可夫斯基距离：</h3><p>闵氏距离有时也指<a href="https://baike.baidu.com/item/%E6%97%B6%E7%A9%BA%E9%97%B4%E9%9A%94/894418">时空间隔</a></p><p>②设n维空间中有两点坐标x, y，p为常数，闵式距离定义为 [1]</p>$$D(x,y) = (\sum_{u=1}^n|x_u - y_u|^p)^{\frac{1}{p}}$$<p>注意：</p><p>（1）闵氏距离与特征参数的量纲有关，有不同量纲的特征参数的闵氏距离常常是无意义的。</p><p>（2）闵氏距离没有考虑特征参数间的相关性，而马哈拉诺比斯距离解决了这个问题。</p><h3 id="1-3-3-曼哈顿距离">1.3.3 曼哈顿距离</h3><p>两点在南北方向上的距离加上在东西方向上的距离，即$d(i,j)=|x_i-x_j|+|y_i-y_j|$​。</p><h3 id="1-3-4-对比说明">1.3.4 对比说明</h3><p>欧式距离使用得最多 <strong>连续占比较大时使用欧式距离</strong> 分类变量</p><p><strong>连续占比较小时使用曼哈顿距离</strong>  虚拟变量</p><h2 id="1-4-交叉验证">1.4 交叉验证</h2><p>在使用训练集对参数进行训练的时候，经常会发现人们通常会将一整个训练集分为三个部分（比如mnist手写训练集）。一般分为：训练集（train_set），评估集（valid_set），测试集（test_set）这三个部分。这其实是为了保证训练效果而特意设置的。其中测试集很好理解，其实就是完全不参与训练的数据，仅仅用来观测测试效果的数据。而训练集和评估集则牵涉到下面的知识了。</p><p>因为在实际的训练中，训练的结果对于训练集的拟合程度通常还是挺好的（初始条件敏感），但是对于训练集之外的数据的拟合程度通常就不那么令人满意了。因此我们通常并不会把所有的数据集都拿来训练，而是分出一部分来（这一部分不参加训练）对训练集生成的参数进行测试，相对客观的判断这些参数对训练集之外的数据的符合程度。这种思想就称为交叉验证（Cross Validation）。</p><p><em><strong>K-fold Cross Validation</strong></em></p><p>另外一种折中的办法叫做K折交叉验证，和LOOCV的不同在于，我们每次的测试集将不再只包含一个数据，而是多个，具体数目将根据K的选取决定。比如，如果K=5，那么我们利用五折交叉验证的步骤就是：</p><p>1.将所有数据集分成5份</p><p>2.不重复地每次取其中一份做测试集，用其他四份做训练集训练模型，之后计算该模型在测试集上的<img src="https://www.zhihu.com/equation?tex=MSE_i" alt="[公式]"></p><p>3.将5次的<img src="https://www.zhihu.com/equation?tex=MSE_i" alt="[公式]">取平均得到最后的MSE</p>$$CV_{(k)} = \frac{1}{k} \sum_{i=1}^k MSE_i$$<h2 id="1-5-ROC-AUC">1.5 ROC AUC</h2><h3 id="1-5-1-ROC曲线">1.5.1 ROC曲线</h3><p><img src="https://picture.mulindya.com/image-20210127114408570.png" alt=""></p><p>受试者工作特征曲线</p><p>ROC曲线的横坐标是假阳性率（FPR）纵坐标是真阳性率（TPR）</p><p>假阳性率：在实际为0 被错误判定为1比例</p><p>真阳性率：在实际为1 被正确判定为1比例</p><p><img src="https://picture.mulindya.com/image-20210127114531940.png" alt=""></p><p><img src="https://picture.mulindya.com/image-20210127114733950.png" alt=""></p><h3 id="1-5-2-AUC">1.5.2 AUC</h3><p>AUC（Area Under Curve）被定义为<a href="https://baike.baidu.com/item/ROC%E6%9B%B2%E7%BA%BF/775606">ROC曲线</a>下与<a href="https://baike.baidu.com/item/%E5%9D%90%E6%A0%87%E8%BD%B4/9763108">坐标轴</a>围成的<a href="https://baike.baidu.com/item/%E9%9D%A2%E7%A7%AF/100551">面积</a>，显然这个面积的数值不会大于1。又由于<a href="https://baike.baidu.com/item/ROC%E6%9B%B2%E7%BA%BF/775606">ROC曲线</a>一般都处于y=x这条直线的上方，所以AUC的取值范围在0.5和1之间。AUC越接近1.0，检测方法真实性越高;等于0.5时，则真实性最低，无应用价值。</p><p><strong>从AUC 判断分类器（预测模型）优劣的标准：</strong></p><ul><li>AUC = 1，是完美分类器。</li><li>AUC = [0.85, 0.95], 效果很好</li><li>AUC = [0.7, 0.85], 效果一般</li><li>AUC = [0.5, 0.7],效果较低，但用于预测股票已经很不错了</li><li>AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。</li><li>AUC &lt; 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。</li></ul><h1>2 案例分析 🐱</h1><h2 id="2-1-数据预处理">2.1 数据预处理</h2><h3 id="2-1-1-极差标准化">2.1.1 极差标准化</h3><p>$$<br>x’ = (x - min(X))/(max(X)-min(X))<br>$$</p><h3 id="2-1-2-中心标准化">2.1.2 中心标准化</h3><h3 id="2-1-3-哑变量生成">2.1.3 哑变量生成</h3><h3 id="2-1-4-代码">2.1.4 代码</h3><p>提取特征值</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">features = data.loc[:,<span class="hljs-string">'income'</span>:<span class="hljs-string">'edueduclass'</span>]<br>features.head()<br></code></pre></td></tr></tbody></table></figure><p>提取目标值</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">label = data.Dated<br>label.head()<br></code></pre></td></tr></tbody></table></figure><p>连续变量进行预处理，进行数据标准化，消除量纲不一致对各个变量产生得影响；</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 数据预处理</span><br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing<br>min_max_sca = preprocessing.MinMaxScaler()<br>features_sca = min_max_sca.fit_transform(features)<br></code></pre></td></tr></tbody></table></figure><h2 id="2-2-切割数据集">2.2 切割数据集</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br>X_train, X_test, y_train, y_test = train_test_split(features_sca,label,test_size=<span class="hljs-number">0.2</span>)<br></code></pre></td></tr></tbody></table></figure><h2 id="2-3-使用k近邻训练模型">2.3 使用k近邻训练模型</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier<br><span class="hljs-comment">#模型训练</span><br>model = KNeighborsClassifier()<br>model.fit(X_train,y_train)<br></code></pre></td></tr></tbody></table></figure><h2 id="2-4-预测">2.4 预测</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">y_predict = model.predict(X_test)<br></code></pre></td></tr></tbody></table></figure><h2 id="2-5-评估训练结果">2.5 评估训练结果</h2><p>model.score（）：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: model.score(X, y, sample_weight=<span class="hljs-literal">None</span>)<br>Docstring:<br>Returns the mean accuracy on the given test data <span class="hljs-keyword">and</span> labels.<br><br>In multi-label classification, this <span class="hljs-keyword">is</span> the subset accuracy<br>which <span class="hljs-keyword">is</span> a harsh metric since you require <span class="hljs-keyword">for</span> each sample that<br>each label <span class="hljs-built_in">set</span> be correctly predicted.<br></code></pre></td></tr></tbody></table></figure><p>metrics.classification_report（）</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: metrics.classification_report(y_true, y_pred, labels=<span class="hljs-literal">None</span>, target_names=<span class="hljs-literal">None</span>, sample_weight=<span class="hljs-literal">None</span>, digits=<span class="hljs-number">2</span>, output_dict=<span class="hljs-literal">False</span>)<br>Docstring:<br>Build a text report showing the main classification metrics<br><br>Read more <span class="hljs-keyword">in</span> the :ref:`User Guide &lt;classification_report&gt;`.<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sklearn.metrics <span class="hljs-keyword">as</span> metrics<br><span class="hljs-built_in">print</span>(metrics.classification_report(y_test,y_predict))<br><span class="hljs-comment">#计算平均准确率</span><br>model.score(X_test,y_test)<br></code></pre></td></tr></tbody></table></figure><h2 id="2-6-找出最优参数">2.6 找出最优参数</h2><h3 id="2-6-1-找出最优得参数-k值">2.6.1 找出最优得参数 k值</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">x =[]<br>y=[]<br><span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">70</span>):<br>    modelk = KNeighborsClassifier(n_neighbors=item)<br>    modelk.fit(X_train,y_train)<br>    score = modelk.score(X_test,y_test)<br>    x.append(item)<br>    y.append(score)<br>   <span class="hljs-comment"># print("当k的值为：",item,'score is',score)</span><br></code></pre></td></tr></tbody></table></figure><h3 id="2-6-2-交叉验证">2.6.2 交叉验证</h3><p>当样本量较小时，适合采用交叉验证 评估模型的效果 需要设定用户搜索空间</p><p>十折交叉验证</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> ParameterGrid,GridSearchCV<br>grid = ParameterGrid({<span class="hljs-string">'n_neighbors'</span>:[<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">15</span>)]})<br>new_model = KNeighborsClassifier()<br>knn_cv = GridSearchCV(new_model,grid,cv=<span class="hljs-number">10</span>,scoring=<span class="hljs-string">'roc_auc'</span>)<br>knn_cv.fit(X_train,y_train)<br></code></pre></td></tr></tbody></table></figure><p>GridSearchCV(new_model,grid,cv=10,scoring=‘roc_auc’)中cv=10表示十折，评估标准是roc_auc</p><h3 id="2-6-3-获取AUC">2.6.3 获取AUC</h3><p>获取测试集上的AUC的值</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">metrics.roc_auc_score(y_test,knn_cv.predict(X_test))<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数据分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>数据分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据分析笔记--决策树</title>
    <link href="/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis8/"/>
    <url>/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis8/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本科实训的时候记录的数据分析的笔记，感觉还挺全面的，部署到博客中，今后对数据分析的应用可以方便回顾。😶</p></blockquote><blockquote><p>本篇主要内容是决策树，简要介绍决策树的相关概念和指标。</p></blockquote><h1>决策树 🌲</h1><p>一条信息的信息量大小和它的不确定性有直接关系</p><h2 id="1-1-熵">1.1 熵</h2><h3 id="1-1-1-信息熵">1.1.1 信息熵</h3><p>信息熵：判定信息的大小</p><p>信息熵的单位：比特</p><p><img src="https://picture.mulindya.com/image-20210126091622561.png" alt=""></p><h3 id="1-1-2-条件熵">1.1.2 条件熵</h3><p>其中log底数为2</p><p><img src="https://picture.mulindya.com/image-20210126093728857.png" alt=""></p><p>信息获取量：通过特征字段作为节点分类获取了多少信息；</p><h2 id="1-2-ID3算法">1.2 ID3算法</h2><h3 id="1-2-1-信息增益">1.2.1 信息增益</h3><p>信息增益：信息熵-条件熵；信息增益越大，则表示使用其属性进行分类决策后获得的“纯度提升”越大；</p><p>选择对大的信息增益作为分类节点</p><p><img src="https://picture.mulindya.com/image-20210126094613560.png" alt=""></p><h3 id="1-2-2-对比">1.2.2 对比</h3><p>id3是对于分类变量分析，因此需要连续变量离散化</p><p><img src="https://picture.mulindya.com/image-20210126102244168.png" alt=""></p><h2 id="1-3-C4-5">1.3 C4.5</h2><p>信息增益率：在自变量A条件下，目标变量D的信息增益/自变量A的信息熵</p><p><img src="https://picture.mulindya.com/image-20210126102502529.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数据分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>数据分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据分析笔记--逻辑回归</title>
    <link href="/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis7/"/>
    <url>/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis7/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本科实训的时候记录的数据分析的笔记，感觉还挺全面的，部署到博客中，今后对数据分析的应用可以方便回顾。😶</p></blockquote><blockquote><p>本篇主要内容是逻辑回归，虽然名字称作回归，但是这个是针对分类的算法哦！标记星号⭐️</p></blockquote><h1>1 分类算法–逻辑回归</h1><p>因变量常为二分类变量，他的自变量既可以是分类变量又可以是连续变量，逻辑回归也可以做多分类哈！也就是使用逻辑回归看这个变量是否被选中，然后再投票就好啦，或者使用softmax也是可以哒。</p><blockquote><p>这里有两种方法使得逻辑回归能进行多分类任务：</p><p>一、将多分类任务拆解成多个二分类任务，利用逻辑回归分类器进行投票求解；</p><p>二、对传统的逻辑回归模型进行改造，使之变为 softmax 回归模型进行多分类任务求解</p></blockquote><h2 id="1-1-特点">1.1 特点</h2><p>能够将输入的特征数据来转化为0，1这两类的概率</p><h2 id="1-2-本质">1.2 本质</h2><p>通过特征值和目标值的<strong>线性方程</strong>，计算出结果后，通过<code>sigmoid</code>映射函数，将连续型数值转换到0-1区间内，一般情况下，LR算法用于二分类问题；</p><h2 id="1-3-映射函数">1.3 映射函数</h2><p><img src="https://picture.mulindya.com/image-20210125104950928.png" alt=""></p><h1>2 案例分析</h1><p>分类变量相关分析 ：列联表分析和卡方检验，连续自变量和二分类因变量的独立性可以用双样本t检验；</p><h2 id="2-1-预处理操作和分析">2.1 预处理操作和分析</h2><p><strong>卡方检验（二分类变量关系）</strong></p><p><img src="https://picture.mulindya.com/image-20210125094325832.png" alt=""></p><h3 id="2-1-1-删除空值的行">2.1.1 删除空值的行</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data = data.dropna(axis=<span class="hljs-number">0</span>,how=<span class="hljs-string">'any'</span>)<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: data.dropna(axis=<span class="hljs-number">0</span>, how=<span class="hljs-string">'any'</span>, thresh=<span class="hljs-literal">None</span>, subset=<span class="hljs-literal">None</span>, inplace=<span class="hljs-literal">False</span>)<br>Docstring:<br>Remove missing values.<br><br>See the :ref:`User Guide &lt;missing_data&gt;` <span class="hljs-keyword">for</span> more on which values are<br>considered missing, <span class="hljs-keyword">and</span> how to work <span class="hljs-keyword">with</span> missing data.<br>how : {<span class="hljs-string">'any'</span>, <span class="hljs-string">'all'</span>}, default <span class="hljs-string">'any'</span><br>    Determine <span class="hljs-keyword">if</span> row <span class="hljs-keyword">or</span> column <span class="hljs-keyword">is</span> removed <span class="hljs-keyword">from</span> DataFrame, when we have<br>    at least one NA <span class="hljs-keyword">or</span> <span class="hljs-built_in">all</span> NA.<br><br>    * <span class="hljs-string">'any'</span> : If <span class="hljs-built_in">any</span> NA values are present, drop that row <span class="hljs-keyword">or</span> column.<br>    * <span class="hljs-string">'all'</span> : If <span class="hljs-built_in">all</span> values are NA, drop that row <span class="hljs-keyword">or</span> column.<br></code></pre></td></tr></tbody></table></figure><h3 id="2-1-2-分析相关关系">2.1.2 分析相关关系</h3><p>曾经破产与是否违约是否存在相关关系</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pd.crosstab(data.bankruptcy_ind,data.bad_ind,margins=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right">bankruptcy_ind\ bad_ind</th><th style="text-align:right">0</th><th style="text-align:right">1</th><th style="text-align:right">All</th></tr></thead><tbody><tr><td style="text-align:right">N</td><td style="text-align:right">3076</td><td style="text-align:right">719</td><td style="text-align:right">3795</td></tr><tr><td style="text-align:right">Y</td><td style="text-align:right">243</td><td style="text-align:right">67</td><td style="text-align:right">310</td></tr><tr><td style="text-align:right">All</td><td style="text-align:right">3319</td><td style="text-align:right">786</td><td style="text-align:right">4105</td></tr></tbody></table><h3 id="2-1-3-列联表">2.1.3 列联表</h3><p>列联表（contingency table）是观测数据按两个或者更多变量分类时列出的观测表；</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">func1</span>(<span class="hljs-params">x</span>):</span><br>    <span class="hljs-string">'当前函数是实现两个变量的列联表'</span><br>    <span class="hljs-comment">#print(x)</span><br>    <span class="hljs-keyword">return</span> x/<span class="hljs-built_in">float</span>(x[-<span class="hljs-number">1</span>])<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">cross_tab.apply(func1,axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></tbody></table></figure><h3 id="2-1-4卡方检验">2.1.4卡方检验</h3><p>卡方检验就是统计样本的实际观测值与理论推断值之间的偏离程度;<br>实际观测值与理论推断值之间的偏离程度就决定卡方值的大小;<br>如果卡方值越大，二者偏差程度越大；反之，二者偏差越小；若两个值完全相等时;<br>卡方值就为0，表明理论值完全符合。注意：卡方检验针对分类变量。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#两个变量卡方检验</span><br>stats.chi2_contingency(cross_tab.iloc[:<span class="hljs-number">2</span>,:<span class="hljs-number">2</span>])<br></code></pre></td></tr></tbody></table></figure><figure class="highlight clojure"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs clojure">(<span class="hljs-number">1.1500371741720943</span>,<br> <span class="hljs-number">0.28354136789919926</span>,<br> <span class="hljs-number">1</span>,<br> array([[<span class="hljs-number">3068.35688185</span>,  <span class="hljs-number">726.64311815</span>],<br>        [ <span class="hljs-number">250.64311815</span>,   <span class="hljs-number">59.35688185</span>]]))<br></code></pre></td></tr></tbody></table></figure><p>p值为0.28 说明破产是否违约没有显著相关</p><h2 id="2-2-回归分析">2.2 回归分析</h2><h3 id="2-2-1-数据集切割">2.2.1 数据集切割</h3><p>在训练模型之前， 需要对数据进行拆分 ，暂时将数据分为训练集和测试集；</p><p>训练集用来进行模型的训练 7 8（占比最大，过小会欠拟合）<br>测试集用来评估模型的优劣 3 2</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#选取80%的数据作为训练集数据 使用简单随机抽样</span><br>train_data = data.sample(frac=<span class="hljs-number">0.8</span>,random_state=<span class="hljs-number">2021</span>) <span class="hljs-comment">#数据按比例切分</span><br><span class="hljs-comment">#测试样本</span><br>test_data = data[~data.index.isin(train_data.index)]<br></code></pre></td></tr></tbody></table></figure><h3 id="2-2-2-模型训练">2.2.2 模型训练</h3><p>**在进行模型训练的过程中 与线性回归类似 但是指定使用广义线性回归 并且指定使用logit变换对数据进行处理 **</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">model = sfa.glm(<span class="hljs-string">'bad_ind~fico_score'</span>,data = train_data,family=sa.families.Binomial(sa.families.links.logit)).fit()<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210125112627183.png" alt=""></p><p>即为 -0.0147*fico_score+8.5519</p><h3 id="2-2-3-向前法参数选择">2.2.3 向前法参数选择</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#向前法</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward_select</span>(<span class="hljs-params">data,label</span>):</span> <span class="hljs-comment">#data:数据 response:目标值</span><br>    <span class="hljs-comment">#todo 获取当前数据当前不重复变量</span><br>    params = <span class="hljs-built_in">set</span>(data.columns)<br>    <br>    <span class="hljs-comment">#将需要保留的变量进行存储</span><br>    selected = []<br>    <br>    <span class="hljs-comment">#将目标值移除当前变量列表</span><br>    params.remove(label)<br>    current_score = <span class="hljs-built_in">float</span>(<span class="hljs-string">'inf'</span>)<br>    best_new_score = <span class="hljs-built_in">float</span>(<span class="hljs-string">'inf'</span>)<br>    <br>    <span class="hljs-comment">#进行筛选</span><br>    <span class="hljs-keyword">while</span> params:<br>        aic_param = []<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>            <span class="hljs-comment">#前y 后x,并且多变量用加号连接,+[],相当于在数组中添加元素</span><br>            formula = <span class="hljs-string">"{}~{}"</span>.<span class="hljs-built_in">format</span>(label,<span class="hljs-string">'+'</span>.join(selected+[param]))<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">'--------------&gt;formula'</span>,formula)<br>            <br>            <span class="hljs-comment">#建立模型 拿到aic</span><br>            aic = sfa.glm(formula,data = data,family=sa.families.Binomial(sa.families.links.logit)).fit().aic<br>            aic_param.append((aic,param)) <span class="hljs-comment">#元组装包</span><br>        <span class="hljs-comment">#得到分数最小的AIC</span><br>        aic_param.sort(reverse=<span class="hljs-literal">True</span>)<br>        best_new_score,best_param = aic_param.pop()<span class="hljs-comment">#列表的最末位</span><br>        <br>        <span class="hljs-comment">#与当前得分比较</span><br>        <span class="hljs-keyword">if</span> current_score&gt;best_new_score:<br>            params.remove(best_param)<br>            selected.append(best_param)<br>            current_score = best_new_score<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">'------------*************&gt;当前current_score'</span>,current_score)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">"over"</span>)<br>            <span class="hljs-keyword">break</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"#################################################"</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"获取到符合条件的变量进行展示"</span>)<br>    <span class="hljs-built_in">print</span>(selected)<br>        <br>    <span class="hljs-comment">#拼接真正的formula</span><br>    fin_formula = <span class="hljs-string">'{}~{}'</span>.<span class="hljs-built_in">format</span>(label,<span class="hljs-string">'+'</span>.join(selected))<br>    <span class="hljs-comment"># 进行线性模型的训练</span><br>    model = sfa.glm(fin_formula,data = data,family=sa.families.Binomial(sa.families.links.logit)).fit()<br>    <span class="hljs-keyword">return</span> model<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">lavels_list = [<span class="hljs-string">'bad_ind'</span>,<span class="hljs-string">'fico_score'</span>,<span class="hljs-string">'bankruptcy_ind'</span>,<span class="hljs-string">'age_oldest_tr'</span>,<span class="hljs-string">'ltv'</span>,<span class="hljs-string">'tot_income'</span>,<span class="hljs-string">'veh_mileage'</span>,<span class="hljs-string">'used_ind'</span>]<br>data_select = train_data[lavels_list]<br>forward_select(data=data_select,label=<span class="hljs-string">'bad_ind'</span>)<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#################################################</span><br>获取到符合条件的变量进行展示<br>[<span class="hljs-string">'fico_score'</span>, <span class="hljs-string">'ltv'</span>, <span class="hljs-string">'age_oldest_tr'</span>, <span class="hljs-string">'bankruptcy_ind'</span>]<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数据分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>数据分析</tag>
      
      <tag>逻辑回归</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据分析笔记--线性回归</title>
    <link href="/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis6/"/>
    <url>/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis6/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本科实训的时候记录的数据分析的笔记，感觉还挺全面的，部署到博客中，今后对数据分析的应用可以方便回顾。😶</p></blockquote><blockquote><p>本篇主要内容是线性回归，灰常重点，也很基础的内容，概念不难理解，主要可以关注多元线性回归中的变量筛选。还有实例代码和操作流程！标记星号⭐️</p></blockquote><h1>线性回归 ⛄️</h1><h1>1 简单线性模型 📃</h1><h2 id="1-1-简单线性回归">1.1 简单线性回归</h2><p>表达形式：</p><p><img src="https://picture.mulindya.com/image-20210120114327110.png" alt=""></p><p>只有一个自变量和一个因变量 评估自变量在解释因变量变异或者表现时的显著性；在给定自变量的情况下预测因变量，扰动项又可以称之为随机误差，服从均值为0的正态分布；</p><h2 id="1-2-线性回归拟合线">1.2 线性回归拟合线</h2><p><img src="https://picture.mulindya.com/image-20210120115645575.png" alt=""></p><p>简单线性回归原理就是拟合一条直线，使得实际值与预测值的差值平方和最小，当这个距离最小时，这条直线就是最好的回归拟合线</p><p>实际值和预测值的差值就是残差</p><p>线性回归的宗旨：使得残差平方最小化；</p><h1>2 多元线性回归 📇</h1><p><img src="https://picture.mulindya.com/image-20210121113429295.png" alt=""></p><p>在多元线性回归中，x1和x2都有明显的线性相关关系并且x1和x2无线性相关关系；</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">model2 = ols(<span class="hljs-string">'avg_exp~Age+Income+dist_home_val+dist_avg_income'</span>,data=exp).fit()<br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right"></th><th style="text-align:right"></th><th></th><th></th></tr></thead><tbody><tr><td style="text-align:right">Dep. Variable:</td><td style="text-align:right">avg_exp</td><td>R-squared:</td><td>0.542</td></tr><tr><td style="text-align:right">Model:</td><td style="text-align:right">OLS</td><td>Adj. R-squared:</td><td>0.513</td></tr><tr><td style="text-align:right">Method:</td><td style="text-align:right">Least Squares</td><td>F-statistic:</td><td>19.20</td></tr><tr><td style="text-align:right">Date:</td><td style="text-align:right">Thu, 21 Jan 2021</td><td>Prob (F-statistic):</td><td>1.82e-10</td></tr><tr><td style="text-align:right">Time:</td><td style="text-align:right">11:45:07</td><td>Log-Likelihood:</td><td>-498.59</td></tr><tr><td style="text-align:right">No. Observations:</td><td style="text-align:right">70</td><td>AIC:</td><td>1007.</td></tr><tr><td style="text-align:right">Df Residuals:</td><td style="text-align:right">65</td><td>BIC:</td><td>1018.</td></tr><tr><td style="text-align:right">Df Model:</td><td style="text-align:right">4</td><td></td><td></td></tr><tr><td style="text-align:right">Covariance Type:</td><td style="text-align:right">nonrobust</td><td></td><td></td></tr></tbody></table><p><strong>注</strong>：R-squared:用于评价模型解释力度 但是收到自变量个数和观测个数的影响；Prob (F-statistic):接近于0 说明当前回归模型是有意义的</p><h1>3 多元线性回归变量筛选 📊</h1><p>向前法 向后法 逐步法<br>这三种方法 赤池信息准则</p><h2 id="3-1-方法：向前法-向后法-逐步法">3.1 方法：向前法 向后法 逐步法</h2><p>这三种方法进入或者提出变量一个准则是AIC （赤池信息准则）也就是最小信息准则；AIC指标（赤池信息准则）是常用的利用趋势估计预测模型的指标之一；</p><h2 id="3-2-AIC">3.2 AIC</h2><p>在一般的情况下，AIC可以表示为： $AIC=2k-2ln(L)$</p><p>其中：k是参数的数量，L是似然函数。</p><p>假设条件是模型的<strong>误差服从独立正态分布。</strong></p><p>让n为观察数，SSR(SUM SQAURE OF RESIDUE)为<strong>残差平方和</strong>，那么AIC变为： $AIC=2k+nln(SSR/n)$；</p><p>增加自由参数的数目提高了拟合的优良性，AIC鼓励数据拟合的优良性但是尽量避免出现过度拟合(Overfitting)的情况。**所以优先考虑的模型应是AIC值最小的那一个。**假设在n个模型中做出选择，可一次算出n个模型的AIC值，并找出最小AIC值相对应的模型作为选择对象。</p><p>即：AIC越小说明模型效果越好，越简洁；类似的准则还有BIC ,P值；</p><blockquote><p>BIC 和AIC</p><p>1、简介</p><p>BIC= Bayesian Information Criterions，贝叶斯信息准则。</p><p>2、表达式</p><p>BIC=ln(n)k-2ln(L)</p><ul><li>L是似然函数</li><li>n是样本大小</li><li>K是参数数量</li></ul><p>3、总结</p><p>1、共性</p><p>构造这些统计量所遵循的统计思想是一致的，就是在考虑拟合残差的同事，依自变量个数施加“惩罚”。</p><p>2、不同点</p><ul><li>BIC的惩罚项比AIC大，考虑了样本个数，样本数量多，可以防止模型精度过高造成的模型复杂度过高。</li><li>AIC和BIC前半部分是一样的，BIC考虑了样本数量，样本数量过多时，可有效防止模型精度过高造成的模型复杂度过高。</li></ul></blockquote><h3 id="3-2-1-向前回归法">3.2.1 向前回归法</h3><ol><li>先将第一个变量代入回归方程，并且进行F检验和t检验，计算残差平方和，记为s1，如果通过检验，保留当前的变量；</li><li>然后引入第二个变量，重新构建一个新的估计方差，并且进行F检验和t检验，计算残差平方和，记为s2；</li></ol><h3 id="3-2-2-向后回归法">3.2.2 向后回归法</h3><p>自变量全部放入模型，进行F检验和t检验；</p><h3 id="3-2-3-逐步回归法">3.2.3 逐步回归法</h3><p>自变量全部放入模型，进行F检验和t检验；</p><h2 id="3-3-使用向前回归法筛选代码">3.3 使用向前回归法筛选代码</h2><p>将待筛选的自变量选出最好的组合：首先从一个变量选取最小的aic，然后再添加变量进行组合，在选取最小的aic直到aic大于当前选择参数所得的aic；</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward_select</span>(<span class="hljs-params">data,label</span>):</span> <span class="hljs-comment">#data:数据 response:目标值</span><br>    <span class="hljs-comment">#todo 获取当前数据当前不重复变量</span><br>    params = <span class="hljs-built_in">set</span>(data.columns)<br>    <br>    <span class="hljs-comment">#将需要保留的变量进行存储</span><br>    selected = []<br>    <br>    <span class="hljs-comment">#将目标值移除当前变量列表</span><br>    params.remove(label)<br>    current_score = <span class="hljs-built_in">float</span>(<span class="hljs-string">'inf'</span>)<br>    best_new_score = <span class="hljs-built_in">float</span>(<span class="hljs-string">'inf'</span>)<br>    <br>    <span class="hljs-comment">#进行筛选</span><br>    <span class="hljs-keyword">while</span> params:<br>        aic_param = []<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>            <span class="hljs-comment">#前y 后x,并且多变量用加号连接,+[],相当于在数组中添加元素</span><br>            formula = <span class="hljs-string">"{}~{}"</span>.<span class="hljs-built_in">format</span>(label,<span class="hljs-string">'+'</span>.join(selected+[param]))<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">'--------------&gt;formula'</span>,formula)<br>            <br>            <span class="hljs-comment">#建立模型 拿到aic</span><br>            aic = ols(formula=formula,data=data).fit().aic<br>            aic_param.append((aic,param)) <span class="hljs-comment">#元组装包</span><br>        <span class="hljs-comment">#得到分数最小的AIC</span><br>        aic_param.sort(reverse=<span class="hljs-literal">True</span>)<br>        best_new_score,best_param = aic_param.pop()<span class="hljs-comment">#列表的最末位</span><br>        <br>        <span class="hljs-comment">#与当前得分比较</span><br>        <span class="hljs-keyword">if</span> current_score&gt;best_new_score:<br>            params.remove(best_param)<br>            selected.append(best_param)<br>            current_score = best_new_score<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">'------------*************&gt;当前current_score'</span>,current_score)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">"over"</span>)<br>            <span class="hljs-keyword">break</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"#################################################"</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"获取到符合条件的变量进行展示"</span>)<br>    <span class="hljs-built_in">print</span>(selected)<br>        <br>    <span class="hljs-comment">#拼接真正的formula</span><br>    fin_formula = <span class="hljs-string">'{}~{}'</span>.<span class="hljs-built_in">format</span>(label,<span class="hljs-string">'+'</span>.join(selected))<br>    <span class="hljs-comment"># 进行线性模型的训练</span><br>    model = ols(formula=fin_formula,data=data).fit()<br>    <span class="hljs-keyword">return</span> model<br></code></pre></td></tr></tbody></table></figure><p>formula前y后x,并且多变量用加号连接,数组+[],相当于在数组中添加元素；</p><p>aic_param.pop()列表的最末位弹出，因此是降序排序；</p><figure class="highlight clean"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs clean">--------------&gt;formula avg_exp~dist_avg_income<br>--------------&gt;formula avg_exp~Age<br>--------------&gt;formula avg_exp~Income<br>--------------&gt;formula avg_exp~dist_home_val<br>------------*************&gt;当前current_score <span class="hljs-number">1007.6801413968115</span><br>--------------&gt;formula avg_exp~dist_avg_income+Age<br>--------------&gt;formula avg_exp~dist_avg_income+Income<br>--------------&gt;formula avg_exp~dist_avg_income+dist_home_val<br>------------*************&gt;当前current_score <span class="hljs-number">1005.4969816306302</span><br>--------------&gt;formula avg_exp~dist_avg_income+Income+Age<br>--------------&gt;formula avg_exp~dist_avg_income+Income+dist_home_val<br>------------*************&gt;当前current_score <span class="hljs-number">1005.2487355956046</span><br>--------------&gt;formula avg_exp~dist_avg_income+Income+dist_home_val+Age<br>over<br>#################################################<br>获取到符合条件的变量进行展示<br>[<span class="hljs-string">'dist_avg_income'</span>, <span class="hljs-string">'Income'</span>, <span class="hljs-string">'dist_home_val'</span>]<br></code></pre></td></tr></tbody></table></figure><h1>线性回归实例 📒</h1><p>对<code>creditcard_exp</code>客户价值分析，使用线性回归拟合模型来进行预测。📝</p><h1>1数据处理</h1><h2 id="1-1-读取数据（空格处理）">1.1 读取数据（空格处理）</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data  = pd.read_csv(<span class="hljs-string">'./data/creditcard_exp.csv'</span>,skipinitialspace=<span class="hljs-literal">True</span>) <br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">skipinitialspace : boolean, default <span class="hljs-literal">False</span><br>    Skip spaces after delimiter.<br></code></pre></td></tr></tbody></table></figure><p><strong>注</strong>：使用skipinitialspace=True将空格设置为空值；</p><h2 id="1-2-选取数据用来建模">1.2 选取数据用来建模</h2><p>取出非空数据 并且取出2到后面列</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">exp = data[data[<span class="hljs-string">'avg_exp'</span>].notnull()].iloc[:,<span class="hljs-number">2</span>:].drop(<span class="hljs-string">'age2'</span>,axis=<span class="hljs-number">1</span>) <br></code></pre></td></tr></tbody></table></figure><p><strong>注</strong>：notnull可以选取非空数据，返回的是bool变量；iloc选择行列；drop可以删除指定行列；</p><h2 id="1-3-线性相关性分析">1.3 线性相关性分析</h2><p>corr函数： 使用pandas中的corr函数可以分析相关系数</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: exp.corr(method=<span class="hljs-string">'pearson'</span>, min_periods=<span class="hljs-number">1</span>)<br>Docstring:<br>Compute pairwise correlation of columns, excluding NA/null values<br><br>Parameters<br>----------<br>method : {<span class="hljs-string">'pearson'</span>, <span class="hljs-string">'kendall'</span>, <span class="hljs-string">'spearman'</span>}<br>    * pearson : standard correlation coefficient<br>    * kendall : Kendall Tau correlation coefficient<br>    * spearman : Spearman rank correlation<br>min_periods : <span class="hljs-built_in">int</span>, optional<br>    Minimum number of observations required per pair of columns<br>    to have a valid result. Currently only available <span class="hljs-keyword">for</span> pearson<br>    <span class="hljs-keyword">and</span> spearman correlation<br><br>Returns<br>-------<br>y : DataFrame<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">exp[[<span class="hljs-string">'Income'</span>,<span class="hljs-string">'avg_exp'</span>,<span class="hljs-string">'Age'</span>,<span class="hljs-string">'dist_home_val'</span>]].corr(method=<span class="hljs-string">'pearson'</span>)<br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right">Income</th><th style="text-align:right">avg_exp</th><th style="text-align:right">Age</th><th style="text-align:right">dist_home_val</th><th></th></tr></thead><tbody><tr><td style="text-align:right">Income</td><td style="text-align:right">1.000000</td><td style="text-align:right">0.674011</td><td style="text-align:right">0.369129</td><td>0.249153</td></tr><tr><td style="text-align:right">avg_exp</td><td style="text-align:right">0.674011</td><td style="text-align:right">1.000000</td><td style="text-align:right">0.258478</td><td>0.319499</td></tr><tr><td style="text-align:right">Age</td><td style="text-align:right">0.369129</td><td style="text-align:right">0.258478</td><td style="text-align:right">1.000000</td><td>0.109323</td></tr><tr><td style="text-align:right">dist_home_val</td><td style="text-align:right">0.249153</td><td style="text-align:right">0.319499</td><td style="text-align:right">0.109323</td><td>1.000000</td></tr></tbody></table><p><strong>注</strong>：经过线性相关性分析 可以得到Income和avg_exp有较大相关性</p><blockquote><p>相关性系数（pearson、spearman、kendall，pointbiserialr）</p><p>用途：</p><p>检查两个变量之间变化趋势的方向以及程度，值范围-1到+1，0表示两个变量不相关，正值表示正相关，负值表示负相关，值越大相关性越强。</p><ul><li><p>计算积距pearson相关系数，连续性变量才可采用;</p></li><li><p>计算Spearman秩相关系数，适合于定序变量或不满足正态分布假设的等间隔数据;</p></li><li><p>计算Kendall秩相关系数，适合于定序变量或不满足正态分布假设的等间隔数据。</p></li></ul></blockquote><h1>2 模型拟合</h1><h2 id="2-1-构建最小二乘法的线性模型">2.1 构建最小二乘法的线性模型</h2><figure class="highlight haskell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-title">from</span> statsmodels.formula.api <span class="hljs-keyword">import</span> ols<br><span class="hljs-title">model1</span> = ols('avg_exp~<span class="hljs-type">Income'</span>,<span class="hljs-class"><span class="hljs-keyword">data</span>=exp).fit()</span><br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210121113456600.png" alt=""></p><h2 id="2-2-构建预测值和残差的表">2.2 构建预测值和残差的表</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pd.DataFrame([model1.predict(exp),model1.resid],index=[<span class="hljs-string">'预测值'</span>,<span class="hljs-string">'残差'</span>]).T<br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right"></th><th style="text-align:right">预测值</th><th style="text-align:right">残差</th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:right">1825.141904</td><td style="text-align:right">-608.111904</td></tr><tr><td style="text-align:right">1</td><td style="text-align:right">1806.803136</td><td style="text-align:right">-555.303136</td></tr><tr><td style="text-align:right">3</td><td style="text-align:right">1379.274813</td><td style="text-align:right">-522.704813</td></tr><tr><td style="text-align:right">4</td><td style="text-align:right">1568.506658</td><td style="text-align:right">-246.676658</td></tr><tr><td style="text-align:right">5</td><td style="text-align:right">1238.281793</td><td style="text-align:right">-422.251793</td></tr><tr><td style="text-align:right">6</td><td style="text-align:right">1402.035798</td><td style="text-align:right">-250.885798</td></tr><tr><td style="text-align:right">7</td><td style="text-align:right">1413.088901</td><td style="text-align:right">-179.318901</td></tr><tr><td style="text-align:right">8</td><td style="text-align:right">1168.156652</td><td style="text-align:right">-365.636652</td></tr><tr><td style="text-align:right">9</td><td style="text-align:right">1849.935644</td><td style="text-align:right">317.834356</td></tr><tr><td style="text-align:right">10</td><td style="text-align:right">1060.684535</td><td style="text-align:right">-406.104535</td></tr></tbody></table><h2 id="2-3-进行预测">2.3 进行预测</h2><figure class="highlight haxe"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs haxe">model1.predict(<span class="hljs-keyword">new</span><span class="hljs-type">_exp</span>)<br></code></pre></td></tr></tbody></table></figure><figure class="highlight basic"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">2 </span>    <span class="hljs-number">1078.969552</span><br><span class="hljs-symbol">11 </span>    <span class="hljs-number">756.465245</span><br><span class="hljs-symbol">13 </span>    <span class="hljs-number">736.919530</span><br><span class="hljs-symbol">19 </span>    <span class="hljs-number">687.077955</span><br><span class="hljs-symbol">20 </span>    <span class="hljs-number">666.554953</span><br><span class="hljs-symbol">21 </span>    <span class="hljs-number">658.736667</span><br><span class="hljs-symbol">24 </span>    <span class="hljs-number">648.963809</span><br><span class="hljs-symbol">28 </span>    <span class="hljs-number">633.327237</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数据分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>数据分析</tag>
      
      <tag>线性回归</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据分析笔记--RFM模型</title>
    <link href="/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis5/"/>
    <url>/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis5/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本科实训的时候记录的数据分析的笔记，感觉还挺全面的，部署到博客中，今后对数据分析的应用可以方便回顾。</p></blockquote><blockquote><p>本篇主要内容是客户生命周期以及在数据分析中常用的RFM模型，本篇的内容是对数据分析中更抽象的角度出发，对客户进行分析，提取有价值的信息。其他主要是对代码操作介绍比较硬核，相比其他的介绍，本篇既有代码的介绍，还包括一些价值分析中的一些概念。更加实际一些哦~ 😶</p></blockquote><h1>1 客户的生命周期 💬</h1><h2 id="1-1-定义">1.1 定义</h2><p>客户生命周期经历诞生，成长，成熟，衰老，死亡的过程。</p><h2 id="1-2-电信行业为例">1.2 电信行业为例</h2><p>生命周期包含着从成为该公司客户并且产生消费开始，经历消费成长，消费稳定，消费下降，最后离网过程；根据客户不同角色分为4个阶段；每个阶段对应不同的数据分析场景和数据挖掘主题；</p><h2 id="1-3-客户终生价值线">1.3 客户终生价值线</h2><p>客户在整个客户生命周期带来的总利润曲线</p><p><img src="https://picture.mulindya.com/image-20210120093416691.png" alt=""></p><p>第一阶段：潜在客户阶段，并不清楚谁会成为我们的客户，只有通过产品设计或者既有的客户画像，知道潜在客户的大致特征；</p><p>第二阶段：响应客户阶段，当前阶段客户已经在递推点完成了申请信用卡的基本信息的填写，当前阶段我们需要对客户价值和信用进行预测，决定信用卡初始额度；若收到信用卡不激活，需执行客户营销策略，决定分配多少 资源进行营销；</p><p>第三阶段：既得客户阶段，当前阶段客户已经成功激活信用卡，并且正常使用信用卡消费，只是客户使用产品单一；我们希望他们购买理财产品，分期还款业务等，会涉及交叉，销售精准营销等工作内容；</p><p>第四阶段：流失客户阶段，对于高价值客户，尽量避免；在客户流失之前尽量挽回；但是对于低价值客户，价值如果一直无法得到提升，可以被动离开</p><h1>2 RFM模型简介 💧</h1><p><strong>R:最近一次消费（Recency）客户上一次的购买时间</strong></p><p><strong>F:消费频率（Frequency）在限定时间内购买次数，最常购买的用户也是满意度最高的用户 体现忠诚度</strong></p><p><strong>M:消费金额（Monetary）最近消费的平均金额 体现客户短期价值的重要变量</strong></p><p><img src="https://picture.mulindya.com/image-20210119093821088.png" alt=""></p><table><thead><tr><th style="text-align:center">客户类型</th><th style="text-align:center">消费特征</th><th style="text-align:center">属性</th><th style="text-align:center">方法</th></tr></thead><tbody><tr><td style="text-align:center">重要价值客户</td><td style="text-align:center">消费额度高 购物频率高 最近购物时间近</td><td style="text-align:center">重要也是忠诚度较高的大客户</td><td style="text-align:center">细心维护</td></tr><tr><td style="text-align:center">重要发展客户</td><td style="text-align:center">消费额度高 购物频率不高 最近购物时间近</td><td style="text-align:center">有巨大发展潜力</td><td style="text-align:center">个性化推荐发放优惠券 增加粘性</td></tr><tr><td style="text-align:center">重要挽留客户</td><td style="text-align:center">消费额度高 购物频率不高 最近购物时间远</td><td style="text-align:center">可能已经流失的重要客户</td><td style="text-align:center">了解流失原因，进行预警，针对性改变</td></tr><tr><td style="text-align:center">重要保持客户</td><td style="text-align:center">消费额度高 购物频率高 最近购物时间远</td><td style="text-align:center">可能是快要流失的客户</td><td style="text-align:center">沟通了解其体验感变差的原因</td></tr><tr><td style="text-align:center">一般价值客户</td><td style="text-align:center">消费额度不高 购物频率高 最近购物时间近</td><td style="text-align:center">感兴趣，活跃，价格敏感型</td><td style="text-align:center">推荐金融产品增加购买力</td></tr><tr><td style="text-align:center">一般发展客户</td><td style="text-align:center">消费额度不高 购物频率不高 最近购物时间近</td><td style="text-align:center">新晋用户 试探性体验</td><td style="text-align:center">留意此类客户 进行短信发送优惠信息</td></tr><tr><td style="text-align:center">一般保持客户</td><td style="text-align:center">消费额度不高 购物频率高 最近购物时间远</td><td style="text-align:center">快要流失的一般客户</td><td style="text-align:center">一般性低成本营销</td></tr><tr><td style="text-align:center">一般挽留客户</td><td style="text-align:center">消费额度不高 购物频率不高 最近购物时间远</td><td style="text-align:center">不是目标客户</td><td style="text-align:center">经费有限时可以直接忽略</td></tr></tbody></table><h1>3 RFM模型分析代码 🐾</h1><h2 id="3-1-R">3.1 R</h2><h3 id="3-1-1-时间转化">3.1.1 时间转化</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> time<br>time.mktime(time.strptime(<span class="hljs-string">'14JUN09:17:58:34'</span>,<span class="hljs-string">'%d%b%y:%H:%M:%S'</span>))<br></code></pre></td></tr></tbody></table></figure><p><strong>注意点</strong>：将非标准的字符串时间格式转化时间数组(strptime) 再转化为为时间戳(mktime)便于计算</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data[<span class="hljs-string">'newtime'</span>] = data[<span class="hljs-string">'time'</span>].<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x:time.mktime(time.strptime(x,<span class="hljs-string">'%d%b%y:%H:%M:%S'</span>)))<br></code></pre></td></tr></tbody></table></figure><p><strong>注意点</strong>：使用map指定新列newtime</p><h3 id="3-1-2-根据id和type分组再显示最近时间">3.1.2 根据id和type分组再显示最近时间</h3><p>查看每一个购物id的每个类型的最近时间</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">R1 = data.groupby([<span class="hljs-string">'cumid'</span>,<span class="hljs-string">'type'</span>])[[<span class="hljs-string">'newtime'</span>]].<span class="hljs-built_in">max</span>()<br></code></pre></td></tr></tbody></table></figure><p>转化为透视表指定行列和内容</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">R2 = pd.pivot_table(R1,index=<span class="hljs-string">'cumid'</span>,columns=<span class="hljs-string">'type'</span>,values=<span class="hljs-string">'newtime'</span>) <br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210119104539349.png" alt=""></p><h3 id="3-1-3-空值填充">3.1.3 空值填充</h3><p>用最久远的购物时间替换缺失值</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">R[[<span class="hljs-string">'Special_offer'</span>,<span class="hljs-string">'returned_goods'</span>]] = R[[<span class="hljs-string">'Special_offer'</span>,<span class="hljs-string">'returned_goods'</span>]].apply(<span class="hljs-keyword">lambda</span> x:x.replace(np.nan,<span class="hljs-built_in">min</span>(x)),axis=<span class="hljs-number">0</span>)<br></code></pre></td></tr></tbody></table></figure><p>对选取的列进行替换 axis为0 对行应用function</p><h3 id="3-1-4-查找最近的购物时间">3.1.4 查找最近的购物时间</h3><p>最近的购物时间 购物时间越大 则时间戳越大</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">R[<span class="hljs-string">'rmax'</span>] = R[[<span class="hljs-string">'Normal'</span>,<span class="hljs-string">'Presented'</span>,<span class="hljs-string">'Special_offer'</span>]].apply(<span class="hljs-keyword">lambda</span> x:<span class="hljs-built_in">max</span>(x),axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210119111110105.png" alt=""></p><h2 id="3-2-F-购物频次">3.2 F 购物频次</h2><h3 id="3-2-1-分组统计用户购物的次数">3.2.1 分组统计用户购物的次数</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">F1 = data.groupby([<span class="hljs-string">'cumid'</span>,<span class="hljs-string">'type'</span>])[[<span class="hljs-string">'transID'</span>]].count()<br>F = pd.pivot_table(F1,index=<span class="hljs-string">'cumid'</span>,columns=<span class="hljs-string">'type'</span>,values=<span class="hljs-string">'transID'</span>)<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210119111839505.png" alt=""></p><h3 id="3-2-2-处理空值以及退货数据">3.2.2 处理空值以及退货数据</h3><p>将空值替换为0值，将退货列处理为负数；</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">F[[<span class="hljs-string">'Special_offer'</span>,<span class="hljs-string">'returned_goods'</span>]] = F[[<span class="hljs-string">'Special_offer'</span>,<span class="hljs-string">'returned_goods'</span>]].fillna(<span class="hljs-number">0</span>)<br>F[<span class="hljs-string">'returned_goods'</span>] = F[<span class="hljs-string">'returned_goods'</span>].<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x:-x)<br>F.head()<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210119112103692.png" alt=""></p><h3 id="3-2-3-求出购物总次数">3.2.3 求出购物总次数</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">F[<span class="hljs-string">'total'</span>] = F.apply(<span class="hljs-keyword">lambda</span> x:<span class="hljs-built_in">sum</span>(x),axis=<span class="hljs-number">1</span>)<br>F.head()<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210119112143811.png" alt=""></p><h2 id="3-3-M-购物金额汇总">3.3 M 购物金额汇总</h2><h3 id="3-3-1-根据用户，类别分类金额">3.3.1 根据用户，类别分类金额</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">M1 = data.groupby([<span class="hljs-string">'cumid'</span>,<span class="hljs-string">'type'</span>])[[<span class="hljs-string">'amount'</span>]].<span class="hljs-built_in">sum</span>()<br></code></pre></td></tr></tbody></table></figure><h3 id="3-3-2-构建透视图">3.3.2  构建透视图</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">M = pd.pivot_table(M1,index=<span class="hljs-string">'cumid'</span>,columns=<span class="hljs-string">'type'</span>,values=<span class="hljs-string">'amount'</span>)<br>M.head()<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210119114146934.png" alt=""></p><h3 id="3-3-3-缺失值填充">3.3.3 缺失值填充</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">M[[<span class="hljs-string">'Special_offer'</span>,<span class="hljs-string">'returned_goods'</span>]] = M[[<span class="hljs-string">'Special_offer'</span>,<span class="hljs-string">'returned_goods'</span>]].fillna(<span class="hljs-number">0</span>)<br></code></pre></td></tr></tbody></table></figure><p>补充：将其填充为0值</p><h3 id="3-3-4-总金额汇总">3.3.4 总金额汇总</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">M[<span class="hljs-string">'mtotal'</span>] = M.apply(<span class="hljs-keyword">lambda</span> x:<span class="hljs-built_in">sum</span>(x),axis=<span class="hljs-number">1</span>)<br>M.head()<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210119114246668.png" alt=""></p><h2 id="3-4-RFM-模型结果分析">3.4 RFM 模型结果分析</h2><h3 id="3-4-1-数据拼接">3.4.1 数据拼接</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">RFM = pd.concat([R[<span class="hljs-string">'rmax'</span>],F[<span class="hljs-string">'total'</span>],M[<span class="hljs-string">'mtotal'</span>]],axis=<span class="hljs-number">1</span>)<br>RFM.head()<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210119120421853.png" alt=""></p><h3 id="3-4-2-分箱打分">3.4.2 分箱打分</h3><p>cut函数：将x数组离散化成bins个分组</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: pd.cut(x, bins, right=<span class="hljs-literal">True</span>, labels=<span class="hljs-literal">None</span>, retbins=<span class="hljs-literal">False</span>, precision=<span class="hljs-number">3</span>, include_lowest=<span class="hljs-literal">False</span>, duplicates=<span class="hljs-string">'raise'</span>)<br>Docstring:<br>Bin values into discrete intervals.<br><br>Use `cut` when you need to segment <span class="hljs-keyword">and</span> sort data values into bins. This<br>function <span class="hljs-keyword">is</span> also useful <span class="hljs-keyword">for</span> going <span class="hljs-keyword">from</span> a continuous variable to a<br>categorical variable. For example, `cut` could convert ages to groups of<br>age ranges. Supports binning into an equal number of bins, <span class="hljs-keyword">or</span> a<br>pre-specified array of bins.<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">RFM[<span class="hljs-string">'rscore'</span>] = pd.cut(RFM.rmax,<span class="hljs-number">3</span>,labels=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],precision=<span class="hljs-number">2</span>)<br>RFM[<span class="hljs-string">'fscore'</span>] = pd.cut(RFM.total,<span class="hljs-number">3</span>,labels=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],precision=<span class="hljs-number">2</span>)<br>RFM[<span class="hljs-string">'mscore'</span>] = pd.cut(RFM.mtotal,<span class="hljs-number">3</span>,labels=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],precision=<span class="hljs-number">2</span>)<br></code></pre></td></tr></tbody></table></figure><p><strong>补充</strong>：<em><strong>cut与qcut</strong></em></p><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">cut(x,bins,<span class="hljs-keyword">right</span><span class="hljs-operator">=</span><span class="hljs-literal">True</span>,labels<span class="hljs-operator">=</span><span class="hljs-keyword">None</span>,retbins<span class="hljs-operator">=</span><span class="hljs-literal">False</span>,<span class="hljs-keyword">precision</span><span class="hljs-operator">=</span><span class="hljs-number">3</span>,include_lowest<span class="hljs-operator">=</span><span class="hljs-literal">False</span>)<br></code></pre></td></tr></tbody></table></figure><p>​    需要将数据值分段并排序到bins中时使用cut。 此函数对于从连续变量转换为离散变量也很有用。 例如，cut可以将年龄转换为年龄范围组。 支持bins到相同数量的箱柜或预先指定的bins阵列。</p><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">qcut(x, q, <span class="hljs-attribute">labels</span>=None, <span class="hljs-attribute">retbins</span>=<span class="hljs-literal">False</span>, <span class="hljs-attribute">precision</span>=3, <span class="hljs-attribute">duplicates</span>=<span class="hljs-string">'raise'</span>)<br></code></pre></td></tr></tbody></table></figure><p>​    基于分位数的离散化功能。 根据等级或基于样本分位数将变量分离为相等大小的桶。 例如，10个分位数的1000个值将产生一个分类对象，表示每个数据点的分位数成员资格</p><h3 id="3-4-3-打标">3.4.3 打标</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">handler_Score</span>(<span class="hljs-params">x,y,z</span>):</span><br>    <span class="hljs-keyword">if</span> x==<span class="hljs-number">3</span> <span class="hljs-keyword">and</span> y==<span class="hljs-number">3</span> <span class="hljs-keyword">and</span> z==<span class="hljs-number">3</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">'重要价值客户'</span><br>    <span class="hljs-keyword">elif</span> x==<span class="hljs-number">3</span> <span class="hljs-keyword">and</span>(y <span class="hljs-keyword">in</span> [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]) <span class="hljs-keyword">and</span> z==<span class="hljs-number">3</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">'重要发展客户'</span><br>    <span class="hljs-keyword">elif</span> (x <span class="hljs-keyword">in</span> [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]) <span class="hljs-keyword">and</span> y==<span class="hljs-number">3</span> <span class="hljs-keyword">and</span> z==<span class="hljs-number">3</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">'重要保持客户'</span><br>    <span class="hljs-keyword">elif</span> (x <span class="hljs-keyword">in</span> [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]) <span class="hljs-keyword">and</span> (y <span class="hljs-keyword">in</span> [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]) <span class="hljs-keyword">and</span> z==<span class="hljs-number">3</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">'重要挽留客户'</span><br>    <span class="hljs-keyword">elif</span> x==<span class="hljs-number">3</span> <span class="hljs-keyword">and</span> y==<span class="hljs-number">3</span> <span class="hljs-keyword">and</span> (z <span class="hljs-keyword">in</span>[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]):<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">'一般价值客户'</span><br>    <span class="hljs-keyword">elif</span> (z <span class="hljs-keyword">in</span> [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]) <span class="hljs-keyword">and</span> (y <span class="hljs-keyword">in</span> [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]) <span class="hljs-keyword">and</span> x==<span class="hljs-number">3</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">'一般发展客户'</span><br>    <span class="hljs-keyword">elif</span> (x <span class="hljs-keyword">in</span> [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]) <span class="hljs-keyword">and</span> y==<span class="hljs-number">3</span> <span class="hljs-keyword">and</span> (z <span class="hljs-keyword">in</span>[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]):<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">'一般保持客户'</span><br>    <span class="hljs-keyword">elif</span> (x <span class="hljs-keyword">in</span> [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]) <span class="hljs-keyword">and</span> (y <span class="hljs-keyword">in</span> [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]) <span class="hljs-keyword">and</span> (x <span class="hljs-keyword">in</span> [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]):<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">'一般挽留客户'</span><br></code></pre></td></tr></tbody></table></figure><p>应用于3个分数</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">RFM[<span class="hljs-string">'label'</span>] = RFM[[<span class="hljs-string">'rscore'</span>,<span class="hljs-string">'fscore'</span>,<span class="hljs-string">'mscore'</span>]].apply(<span class="hljs-keyword">lambda</span> x:handler_Score(x[<span class="hljs-number">0</span>],x[<span class="hljs-number">1</span>],x[<span class="hljs-number">2</span>]),axis=<span class="hljs-number">1</span>)<br>RFM.head()<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210119121121466.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数据分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>数据分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据分析笔记--数据清理</title>
    <link href="/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis4/"/>
    <url>/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis4/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本科实训的时候记录的数据分析的笔记，感觉还挺全面的，部署到博客中，今后对数据分析的应用可以方便回顾。</p></blockquote><blockquote><p>本篇主要内容是数据清洗，包括重复值处理，缺失值处理，噪声值处理。还有pandas中拆分和堆叠的函数，赋值和条件赋值的方法。😉</p></blockquote><h1>1 拆分与堆叠 📞</h1><table><thead><tr><th style="text-align:right"></th><th style="text-align:right">id</th><th style="text-align:right">type</th><th style="text-align:right">money</th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:right">1001</td><td style="text-align:right">normal</td><td style="text-align:right">2000</td></tr><tr><td style="text-align:right">1</td><td style="text-align:right">1110</td><td style="text-align:right">spe</td><td style="text-align:right">300</td></tr><tr><td style="text-align:right">2</td><td style="text-align:right">1002</td><td style="text-align:right">normal</td><td style="text-align:right">1000</td></tr><tr><td style="text-align:right">3</td><td style="text-align:right">1002</td><td style="text-align:right">spe</td><td style="text-align:right">3500</td></tr><tr><td style="text-align:right">4</td><td style="text-align:right">1003</td><td style="text-align:right">spe</td><td style="text-align:right">4500</td></tr><tr><td style="text-align:right">5</td><td style="text-align:right">1003</td><td style="text-align:right">spe</td><td style="text-align:right">10000</td></tr></tbody></table><h2 id="1-1-拆分">1.1 拆分</h2><p><code>pivot_table函数：</code></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: pd.pivot_table(data, values=<span class="hljs-literal">None</span>, index=<span class="hljs-literal">None</span>, columns=<span class="hljs-literal">None</span>, aggfunc=<span class="hljs-string">'mean'</span>, fill_value=<span class="hljs-literal">None</span>, margins=<span class="hljs-literal">False</span>, dropna=<span class="hljs-literal">True</span>, margins_name=<span class="hljs-string">'All'</span>)<br>Docstring:<br>Create a spreadsheet-style pivot table <span class="hljs-keyword">as</span> a DataFrame. The levels <span class="hljs-keyword">in</span><br>the pivot table will be stored <span class="hljs-keyword">in</span> MultiIndex objects (hierarchical<br>indexes) on the index <span class="hljs-keyword">and</span> columns of the result DataFrame<br></code></pre></td></tr></tbody></table></figure><p>data：等待拆分的表</p><p>index：标识列</p><p>columns：取值是新变量的变量名</p><p>values：等待拆分的列</p><p><strong>注意点</strong>：默认 汇总函数是均值 如果存在缺失用nan填充</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pd.pivot_table(data,index=<span class="hljs-string">'id'</span>,columns=<span class="hljs-string">'type'</span>,values=<span class="hljs-string">'money'</span>) <br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right">type</th><th style="text-align:right">normal</th><th style="text-align:right">spe</th></tr></thead><tbody><tr><td style="text-align:right">id</td><td style="text-align:right"></td><td style="text-align:right"></td></tr><tr><td style="text-align:right">1001</td><td style="text-align:right">2000.0</td><td style="text-align:right">NaN</td></tr><tr><td style="text-align:right">1002</td><td style="text-align:right">1000.0</td><td style="text-align:right">3500.0</td></tr><tr><td style="text-align:right">1003</td><td style="text-align:right">NaN</td><td style="text-align:right">7250.0</td></tr><tr><td style="text-align:right">1110</td><td style="text-align:right">NaN</td><td style="text-align:right">300.0</td></tr></tbody></table><h2 id="1-2-堆叠">1.2 堆叠</h2><p>堆叠是拆分的反操作</p><p>使用<code>pd.melt()</code>函数：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: pd.melt(frame, id_vars=<span class="hljs-literal">None</span>, value_vars=<span class="hljs-literal">None</span>, var_name=<span class="hljs-literal">None</span>, value_name=<span class="hljs-string">'value'</span>, col_level=<span class="hljs-literal">None</span>)<br>Docstring:<br><span class="hljs-string">"Unpivots"</span> a DataFrame <span class="hljs-keyword">from</span> wide <span class="hljs-built_in">format</span> to long <span class="hljs-built_in">format</span>, optionally<br>leaving identifier variables <span class="hljs-built_in">set</span>.<br></code></pre></td></tr></tbody></table></figure><p>id_vars：标识变量；</p><p>value_vars：表示指定进行堆叠的列；</p><p>var_name: 原数据列堆叠后的取名；</p><p>value_name：原数据元素队列后取名；</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pd.melt(data2,id_vars=<span class="hljs-string">'id'</span>,value_name=<span class="hljs-string">'money'</span>,var_name=<span class="hljs-string">'Type'</span>,value_vars=[<span class="hljs-string">'normal'</span>,<span class="hljs-string">'spe'</span>])<br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right"></th><th style="text-align:right">id</th><th style="text-align:right">Type</th><th style="text-align:right">money</th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:right">1001</td><td style="text-align:right">normal</td><td style="text-align:right">2000</td></tr><tr><td style="text-align:right">1</td><td style="text-align:right">1002</td><td style="text-align:right">normal</td><td style="text-align:right">1000</td></tr><tr><td style="text-align:right">2</td><td style="text-align:right">1003</td><td style="text-align:right">normal</td><td style="text-align:right">0</td></tr><tr><td style="text-align:right">3</td><td style="text-align:right">1110</td><td style="text-align:right">normal</td><td style="text-align:right">0</td></tr></tbody></table><h1>2 赋值与条件赋值  📢</h1><h2 id="sample案例分析">sample案例分析</h2><p>sample数据：</p><table><thead><tr><th style="text-align:right"></th><th style="text-align:right">chinese</th><th style="text-align:right">class</th><th style="text-align:right">grade</th><th style="text-align:right">math</th><th style="text-align:right">name</th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:right">88</td><td style="text-align:right">1</td><td style="text-align:right">1</td><td style="text-align:right">98.0</td><td style="text-align:right">Bob</td></tr><tr><td style="text-align:right">1</td><td style="text-align:right">78</td><td style="text-align:right">1</td><td style="text-align:right">1</td><td style="text-align:right">78.0</td><td style="text-align:right">Lindy</td></tr><tr><td style="text-align:right">2</td><td style="text-align:right">86</td><td style="text-align:right">1</td><td style="text-align:right">1</td><td style="text-align:right">87.0</td><td style="text-align:right">Mark</td></tr><tr><td style="text-align:right">3</td><td style="text-align:right">56</td><td style="text-align:right">2</td><td style="text-align:right">2</td><td style="text-align:right">77.0</td><td style="text-align:right">Miki</td></tr><tr><td style="text-align:right">4</td><td style="text-align:right">77</td><td style="text-align:right">1</td><td style="text-align:right">2</td><td style="text-align:right">77.0</td><td style="text-align:right">Sully</td></tr><tr><td style="text-align:right">5</td><td style="text-align:right">54</td><td style="text-align:right">2</td><td style="text-align:right">2</td><td style="text-align:right">NaN</td><td style="text-align:right">Rose</td></tr></tbody></table><h2 id="2-1-replace函数">2.1 replace函数</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: data.math.replace(to_replace=<span class="hljs-literal">None</span>, value=<span class="hljs-literal">None</span>, inplace=<span class="hljs-literal">False</span>, limit=<span class="hljs-literal">None</span>, regex=<span class="hljs-literal">False</span>, method=<span class="hljs-string">'pad'</span>)<br>Docstring:<br>Replace values given <span class="hljs-keyword">in</span> `to_replace` <span class="hljs-keyword">with</span> `value`.<br><br>Values of the Series are replaced <span class="hljs-keyword">with</span> other values dynamically.<br>This differs <span class="hljs-keyword">from</span> updating <span class="hljs-keyword">with</span> ``.loc`` <span class="hljs-keyword">or</span> ``.iloc``, which require<br>you to specify a location to update <span class="hljs-keyword">with</span> some value.<br></code></pre></td></tr></tbody></table></figure><p>替换数学成绩的98为空值</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.math.replace(<span class="hljs-number">98</span>,np.nan)<br></code></pre></td></tr></tbody></table></figure><p>替换多个值 使用字典嵌套指定</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">data.replace({<br>    <span class="hljs-string">'math'</span>:{<span class="hljs-number">98</span>:np.nan},<br>    <span class="hljs-string">'name'</span>:{<span class="hljs-string">'Bob'</span>:<span class="hljs-string">'Jim'</span>}<br>},inplace=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right"></th><th style="text-align:right">chinese</th><th style="text-align:right">class</th><th style="text-align:right">grade</th><th style="text-align:right">math</th><th style="text-align:right">name</th><th style="text-align:right">class_n</th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:right">88</td><td style="text-align:right">1</td><td style="text-align:right">1</td><td style="text-align:right">NaN</td><td style="text-align:right">Jim</td><td style="text-align:right">class1</td></tr><tr><td style="text-align:right">1</td><td style="text-align:right">78</td><td style="text-align:right">1</td><td style="text-align:right">1</td><td style="text-align:right">78.0</td><td style="text-align:right">Lindy</td><td style="text-align:right">class1</td></tr><tr><td style="text-align:right">2</td><td style="text-align:right">86</td><td style="text-align:right">1</td><td style="text-align:right">1</td><td style="text-align:right">87.0</td><td style="text-align:right">Mark</td><td style="text-align:right">class1</td></tr><tr><td style="text-align:right">3</td><td style="text-align:right">56</td><td style="text-align:right">2</td><td style="text-align:right">2</td><td style="text-align:right">77.0</td><td style="text-align:right">Miki</td><td style="text-align:right">class2</td></tr><tr><td style="text-align:right">4</td><td style="text-align:right">77</td><td style="text-align:right">1</td><td style="text-align:right">2</td><td style="text-align:right">77.0</td><td style="text-align:right">Sully</td><td style="text-align:right">class1</td></tr><tr><td style="text-align:right">5</td><td style="text-align:right">54</td><td style="text-align:right">2</td><td style="text-align:right">2</td><td style="text-align:right">NaN</td><td style="text-align:right">Rose</td><td style="text-align:right">class2</td></tr></tbody></table><h2 id="2-2-apply函数">2.2 apply函数</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: data.apply(func, axis=<span class="hljs-number">0</span>, broadcast=<span class="hljs-literal">None</span>, raw=<span class="hljs-literal">False</span>, reduce=<span class="hljs-literal">None</span>, result_type=<span class="hljs-literal">None</span>, args=(), **kwds)<br>Docstring:<br>Apply a function along an axis of the DataFrame.<br><br>Objects passed to the function are Series objects whose index <span class="hljs-keyword">is</span><br>either the DataFrame<span class="hljs-string">'s index (``axis=0``) or the DataFrame'</span>s columns<br>(``axis=<span class="hljs-number">1</span>``). By default (``result_type=<span class="hljs-literal">None</span>``), the final <span class="hljs-keyword">return</span> <span class="hljs-built_in">type</span><br><span class="hljs-keyword">is</span> inferred <span class="hljs-keyword">from</span> the <span class="hljs-keyword">return</span> <span class="hljs-built_in">type</span> of the applied function. Otherwise,<br>it depends on the `result_type` argument.<br><br>Series objects ：是传入参数对象<br></code></pre></td></tr></tbody></table></figure><p>会自动传参func，axis=0 是传参整列 axis=1是传参整行 返回series</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">func1</span>(<span class="hljs-params">p1</span>):</span><br>    <span class="hljs-keyword">if</span>(p1[<span class="hljs-string">'class'</span>]==<span class="hljs-number">1</span>): <br>        <span class="hljs-keyword">return</span> <span class="hljs-string">"class1"</span><br>    <span class="hljs-keyword">elif</span> p1[<span class="hljs-string">'class'</span>]==<span class="hljs-number">2</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">"class2"</span><br>data.apply(func1,axis=<span class="hljs-number">1</span>) <span class="hljs-comment">#自动传参       </span><br></code></pre></td></tr></tbody></table></figure><figure class="highlight ceylon"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs ceylon"><span class="hljs-number">0</span>    <span class="hljs-keyword">class</span><span class="hljs-number">1</span><br><span class="hljs-number">1</span>    <span class="hljs-keyword">class</span><span class="hljs-number">1</span><br><span class="hljs-number">2</span>    <span class="hljs-keyword">class</span><span class="hljs-number">1</span><br><span class="hljs-number">3</span>    <span class="hljs-keyword">class</span><span class="hljs-number">2</span><br><span class="hljs-number">4</span>    <span class="hljs-keyword">class</span><span class="hljs-number">1</span><br><span class="hljs-number">5</span>    <span class="hljs-keyword">class</span><span class="hljs-number">2</span><br>dtype: <span class="hljs-keyword">object</span><br></code></pre></td></tr></tbody></table></figure><p>可以使用<code>data.assign函数</code>进行指定赋值</p><p><code>assign函数</code>赋值不在原始数据上操作</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">data = data.assign(class_n = data.apply(func1,axis=<span class="hljs-number">1</span>))  <br><span class="hljs-comment">#Assign new columns to a DataFrame, </span><br><span class="hljs-comment">#returning a new object(a copy) with the new columns added to the original ones.</span><br></code></pre></td></tr></tbody></table></figure><h2 id="2-3-使用loc进行条件赋值">2.3 使用loc进行条件赋值</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">data.loc[data.grade==<span class="hljs-number">1</span>,<span class="hljs-string">'grade_n'</span>] = <span class="hljs-string">'grade1'</span> <span class="hljs-comment">#在原始数据上修改</span><br>data.loc[data.grade==<span class="hljs-number">2</span>,<span class="hljs-string">'grade_n'</span>] = <span class="hljs-string">'grade2'</span> <span class="hljs-comment">#直接条件查询进行条件复制</span><br></code></pre></td></tr></tbody></table></figure><h1>3 数据清洗 💡</h1><table><thead><tr><th style="text-align:right"></th><th style="text-align:right">id</th><th style="text-align:right">name</th><th style="text-align:right">score</th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">zhang1</td><td style="text-align:right">80.0</td></tr><tr><td style="text-align:right">1</td><td style="text-align:right">1</td><td style="text-align:right">zhang1</td><td style="text-align:right">80.0</td></tr><tr><td style="text-align:right">2</td><td style="text-align:right">1</td><td style="text-align:right">zhang2</td><td style="text-align:right">64.0</td></tr><tr><td style="text-align:right">3</td><td style="text-align:right">3</td><td style="text-align:right">zhang3</td><td style="text-align:right">70.0</td></tr><tr><td style="text-align:right">4</td><td style="text-align:right">4</td><td style="text-align:right">zhang4</td><td style="text-align:right">89.0</td></tr><tr><td style="text-align:right">5</td><td style="text-align:right">5</td><td style="text-align:right">zhang5</td><td style="text-align:right">NaN</td></tr></tbody></table><h2 id="3-1-重复数处理">3.1 重复数处理</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data2.duplicated()<br></code></pre></td></tr></tbody></table></figure><p>重复数一般是直接清除重复数，使用duplicated方法可以找到重复的数据项。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data2[data2.duplicated()]<br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right">id</th><th style="text-align:right">name</th><th style="text-align:right">score</th><th></th></tr></thead><tbody><tr><td style="text-align:right">1</td><td style="text-align:right">1</td><td style="text-align:right">zhang1</td><td>80.0</td></tr></tbody></table><h2 id="3-2-缺失值处理">3.2 缺失值处理</h2><table><thead><tr><th></th><th>连续变量</th><th>分类变量</th><th>补充说明</th></tr></thead><tbody><tr><td>小于20%</td><td>均值或者中位数</td><td>不需要填补，单算一类或众数填补</td><td></td></tr><tr><td>20%-80%</td><td>均值或者中位数</td><td>不需要填补，单算一类或众数填补</td><td>填补方式与20%类似，但是每个缺失值变量可以设置一个指示哑变量，参与后续建模</td></tr><tr><td>大于80%</td><td></td><td></td><td>每个有缺失值的变量生成一个指示哑变量，参与后续建模，不再使用原始变量</td></tr></tbody></table><p><strong>缺失值为20%-80%时：</strong></p><p><img src="https://picture.mulindya.com/image-20210115110534941.png" alt=""></p><h3 id="3-2-1-统计空值所各个列的比例">3.2.1 统计空值所各个列的比例</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.apply(<span class="hljs-keyword">lambda</span> x:<span class="hljs-built_in">sum</span>(x.isnull())/x.size)<br></code></pre></td></tr></tbody></table></figure><p>可以对Series进行sum操作 ；</p><p>这里布尔类型就会返回True的个数；</p><h3 id="3-2-2-填充">3.2.2 填充</h3><p>fillna（）：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: data.math.fillna(value=<span class="hljs-literal">None</span>, method=<span class="hljs-literal">None</span>, axis=<span class="hljs-literal">None</span>, inplace=<span class="hljs-literal">False</span>, limit=<span class="hljs-literal">None</span>, downcast=<span class="hljs-literal">None</span>, **kwargs)<br>Docstring:<br>Fill NA/NaN values using the specified method<br></code></pre></td></tr></tbody></table></figure><h4 id="3-2-2-1-均值填充">3.2.2.1 均值填充</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.math.fillna(data.math.mean())<br></code></pre></td></tr></tbody></table></figure><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">0</span>    <span class="hljs-number">98</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">1</span>    <span class="hljs-number">78</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">2</span>    <span class="hljs-number">87</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">3</span>    <span class="hljs-number">77</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">4</span>    <span class="hljs-number">77</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">5</span>    <span class="hljs-number">83</span>.<span class="hljs-number">4</span><br><span class="hljs-attribute">Name</span>: math, dtype: float<span class="hljs-number">64</span><br></code></pre></td></tr></tbody></table></figure><h4 id="3-2-2-1-中位数填充">3.2.2.1 中位数填充</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.math.fillna(data.math.median())<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-number">0</span>    <span class="hljs-number">98.0</span><br><span class="hljs-number">1</span>    <span class="hljs-number">78.0</span><br><span class="hljs-number">2</span>    <span class="hljs-number">87.0</span><br><span class="hljs-number">3</span>    <span class="hljs-number">77.0</span><br><span class="hljs-number">4</span>    <span class="hljs-number">77.0</span><br><span class="hljs-number">5</span>    <span class="hljs-number">78.0</span><br>Name: math, dtype: float64<br></code></pre></td></tr></tbody></table></figure><h3 id="3-2-3-缺失值指示变量">3.2.3 缺失值指示变量</h3><figure class="highlight haskell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-class"><span class="hljs-keyword">data</span>.math.isnull().apply(<span class="hljs-title">int</span>)</span><br></code></pre></td></tr></tbody></table></figure><p>.apply(int)对相应的布尔 返回0，1</p><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">0</span>    <span class="hljs-number">0</span><br><span class="hljs-attribute">1</span>    <span class="hljs-number">0</span><br><span class="hljs-attribute">2</span>    <span class="hljs-number">0</span><br><span class="hljs-attribute">3</span>    <span class="hljs-number">0</span><br><span class="hljs-attribute">4</span>    <span class="hljs-number">0</span><br><span class="hljs-attribute">5</span>    <span class="hljs-number">1</span><br><span class="hljs-attribute">Name</span>: math, dtype: int<span class="hljs-number">64</span><br></code></pre></td></tr></tbody></table></figure><h2 id="3-3-噪声值处理">3.3 噪声值处理</h2><blockquote><p>这里简要介绍，在最后的实战中可以看到详细的噪声处理的具体函数和方法。</p></blockquote><p>噪声值：数据中有一个和多个与其他数值相差较大的值，异常值，离群值；</p><h3 id="3-3-1-处理方法">3.3.1 处理方法</h3><p>单变量： 盖帽法，分箱法；</p><p>多变量：聚类法；</p><h3 id="3-3-2-盖帽法">3.3.2 盖帽法</h3><p>将连续型变量均值上下三倍标准差范围外数据替换为均值上下三倍标准差；</p><h1>数据清洗实战 📋</h1><h1>处理脏数据</h1><h2 id="1-0值处理">1. 0值处理</h2><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-section">&lt;class 'pandas.core.frame.DataFrame'&gt;</span><br><span class="hljs-attribute">RangeIndex</span>: <span class="hljs-number">9686</span> entries, <span class="hljs-number">0</span> to <span class="hljs-number">9685</span><br><span class="hljs-attribute">Data</span> columns (total <span class="hljs-number">14</span> columns):<br><span class="hljs-attribute">ID</span>              <span class="hljs-number">9686</span> non-null int<span class="hljs-number">64</span><br><span class="hljs-attribute">Suc_flag</span>        <span class="hljs-number">9686</span> non-null int<span class="hljs-number">64</span><br><span class="hljs-attribute">ARPU</span>            <span class="hljs-number">4843</span> non-null float<span class="hljs-number">64</span><br><span class="hljs-attribute">PromCnt12</span>       <span class="hljs-number">9686</span> non-null int<span class="hljs-number">64</span><br><span class="hljs-attribute">PromCnt36</span>       <span class="hljs-number">9686</span> non-null int<span class="hljs-number">64</span><br><span class="hljs-attribute">PromCntMsg12</span>    <span class="hljs-number">9686</span> non-null int<span class="hljs-number">64</span><br><span class="hljs-attribute">PromCntMsg36</span>    <span class="hljs-number">9686</span> non-null int<span class="hljs-number">64</span><br><span class="hljs-attribute">Class</span>           <span class="hljs-number">9686</span> non-null int<span class="hljs-number">64</span><br><span class="hljs-attribute">Age</span>             <span class="hljs-number">7279</span> non-null float<span class="hljs-number">64</span><br><span class="hljs-attribute">Gender</span>          <span class="hljs-number">9686</span> non-null object<br><span class="hljs-attribute">HomeOwner</span>       <span class="hljs-number">9686</span> non-null object<br><span class="hljs-attribute">AvgARPU</span>         <span class="hljs-number">9686</span> non-null float<span class="hljs-number">64</span><br><span class="hljs-attribute">AvgHomeValue</span>    <span class="hljs-number">9686</span> non-null int<span class="hljs-number">64</span><br><span class="hljs-attribute">AvgIncome</span>       <span class="hljs-number">9686</span> non-null int<span class="hljs-number">64</span><br><span class="hljs-attribute">dtypes</span>: float<span class="hljs-number">64</span>(<span class="hljs-number">3</span>), int<span class="hljs-number">64</span>(<span class="hljs-number">9</span>), object(<span class="hljs-number">2</span>)<br><span class="hljs-attribute">memory</span> usage: <span class="hljs-number">1</span>.<span class="hljs-number">0</span>+ MB<br></code></pre></td></tr></tbody></table></figure><p><img src="C:%5CUsers%5C86137%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210118114510765.png" alt="image-20210118114510765"></p><p>在AvgHomeValue，AvgIncome中的0值替换为缺失值</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">data[<span class="hljs-string">'AvgHomeValue'</span>] = data[<span class="hljs-string">'AvgHomeValue'</span>].replace({<span class="hljs-number">0</span>:np.NaN})<br>data[<span class="hljs-string">'AvgIncome'</span>] = data[<span class="hljs-string">'AvgIncome'</span>].replace({<span class="hljs-number">0</span>:np.NaN})<br></code></pre></td></tr></tbody></table></figure><h2 id="2-标记重复数据">2. 标记重复数据</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">data[<span class="hljs-string">'dup'</span>] = data.duplicated() <br>data_dup = data[data[<span class="hljs-string">'dup'</span>]==<span class="hljs-literal">True</span>]<br><span class="hljs-built_in">print</span>(data_dup)<br>data_undup = data[data[<span class="hljs-string">'dup'</span>]==<span class="hljs-literal">False</span>]<br></code></pre></td></tr></tbody></table></figure><h2 id="3-缺失值填充">3. 缺失值填充</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">mean = data[<span class="hljs-string">'Age'</span>].mean(skipna=<span class="hljs-literal">True</span>)<br>data[<span class="hljs-string">'newage'</span>] = data[<span class="hljs-string">'Age'</span>].fillna(mean)<br>mean = data[<span class="hljs-string">'AvgIncome'</span>].mean(skipna=<span class="hljs-literal">True</span>)<br>data[<span class="hljs-string">'newAvgIncome_flag'</span>] = data[<span class="hljs-string">'AvgIncome'</span>].isnull()<br>data[<span class="hljs-string">'newAvgIncome'</span>] = data[<span class="hljs-string">'AvgIncome'</span>].fillna(mean)<br></code></pre></td></tr></tbody></table></figure><h2 id="4-噪声处理">4. 噪声处理</h2><h3 id="4-1-计算出百分位数">4.1 计算出百分位数</h3><p><strong>填充之后的数据进行噪声处理</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">q1 = data[<span class="hljs-string">'newage'</span>].quantile(<span class="hljs-number">0.01</span>)<br>q99 = data[<span class="hljs-string">'newage'</span>].quantile(<span class="hljs-number">0.99</span>)<br></code></pre></td></tr></tbody></table></figure><h3 id="4-2-盖帽法处理噪声">4.2 盖帽法处理噪声</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">func</span>(<span class="hljs-params">floor,qmax</span>):</span> <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">f</span>(<span class="hljs-params">x</span>):</span><br>        <span class="hljs-keyword">if</span> x&lt;floor:<br>            x = floor<br>        <span class="hljs-keyword">elif</span> x&gt;qmax:<br>            x = qmax<br>        <span class="hljs-keyword">return</span> x<br>    <span class="hljs-keyword">return</span> f<br></code></pre></td></tr></tbody></table></figure><p>处理噪声</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">func1 = func(q1,q99)<br>data[<span class="hljs-string">'newage'</span>] = data[<span class="hljs-string">'newage'</span>].<span class="hljs-built_in">map</span>(func1) <br></code></pre></td></tr></tbody></table></figure><p><em>使用map函数处理噪声，将百分之1以下的数据替换为q1,将百分之99以上的数据替换为q99；</em></p><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">count</span>    <span class="hljs-number">9686</span>.<span class="hljs-number">000000</span><br><span class="hljs-attribute">mean</span>       <span class="hljs-number">49</span>.<span class="hljs-number">624685</span><br><span class="hljs-attribute">std</span>         <span class="hljs-number">5</span>.<span class="hljs-number">835803</span><br><span class="hljs-attribute">min</span>        <span class="hljs-number">31</span>.<span class="hljs-number">000000</span><br><span class="hljs-attribute">25</span>%        <span class="hljs-number">47</span>.<span class="hljs-number">000000</span><br><span class="hljs-attribute">50</span>%        <span class="hljs-number">49</span>.<span class="hljs-number">567386</span><br><span class="hljs-attribute">75</span>%        <span class="hljs-number">54</span>.<span class="hljs-number">000000</span><br><span class="hljs-attribute">max</span>        <span class="hljs-number">60</span>.<span class="hljs-number">000000</span><br><span class="hljs-attribute">Name</span>: newage, dtype: float<span class="hljs-number">64</span><br></code></pre></td></tr></tbody></table></figure><h3 id="4-3-分箱法处理噪声">4.3 分箱法处理噪声</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 噪声处理 分箱法</span><br>data[<span class="hljs-string">'newage_qcut'</span>] = pd.qcut(data[<span class="hljs-string">'newage'</span>],<span class="hljs-number">4</span>)<br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right"></th><th style="text-align:right">newage</th><th style="text-align:right">newage_qcut</th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:right">57.000000</td><td style="text-align:right">(54.0, 60.0]</td></tr><tr><td style="text-align:right">1</td><td style="text-align:right">55.000000</td><td style="text-align:right">(54.0, 60.0]</td></tr><tr><td style="text-align:right">2</td><td style="text-align:right">57.000000</td><td style="text-align:right">(54.0, 60.0]</td></tr><tr><td style="text-align:right">3</td><td style="text-align:right">52.000000</td><td style="text-align:right">(49.567, 54.0]</td></tr><tr><td style="text-align:right">4</td><td style="text-align:right">49.567386</td><td style="text-align:right">(47.0, 49.567]</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数据分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>数据分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据分析笔记--数据查询和表相关操作</title>
    <link href="/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis3/"/>
    <url>/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis3/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本科实训的时候记录的数据分析的笔记，感觉还挺全面的，部署到博客中，今后对数据分析的应用可以方便回顾。</p></blockquote><blockquote><p>本篇主要内容是数据查询以及表的各种操作，包括单条件查询，多条件查询，连续查询，不连续查询，还可以使用正则表达式查询。😉还有一些表的操作，内连接，外连接，合并，排序，分类汇总。很干货了呀~</p></blockquote><h1>1 数据查询</h1><p><em>表：</em></p><table><thead><tr><th style="text-align:right"></th><th style="text-align:right">name</th><th style="text-align:right">score</th><th style="text-align:right">group</th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:right">zhang1</td><td style="text-align:right">61</td><td style="text-align:right">1</td></tr><tr><td style="text-align:right">1</td><td style="text-align:right">zhang2</td><td style="text-align:right">85</td><td style="text-align:right">1</td></tr><tr><td style="text-align:right">2</td><td style="text-align:right">zhang3</td><td style="text-align:right">47</td><td style="text-align:right">1</td></tr><tr><td style="text-align:right">3</td><td style="text-align:right">zhang4</td><td style="text-align:right">99</td><td style="text-align:right">2</td></tr><tr><td style="text-align:right">4</td><td style="text-align:right">zhang5</td><td style="text-align:right">100</td><td style="text-align:right">3</td></tr><tr><td style="text-align:right">5</td><td style="text-align:right">zhang6</td><td style="text-align:right">75</td><td style="text-align:right">1</td></tr></tbody></table><h2 id="1-1-单条件查询">1.1 单条件查询</h2><p>查询分数大于80的同学姓名</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df1[df1.score&gt;<span class="hljs-number">80</span>].name<br></code></pre></td></tr></tbody></table></figure><h2 id="1-2-多条件查询">1.2 多条件查询</h2><h3 id="1-2-1-使用位运算">1.2.1 使用位运算</h3><p>查询分数大于90或者分组为2的列表</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df1[(df1.score&gt;<span class="hljs-number">90</span>) | (df1.group==<span class="hljs-number">2</span>)]<br></code></pre></td></tr></tbody></table></figure><p>查询分数大于60并且分组为1的列表</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df1[(df1.score&gt;<span class="hljs-number">60</span>) &amp; (df1.group==<span class="hljs-number">1</span>)] <br></code></pre></td></tr></tbody></table></figure><p><strong>注意点</strong> 在条件筛选时要使用&amp;|~ 进行位运算</p><p><font color="purple">不可以用and关键字 只能用&amp;符号 &amp;|~;&amp;指的是位运算，Python中的逻辑操作符为 and  or  not，and指的是逻辑运算。所以在选择结构中表示 与 用 and。或用 or。这里要用位运算符。</font></p><h3 id="1-2-1-query">1.2.1 query</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df1.query(<span class="hljs-string">'score&gt;88'</span>)<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: df1.query(expr, inplace=<span class="hljs-literal">False</span>, **kwargs)<br>Docstring:<br>Query the columns of a frame <span class="hljs-keyword">with</span> a boolean expression.<br></code></pre></td></tr></tbody></table></figure><p><strong>注意点</strong>：条件是用字符串表达；并且直接引用score。</p><h2 id="1-3-其他查询">1.3 其他查询</h2><h3 id="1-3-1连续查询">1.3.1连续查询</h3><p>使用<strong>between</strong>函数；</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df1[df1.score.between(<span class="hljs-number">70</span>,<span class="hljs-number">85</span>,inclusive=<span class="hljs-literal">False</span>)] <br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right"></th><th style="text-align:right">name</th><th style="text-align:right">score</th><th style="text-align:right">group</th></tr></thead><tbody><tr><td style="text-align:right">5</td><td style="text-align:right">zhang6</td><td style="text-align:right">75</td><td style="text-align:right">1</td></tr></tbody></table><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: df1.score.between(left, right, inclusive=<span class="hljs-literal">True</span>)<br>Docstring:<br>Return boolean Series equivalent to left &lt;= series &lt;= right<br></code></pre></td></tr></tbody></table></figure><p>between函数默认包含边界</p><h3 id="1-3-2-不连续查询">1.3.2 不连续查询</h3><p>使用<strong>isin</strong>函数；</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df1[df1.name.isin([<span class="hljs-string">'zhang3'</span>,<span class="hljs-string">'zhang5'</span>])]<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: df1.name.isin(values)<br>Docstring:<br>Check whether `values` are contained <span class="hljs-keyword">in</span> Series.<br>Return a boolean Series showing whether each element <span class="hljs-keyword">in</span> the Series<br>matches an element <span class="hljs-keyword">in</span> the passed sequence of `values` exactly.<br></code></pre></td></tr></tbody></table></figure><p><strong>注意点</strong>：values : <em>set or list-like</em> 内部的参数必须是一个集合形式；</p><h3 id="1-3-3-正则表达式">1.3.3 正则表达式</h3><p>使用正则表达式进行字符串匹配；</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df1[df1.name.<span class="hljs-built_in">str</span>.contains(<span class="hljs-string">'zhang+'</span>)] <br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: df1.name.<span class="hljs-built_in">str</span>.contains(pat, case=<span class="hljs-literal">True</span>, flags=<span class="hljs-number">0</span>, na=nan, regex=<span class="hljs-literal">True</span>)<br>Docstring:<br>Test <span class="hljs-keyword">if</span> pattern <span class="hljs-keyword">or</span> regex <span class="hljs-keyword">is</span> contained within a string of a Series <span class="hljs-keyword">or</span> Index.<br><br>Return boolean Series <span class="hljs-keyword">or</span> Index based on whether a given pattern <span class="hljs-keyword">or</span> regex <span class="hljs-keyword">is</span><br>contained within a string of a Series <span class="hljs-keyword">or</span> Index.<br></code></pre></td></tr></tbody></table></figure><p><strong>注意点</strong>：#转化为str再进行匹配</p><h1>2 数据连接</h1><p><img src="https://picture.mulindya.com/image-20210114103553639.png" alt=""></p><h2 id="2-1-内连接">2.1 内连接</h2><p><strong>取两表中的交集</strong> ，有数据损失；</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: df1.merge(right, how=<span class="hljs-string">'inner'</span>, on=<span class="hljs-literal">None</span>, left_on=<span class="hljs-literal">None</span>, right_on=<span class="hljs-literal">None</span>, left_index=<span class="hljs-literal">False</span>, right_index=<span class="hljs-literal">False</span>, sort=<span class="hljs-literal">False</span>, suffixes=(<span class="hljs-string">'_x'</span>, <span class="hljs-string">'_y'</span>), copy=<span class="hljs-literal">True</span>, indicator=<span class="hljs-literal">False</span>, validate=<span class="hljs-literal">None</span>)<br>Docstring:<br>Merge DataFrame objects by performing a database-style join operation by<br>columns <span class="hljs-keyword">or</span> indexes.<br></code></pre></td></tr></tbody></table></figure><p>how: 连接方式；</p><p>on:  公共字段</p><figure class="highlight livecodeserver"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">df1.<span class="hljs-built_in">merge</span>(df2,how=<span class="hljs-string">"inner"</span>,<span class="hljs-keyword">on</span>=<span class="hljs-string">'id'</span>)<br><br>df1.<span class="hljs-built_in">merge</span>(df2,how=<span class="hljs-string">'inner'</span>,left_on=<span class="hljs-string">'id'</span>,right_on=<span class="hljs-string">'id'</span>) <br></code></pre></td></tr></tbody></table></figure><p><strong>注意点</strong>： <em>公共字段在两表中名字不一致时使用</em>left_on,right_on</p><h2 id="2-2-外连接">2.2 外连接</h2><h3 id="2-2-1-左连接">2.2.1 左连接</h3><p>通过公共字段 保留左表信息 右在左缺失数据全部以nan填充；</p><figure class="highlight livecodeserver"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">df1.<span class="hljs-built_in">merge</span>(df2,how=<span class="hljs-string">'left'</span>,<span class="hljs-keyword">on</span>=<span class="hljs-string">'id'</span>)<br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right">id</th><th style="text-align:right">coll_x</th><th style="text-align:right">coll_y</th><th></th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">a</td><td>NaN</td></tr><tr><td style="text-align:right">1</td><td style="text-align:right">2</td><td style="text-align:right">b</td><td>NaN</td></tr><tr><td style="text-align:right">2</td><td style="text-align:right">3</td><td style="text-align:right">c</td><td>e</td></tr></tbody></table><figure class="highlight livecodeserver"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">df2.<span class="hljs-built_in">merge</span>(df1,how=<span class="hljs-string">'left'</span>,<span class="hljs-keyword">on</span>=<span class="hljs-string">'id'</span>)<br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right"></th><th style="text-align:right">id</th><th style="text-align:right">coll_x</th><th style="text-align:right">coll_y</th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:right">4</td><td style="text-align:right">d</td><td style="text-align:right">NaN</td></tr><tr><td style="text-align:right">1</td><td style="text-align:right">3</td><td style="text-align:right">e</td><td style="text-align:right">c</td></tr></tbody></table><p>左连接是以左表为主表，所以，数据展示是以左表为主，因此与调用对象有关。</p><h3 id="2-2-2-右连接">2.2.2 右连接</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df1.merge(df2,how=<span class="hljs-string">'right'</span>,on=<span class="hljs-string">'id'</span>)<br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right"></th><th style="text-align:right">id</th><th style="text-align:right">coll_x</th><th style="text-align:right">coll_y</th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:right">3</td><td style="text-align:right">c</td><td style="text-align:right">e</td></tr><tr><td style="text-align:right">1</td><td style="text-align:right">4</td><td style="text-align:right">NaN</td><td style="text-align:right">d</td></tr></tbody></table><h3 id="2-2-3-全连接">2.2.3 全连接</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df1.merge(df2,how=<span class="hljs-string">'outer'</span>,on=<span class="hljs-string">'id'</span>)<br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right">id</th><th style="text-align:right">coll_x</th><th style="text-align:right">coll_y</th><th></th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:right">1</td><td style="text-align:right">a</td><td>NaN</td></tr><tr><td style="text-align:right">1</td><td style="text-align:right">2</td><td style="text-align:right">b</td><td>NaN</td></tr><tr><td style="text-align:right">2</td><td style="text-align:right">3</td><td style="text-align:right">c</td><td>e</td></tr><tr><td style="text-align:right">3</td><td style="text-align:right">4</td><td style="text-align:right">NaN</td><td>d</td></tr></tbody></table><h2 id="2-3-行索引连接">2.3 行索引连接</h2><h3 id="2-3-1-横向合并">2.3.1 横向合并</h3><p>pd的concat函数：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: pd.concat(objs, axis=<span class="hljs-number">0</span>, join=<span class="hljs-string">'outer'</span>, join_axes=<span class="hljs-literal">None</span>, ignore_index=<span class="hljs-literal">False</span>, keys=<span class="hljs-literal">None</span>, levels=<span class="hljs-literal">None</span>, names=<span class="hljs-literal">None</span>, verify_integrity=<span class="hljs-literal">False</span>, sort=<span class="hljs-literal">None</span>, copy=<span class="hljs-literal">True</span>)<br>Docstring:<br>Concatenate pandas objects along a particular axis <span class="hljs-keyword">with</span> optional <span class="hljs-built_in">set</span> logic<br>along the other axes.<br></code></pre></td></tr></tbody></table></figure><p>默认axis为0，是对行进行堆叠；<strong>横向合并要改为1</strong></p><p>join()函数；</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: df3.join(other, on=<span class="hljs-literal">None</span>, how=<span class="hljs-string">'left'</span>, lsuffix=<span class="hljs-string">''</span>, rsuffix=<span class="hljs-string">''</span>, sort=<span class="hljs-literal">False</span>)<br>Docstring:<br>Join columns <span class="hljs-keyword">with</span> other DataFrame either on index <span class="hljs-keyword">or</span> on a key<br>column. Efficiently Join multiple DataFrame objects by index at once by<br>passing a <span class="hljs-built_in">list</span>.<br></code></pre></td></tr></tbody></table></figure><p>如果是join函数在使用是合并对象的列不可重复</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">pd.concat([df3,df4],axis=<span class="hljs-number">1</span>) <br>或者<br>df3.join(df4)<br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right"></th><th style="text-align:right">key</th><th style="text-align:right">col1</th><th style="text-align:right">id</th><th style="text-align:right">col2</th></tr></thead><tbody><tr><td style="text-align:right">1</td><td style="text-align:right">1</td><td style="text-align:right">a</td><td style="text-align:right">1</td><td style="text-align:right">aa</td></tr><tr><td style="text-align:right">2</td><td style="text-align:right">2</td><td style="text-align:right">b</td><td style="text-align:right">3</td><td style="text-align:right">cc</td></tr><tr><td style="text-align:right">3</td><td style="text-align:right">3</td><td style="text-align:right">c</td><td style="text-align:right">2</td><td style="text-align:right">bb</td></tr></tbody></table><h3 id="2-3-2-纵向合并">2.3.2 纵向合并</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">pd.concat([df5,df6],keys=[<span class="hljs-string">'A'</span>,<span class="hljs-string">'B'</span>])<br>pd.concat([df5,df6],ignore_index=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></tbody></table></figure><p>合并完成之后 注意重复数据 删除重复数据 可以使用drop_duplicates()</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pd.concat([df5,df6],ignore_index=<span class="hljs-literal">True</span>).drop_duplicates()<br></code></pre></td></tr></tbody></table></figure><h2 id="2-4-排序">2.4 排序</h2><p>sort_values()函数：按值排序</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: df1.sort_values(by, axis=<span class="hljs-number">0</span>, ascending=<span class="hljs-literal">True</span>, inplace=<span class="hljs-literal">False</span>, kind=<span class="hljs-string">'quicksort'</span>, na_position=<span class="hljs-string">'last'</span>)<br>Docstring:<br>Sort by the values along either axis<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df1.sort_values([<span class="hljs-string">'group'</span>,<span class="hljs-string">'score'</span>])<br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right"></th><th style="text-align:right">name</th><th style="text-align:right">score</th><th>group</th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:right">zhang1</td><td style="text-align:right">61.0</td><td>1</td></tr><tr><td style="text-align:right">1</td><td style="text-align:right">zhang2</td><td style="text-align:right">85.0</td><td>1</td></tr><tr><td style="text-align:right">2</td><td style="text-align:right">zhang3</td><td style="text-align:right">90.0</td><td>1</td></tr><tr><td style="text-align:right">5</td><td style="text-align:right">zhang6</td><td style="text-align:right">NaN</td><td>1</td></tr><tr><td style="text-align:right">3</td><td style="text-align:right">zhang4</td><td style="text-align:right">87.0</td><td>2</td></tr><tr><td style="text-align:right">4</td><td style="text-align:right">zhang5</td><td style="text-align:right">100.0</td><td>3</td></tr></tbody></table><h1>3 分类汇总</h1><h2 id="3-1-分类">3.1 分类</h2><table><thead><tr><th style="text-align:right"></th><th style="text-align:right">chinese</th><th style="text-align:right">class</th><th style="text-align:right">grade</th><th style="text-align:right">math</th><th style="text-align:right">name</th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:right">88</td><td style="text-align:right">1</td><td style="text-align:right">1</td><td style="text-align:right">98.0</td><td style="text-align:right">Bob</td></tr><tr><td style="text-align:right">1</td><td style="text-align:right">78</td><td style="text-align:right">1</td><td style="text-align:right">1</td><td style="text-align:right">78.0</td><td style="text-align:right">Lindy</td></tr><tr><td style="text-align:right">2</td><td style="text-align:right">86</td><td style="text-align:right">1</td><td style="text-align:right">1</td><td style="text-align:right">87.0</td><td style="text-align:right">Mark</td></tr><tr><td style="text-align:right">3</td><td style="text-align:right">56</td><td style="text-align:right">2</td><td style="text-align:right">2</td><td style="text-align:right">77.0</td><td style="text-align:right">Miki</td></tr><tr><td style="text-align:right">4</td><td style="text-align:right">77</td><td style="text-align:right">1</td><td style="text-align:right">2</td><td style="text-align:right">77.0</td><td style="text-align:right">Sully</td></tr></tbody></table><h3 id="3-1-1-按照年级和班级-对成绩求均值">3.1.1 按照年级和班级 对成绩求均值</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.groupby([<span class="hljs-string">'grade'</span>,<span class="hljs-string">'class'</span>])[[<span class="hljs-string">'math'</span>]].mean()<br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right"></th><th style="text-align:right">math</th><th style="text-align:right"></th></tr></thead><tbody><tr><td style="text-align:right">grade</td><td style="text-align:right">class</td><td style="text-align:right"></td></tr><tr><td style="text-align:right">1</td><td style="text-align:right">1</td><td style="text-align:right">87.666667</td></tr><tr><td style="text-align:right">2</td><td style="text-align:right">1</td><td style="text-align:right">77.000000</td></tr><tr><td style="text-align:right">2</td><td style="text-align:right">2</td><td style="text-align:right">77.000000</td></tr></tbody></table><h3 id="3-1-2-按照年级汇总数学语文-均值">3.1.2 按照年级汇总数学语文 均值</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.groupby([<span class="hljs-string">'grade'</span>])[[<span class="hljs-string">'math'</span>,<span class="hljs-string">'chinese'</span>]].mean()<br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right">grade</th><th style="text-align:right">math</th><th style="text-align:right">chinese</th></tr></thead><tbody><tr><td style="text-align:right">1</td><td style="text-align:right">87.666667</td><td style="text-align:right">84.000000</td></tr><tr><td style="text-align:right">2</td><td style="text-align:right">77.000000</td><td style="text-align:right">62.333333</td></tr></tbody></table><p><em><em>注意点：<strong>首先对data表进行groupby，然后在返回的对象中选取列，用</strong></em>列表封装</em>**选取；</p><h2 id="3-2-汇总">3.2  汇总</h2><p>使用agg聚合进行显示均值，最值，中位数，标准差，平均绝对偏差，计数，偏差；</p><figure class="highlight stylus"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">data<span class="hljs-selector-class">.groupby</span>(<span class="hljs-selector-attr">[<span class="hljs-string">'grade'</span>]</span>)<span class="hljs-selector-attr">[[<span class="hljs-string">'math'</span>,<span class="hljs-string">'chinese'</span>]</span>]<span class="hljs-selector-class">.agg</span>(<span class="hljs-selector-attr">[<span class="hljs-string">'mean'</span>,<span class="hljs-string">'max'</span>,<span class="hljs-string">'min'</span>,<span class="hljs-string">'median'</span>,<span class="hljs-string">'std'</span>,<span class="hljs-string">'mad'</span>,<span class="hljs-string">'count'</span>,<span class="hljs-string">'skew'</span>]</span>)<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数据分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>数据分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据分析笔记--数据分析</title>
    <link href="/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis2/"/>
    <url>/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis2/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本科实训的时候记录的数据分析的笔记，感觉还挺全面的，部署到博客中，今后对数据分析的应用可以方便回顾。</p></blockquote><blockquote><p>本篇主要内容是数据分析，包括单纯的描述性分析和报表分析，这里主要讲解了单连续变量描述统计量的描述性分析以及报表分析。可以参考本篇的图表绘制方法哦！ 👾</p></blockquote><h1>1 描述性分析 🎩</h1><ol><li>单分类变量描述频数，例如：value_counts()描述分类变量 柱形图</li><li>单连续变量描述统计量（均值，中位数，四分位数，总和等），例如：聚合函数agg（）描述价格变量 直方图</li><li>分类变量与分类变量描述频数，例如：交叉表crosstab()描述各地区与是否学区房 交叉表——堆叠柱状图</li><li>单分类变量与单连续变量描述连续变量统计值，例如，分组groupby()描述各地区的房价分布</li><li>双分类变量与连续变量描述连续变量统计值，透视表pivot_table()描述各地区房价与地域，学区房的关系</li></ol><h2 id="1-1-单变量描述">1.1 单变量描述</h2><p>这里主要讲解单连续变量描述统计量。</p><h3 id="基本的数据描述">基本的数据描述</h3><ul><li><p>平均值</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">data.loc[:,<span class="hljs-string">'price'</span>].mean()<br><span class="hljs-keyword">or</span><br>data.price.mean()<br></code></pre></td></tr></tbody></table></figure></li><li><p>中位数</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.price.median()<br></code></pre></td></tr></tbody></table></figure></li><li><p>标准差</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.price.std()<br></code></pre></td></tr></tbody></table></figure></li><li><p>方差</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.price.var()<br></code></pre></td></tr></tbody></table></figure></li><li><p>使用聚合函数</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.price.agg([<span class="hljs-string">'mean'</span>,<span class="hljs-string">'median'</span>,<span class="hljs-string">'std'</span>,<span class="hljs-string">'var'</span>])<br></code></pre></td></tr></tbody></table></figure></li></ul><h2 id="1-2-绘制图分析">1.2 绘制图分析</h2><p>​绘制直方图</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.price.hist(bins=<span class="hljs-number">20</span>) <br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210113100910142.png" alt=""></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">data.price.skew() <span class="hljs-comment">#大于0为右偏 小于0是左偏</span><br><span class="hljs-comment">#0.6794935869486859</span><br></code></pre></td></tr></tbody></table></figure><h3 id="1-2-1-偏度（Skewness）">1.2.1 偏度（Skewness）</h3><p>Definition:是描述数据分布形态的统计量，其描述的是某总体取值分布的<strong>对称性</strong>，简单来说就是数据的不对称程度。。</p><p>偏度是三阶中心距计算出来的。<br>（1）Skewness = 0 ，分布形态与正态分布偏度相同。<br>（2）Skewness &gt; 0 ，正偏差数值较大，为正偏或右偏。长尾巴拖在右边，数据右端有较多的极端值。<br>（3）Skewness &lt; 0 ，负偏差数值较大，为负偏或左偏。长尾巴拖在左边，数据左端有较多的极端值。<br>（4）数值的绝对值越大，表明数据分布越不对称，偏斜程度大。<br>计算公式：<br>$$<br>Skewness=E[((x-E(x))/(\sqrt{D(x)}))^3]<br>$$</p><p>$$<br>| Skewness|越大，分布形态偏移程度越大。<br>$$</p><p><img src="https://picture.mulindya.com/image-20210113101410092.png" alt=""></p><h3 id="1-2-2-峰度（Kurtosis）">1.2.2 峰度（Kurtosis）</h3><p>Definition:偏度是描述某变量所有取值分布形态陡缓程度的统计量，简单来说就是数据分布顶的<strong>尖锐程度</strong>。<br>峰度是四阶标准矩计算出来的。<br>（1）Kurtosis=0 与正态分布的陡缓程度相同。<br>（2）Kurtosis&gt;0 比正态分布的高峰更加陡峭——尖顶峰<br>（3）Kurtosis&lt;0 比正态分布的高峰来得平台——平顶峰<br>计算公式：<br>$$<br>Kurtosis=E[ ( (x-E(x))/ (\sqrt(D(x))) )^4 ]-3<br>$$</p><h3 id="1-2-3-分位数">1.2.3 分位数</h3><p>其中0.25 和0.75 为四分位数，0.5是均值</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.price.quantile([<span class="hljs-number">0.25</span>,<span class="hljs-number">0.5</span>,<span class="hljs-number">0.75</span>]) <br></code></pre></td></tr></tbody></table></figure><p><strong>注意点</strong>：四分位 忽略NA值</p><h1>2  报表分析 👑</h1><p>报表展示数据主要信息 ；分为维度指标（分类指标） 和度量指标 （连续变量）；仅包含维度指标的报表为频次表（单个分类变量）和交叉表（两个和两个以上分类变量）。包含维度和度量两类指标的报表称之为汇总表 度量指标总是以某个统计量的形式出现，最常见的是均值，总和，频次。</p><h2 id="2-1-表分析">2.1 表分析</h2><h3 id="2-1-1交叉表">2.1.1交叉表</h3><p>分析两个分类变量的联合分布情况 提供每个单元格频次,百分比和边沿分布。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">subway_school = pd.crosstab(data.subway,data.school)<br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right">subway\school</th><th style="text-align:right">0</th><th style="text-align:right">1</th></tr></thead><tbody><tr><td style="text-align:right">0</td><td style="text-align:right">2378</td><td style="text-align:right">413</td></tr><tr><td style="text-align:right">1</td><td style="text-align:right">8919</td><td style="text-align:right">4500</td></tr></tbody></table><p><strong>绘图：</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">subway_school.plot(kind=<span class="hljs-string">'bar'</span>)<br></code></pre></td></tr></tbody></table></figure><p>横轴默认为subway（行）</p><p><img src="https://picture.mulindya.com/image-20210113123315967.png" alt=""></p><p>进一步分析：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">subway_school.<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>)是axis为<span class="hljs-number">1</span>的条件下的和（对列相加）<br></code></pre></td></tr></tbody></table></figure><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">subway</span><br><span class="hljs-attribute">0</span>     <span class="hljs-number">2791</span><br><span class="hljs-attribute">1</span>    <span class="hljs-number">13419</span><br><span class="hljs-attribute">dtype</span>: int<span class="hljs-number">64</span><br></code></pre></td></tr></tbody></table></figure><p><em><strong>div函数</strong></em>： sum的axis为1，在使用div函数时div函数中的axis应该取0，也就是对应的行中的数据占此行总数的比例</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: subway_school.div(other, axis=<span class="hljs-string">'columns'</span>, level=<span class="hljs-literal">None</span>, fill_value=<span class="hljs-literal">None</span>)<br>Docstring:<br>Floating division of dataframe <span class="hljs-keyword">and</span> other, element-wise (binary operator `truediv`).<br><br>Equivalent to ``dataframe / other``, but <span class="hljs-keyword">with</span> support to substitute a fill_value <span class="hljs-keyword">for</span><br>missing data <span class="hljs-keyword">in</span> one of the inputs.<br></code></pre></td></tr></tbody></table></figure><p>实例代码：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">subway_school_per = subway_school.div(subway_school.<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>),axis=<span class="hljs-number">0</span>) <span class="hljs-comment">#百分比</span><br>subway_school_per.plot(kind=<span class="hljs-string">'bar'</span>,stacked=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210113124417643.png" alt=""></p><h3 id="2-1-2-分类汇总">2.1.2 分类汇总</h3><h4 id="2-1-2-1-使用groupby分析">2.1.2.1 使用groupby分析</h4><p>**注意点：**groupbby分析返回的是对象</p><ul><li><p>通过dist对price分组 在分组中求均值</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.price.groupby(data.dist).mean()<br></code></pre></td></tr></tbody></table></figure><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">dist</span><br><span class="hljs-attribute">chaoyang</span>       <span class="hljs-number">52800</span>.<span class="hljs-number">624651</span><br><span class="hljs-attribute">dongcheng</span>      <span class="hljs-number">71883</span>.<span class="hljs-number">595041</span><br><span class="hljs-attribute">fengtai</span>        <span class="hljs-number">42500</span>.<span class="hljs-number">904309</span><br><span class="hljs-attribute">haidian</span>        <span class="hljs-number">68757</span>.<span class="hljs-number">602261</span><br><span class="hljs-attribute">shijingshan</span>    <span class="hljs-number">40286</span>.<span class="hljs-number">889574</span><br><span class="hljs-attribute">xicheng</span>        <span class="hljs-number">85674</span>.<span class="hljs-number">778545</span><br><span class="hljs-attribute">Name</span>: price, dtype: float<span class="hljs-number">64</span><br></code></pre></td></tr></tbody></table></figure></li><li><p>绘图</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.price.groupby(data.dist).mean().plot(kind=<span class="hljs-string">'bar'</span>)<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210113110942085.png" alt=""></p></li><li><p>排序</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.price.groupby(data.dist).mean().sort_values(ascending=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></tbody></table></figure><p>sort_values:是对数值进行排序，ascending默认是True，也就是按升序排序；</p></li><li><p>排序后绘图</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.price.groupby(data.dist).mean().sort_values(ascending=<span class="hljs-literal">False</span>).plot(kind=<span class="hljs-string">'bar'</span>)<br></code></pre></td></tr></tbody></table></figure></li></ul><p><img src="https://picture.mulindya.com/image-20210113110957663.png" alt=""></p><ul><li><p>归并函数结果</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.price.groupby(data.dist).agg([<span class="hljs-string">'mean'</span>,<span class="hljs-string">'max'</span>,<span class="hljs-string">'min'</span>,<span class="hljs-string">'std'</span>]) <br></code></pre></td></tr></tbody></table></figure><table><thead><tr><th style="text-align:right">dist</th><th style="text-align:right">mean</th><th style="text-align:right">max</th><th style="text-align:right">min</th><th style="text-align:right">std</th></tr></thead><tbody><tr><td style="text-align:right">chaoyang</td><td style="text-align:right">52800.624651</td><td style="text-align:right">124800</td><td style="text-align:right">23011</td><td style="text-align:right">13305.691821</td></tr><tr><td style="text-align:right">dongcheng</td><td style="text-align:right">71883.595041</td><td style="text-align:right">149254</td><td style="text-align:right">20089</td><td style="text-align:right">18368.096658</td></tr><tr><td style="text-align:right">fengtai</td><td style="text-align:right">42500.904309</td><td style="text-align:right">87838</td><td style="text-align:right">18348</td><td style="text-align:right">8888.588815</td></tr><tr><td style="text-align:right">haidian</td><td style="text-align:right">68757.602261</td><td style="text-align:right">135105</td><td style="text-align:right">25568</td><td style="text-align:right">17128.956039</td></tr><tr><td style="text-align:right">shijingshan</td><td style="text-align:right">40286.889574</td><td style="text-align:right">100000</td><td style="text-align:right">18854</td><td style="text-align:right">10389.217354</td></tr><tr><td style="text-align:right">xicheng</td><td style="text-align:right">85674.778545</td><td style="text-align:right">149871</td><td style="text-align:right">21918</td><td style="text-align:right">19964.458991</td></tr></tbody></table></li></ul><h4 id="2-1-2-2-箱型图">2.1.2.2 箱型图</h4><p><img src="https://picture.mulindya.com/image-20210113105256801.png" alt=""></p><p>IQR： 内分位距，为上四分位数-下四分位数</p><p>上边缘是上1.5倍IQR，等于上四分位+1.5*IQR</p><p>下边缘是下1.5倍IQR，等于下四分位-1.5*IQR</p><p><em>凡是超过上边缘，越过下边缘为异常值，不一定是错误值</em></p><p><strong>代码实现：</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br>sns.boxplot(x=<span class="hljs-string">'dist'</span>,y=<span class="hljs-string">'price'</span>,data=data) <span class="hljs-comment">#箱形图 变量分布和异常值信息</span><br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210113110145360.png" alt=""></p><h3 id="2-1-3-汇总表">2.1.3 汇总表</h3><h4 id="2-1-3-1-透视表">2.1.3.1 透视表</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.pivot_table(values=<span class="hljs-string">'price'</span>,index=<span class="hljs-string">'dist'</span>,columns=<span class="hljs-string">'school'</span>,aggfunc=np.mean)<br></code></pre></td></tr></tbody></table></figure><p>使用index和columns指定行列，values是统计的对象，aggfunc是聚合函数–使用的是numpy的mean函数，也就是展现的是price的平均值；</p><table><thead><tr><th style="text-align:right">dist\ school</th><th style="text-align:right">0</th><th style="text-align:right">1</th></tr></thead><tbody><tr><td style="text-align:right">chaoyang</td><td style="text-align:right">51588.511689</td><td style="text-align:right">57403.405360</td></tr><tr><td style="text-align:right">dongcheng</td><td style="text-align:right">66276.887931</td><td style="text-align:right">78514.900392</td></tr><tr><td style="text-align:right">fengtai</td><td style="text-align:right">42291.003505</td><td style="text-align:right">48871.617021</td></tr><tr><td style="text-align:right">haidian</td><td style="text-align:right">61385.803653</td><td style="text-align:right">76911.258297</td></tr><tr><td style="text-align:right">shijingshan</td><td style="text-align:right">40353.883878</td><td style="text-align:right">33107.333333</td></tr><tr><td style="text-align:right">xicheng</td><td style="text-align:right">76989.369511</td><td style="text-align:right">92468.873623</td></tr></tbody></table><h5 id="2-1-3-1-1绘制直方图">2.1.3.1.1<strong>绘制直方图</strong></h5><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.pivot_table(values=<span class="hljs-string">'price'</span>,index=<span class="hljs-string">'dist'</span>,columns=<span class="hljs-string">'school'</span>,aggfunc=np.mean).plot(kind=<span class="hljs-string">'bar'</span>)<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210113112824144.png" alt=""></p><h5 id="2-1-3-1-2绘制散点图">2.1.3.1.2<strong>绘制散点图</strong></h5><p>分析两个连续变量 分析area是否影响price</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">data.plot.scatter(x=<span class="hljs-string">'AREA'</span>,y=<span class="hljs-string">'price'</span>)<br><span class="hljs-comment">#分析两个连续变量 分析area是否影响price</span><br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210113121653569.png" alt=""></p><h5 id="2-1-3-1-3绘制双轴图">2.1.3.1.3<strong>绘制双轴图</strong></h5><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">fig = plt.figure() <span class="hljs-comment">#画布</span><br>ax1 = fig.add_subplot(<span class="hljs-number">111</span>) <span class="hljs-comment">#1行1列 的第一个</span><br>ax1.plot(x,gdp_list,<span class="hljs-string">'g-'</span>)<br>ax1.set_xlim(<span class="hljs-number">2000</span>,<span class="hljs-number">2018</span>)<br>ax2 = ax1.twinx()<br>ax2.plot(x,gdpcr,<span class="hljs-string">'b-'</span>)<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210113121558625.png" alt=""></p><h2 id="2-2-合并操作">2.2  合并操作</h2><h3 id="2-2-1-merge操作">2.2.1 merge操作</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">pd.merge(df3,df4)<br>pd.merge(df3,df4,on=<span class="hljs-string">'key'</span>)<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210113124935656.png" alt=""></p><h3 id="2-2-2-concat操作">2.2.2 concat操作</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">pd.concat([df3,df4]) <span class="hljs-comment">#进行堆叠</span><br>pd.concat([df3,df4],axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210113124828815.png" alt=""></p><p><img src="https://picture.mulindya.com/image-20210113124919494.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数据分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>数据分析</tag>
      
      <tag>绘图</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据分析笔记--索引操作</title>
    <link href="/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis1/"/>
    <url>/2022/01/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/DataAnalysis1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本科实训的时候记录的数据分析的笔记，感觉还挺全面的，部署到博客中，今后对pandas的应用可以方便回顾。<br>本篇主要内容数据分析的索引操作，对Series以及DataFrame的索引操作。😉</p></blockquote><h1>1 索引操作 📆</h1><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#索引操作</span><br>ser1 = pd.Series(<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>,<span class="hljs-number">15</span>),index = <span class="hljs-built_in">list</span>(<span class="hljs-string">'ABCDE'</span>))<br>ser2 = pd.Series(<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>,<span class="hljs-number">15</span>),index = <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">6</span>))<br><span class="hljs-comment"># ser2[1:3] #隐式取值 不包含结束位</span><br><span class="hljs-comment"># ser2[1] #字母情况可以使用下标隐式 数字时默认显示取值</span><br><span class="hljs-comment"># ser1['A':'C'] #索引取值包含结束位</span><br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># #不连续时</span><br><span class="hljs-comment"># ser1[['B','E']]</span><br><span class="hljs-comment"># #布尔索引</span><br><span class="hljs-comment"># ser1</span><br><span class="hljs-comment"># ser1[ser1&gt;12]</span><br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">newdict = {<br>    <span class="hljs-string">'A'</span>:<span class="hljs-number">11</span>,<br>    <span class="hljs-string">'B'</span>:[<span class="hljs-string">'java'</span>,<span class="hljs-string">'python'</span>,<span class="hljs-string">'go'</span>,<span class="hljs-string">'C++'</span>],<br>    <span class="hljs-string">'C'</span>:<span class="hljs-string">'addasf'</span><br>}<br>df1 = pd.DataFrame(newdict,index = <span class="hljs-built_in">list</span>(<span class="hljs-string">'abcd'</span>))<br>df2 = pd.DataFrame(np.random.rand(<span class="hljs-number">4</span>,<span class="hljs-number">5</span>),columns=<span class="hljs-built_in">list</span>(<span class="hljs-string">'ABCDE'</span>),index=<span class="hljs-built_in">list</span>(<span class="hljs-string">'abcd'</span>))<br></code></pre></td></tr></tbody></table></figure><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>A</th>      <th>B</th>      <th>C</th>    </tr>  </thead>  <tbody>    <tr>      <th>a</th>      <td>11</td>      <td>java</td>      <td>addasf</td>    </tr>    <tr>      <th>b</th>      <td>11</td>      <td>python</td>      <td>addasf</td>    </tr>    <tr>      <th>c</th>      <td>11</td>      <td>go</td>      <td>addasf</td>    </tr>    <tr>      <th>d</th>      <td>11</td>      <td>C++</td>      <td>addasf</td>    </tr>  </tbody></table><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>A</th>      <th>B</th>      <th>C</th>      <th>D</th>      <th>E</th>    </tr>  </thead>  <tbody>    <tr>      <th>a</th>      <td>0.093207</td>      <td>0.557518</td>      <td>0.333789</td>      <td>0.695109</td>      <td>0.206757</td>    </tr>    <tr>      <th>b</th>      <td>0.412221</td>      <td>0.318664</td>      <td>0.335479</td>      <td>0.279908</td>      <td>0.185551</td>    </tr>    <tr>      <th>c</th>      <td>0.609854</td>      <td>0.506528</td>      <td>0.934166</td>      <td>0.709873</td>      <td>0.914060</td>    </tr>    <tr>      <th>d</th>      <td>0.728796</td>      <td>0.538920</td>      <td>0.153949</td>      <td>0.497407</td>      <td>0.894722</td>    </tr>  </tbody></table><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#默认不支持连续索引取多列 使用高级索引</span><br><span class="hljs-comment">#默认不支持索引取不连续多行</span><br><span class="hljs-comment">#df1['a':'b'] #可以实现但是不推荐</span><br></code></pre></td></tr></tbody></table></figure><h1>2 高级索引 📜</h1><h2 id="2-1-loc-标签索引">2.1 loc 标签索引</h2><h3 id="2-1-1-对Series操作">2.1.1 对Series操作</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#取连续多行</span><br><span class="hljs-built_in">print</span>(ser1.loc[<span class="hljs-string">'A'</span>:<span class="hljs-string">'D'</span>])<br><span class="hljs-comment">#取连续多行</span><br><span class="hljs-built_in">print</span>(ser1.loc[[<span class="hljs-string">'A'</span>,<span class="hljs-string">'C'</span>,<span class="hljs-string">'E'</span>]])<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#dataframe 取单行</span><br>df1.loc[<span class="hljs-string">'a'</span>] <span class="hljs-comment">#返回series 与df1.loc['a',:]效果一样</span><br></code></pre></td></tr></tbody></table></figure><h3 id="2-1-2-对dataframe操作">2.1.2 对dataframe操作</h3><h4 id="2-1-2-1索引取值操作">2.1.2.1索引取值操作</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#data 取单列</span><br>df1.loc[:,<span class="hljs-string">'A'</span>] <span class="hljs-comment">#返回series</span><br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df1.loc[<span class="hljs-string">'b'</span>,<span class="hljs-string">'B'</span>] <span class="hljs-comment">#单值</span><br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#取连续多列</span><br><span class="hljs-built_in">print</span>(df1.loc[<span class="hljs-string">'a'</span>:<span class="hljs-string">'c'</span>]) <span class="hljs-comment">#包含结束位 可以省略后面的，：</span><br><span class="hljs-comment">#取连续多列</span><br><span class="hljs-built_in">print</span>(df1.loc[:,<span class="hljs-string">'B'</span>:<span class="hljs-string">'C'</span>]) <span class="hljs-comment">#包含结束位 逗号分割前为行后为列</span><br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(df1.loc[[<span class="hljs-string">'a'</span>,<span class="hljs-string">'d'</span>]])<br><span class="hljs-built_in">print</span>(df1.loc[:,[<span class="hljs-string">'A'</span>,<span class="hljs-string">'C'</span>]])<br><span class="hljs-built_in">print</span>(df1.loc[[<span class="hljs-string">'a'</span>,<span class="hljs-string">'d'</span>],[<span class="hljs-string">'A'</span>,<span class="hljs-string">'C'</span>]])<br></code></pre></td></tr></tbody></table></figure><h4 id="2-1-2-2布尔索引">2.1.2.2布尔索引</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df2[<span class="hljs-string">'a'</span>:<span class="hljs-string">'c'</span>]&lt;<span class="hljs-number">0.5</span><br></code></pre></td></tr></tbody></table></figure><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>A</th>      <th>B</th>      <th>C</th>      <th>D</th>      <th>E</th>    </tr>  </thead>  <tbody>    <tr>      <th>a</th>      <td>True</td>      <td>False</td>      <td>True</td>      <td>False</td>      <td>True</td>    </tr>    <tr>      <th>b</th>      <td>True</td>      <td>True</td>      <td>True</td>      <td>True</td>      <td>True</td>    </tr>    <tr>      <th>c</th>      <td>False</td>      <td>False</td>      <td>False</td>      <td>False</td>      <td>False</td>    </tr>  </tbody></table><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df2[df2[<span class="hljs-string">'a'</span>:<span class="hljs-string">'c'</span>]&lt;<span class="hljs-number">0.5</span>]<br></code></pre></td></tr></tbody></table></figure><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>A</th>      <th>B</th>      <th>C</th>      <th>D</th>      <th>E</th>    </tr>  </thead>  <tbody>    <tr>      <th>a</th>      <td>0.093207</td>      <td>NaN</td>      <td>0.333789</td>      <td>NaN</td>      <td>0.206757</td>    </tr>    <tr>      <th>b</th>      <td>0.412221</td>      <td>0.318664</td>      <td>0.335479</td>      <td>0.279908</td>      <td>0.185551</td>    </tr>    <tr>      <th>c</th>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>    </tr>    <tr>      <th>d</th>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>    </tr>  </tbody></table><h2 id="2-2-iloc位置索引">2.2 iloc位置索引</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df2.iloc[<span class="hljs-number">1</span>:<span class="hljs-number">3</span>,<span class="hljs-number">2</span>:<span class="hljs-number">4</span>] <span class="hljs-comment">#不包含结束位</span><br></code></pre></td></tr></tbody></table></figure><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>C</th>      <th>D</th>    </tr>  </thead>  <tbody>    <tr>      <th>b</th>      <td>0.335479</td>      <td>0.279908</td>    </tr>    <tr>      <th>c</th>      <td>0.934166</td>      <td>0.709873</td>    </tr>  </tbody></table><h2 id="2-3-ix-混合索引-基本上不使用">2.3 ix 混合索引 基本上不使用</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">df2.ix[df2.A&lt;<span class="hljs-number">0.5</span>,:<span class="hljs-string">'C'</span>]<br></code></pre></td></tr></tbody></table></figure><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>A</th>      <th>B</th>      <th>C</th>    </tr>  </thead>  <tbody>    <tr>      <th>a</th>      <td>0.093207</td>      <td>0.557518</td>      <td>0.333789</td>    </tr>    <tr>      <th>b</th>      <td>0.412221</td>      <td>0.318664</td>      <td>0.335479</td>    </tr>  </tbody></table><h1>3 删除操作 🎯</h1><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#删除指定行数据</span><br><span class="hljs-built_in">print</span>(df1)<br>df1.drop(<span class="hljs-string">'a'</span>,inplace=<span class="hljs-literal">True</span>) <span class="hljs-comment">#axis=0 默认指定行标 inplace指定是否在原始数据上操作</span><br><span class="hljs-built_in">print</span>(df1)<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#删除指定列数据</span><br><span class="hljs-built_in">print</span>(df1)<br>temp = df1.drop(<span class="hljs-string">'B'</span>,axis=<span class="hljs-number">1</span>) <span class="hljs-comment">#axis=1 指定列</span><br><span class="hljs-built_in">print</span>(df1)<br><span class="hljs-built_in">print</span>(temp)<br></code></pre></td></tr></tbody></table></figure><h1>4 数据分析实例 🏠</h1><h2 id="4-1-数据基本信息处理">4.1 数据基本信息处理</h2><h3 id="4-1-1读取数据">4.1.1读取数据</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data = pd.read_csv(<span class="hljs-string">'./data/sndHsPr.csv'</span>)<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/image-20210112130635768.png" alt=""></p><h3 id="4-1-2-计算总价-加入当前数据">4.1.2 计算总价 加入当前数据</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#计算总价 并且将总价加入到当前数据</span><br>temp = data.loc[:,[<span class="hljs-string">'AREA'</span>,<span class="hljs-string">'price'</span>]].apply(<span class="hljs-keyword">lambda</span> x:x[<span class="hljs-number">0</span>]*x[<span class="hljs-number">1</span>],axis=<span class="hljs-number">1</span>) <br><span class="hljs-comment">#将function应用到行或者列</span><br>data[<span class="hljs-string">'sumprice'</span>] = temp<br></code></pre></td></tr></tbody></table></figure><p><strong>loc选取指定列，使用apply()函数对选取的列及进行处理； axis为0则选取列 ，为1则选取行 ，默认axis为0。</strong></p><p><img src="https://picture.mulindya.com/image-20210112131321319.png" alt=""></p><h3 id="4-1-3-将dict转化为中文插入表中">4.1.3 将dict转化为中文插入表中</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">newdict = {<span class="hljs-string">'chaoyang'</span>:<span class="hljs-string">'朝阳'</span>,<span class="hljs-string">'dongcheng'</span>:<span class="hljs-string">'东城'</span>,<span class="hljs-string">'fengtai'</span>:<span class="hljs-string">'丰台'</span>,<span class="hljs-string">'haidian'</span>:<span class="hljs-string">'海淀'</span>,<span class="hljs-string">'shijingshan'</span>:<span class="hljs-string">'石景山'</span>,<span class="hljs-string">'xicheng'</span>:<span class="hljs-string">'西城'</span>}<br>data[<span class="hljs-string">'newdist'</span>] = data.loc[:,<span class="hljs-string">'dist'</span>].<span class="hljs-built_in">map</span>(newdict)<br></code></pre></td></tr></tbody></table></figure><p>使用loc进行选取对应列然后进行map操作，将字典的键转化为对应值，返回series对象</p><h2 id="4-2-简单绘图展示">4.2 简单绘图展示</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">data.dist.value_counts().plot(kind=<span class="hljs-string">'barh'</span>)<br>data.dist.value_counts().plot(kind=<span class="hljs-string">'pie'</span>)<br></code></pre></td></tr></tbody></table></figure><p>value_counts函数可以进行统计不同值的个数</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> pylab <span class="hljs-keyword">import</span> mpl<br>mpl.rcParams[<span class="hljs-string">'font.sans-serif'</span>] = [<span class="hljs-string">'SimHei'</span>]<br>data.newdist.value_counts().plot(kind=<span class="hljs-string">'pie'</span>)<br></code></pre></td></tr></tbody></table></figure><p><strong>中文显示问题</strong> 修改属性参数’font.sans-serif’为[‘SimHei’]</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数据分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>数据分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Latex中的空格</title>
    <link href="/2022/01/18/project_tool/quat/"/>
    <url>/2022/01/18/project_tool/quat/</url>
    
    <content type="html"><![CDATA[<blockquote><p>记录Latex在公式中使用空格。</p></blockquote><p>一般情况下使用空格都是<code>\quad</code> 命令。但最近发现这个空格距离太大了，需要小一点的空格。<br>所以改用\ 命令。</p><h2 id="一个空格">一个空格</h2><figure class="highlight css"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-tag">a</span> \quad <span class="hljs-selector-tag">b</span><br></code></pre></td></tr></tbody></table></figure><p>$$<br>a \quad b<br>$$</p><h2 id="两个空格">两个空格</h2><figure class="highlight css"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-tag">a</span> \qquad <span class="hljs-selector-tag">b</span><br></code></pre></td></tr></tbody></table></figure><p>$$<br>a \qquad b<br>$$</p><h2 id="一个m的长度">一个m的长度</h2><figure class="highlight css"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-tag">a</span> \ <span class="hljs-selector-tag">b</span><br></code></pre></td></tr></tbody></table></figure><p>$$<br>a \ b<br>$$</p>]]></content>
    
    
    <categories>
      
      <category>配置</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Latex</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>praticalML第四章笔记</title>
    <link href="/2022/01/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PracticeML4/"/>
    <url>/2022/01/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PracticeML4/</url>
    
    <content type="html"><![CDATA[<blockquote><p>斯坦福2021秋季的实用机器学习上线啦~ 😉 跟着沐神复习机器学习冲冲冲！ 记录一下笔记和重点，不一定很全哦~，只是记录自我感觉的重点。</p></blockquote><h1>第四章</h1><h2 id="4-1-模型评估">4.1 模型评估</h2><p>P来源于data采样得到模型之后得到预测，这个新的预测是更加关心的。</p><p>给定数据给定 超参数 已经获取到模型</p><ul><li><strong>Loss measures</strong> how good the model in predicting the outcome in supervised learning</li><li>Other metrics to evaluate the model performance<br>• Model specific: e.g. accuracy for classification, mAP for object detection<br>• Business specific: e.g. revenue, inference latency</li><li>We select models by multiple metrics<br>• Just like how you choose cars</li></ul><p>在监督学习中损失value是一个好的指标，除此之外，还有其他的精度比如acc，mAP，商业相关指标（营收增长，流量），我们会衡量多个指标来判断模型好坏。</p><h3 id="4-1-1-常见分类指标">4.1.1 常见分类指标</h3><ul><li><p>准确率Accuracy: # correct predictions / # examples  得到的y中有多少正确预测了</p>  <figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">sum</span>(y==y_hat)/y.size<br></code></pre></td></tr></tbody></table></figure></li><li><p>精度Precision: # True positive / # (True positive + False positive)</p><p>负类数据远大于正类，并且更关注正类时，acc就不适用了。</p><p>precision对于预测具体真实类别（正例），哪些被正确预测了。判断为正例的置信度很大，也就是对正例判断越严谨精度越大。</p>  <figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">sum</span>((y_hat==<span class="hljs-number">1</span>)&amp;(y==<span class="hljs-number">1</span>))/<span class="hljs-built_in">sum</span>(y_hat==<span class="hljs-number">1</span>)<br></code></pre></td></tr></tbody></table></figure></li><li><p>召回率Recall: # True positive / # Positive examples</p><p>在所有的正类中有多少被预测出来了，也就是考虑覆盖性的问题，是否所有的正例都被预测出来了。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">sum</span>((y_hat==<span class="hljs-number">1</span>)&amp;(y==<span class="hljs-number">1</span>))/<span class="hljs-built_in">sum</span>(y==<span class="hljs-number">1</span>)<br></code></pre></td></tr></tbody></table></figure></li><li><p>One metric that balances precision and recall  精度和召回率的权衡</p><p>• <strong>F1</strong>: the harmonic mean of precision and recall: <strong>2pr /( p + r)</strong></p></li></ul><h4 id="AUC-ROC">AUC-ROC</h4><ul><li><p>AUC，the area uder ROC curve，measures the chance a  model can distinguish classees.</p></li><li><p>choose various $\theta$,predict as pos if $\hat{y} \geq \theta$ else neg</p><p>实际生产当中，$ \theta $是需要选取调节的</p><p>ROC曲线的</p><p>x轴是 分母是负例样本 分子是预测成正例的负例样本数</p><p>y轴是 正例的召回率 分母是所有的正类 分子是预测正确的正类样本数</p><p><img src="https://picture.mulindya.com/pML4-1.png" alt=""></p></li></ul><p>AUC是表示ROC下的面积，取值范围是[0,1]</p><p><img src="https://picture.mulindya.com/pML4-2.png" alt=""></p><h4 id="商业指标">商业指标</h4><ul><li>Optimize both revenue and customer experience<br>• Latency: ads should be shown to users at the same time as others<br>• ASN: average #ads shown in a page<br>• CTR: actual user click through rate<br>• ACP: average price advertiser pays per click</li><li>revenue = #pageviews   ASN   CTR   ACP</li></ul><p>Latency表示在多久在页面显示，一般控制在500ms之内，包括模型计算预测部署的时间</p><p>ASN 每一页投放的广告数量</p><p>CTR 上线之后点击频率</p><p>ACP 每一个广告点击，广告主的支付费用</p><h4 id="4-1-2-模型-商业评估">4.1.2 模型-&gt;商业评估</h4><ul><li>The key model metric is AUC</li><li>A new model with increased AUC may harm business metrics, possible reasons:<br>• Lower estimated CTR   less ads displayed<br>• Lower real CTR because we trained and evaluated on past data<br>• Lower prices</li><li>Online experiment: deploy models to evaluate on real traffic data</li></ul><p>实际上只看auc是不够的，需要各种权衡和模拟。</p><h3 id="4-1-3-总结">4.1.3 总结</h3><ul><li>We evaluate models with multiple metrics</li><li>Model metrics evaluate model performance on examples<br>• E.g. accuracy, precision, recall, F1, AUC for classification models</li><li>Business metrics measure how models impact the product</li></ul><h2 id="4-2-过拟合-欠拟合">4.2 过拟合&amp;欠拟合</h2><h3 id="4-2-1-训练误差-泛化误差">4.2.1 训练误差 泛化误差</h3><p>• <strong>Training error</strong>: model error on the training data<br>• <strong>Generalization error</strong>: model error on new data</p><p><img src="https://picture.mulindya.com/pML4-3.png" alt=""></p><h3 id="4-2-2-原因">4.2.2 原因</h3><p><img src="https://picture.mulindya.com/pML4-4.png" alt=""></p><p>数据复杂性 VS 模型复杂性</p><p>两者的复杂性越对等越好；</p><p><img src="https://picture.mulindya.com/pML4-5.png" alt=""></p><p>数据简单 and 模型复杂就会导致过拟合</p><p>数据比模型更复杂，模型不能拟合数据，就会导致欠拟合。</p><h3 id="4-2-3-模型复杂度">4.2.3 模型复杂度</h3><ul><li>The capacity of a set of function to fit data points</li><li>In ML, model complexity usually refers to:<br>• The number of learnable parameters<br>• The value range for those parameters</li><li>It’s hard to compare between different types of ML models<br>• E.g. trees vs neural network</li><li>More precisely measure of complexity: VC dimension<br>• VC dim for classification model: the maximum number of examples the model can shatter</li></ul><p>模型复杂性可以描述为拟合各种函数的能力，很难比较模型之间的复杂度(比如树和神经网络)，通常参数越多，每层的参数范围越大，模型越复杂.</p><h3 id="4-2-4-产生的影响">4.2.4 产生的影响</h3><p><img src="https://picture.mulindya.com/ParacticeML4-1-1.png" alt=""></p><p>固定数据，选取不同的复杂性的模型，可以看到模型越复杂越容易过拟合，越简单会导致欠拟合，最好的情况是泛化误差最小的时候，但是在最优解处也是存在过拟合的。</p><h4 id="具体例子">具体例子</h4><p>将买房的数据切分得到训练集和验证集，使用<code>scikit-learn</code>中的<code>DecisionTreeRegressor</code>（决策树回归器）树的深度为x轴，y为错误率。</p><p><img src="https://picture.mulindya.com/ParacticeML4-1-2.png" alt=""></p><h3 id="4-2-5-数据复杂度">4.2.5 数据复杂度</h3><ul><li>Multiple factors matters</li></ul><p>• # of examples</p><p>• # of features in each example</p><p>• time/space structure</p><p>• diversity</p><ul><li>Again, hard to compare among very different data</li></ul><p>• E.g a char vs a pixel</p><ul><li>More precisely, Kolmogorov complexity</li></ul><p>• A data is simple if it can be generated by a short program</p><p>多样性，时序结构，空间结构的复杂性；一般可以比较类似的数据集的复杂度；</p><h3 id="4-2-6-Data-VS-Model">4.2.6 Data VS Model</h3><p><img src="https://picture.mulindya.com/ParacticeML4-1-3.png" alt=""></p><p>随着数据的复杂性都会使得模型的泛化能力增加，误差减少。</p><p>蓝色是简单模型，绿色是复杂模型；在起始状态，复杂模型容易过拟合，所以泛化能力较差；但是数据越复杂复杂模型训练会比简单的模型效果更好。因此当数据比较简单时，使用简单模型就可以了，随着数据量变大，可以来匹配更复杂的模型这样泛化误差更小。</p><h4 id="泛化误差">泛化误差</h4><ul><li>Generalization error bound (an informal statement)</li></ul>    $$  |error \ on \ unseen \ data - training \ error| \le \sqrt{\frac{D}{N}(log(\frac{2N}{D}+1))}  $$  <p>• D: VC-dim, N: number of training examples</p><ul><li><p>Generalization error also depends on the training algorithm</p><p>• Adding regularization can penalize complex models</p><p>• Model trained with stochastic gradient methods generalizes better</p></li></ul><p>泛化误差与训练误差之间的差距不超过某个值，这个值和训练算法有关，可以加入正则化项和惩罚模型，可以使用SGD的方法来训练。</p><h3 id="4-2-7-模型选择">4.2.7 模型选择</h3><ul><li><p>Pick a model with a proper complexity for your data</p><p>• Minimize the generalization error</p><p>• Also consider business metrics</p></li><li><p>Pick up a model family, then select proper hyper-parameters 调参</p><p>• Trees: #trees, maximal depths</p></li></ul><p>• Neural networks: architecture, depth (#layers), width (#hidden units), regularizations</p><p>需要选择和数据合适复杂度的模型，同时考虑商业指标。</p><h3 id="4-2-8-总结">4.2.8 总结</h3><ul><li>我们更关注泛化误差而不是训练误差；</li><li>复杂度：函数/信息量越大，复杂度越高；</li><li>模型选择：数据复杂度和模型复杂度的匹配。</li></ul><h2 id="4-3-模型验证">4.3 模型验证</h2><p>主要讲解了validate数据集和test数据集，评估泛化误差使用验证集，最后使用测试集。</p><p>数据足够多，可以选取一半的数据作为验证；</p><p>数据不多可以选取10%，20%作为验证集；</p><h3 id="4-3-1-非独立同分布数据切分">4.3.1 非独立同分布数据切分</h3><p>一般随机分数据不可行，除非数据独立同分布。</p><ul><li><p>Random data splitting may lead to underestimate of generalization error</p></li><li><p>Sequential data 买房，股票信息都有时序信息的</p></li></ul><p>​• e.g. house sales, stock prices</p><p>​• Valid set should not overlap with train set in time 重复信息 比如人脸识别，在分数据的时候同一张脸出现在训练集和测试集之中，这是不符合规范的。</p><ul><li><p>Examples are highly clustered 类别数量不均衡</p><p>• e.g. photos of the same person, clips of the same video</p><p>• Split clusters instead of examples</p></li><li><p>Highly imbalanced label classes</p></li></ul><p>• Sample more from minor classes</p><p>需要保证验证集样本在训练集之后，同时保证数据集没有重复的（可以首先在组信息分割）。</p><h4 id="反向实例">反向实例</h4><p><img src="https://picture.mulindya.com/ParacticeML4-3-1.png" alt=""></p><p>第一幅图是前面一半的时间的样本数据训练，后面的时间样本数据预测；</p><p>第二幅图是随机挑选数据来训练和预测。</p><p>通过决策树查看训练，分析过拟合的出现；比较两者，在随机挑选得数据中过拟合发生得晚一些，它可以获取更加整体得细节，前者过度拟合了局部信息。</p><p>在线性回归上更加明显，使用顺序的数据在验证集上偏差很大。</p><h3 id="4-3-2-K-fold-Cross-Validation">4.3.2 K-fold Cross Validation</h3><p><img src="https://picture.mulindya.com/ParacticeML4-3-2.png" alt=""></p><p>当数据不充足时可以使用K折交叉验证。把数据切成K份，然后选取k-1份训练另外一份来验证，再去k个验证误差来做平均得到验证集误差。一般K选择5或则10。比如K为5时，80%数据训练，20%数据验证，重复5次得到验证集误差。数据比较少的时候可以选择10，也就是在90%数据训练，10%数据验证。代价是重复更多的次数。</p><h3 id="4-3-3-Bug">4.3.3 Bug</h3><p>• If your ML model performance is too good to be true, very likely there is a bug, and contaminated valid set is the #1 reason</p><ul><li><p>Valid set has examples from train set</p><p>• duplicated examples from original set</p><p>• Often happens when integrating multiple datasets</p><p>​• Scrape images from search engine to evaluate models trained on ImageNet</p></li><li><p>Information leaking from train set to valid set</p></li></ul><p>• Often happens for non I.I.D data</p><p>• use future to predict past, see a person’s face before</p><p>• Excessive use of valid set for hyper param tuning is cheating</p><p>表现效果特别好，有时可能出现了bug；需要检查一下：</p><ol><li>验证集和训练集可能会有重叠；</li><li>在数据融合时出现了数据泄露；</li></ol><h3 id="4-3-4-总结">4.3.4 总结</h3><ul><li><p>The test data is used once to evaluate your model</p></li><li><p>One can hold out a validation set from the training data to estimate the test data</p><p>• You can use valid set multiple times for model selections and hyper param tuning</p><p>• Validation data should be close to the test data</p><p>• Improper valid set is a common mistake that lead to over estimate of the model performance</p></li></ul><p>验证集要尽量的选取真实数据。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>李沐</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深度理解3D卷积</title>
    <link href="/2022/01/11/deep_learning/conv3d/"/>
    <url>/2022/01/11/deep_learning/conv3d/</url>
    
    <content type="html"><![CDATA[<blockquote><p>在帕金森数据中涉及三维数据的训练和预测，用到了conv3但是对其背后的原理还有一些模糊的地方，conv2d与多通道的conv2d的区别在哪里？conv3d的思想理论是什么？对此进行探究和记录… 😳</p></blockquote><blockquote><p>首先要明确多通道的2d卷积和3d卷积是不一样的，3d是可以在通道中移动的，2d达咩！</p></blockquote><h2 id="卷积核的维度">卷积核的维度</h2><p>卷积核的维度指的的进行滑窗操作的维度，而滑窗操作不在channel维度上进行，不管有几个channel，它们都共享同一个滑窗位置（虽然2D多channel卷积的时候每个channel上的卷积核权重是独立的，但滑窗位置是共享的）。所以在讨论卷积核维度的时候，是不把channel维加进去的。</p><p><font color="purple"> <strong>2D conv的卷积核就是$(c, k_h, k_w)$，因此，对于RGB图像做2D卷积，卷积核可以是conv2D(3,3) 而不该是conv3D(3,3,3)；</strong></font></p><p><font color="green"> <strong>3D conv的卷积核就是$(c, k_d, k_h, k_w)$，其中k_d就是多出来的第三维，根据具体应用，在视频中就是时间维，在CT图像中就是层数维.</strong>  </font></p><h2 id="2D卷积">2D卷积</h2><h3 id="单通道">单通道</h3><p>首先了解什么是卷积核，卷积核(filter)是由一组参数构成的张量，卷积核相当于权值，图像相当于输入量，卷积的操作就是根据卷积核对这些输入量进行加权求和。我们通常用卷积来提取图像的特征。</p><p>直观理解如下：下图使用的是 3x3卷积核(height x width,简写$ H \times W$) 的卷积，padding为1(周围的虚线部分，卷积时为了使卷积后的图像大小与原来一致，会对原图像进行填充)，两个维度上的strides均为1(滑动步长，这里体现为每次滑动几个小方格)。</p><p><img src="https://picture.mulindya.com/2dconv.gif" alt=""></p><p>针对单通道，输入图像的channel为1，即输入大小为$(1, height, weight)$，卷积核尺寸为 $(1, k_h, k_w)$，卷积核在输入图像上的的空间维度（即(height, width)两维）上进行进行滑窗操作，每次滑窗和 $(k_h, k_w)$ 窗口内的values进行卷积操作（现在都用相关操作取代），得到输出图像中的一个value。</p><p>上图是通道数为1的2维图像的卷积操作，静态表示为：</p><p><img src="https://picture.mulindya.com/conv3d-1.png" alt=""></p><h3 id="多通道">多通道</h3><p>了解了单通道图像的卷积之后，再来看多通道图像的卷积，我们知道灰度图像只有一个通道，而 RGB 图像有R、G、B三个通道。<br>多通道图像的一次卷积要对所有通道上同一位置的元素做加权和，因此卷积核的shape变成了 $H \times W \times channels$，没有错卷积核变成了3维，但这不是3维卷积，因为我们区分几维卷积看的是卷积核可以在几个维度上的滑动，卷积核是不能在 channels上滑动的，因为上面提到每次卷积都要关联所有通道上同一位置上的元素。<br>3通道的卷积表示如下：是对每个通道进行2d卷积操作然后把最后的值相加的到右侧的小方块。</p><p><img src="https://picture.mulindya.com/conv3d-2.png" alt=""></p><p>上图将3个通道分开表示，卷积核也分开表示，filter1、filter2、filter3均为二维卷积核，堆叠在一起便形成了$ H \times W \times 3$的卷积核，同样的我们将3个通道也堆叠在一起;</p><p>针对多通道，假定输入图像的channel为c，即输入大小为$(c, height, weight)$，卷积核尺寸为 $(c, k_h, k_w)$， 卷积核在输入图像的空间维度即$(height, width)$两维上进行滑窗操作（在channel这一维度没有滑动只有相加），每次滑窗与c个channels上的$ (k_h, k_w)$ 窗口内的所有的values进行相关操作，得到输出图像中的一个value（多通道的信息被完全压缩了)</p><p>于是形成了下面的3维表示图：<br><img src="https://picture.mulindya.com/conv3d-3.png" alt=""></p><p>虽然是一个卷积核，但是每个filter的权重值是不一样的哦~</p><p>如下如所示：在卷积核的每个通道上的权重是不一定相同的，<code>这里的6=4+0+1+偏移1</code></p><p><img src="https://picture.mulindya.com/conv3d-6.png" alt=""></p><h3 id="代码">代码</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, groups=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>, padding_mode=<span class="hljs-string">'zeros'</span>, device=<span class="hljs-literal">None</span>, dtype=<span class="hljs-literal">None</span>)<br></code></pre></td></tr></tbody></table></figure><ul><li><strong>in_channels</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) – Number of channels in the input image</li><li><strong>out_channels</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) – Number of channels produced by the convolution</li><li><strong>kernel_size</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a>) – Size of the convolving kernel</li><li><strong>stride</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>,</em> <em>optional</em>) – Stride of the convolution. Default: 1</li><li><strong>padding</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <a href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a> <em>or</em> <a href="https://docs.python.org/3/library/stdtypes.html#str"><em>str</em></a><em>,</em> <em>optional</em>) – Padding added to all four sides of the input. Default: 0</li><li><strong>padding_mode</strong> (<em>string</em>*,* <em>optional</em>) – <code>'zeros'</code>, <code>'reflect'</code>, <code>'replicate'</code> or <code>'circular'</code>. Default: <code>'zeros'</code></li><li><strong>dilation</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>,</em> <em>optional</em>) – Spacing between kernel elements. Default: 1</li><li><strong>groups</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <em>optional</em>) – Number of blocked connections from input channels to output channels. Default: 1</li><li><strong>bias</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a><em>,</em> <em>optional</em>) – If <code>True</code>, adds a learnable bias to the output. Default: <code>True</code></li></ul><p>Applies a 2D convolution over an input signal composed of several input planes.</p><p>In the simplest case, the output value of the layer with input size $(N, C_{\text{in}}, H, W)$and output $(N, C_{\text{out}}, H_{\text{out}}, W_{\text{out}})$ can be precisely described as:</p>$$\text{out}(N_i, C_{\text{out}_j}) = \text{bias}(C_{\text{out}_j}) + \sum_{k = 0}^{C_{\text{in}} - 1} \text{weight}(C_{\text{out}_j}, k) \star \text{input}(N_i, k)$$<p>where ⋆ is the valid 2D <a href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a> operator, N<em>N</em> is a batch size, C<em>C</em> denotes a number of channels, H<em>H</em> is a height of input planes in pixels, and W<em>W</em> is width in pixels.</p><p>This module supports <a href="https://pytorch.org/docs/stable/notes/cuda.html#tf32-on-ampere">TensorFloat32</a>.</p><ul><li><p><code>stride</code> controls the stride for the cross-correlation, a single number or a tuple.</p></li><li><p><code>padding</code> controls the amount of padding applied to the input. It can be either a string {‘valid’, ‘same’} or a tuple of ints giving the amount of implicit padding applied on both sides.</p></li><li><p><code>dilation</code> controls the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this <a href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">link</a> has a nice visualization of what <code>dilation</code> does.</p></li><li><p><code>groups</code> controls the connections between inputs and outputs. <code>in_channels</code> and <code>out_channels</code> must both be divisible by <code>groups</code>. For example,</p><blockquote><ul><li>At groups=1, all inputs are convolved to all outputs.</li><li>At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels and producing half the output channels, and both subsequently concatenated.</li><li>At groups= <code>in_channels</code>, each input channel is convolved with its own set of filters (of size $\frac{\text{out_channels}}{\text{in_channels}}$ ).</li></ul></blockquote></li></ul><p>The parameters <code>kernel_size</code>, <code>stride</code>, <code>padding</code>, <code>dilation</code> can either be:</p><blockquote><ul><li>a single <code>int</code> – in which case the same value is used for the height and width dimension</li><li>a <code>tuple</code> of two ints – in which case, the first int is used for the height dimension, and the second int for the width dimension</li></ul></blockquote><h4 id="example">example</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># With square kernels and equal stride</span><br>m = nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">33</span>, <span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>)<br><span class="hljs-comment"># non-square kernels and unequal stride and with padding</span><br>m = nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">33</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">5</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">4</span>, <span class="hljs-number">2</span>))<br><span class="hljs-comment"># non-square kernels and unequal stride and with padding and dilation</span><br>m = nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">33</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">5</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">4</span>, <span class="hljs-number">2</span>), dilation=(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>))<br><span class="hljs-built_in">input</span> = torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">50</span>, <span class="hljs-number">100</span>)<br>output = m(<span class="hljs-built_in">input</span>)<br></code></pre></td></tr></tbody></table></figure><h4 id="2d卷积操作后变化">2d卷积操作后变化</h4><p><img src="https://picture.mulindya.com/conv3d-7.png" alt=""></p><h2 id="3D卷积">3D卷积</h2><h3 id="单通道-2">单通道</h3><p>用类似的方法我们先分析单通道图像的3D卷积，3D卷积的对象是三维图像，因此卷积核变成了$depth \times height \times width $简写为$D \times H \times W $。单通道的<code>3D卷积</code>动态图如下：<br><img src="https://picture.mulindya.com/conv3d.gif" alt=""></p><p>针对单通道，与2D卷积不同之处在于，<strong>输入图像多了一个 depth 维度</strong>，故输入大小为$(1, depth, height, width)$，卷积核也多了一个$k_d$维度，因此卷积核在输入3D图像的空间维度$(depth,height,width)$上均进行滑窗操作，每次滑窗与$ (k_d, k_h, k_w) $窗口内的values进行相关操作，得到输出3D图像中的一个value，最终输出一个3D的特征图。</p><p>这里的3D不是通道导致的，而是深度（多层切片，多帧视频），因此，虽然输入和卷积核和输出都是3D的，但都可以是单通道的。</p><p>将上述静态表示成：</p><p><img src="https://picture.mulindya.com/conv3d-4.png" alt=""></p><h3 id="多通道-2">多通道</h3><p><img src="https://picture.mulindya.com/conv3d-5.png" alt=""></p><p>然后将filter1、filter2、filter3堆叠在一起形成一个4维卷积核$ D \times H \times W \times 3$，同理将各通道堆叠在一起就形成了多通道的3D卷积输入图像。</p><p>针对多通道,比如c个通道，输入大小为$(c, depth, height, width)$，与2D多通道卷积的操作类似，对于每次滑窗，卷积核同时与c个channels上的 $(k_d, k_h, k_w)$ 窗口内的所有values进行相关操作，得到输出3D图像中的一个value。<br>由于3D卷积中的卷积核是3D的，因此在每个channel下使用的是同样的参数，权重共享。不同于2D多通道下的卷积核，后者在每一个channel使用的权重是一样的，不同的通道权重可能不一样。</p><h4 id="代码-2">代码</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.nn.Conv3d(in_channels, out_channels, kernel_size, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, groups=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>, padding_mode=<span class="hljs-string">'zeros'</span>, device=<span class="hljs-literal">None</span>, dtype=<span class="hljs-literal">None</span>)<br></code></pre></td></tr></tbody></table></figure><ul><li><strong>in_channels</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) – Number of channels in the input image</li><li><strong>out_channels</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) – Number of channels produced by the convolution</li><li><strong>kernel_size</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a>) – Size of the convolving kernel</li><li><strong>stride</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>,</em> <em>optional</em>) – Stride of the convolution. Default: 1</li><li><strong>padding</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <a href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a> <em>or</em> <a href="https://docs.python.org/3/library/stdtypes.html#str"><em>str</em></a><em>,</em> <em>optional</em>) – Padding added to all six sides of the input. Default: 0</li><li><strong>padding_mode</strong> (<em>string</em>*,* <em>optional</em>) – <code>'zeros'</code>, <code>'reflect'</code>, <code>'replicate'</code> or <code>'circular'</code>. Default: <code>'zeros'</code></li><li><strong>dilation</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a> <em>or</em> <a href="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>,</em> <em>optional</em>) – Spacing between kernel elements. Default: 1</li><li><strong>groups</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em> <em>optional</em>) – Number of blocked connections from input channels to output channels. Default: 1</li><li><strong>bias</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a><em>,</em> <em>optional</em>) – If <code>True</code>, adds a learnable bias to the output. Default: <code>True</code></li></ul><p><font color="red"><strong>和2D卷积函数基本上是一样的，只是维度和内部的工作机制不太一样。</strong></font></p><p>Applies a 3D convolution over an input signal composed of several input planes.</p><p>In the simplest case, the output value of the layer with input size$ (N, C_{in}, D, H, W)$  and output $(N, C_{out}, D_{out}, H_{out}, W_{out})$ can be precisely described as:</p>$$out(N_i, C_{out_j}) = bias(C_{out_j}) + \sum_{k = 0}^{C_{in} - 1} weight(C_{out_j}, k) \star input(N_i, k)$$<p>where ⋆ is the valid 3D <a href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a> operator</p><p>This module supports <a href="https://pytorch.org/docs/stable/notes/cuda.html#tf32-on-ampere">TensorFloat32</a>.</p><ul><li><p><code>stride</code> controls the stride for the cross-correlation.</p></li><li><p><code>padding</code> controls the amount of padding applied to the input. It can be either a string {‘valid’, ‘same’} or a tuple of ints giving the amount of implicit padding applied on both sides.</p></li><li><p><code>dilation</code> controls the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this <a href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">link</a> has a nice visualization of what <code>dilation</code> does.</p></li><li><p><code>groups</code> controls the connections between inputs and outputs. <code>in_channels</code> and <code>out_channels</code> must both be divisible by <code>groups</code>. For example,</p><blockquote><ul><li>At groups=1, all inputs are convolved to all outputs.</li><li>At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels and producing half the output channels, and both subsequently concatenated.</li><li>At groups= <code>in_channels</code>, each input channel is convolved with its own set of filters (of size $\frac{\text{out_channels}}{\text{in_channels}}$).</li></ul></blockquote></li></ul><p>The parameters <code>kernel_size</code>, <code>stride</code>, <code>padding</code>, <code>dilation</code> can either be:</p><blockquote><ul><li>a single <code>int</code> – in which case the same value is used for the depth, height and width dimension</li><li>a <code>tuple</code> of three ints – in which case, the first int is used for the depth dimension, the second int for the height dimension and the third int for the width dimension</li></ul></blockquote><p><img src="https://picture.mulindya.com/conv3d-8.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>praticalML第三章笔记</title>
    <link href="/2022/01/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PracticeML3/"/>
    <url>/2022/01/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PracticeML3/</url>
    
    <content type="html"><![CDATA[<blockquote><p>斯坦福2021秋季的实用机器学习上线啦~ 😉 跟着沐神复习机器学习冲冲冲！ 记录一下笔记和重点，不一定很全哦~，只是记录自我感觉的重点。<br>这一章的内容是对各种机器学习模型的介绍，包括有决策树，线性模型，多层感知机，卷积神经网络，循环神经网络。</p></blockquote><h1>第三章 机器学习模型</h1><h2 id="3-1-机器学习介绍🎈">3.1 机器学习介绍🎈</h2><p>分类可以分成：</p><ol><li>监督学习（Surprised）：有标号的数据上来训练模型来预测标号<ul><li>衍生出现self-supervised 自监督学习：可以产生标号，只是其标号是来自数据本身（eg:word2vec,BERT）</li></ul></li><li>半监督学习（Semi-superised）存在小部分有标号的数据，还有大部分没有标号的数据。<ul><li>eg：self-training 使用自训练的过程来预测标号再一起训练。</li></ul></li><li>无监督学习（Unsuperised）在没有标号的数据上训练<ul><li>eg：clustering，density estimation（GAN）</li></ul></li><li>强化学习（Reinforce）在一个环境中交互，并且基于观察点来学习，类似人类学习的方法。Use observations from the interaction with the environment to take actions to maximize reward。</li></ol><h3 id="3-1-1-监督学习中的Components">3.1.1 监督学习中的Components</h3><ul><li>Model（模型） 从输入中得到输出</li><li>Loss（损失函数）评估真实样本和预测结果的差距</li><li>Objective（目标函数对象）The goal to optimize model params for</li><li>Optimization（优化算法）he algorithm for solving the objective</li></ul><h3 id="3-1-2-监督学习模型">3.1.2 监督学习模型</h3><ul><li><strong>Decision trees</strong>  • Use trees to make decisions</li><li><strong>Linear methods</strong> • Decision is made from a linear combination of input features（做决策的输出是输入的线性组合）</li><li><strong>Kernel machines</strong> • Use kernel functions to compute feature similarities  （核函数来衡量两个样本特征之间的相似度，指定不同的核函数，特征相似度不同，达到非线性的效果）</li><li><strong>Neural Networks</strong> • Use neural networks to learn feature representations</li></ul><h3 id="3-1-3-总结">3.1.3 总结</h3><p><img src="https://picture.mulindya.com/pML3-1.png" alt=""></p><h2 id="3-2-决策树-🌴">3.2 决策树 🌴</h2><p>包括有分类树，回归树（此时叶子节点不是类别而是实数值）</p><h5 id="好处（pros）：">好处（pros）：</h5><ul><li>可解释（可应用于银行业，保险业）；</li><li>可以用于数值或类别特征；</li></ul><h5 id="缺点（cons）：">缺点（cons）：</h5><ul><li>鲁棒性差（可以用集成学习改善）；</li><li>数据很复杂时可能产生过拟合（可以使用剪枝）；</li><li>难以使用并行计算</li></ul><h3 id="3-2-1-生成决策树">3.2.1 生成决策树</h3><p><img src="https://picture.mulindya.com/pML3-2.png" alt=""></p><h3 id="3-2-2-随机森林">3.2.2 随机森林</h3><p>训练多个决策树来增强并行性，分类时使用投票机制，回归时使用多个树的平均；对整个树的稳定性有好处。</p><ul><li>Train multiple decision trees to improve robustness<br>• Trees are trained independently in parallel<br>• Majority voting for classification, average for regression</li><li>Where is the randomness from?<br>• Bagging: randomly sample training examples with replacement<br>• E.g. [1,2,3,4,5]   [1,2,2,3,4]<br>• Randomly select a subset of features</li></ul><p>这里的随机森林中的随机来自于两个方面哦~</p><p>一个是Bagging，训练一棵树在训练集中随机采样一些样本出来（可重复采样），所以在训练集中会出现重复样本，继续重复训练其他树；</p><p>另一个是对于获取的训练集是随机进行采样特征列（此时是无重复的特征列采样）；</p><h3 id="3-2-3-Gradient-Boosting-Decision-Trees">3.2.3 Gradient Boosting Decision Trees</h3><p>训练多棵树，但是这里不是独立完成决策，而是顺序的完成，利用这些树来合成一个大的模型出来，在t时刻 $ F_t(x) $ 表示是对前面训练的t-1棵树求和，训练的这颗树需要和所有的树的结果加起来，利用残差的思想训练$f_t(x)$（也就是“不准”的部分）</p><p>同时这里的残差（$y_i-F_t(x_i)$）就等于梯度值($ -\frac{\alpha L}{\alpha F} $)（使用均方误差作为loss）</p><p><img src="https://picture.mulindya.com/pML3-3.png" alt=""></p><h3 id="3-2-3-总结">3.2.3 总结</h3><ul><li>Decision tree: an explainable model for classification/regression</li><li>Easy to train and tune, widely used in industry</li><li>Sensitive to data<br>• Ensemble can help (more on bagging and boosting latter)</li></ul><p>决策树是一个为数不多的可解释性模型，对数据的噪音很敏感所以可以使用很多树一起训练来降低偏移和方差。可以用树模型时尽量用树模型哟。</p><h2 id="3-3-线性回归-📈">3.3 线性回归 📈</h2><h3 id="3-3-1-概念">3.3.1 概念</h3><p><img src="https://picture.mulindya.com/pML3-4.png" alt=""></p><p>x*w是按元素来做乘积得到还是一个向量（list）</p><h3 id="3-3-2-目标函数">3.3.2 目标函数</h3><p><img src="https://picture.mulindya.com/pML3-5.png" alt=""></p><p>学习参数w，b；在所有样本中求均方误差，最小化MSE。</p><h3 id="3-3-3-使用线性回归来分类">3.3.3 使用线性回归来分类</h3><p><img src="https://picture.mulindya.com/pML3-6.png" alt=""></p><p>使用线性回归的二分类称为逻辑回归；</p><p>这里类别数为m，真实标号y是one-hot向量，Oi也是一个长度为m的向量，Wi为矩阵形式，目标函数依然是最小化均方误差。类似没有隐藏层的”神经网络“。</p><h3 id="3-3-4-Softmax-Regression">3.3.4 Softmax Regression</h3><p><img src="https://picture.mulindya.com/pML3-7.png" alt=""></p><p>这种方法的侧重点是最大化one-hot中正确样本的值，对其他样本点值置信度不会强制逼近为0。避免精力集中于one-hot中其他样本为0的拟合；首先把输出转化为概率分布的形式，这里虽然出现了非线性变换（使用softmax），但是此决策方法还是线性模型。</p><p>此时比较两个概率分布，使用交叉熵来衡量向量的差别，只用关注真实类的值，让其越大越好。</p><h2 id="3-4-随机梯度下降-📉">3.4 随机梯度下降 📉</h2><p><img src="https://picture.mulindya.com/pML3-8.png" alt=""></p><p>求解最优解的方法可以使用随机梯度下降的方法，线性回归中的b是在输入的X中增加一行1,所以这里的b表示批量大小。<br>$$<br>O = W^TX+b<br>$$<br>在X中加一行全1数据<br>$$<br>O = W^TX<br>$$<br>可以解决除了决策树以外的其他算法（课内）的收敛，超参数是b和n；</p><h3 id="3-4-1-代码">3.4.1 代码</h3><p>• Train a linear regression model with min-batch SGD<br>• Hyperparameters<br>• batch_size<br>• learning_rate<br>• num_epochs</p><p>这里是输出一个结果值而非向量，因为这里是回归哟~</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># `features` shape is (n, p),样本数 特征数 `labels` shape is (n, 1) </span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">data_iter</span>(<span class="hljs-params">batch_size, features, labels</span>):</span> <span class="hljs-comment">#小批量的读取</span><br>    num_examples = <span class="hljs-built_in">len</span>(features)  <span class="hljs-comment">#样本数</span><br>    indices = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(num_examples)) <br>    random.shuffle(indices)  <span class="hljs-comment"># read examples at random  随机采样</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_examples, batch_size): <br>        batch_indices = torch.tensor( <br>            indices[i:<span class="hljs-built_in">min</span>(i + batch_size, num_examples)]) <br>        <span class="hljs-keyword">yield</span> features[batch_indices], labels[batch_indices] <span class="hljs-comment">#yield是一个反复的操作，会创建迭代器，可以用for来遍历</span><br>w = torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>, size=(p, <span class="hljs-number">1</span>), requires_grad=<span class="hljs-literal">True</span>) <br>b = torch.zeros(<span class="hljs-number">1</span>, requires_grad=<span class="hljs-literal">True</span>) <br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs): <br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter(batch_size, features, labels): <br>        y_hat = X @ w + b  <span class="hljs-comment">#@是用来对tensor进行矩阵相乘的；*用来对tensor进行矩阵进行逐元素相乘；</span><br>        loss = ((y_hat - y)**<span class="hljs-number">2</span> / <span class="hljs-number">2</span>).mean() <span class="hljs-comment">#均方误差</span><br>        loss.backward()  <span class="hljs-comment">#求导</span><br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> [w, b]: <span class="hljs-comment"># 对w，b更新</span><br>            param -= learning_rate * param.grad   <span class="hljs-comment">#梯度更新</span><br>            param.grad.zero_()  <span class="hljs-comment">#梯度清零</span><br></code></pre></td></tr></tbody></table></figure><h3 id="3-4-2-总结">3.4.2 总结</h3><p>• Linear methods linearly combine inputs to obtain predictions<br>• Linear regression uses MSE as the loss function<br>• Softmax regression is used for multiclass classification<br>• Turn predictions into probabilities and use cross-entropy as loss<br>• Cross entropy loss between two probability distribution<br>• Mini-batch SGD can learn both models (and later neural networks as well)</p><h2 id="3-5-神经网络-✏️">3.5 神经网络 ✏️</h2><p>• NN usually requires more data and more computation<br>• NN architectures to model data structures<br>• Multilayer perceptions<br>• Convolutional neural networks<br>• Recurrent neural networks<br>• Transformer<br>• Design NN to incorporate prior knowledge about the data</p><p>使用机器来提取特征比手动提取特征要好，但是需要更多的数据，可能数据集大了1000倍。</p><h3 id="3-5-1-多层感知机">3.5.1 多层感知机</h3><p><img src="https://picture.mulindya.com/pML3-9.png" alt=""></p><ul><li><p>线性回归相当于是m=1的全连接层</p></li><li><p>Softmax回归是m为m的全连接层</p></li></ul><h4 id="MLP">MLP</h4><p>通过激活函数来构建非线性模型</p><ul><li><p>Activation is a elemental-wise non-linear function</p><p>eg:</p></li></ul><p>$$<br>sigmoid(x) = \frac{1}{1+e^{(-x)}}<br>$$</p><p>$$<br>Relu(x) = max(x,0)<br>$$<br>​• It leads to non-linear models</p><ul><li>Stack multiple hidden layers  (dense + activation) to get deeper models 堆叠隐藏层</li><li>Hyper-parameters:<br># hidden layers, # outputs of each hidden layer</li><li>Universal approximation theorem</li></ul><h4 id="code">code</h4><p>• MLP with 1 hidden layer<br>• Hyperparameter: num_hiddens</p><p>一个隐藏层H 最后做一个线性映射输出。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">relu</span>(<span class="hljs-params">X</span>):</span> <br>    <span class="hljs-keyword">return</span> torch.<span class="hljs-built_in">max</span>(X, <span class="hljs-number">0</span>) <br>W1 = nn.Parameter(torch.randn(num_inputs, num_hiddens) * <span class="hljs-number">0.01</span>) <br>b1 = nn.Parameter(torch.zeros(num_hiddens)) <br>W2 = nn.Parameter(torch.randn(num_hiddens, num_outputs) * <span class="hljs-number">0.01</span>) <br>b2 = nn.Parameter(torch.zeros(num_outputs)) <br>H = relu(X @ W1 + b1) <br>Y = H @ W2 + b2 <br></code></pre></td></tr></tbody></table></figure><h3 id="3-5-2-卷积神经网络">3.5.2 卷积神经网络</h3><h4 id="引入">引入</h4><ul><li>Learn ImageNet (300x300 images with 1K classes) by a MLP with a single hidden layer with 10K outputs<br>• It leads to 1 billion learnable parameters, that’s too big!<br>• Fully connected: an output is a weighted sum over all inputs</li><li>Recognize objects in images<br>• <strong>Translation invariance</strong>: similar output  no matter where the object is<br>• <strong>Locality</strong>: pixels are more related to  near neighbors</li><li>Build the prior knowledge into the model structure<br>• Achieve same model capacity with less # params</li></ul><p>由于全连接层的参数量为m*n，纯用MLP参数量太大了，引用卷积层</p><p>对于图像有两大特性</p><ol><li>变换不变性：表示同一object在图像区域的变换对结果没有影响；</li><li>本地性：某一像素与附近的像素点的关联度较高，远处的关联度比较低；</li></ol><h4 id="具体机制">具体机制</h4><p><img src="https://picture.mulindya.com/pML3-10.png" alt=""></p><ul><li><p>本地性：卷积层的一个输出只是来源于k*k的一个像素块进行局部计算；</p></li><li><p>平移（/变换）不变性：在一个feature map的channel上使用相同卷积核，权重共享，因为和位置无关。</p></li></ul><p>所以模型的参数量只与k有关，与输入输出的大小无关；卷积核通常是会被学习成去识别一个图像中的pattern。</p><h4 id="代码">代码</h4><p>单通道卷积的实现，k是kernel的权重，Y是最后的输出，其维度是X的宽高减去对应的k宽高再加1。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># both input `X` and weight `K` are matrices </span><br>h, w = K.shape <br>Y = torch.zeros((X.shape[<span class="hljs-number">0</span>] - h + <span class="hljs-number">1</span>, X.shape[<span class="hljs-number">1</span>] - w + <span class="hljs-number">1</span>)) <br><span class="hljs-comment"># stride = 1 </span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(Y.shape[<span class="hljs-number">0</span>]):   <br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(Y.shape[<span class="hljs-number">1</span>]): <br>        Y[i, j] = (X[i : i+h, j : j+w] * K).<span class="hljs-built_in">sum</span>() <span class="hljs-comment">#点乘再求和的计算称为交叉相关</span><br></code></pre></td></tr></tbody></table></figure><h4 id="Pooling-Layer-汇聚层">Pooling Layer 汇聚层</h4><p>卷积层对输入的位置敏感，如果输入的object移动一个微小距离对应的输出也会出现移动，这样鲁棒性会降低，通过池化层（汇聚层）可以解决这个问题。</p><p>每一次在K*K的窗口中使用平均汇聚或者最大汇聚，这样对K个像素的偏移就不会太大影响。</p><ul><li>Convolution is sensitive to location<br>• A translation/rotation of a pattern in the input results similar changes of a pattern in the output</li><li>A pooling layer computes mean/max in windows of size k × k</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># h, w: pooling window height and width </span><br><span class="hljs-comment"># mode: max or avg </span><br>Y = torch.zeros((X.shape[<span class="hljs-number">0</span>] - h + <span class="hljs-number">1</span>, X.shape[<span class="hljs-number">1</span>] - w + <span class="hljs-number">1</span>)) <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(Y.shape[<span class="hljs-number">0</span>]): <br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(Y.shape[<span class="hljs-number">1</span>]): <br>        <span class="hljs-keyword">if</span> mode == <span class="hljs-string">'max'</span>: <br>            Y[i, j] = X[i : i+h, j : j+w].<span class="hljs-built_in">max</span>() <br>        <span class="hljs-keyword">elif</span> mode == <span class="hljs-string">'avg'</span>: <br>            Y[i, j] = X[i : i+h, j : j+w].mean()<br></code></pre></td></tr></tbody></table></figure><h4 id="卷积神经网络">卷积神经网络</h4><ul><li>Stacking convolution layers to extract features<br>• Activation is applied after each convolution layer<br>• Using pooling to reduce location sensitivity</li><li>Modern CNNs are deep neural network with various hyper-parameters and layer connections (AlexNet, VGG, Inceptions, ResNet, MobileNet)</li></ul><p>卷积神经网络把卷积层堆叠起来，使用卷积层抽取空间信息，满足变换不变性和本地性的特征。激活层在卷积层之后，卷积层是一种特殊的全连接层（每次只看小窗口，其他权重为0），本质上还是线性变换，所以需要激活层来非线性化；同时使用汇聚层来降低卷积层对位置的敏感性。</p><blockquote><p>lenet = nn.Sequential(<br>nn.Conv2d(…),<br>nn.Sigmoid(),<br>nn.AvgPool2d(…),<br>nn.Conv2d(),<br>nn.Sigmoid(),<br>nn.AvgPool2d(…),<br>nn.Flatten(),<br>nn.Linear(…),<br>nn.Sigmoid(),<br>nn.Linear(…),<br>nn.Sigmoid(),<br>nn.Linear(…))</p></blockquote><h3 id="3-5-3-循环神经网络">3.5.3 循环神经网络</h3><p>语言模型中设计循环神经网络，通过前面的信息来预测当前信息，时间序列信息中通过前面几个项来预测后一个项。</p><p>使用Dense时由前一个词作为输入预测当前词，当时无法获取时间序列信息，因为输入长度维度不可随意变化。所以这里需要对时序信息添加到输入中，也就是RNN，可以将前面的输出（隐藏层）添加进入当前层的输入。<strong>注意这里的对每个词权重是一样的</strong>（后续代码中也可以看到）。</p><h4 id="Dense与Recurrent-networks">Dense与Recurrent networks</h4><p><img src="https://picture.mulindya.com/pML3-11.png" alt=""></p><h4 id="RNN和变种">RNN和变种</h4><p><img src="https://picture.mulindya.com/pML3-12.png" alt=""></p><p>注意隐藏层是经过激活层激活之后再输入，增加前向隐藏层。<br>$$<br>h_t = \sigma(W_{hh}h_{t-1}+W_{hx}x_t+b_h)<br>$$<br>有些变种会涉及门来抑制某些信息比如LSTM，GRU，会对信息流进行细致的控制，比如对过去或者现在的信息采取遗忘、抑制，这种操作也是通过一组权重来学习决定是否对特定信息抑制。</p><h4 id="代码-2">代码</h4><p>实现简单的RNN。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">W_xh = nn.Parameter(torch.randn(num_inputs, num_hiddens) * <span class="hljs-number">0.01</span>) <br>W_hh = nn.Parameter(torch.randn(num_hiddens, num_hiddens) * <span class="hljs-number">0.01</span>)  <span class="hljs-comment">#多出来的</span><br>b_h = nn.Parameter(torch.zeros(num_hiddens)) <br>H = torch.zeros(num_hiddens) <br>outputs = [] <br><span class="hljs-comment">#把每个词放入作为输入</span><br><span class="hljs-keyword">for</span> X <span class="hljs-keyword">in</span> inputs:  <span class="hljs-comment"># `inputs` shape : (num_steps, batch_size, num_inputs)  num_steps表示一组输入 各个词</span><br>    H = torch.tanh(X @ W_xh + H @ W_hh + b_h)  <span class="hljs-comment">#对每个词其实权重是一样的，只是绘图的时候方便表示展开拉长</span><br>    outputs.append(H)<br></code></pre></td></tr></tbody></table></figure><h4 id="Bi-RNN-and-Deep-RNN">Bi-RNN and Deep RNN</h4><p><img src="https://picture.mulindya.com/pML3-13.png" alt=""></p><p>可以从双向来检索，这样yt的信息来源是它两侧的信息，比如完形填空，是可以获取双向信息哦。</p><h4 id="模型选择">模型选择</h4><p>不同的模型使用与不同数据，表格数据使用一般树模型，线性模型，神经网络。Transformer对文本和图像都可以处理，实际上文本信息和图像信息有相似的内部特性，只是维度不一样而已。</p><p><img src="https://picture.mulindya.com/pML3-14.png" alt=""></p><h3 id="3-5-4-总结">3.5.4 总结</h3><p>• MLP: stack dense layers with non-linear activations<br>• CNN: stack convolution activation and pooling layers to efficient extract spatial information<br>• RNN: stack recurrent layers to pass temporal information through hidden state</p><p>CNN：高效抓取空间信息</p><p>RNN：持续信息的数据，比如对时序信息。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>李沐</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Depthwise Separable Convolution</title>
    <link href="/2022/01/06/deep_learning/dsconv/"/>
    <url>/2022/01/06/deep_learning/dsconv/</url>
    
    <content type="html"><![CDATA[<h1>Depthwise Separable Convolution</h1><blockquote><p>在Mobilenet中使用DSconv，通过改进架构减少参数量的方法，所以也顺势记录一下Depthwise Separable卷积的原理。笔记来源于李宏毅的课程。😢</p></blockquote><h2 id="传统的卷积过程">传统的卷积过程</h2><p><img src="https://picture.mulindya.com/kDistillation-3.png" alt=""></p><h2 id="Depthwise-Convolution">Depthwise Convolution</h2><p>第一个步骤，每一个filter只作用到一个Chanel，这里input和output的channel是相同的。</p><p><img src="https://picture.mulindya.com/kDistillation-4.png" alt=""></p><h2 id="Pointwise-Convolution">Pointwise Convolution</h2><p>跨channel操作是通过Pointwise Convolution来得到Feature map，这里是1*1的大小filter 因为只用考虑不同channel之间的关系即可。前面的Depthwise Convolution是已经考虑Channel内部的关系。</p><p><img src="https://picture.mulindya.com/kDistillation-5.png" alt=""></p><p><img src="https://picture.mulindya.com/kDistillation-6.png" alt=""></p><p>所以参数量会减少K*K倍。</p><h2 id="原理">原理</h2><h3 id="Low-rank-approximation">Low rank approximation</h3><p><img src="https://picture.mulindya.com/kDistillation-7.png" alt=""></p><p>这样可以减少参数。从W到U+V的参数规模，但是这样的变换会导致某些限制，减少w的可能性，因为使用U*V的秩是小于等于W的秩，所以映射的空间会减小。</p><p><img src="https://picture.mulindya.com/kDistillation-8.png" alt=""></p><p>就可以对比传统的卷积和Depthwise卷积的原理就相当于W和UV的关系，把一层的映射拆成两次，所以参数量减少了，模型表示减小。</p><h2 id="相关网络">相关网络</h2><p>使用Depthwise Conv的网络架构</p><p>•SqueezeNet<br>• <a href="https://arxiv.org/abs/1602.07360">https://arxiv.org/abs/1602.07360</a><br>•MobileNet<br>• <a href="https://arxiv.org/abs/1704.04861">https://arxiv.org/abs/1704.04861</a><br>•ShuffleNet<br>• <a href="https://arxiv.org/abs/1707.01083">https://arxiv.org/abs/1707.01083</a><br>•Xception<br>• <a href="https://arxiv.org/abs/1610.02357">https://arxiv.org/abs/1610.02357</a><br>•GhostNet<br>• <a href="https://arxiv.org/abs/1911.11907">https://arxiv.org/abs/1911.11907</a></p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
      <category>MobileNet</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>MobileNet</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Knowledge Distillation笔记</title>
    <link href="/2022/01/05/deep_learning/KnowledgeDistillation/"/>
    <url>/2022/01/05/deep_learning/KnowledgeDistillation/</url>
    
    <content type="html"><![CDATA[<blockquote><p>因为项目中要使用到知识蒸馏来训练网络，所以先好好学一下它的原理。在网上找到了李宏毅机器学习的模型压缩中讲到了这个，那，就开始学习叭😉</p></blockquote><h1>知识蒸馏🌌</h1><h2 id="概念">概念</h2><p>先训练一个大的network（teacher），再根据这个network来制造小的network（student），同时student是根据teacher的结构做一些修剪得到的小网络，student network是根据teacher network来学习的哦。</p><p><img src="https://picture.mulindya.com/kDistillation-1.png" alt=""></p><p>student network是去拟合teacher的结果，可以使用Ensemble的网络作为teacher，这样表现得结果更好。</p><p><img src="https://picture.mulindya.com/kDistillation-2.png" alt=""></p><p>在使用知识蒸馏时有一个小技巧，可以稍微改一下Softmax的函数，T是一个超参数，可以使得函数点更加平滑。因为student要学习teacher给的结果，并且teacher给的结果要告诉student，哪些类别比较相似，而不是直接给出1，0，0（和真实结果没有差别），所以teacher 的输出不应该过度集中，需要更加平滑。这样分类结果不同，但是student学习更加有意义。同时不一定要用softmax之后的结果去拟合student，完全可以使用之前的，或者类似student的第6层拟合teacher的12层，第3层拟合teacher的第6层，这样结果往往会更好。</p><h2 id="实例🌻">实例🌻</h2><h3 id="Intuition">Intuition</h3><p>通常模型Teacher比模型Student更强，在模型Teacher的帮助下，模型student可以"青出于蓝而胜于蓝"😉,因为从计算资源的角度上庞大的模型部署有很多问题，所以通过知识蒸馏可以训练一个相似的小模型去拟合大模型的训练效果，这样预测和部署会便捷很多。同时使用知识蒸馏的方法可以让小模型学到样本之间的相似关系。</p><p><img src="https://picture.mulindya.com/kDistillation-9.png" alt=""></p><p>这里不仅仅知道西红柿是真实标签，还可以知道这个样本和柿子这个标签很相似，这样可以获取更多信息，这是蒸馏更有价值的地方。</p><h3 id="Loss-Function-in-Pytorch">Loss Function in Pytorch</h3><ul><li><code>Softmax</code>：将一个数值序列映射到概率空间（每个元素分布并且所有和为1）</li><li><code>log_softmax</code>：在softmax的基础上取对数</li><li><code>NLLLoss</code>：对log_softmax与one-hot进行计算</li><li><code>CrossEntropy</code>：衡量两个概率分布的差别（交叉熵）</li></ul><h4 id="代码实证">代码实证</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-string">'''</span><br><span class="hljs-string">torch.nn.functional 涉及了所有 torch.nn 需要 类 和 方法 ，torch.nn 构建的模块通常就是调用 torch.nn.functional 里的方法实现的.</span><br><span class="hljs-string">'''</span><br>torch.manual_seed(<span class="hljs-number">0</span>)<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">output = torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br><span class="hljs-built_in">print</span>(output)<br><span class="hljs-comment">#tensor([[ 1.5410, -0.2934, -2.1788],</span><br><span class="hljs-comment">#        [ 0.5684, -1.0845, -1.3986]])</span><br><span class="hljs-built_in">print</span>(F.softmax(output, dim=<span class="hljs-number">1</span>))<br><span class="hljs-comment"># 这里dim的意思是计算Softmax的维度，这里设置dim=1，可以看到每一行的加和为1。0是对列 1 是对行</span><br><span class="hljs-comment">#tensor([[0.8446, 0.1349, 0.0205],</span><br><span class="hljs-comment">#       [0.7511, 0.1438, 0.1051]])</span><br></code></pre></td></tr></tbody></table></figure><h4 id="What-is-log-softmax">What is log_softmax</h4><p>这个很好理解，其实就是对<code>softmax</code>处理之后的结果执行一次对数运算。可以理解为 <code>log(softmax(output))</code></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(F.log_softmax(output, dim=<span class="hljs-number">1</span>))<br><span class="hljs-built_in">print</span>(torch.log(F.softmax(output, dim=<span class="hljs-number">1</span>)))<br><span class="hljs-comment"># 输出结果是一致的</span><br></code></pre></td></tr></tbody></table></figure><blockquote><p>tensor([[-0.1689, -2.0033, -3.8886],        [-0.2862, -1.9392, -2.2532]]) tensor([[-0.1689, -2.0033, -3.8886],        [-0.2862, -1.9392, -2.2532]])</p></blockquote><h4 id="损失函数">损失函数</h4><h4 id="What-is-NLLLoss？">What is NLLLoss？</h4><p>该函数的全称是<code>negative log likelihood loss</code>. 若$x_i=[q_1, q_2, …, q_N]$ 为神经网络对第i个样本的输出值，$y_i$为真实标签。则：<br>$$<br>f(x_i,y_i)=-q_{y_i}<br>$$<br>其中输入：log_softmax(output), target</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(F.nll_loss(torch.tensor([[-<span class="hljs-number">1.2</span>, -<span class="hljs-number">2</span>, -<span class="hljs-number">3</span>]]), torch.tensor([<span class="hljs-number">0</span>])))<br><span class="hljs-comment">#结果是tensor(1.2000) 就是取第0个的负数</span><br></code></pre></td></tr></tbody></table></figure><p><strong>通常我们结合 log_softmax 和 nll_loss一起用</strong> 👋。</p><h4 id="CrossEntropy交叉熵">CrossEntropy交叉熵</h4><p><strong>在分类问题中，CrossEntropy等价于log_softmax 结合 nll_loss</strong></p><p>$N$分类问题，对于一个特定的样本，已知其真实标签，<code>CrossEntropy</code>的计算公式为：</p><p>$$<br>cross_entropy=-\sum_{k=1}^{N}\left(p_{k} * \log q_{k}\right)<br>$$</p><p>其中p表示真实值，在这个公式中是one-hot形式；q是经过<code>softmax</code>计算后的结果， $q_k$为神经网络认为该样本为第$k$类的概率。</p><p>仔细观察可以知道，因为p的元素不是0就是1，而且又是乘法，所以很自然地我们如果知道1所对应的index，那么就不用做其他无意义的运算了。所以在pytorch代码中target不是以one-hot形式表示的，而是直接用scalar表示。若该样本的真实标签为$y$,则交叉熵的公式可变形为：</p><p>$$cross_entropy=-\sum_{k=1}^{N}\left(p_{k} * \log q_{k}\right)=-log , q_{y}$$</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">output = torch.tensor([[<span class="hljs-number">1.2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]])<br>target = torch.tensor([<span class="hljs-number">0</span>])<br><br>log_sm_output = F.log_softmax(output, dim=<span class="hljs-number">1</span>)<br>nll_loss_of_log_sm_output = F.nll_loss(log_sm_output, target)<br><span class="hljs-built_in">print</span>(nll_loss_of_log_sm_output)<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">output = torch.tensor([[<span class="hljs-number">1.2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]])<br>target = torch.tensor([<span class="hljs-number">0</span>])<br><br>ce_loss = F.cross_entropy(output, target)<br><span class="hljs-built_in">print</span>(ce_loss)<br><br>F.cross_entropy 《==》 F.log_softmax(output, dim=<span class="hljs-number">1</span>)+F.nll_loss(log_sm_output, target)<br></code></pre></td></tr></tbody></table></figure><p>这两者是等价的哦~</p><h4 id="T-softmax">T-softmax</h4><p>T-softmax的目的是平滑分布，不让分布太过于极端。比如可以看下面的实例哈。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">softmax</span>(<span class="hljs-params">x</span>):</span><br>    x_exp = np.exp(x)<br>    <span class="hljs-keyword">return</span> x_exp / np.<span class="hljs-built_in">sum</span>(x_exp)<br><br>output = np.array([<span class="hljs-number">0.1</span>, <span class="hljs-number">1.6</span>, <span class="hljs-number">3.6</span>])<br><span class="hljs-built_in">print</span>(softmax(output))<br><span class="hljs-comment">#[0.02590865 0.11611453 0.85797681]</span><br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">softmax_t</span>(<span class="hljs-params">x, t</span>):</span><br>    x_exp = np.exp(x / t)<br>    <span class="hljs-keyword">return</span> x_exp / np.<span class="hljs-built_in">sum</span>(x_exp)<br><br>output = np.array([<span class="hljs-number">0.1</span>, <span class="hljs-number">1.6</span>, <span class="hljs-number">3.6</span>])<br><span class="hljs-built_in">print</span>(softmax_t(output, <span class="hljs-number">5</span>))<br><span class="hljs-comment">#[0.22916797 0.3093444  0.46148762]</span><br></code></pre></td></tr></tbody></table></figure><p>设置为5可以看到分布在【0，1】的数更加平滑了哦~</p><h2 id="KD训练代码">KD训练代码</h2><h3 id="导入包">导入包</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets, transforms<br><span class="hljs-keyword">import</span> torch.utils.data<br>torch.manual_seed(<span class="hljs-number">0</span>)<br>torch.cuda.manual_seed(<span class="hljs-number">0</span>) <span class="hljs-comment">#设置GPU生成随机数的种子，方便下次复现实验结果。</span><br></code></pre></td></tr></tbody></table></figure><h3 id="网络架构">网络架构</h3><h4 id="teacher网络">teacher网络</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TeacherNet</span>(<span class="hljs-params">nn.Module</span>):</span> <span class="hljs-comment">#继承Module</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>(TeacherNet, self).__init__()<br>        self.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">32</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br>        self.conv2 = nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br>        self.dropout1 = nn.Dropout2d(<span class="hljs-number">0.3</span>)<br>        self.dropout2 = nn.Dropout2d(<span class="hljs-number">0.5</span>)<br>        self.fc1 = nn.Linear(<span class="hljs-number">9216</span>, <span class="hljs-number">128</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        x = self.conv1(x)<br>        x = F.relu(x)<br>        x = self.conv2(x)<br>        x = F.relu(x)<br>        x = F.max_pool2d(x, <span class="hljs-number">2</span>)<br>        x = self.dropout1(x)<br>        x = torch.flatten(x, <span class="hljs-number">1</span>)<br>        x = self.fc1(x)<br>        x = F.relu(x)<br>        x = self.dropout2(x)<br>        output = self.fc2(x)<br>        <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></tbody></table></figure><h4 id="student网络">student网络</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">StudentNet</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>(StudentNet, self).__init__()<br>        self.fc1 = nn.Linear(<span class="hljs-number">28</span> * <span class="hljs-number">28</span>, <span class="hljs-number">128</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">64</span>)<br>        self.fc3 = nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        x = torch.flatten(x, <span class="hljs-number">1</span>)<br>        x = F.relu(self.fc1(x))<br>        x = F.relu(self.fc2(x))<br>        output = F.relu(self.fc3(x))<br>        <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></tbody></table></figure><h3 id="teacher网络训练">teacher网络训练</h3><h4 id="定义基本函数">定义基本函数</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train_teacher</span>(<span class="hljs-params">model, device, train_loader, optimizer, epoch</span>):</span><br>    model.train() <span class="hljs-comment">#train过程model.train()的作用是启用 Batch Normalization 和 Dropout。model.train()是保证BN层能够用到每一批数据的均值和方差</span><br>    trained_samples = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> batch_idx, (data, target) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader):<br>        data, target = data.to(device), target.to(device) <span class="hljs-comment">#放到GPU</span><br>        optimizer.zero_grad() <span class="hljs-comment">#归0</span><br>        output = model(data) <span class="hljs-comment">#得到结果</span><br>        loss = F.cross_entropy(output, target) <span class="hljs-comment">#计算损失 使用交叉熵</span><br>        loss.backward() <span class="hljs-comment">#后向传播更新参数</span><br>        optimizer.step() <span class="hljs-comment">#优化器调整超参数</span><br><br>        trained_samples += <span class="hljs-built_in">len</span>(data)<br>        progress = math.ceil(batch_idx / <span class="hljs-built_in">len</span>(train_loader) * <span class="hljs-number">50</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">"\rTrain epoch %d: %d/%d, [%-51s] %d%%"</span> %<br>              (epoch, trained_samples, <span class="hljs-built_in">len</span>(train_loader.dataset),<br>               <span class="hljs-string">'-'</span> * progress + <span class="hljs-string">'&gt;'</span>, progress * <span class="hljs-number">2</span>), end=<span class="hljs-string">''</span>)<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test_teacher</span>(<span class="hljs-params">model, device, test_loader</span>):</span><br>    model.<span class="hljs-built_in">eval</span>() <span class="hljs-comment">#保证BN层能够用全部训练数据的均值和方差</span><br>    test_loss = <span class="hljs-number">0</span><br>    correct = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad(): <span class="hljs-comment">#冻结参数</span><br>        <span class="hljs-keyword">for</span> data, target <span class="hljs-keyword">in</span> test_loader:<br>            data, target = data.to(device), target.to(device)<br>            output = model(data) <span class="hljs-comment">#模型得到结果</span><br>            test_loss += F.cross_entropy(output, target, reduction=<span class="hljs-string">'sum'</span>).item()  <span class="hljs-comment"># 统计所有的losssum up batch loss</span><br>            pred = output.argmax(dim=<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># get the index of the max log-probability 得到每一行的最大值下标</span><br>            correct += pred.eq(target.view_as(pred)).<span class="hljs-built_in">sum</span>().item() <span class="hljs-comment">#eq是一个判断函数 view_as是拉成一列</span><br><br>    test_loss /= <span class="hljs-built_in">len</span>(test_loader.dataset) <span class="hljs-comment">#得到平均loss</span><br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">'\nTest: average loss: {:.4f}, accuracy: {}/{} ({:.0f}%)'</span>.<span class="hljs-built_in">format</span>(<br>        test_loss, correct, <span class="hljs-built_in">len</span>(test_loader.dataset),<br>        <span class="hljs-number">100.</span> * correct / <span class="hljs-built_in">len</span>(test_loader.dataset)))<br>    <span class="hljs-keyword">return</span> test_loss, correct / <span class="hljs-built_in">len</span>(test_loader.dataset)<br><br></code></pre></td></tr></tbody></table></figure><h4 id="训练主函数">训练主函数</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">teacher_main</span>():</span><br>    epochs = <span class="hljs-number">10</span><br>    batch_size = <span class="hljs-number">64</span><br>    torch.manual_seed(<span class="hljs-number">0</span>) <span class="hljs-comment">#设置CPU生成随机数的种子，方便下次复现实验结果。</span><br><br>    device = torch.device(<span class="hljs-string">"cuda"</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">"cpu"</span>)<br><br>    train_loader = torch.utils.data.DataLoader(<br>        datasets.MNIST(<span class="hljs-string">'../data/MNIST'</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>,<br>                       transform=transforms.Compose([<br>                           transforms.ToTensor(),<br>                           transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))<br>                       ])),<br>        batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>)<br>    test_loader = torch.utils.data.DataLoader(<br>        datasets.MNIST(<span class="hljs-string">'../data/MNIST'</span>, train=<span class="hljs-literal">False</span>, download=<span class="hljs-literal">True</span>, transform=transforms.Compose([<br>            transforms.ToTensor(),<br>            transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))<br>        ])),<br>        batch_size=<span class="hljs-number">1000</span>, shuffle=<span class="hljs-literal">True</span>)<br><br>    model = TeacherNet().to(device) <span class="hljs-comment">#模型装进GPU中</span><br>    optimizer = torch.optim.Adadelta(model.parameters()) <span class="hljs-comment">#定义优化器 其实需要传入模型参数让优化器知道参数空间</span><br>    <span class="hljs-string">'''</span><br><span class="hljs-string">    optimzier优化器的作用：优化器就是需要根据网络反向传播的梯度信息来</span><br><span class="hljs-string">    再次更新网络的参数，以起到降低loss函数计算值的作用。</span><br><span class="hljs-string">    '''</span><br>    <br>    teacher_history = [] <span class="hljs-comment">#保存历史数据</span><br><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):<br>        train_teacher(model, device, train_loader, optimizer, epoch)<br>        loss, acc = test_teacher(model, device, test_loader) <span class="hljs-comment">#相当于验证集作用 也可以绘图</span><br>        <br>        teacher_history.append((loss, acc))<br><br>    torch.save(model.state_dict(), <span class="hljs-string">"teacher.pt"</span>)<br>    <span class="hljs-keyword">return</span> model, teacher_history<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 训练教师网络</span><br>teacher_model, teacher_history = teacher_main()<br></code></pre></td></tr></tbody></table></figure><h3 id="student网络训练（重点）🌸">student网络训练（重点）🌸</h3><h4 id="理论部分">理论部分</h4><p><img src="https://picture.mulindya.com/kDistillation-10.png" alt=""></p><p>这里的q是经过了<code>softmax</code>之后的分布</p><p>student的loss来源于两个部分，Loss将两个loss相加</p><ul><li>studet的HARD Loss是根据one-hot的真实样本p分布得到（和一般的loss一样）</li><li>student的SOFT loss是来源于teacher的分布q’‘（是将q’蒸馏平滑后的结果）</li></ul><h4 id="定义kd的loss">定义kd的loss</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 这里定义的是SOFT Loss + 交叉熵（HARD Loss）</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">distillation</span>(<span class="hljs-params">y, labels, teacher_scores, temp, alpha</span>):</span><br>    <span class="hljs-keyword">return</span> nn.KLDivLoss()(F.log_softmax(y / temp, dim=<span class="hljs-number">1</span>), F.softmax(teacher_scores / temp, dim=<span class="hljs-number">1</span>)) * (<br>            temp * temp * <span class="hljs-number">2.0</span> * alpha) + F.cross_entropy(y, labels) * (<span class="hljs-number">1.</span> - alpha) <span class="hljs-comment">#两个分布都是T_softmax来求相对熵</span><br><br></code></pre></td></tr></tbody></table></figure><blockquote><p>nn.KLDivLoss()(input,target)相对熵损失 通过求散度得到Loss值</p><p>用于衡量两个分布的相似性，越小越相似</p></blockquote>$$l_{n}=y_{n} \cdot\left(\log y_{n}-x_{n}\right)$$<p>可以指定loss function的reduction参数，来设置每个样本loss的最后得到数据loss计算方式；</p>$$\ell(x, y)=\left\{\begin{array}{ll}L, &amp; \text { if reduction }=\text { 'none' } \\ \operatorname{mean}(L), &amp; \text { if reduction }=\text { 'mean' } \\ N*\operatorname {mean}(L), &amp; \text { if reduction }=\text { 'batchmean' } \\ \operatorname{sum}(L), &amp; \text { if reduction }=\text { 'sum' }\end{array} \right.$$<h4 id="定义基本函数-2">定义基本函数</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train_student_kd</span>(<span class="hljs-params">model, device, train_loader, optimizer, epoch</span>):</span><br>    model.train()<br>    trained_samples = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> batch_idx, (data, target) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader):<br>        data, target = data.to(device), target.to(device)<br>        optimizer.zero_grad()<br>        output = model(data)<br>        teacher_output = teacher_model(data)  <span class="hljs-comment">#得到teacher网络的推断用于后续计算student的loss</span><br>        teacher_output = teacher_output.detach()  <span class="hljs-comment"># 切断老师网络的反向传播</span><br>        loss = distillation(output, target, teacher_output, temp=<span class="hljs-number">5.0</span>, alpha=<span class="hljs-number">0.7</span>)<br>        loss.backward()<br>        optimizer.step()<br><br>        trained_samples += <span class="hljs-built_in">len</span>(data)<br>        progress = math.ceil(batch_idx / <span class="hljs-built_in">len</span>(train_loader) * <span class="hljs-number">50</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">"\rTrain epoch %d: %d/%d, [%-51s] %d%%"</span> %<br>              (epoch, trained_samples, <span class="hljs-built_in">len</span>(train_loader.dataset),<br>               <span class="hljs-string">'-'</span> * progress + <span class="hljs-string">'&gt;'</span>, progress * <span class="hljs-number">2</span>), end=<span class="hljs-string">''</span>)<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test_student_kd</span>(<span class="hljs-params">model, device, test_loader</span>):</span><br>    model.<span class="hljs-built_in">eval</span>()<br>    test_loss = <span class="hljs-number">0</span><br>    correct = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> data, target <span class="hljs-keyword">in</span> test_loader:<br>            data, target = data.to(device), target.to(device)<br>            output = model(data)<br>            test_loss += F.cross_entropy(output, target, reduction=<span class="hljs-string">'sum'</span>).item()  <span class="hljs-comment"># sum up batch loss item()函数可以理解为得到纯粹的数值</span><br>            pred = output.argmax(dim=<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># get the index of the max log-probability</span><br>            correct += pred.eq(target.view_as(pred)).<span class="hljs-built_in">sum</span>().item()<br><br>    test_loss /= <span class="hljs-built_in">len</span>(test_loader.dataset)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">'\nTest: average loss: {:.4f}, accuracy: {}/{} ({:.0f}%)'</span>.<span class="hljs-built_in">format</span>(<br>        test_loss, correct, <span class="hljs-built_in">len</span>(test_loader.dataset),<br>        <span class="hljs-number">100.</span> * correct / <span class="hljs-built_in">len</span>(test_loader.dataset)))<br>    <span class="hljs-keyword">return</span> test_loss, correct / <span class="hljs-built_in">len</span>(test_loader.dataset)<br></code></pre></td></tr></tbody></table></figure><h4 id="训练主函数-2">训练主函数</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">student_kd_main</span>():</span><br>    epochs = <span class="hljs-number">10</span><br>    batch_size = <span class="hljs-number">64</span><br>    torch.manual_seed(<span class="hljs-number">0</span>)<br><br>    device = torch.device(<span class="hljs-string">"cuda"</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">"cpu"</span>)<br><br>    train_loader = torch.utils.data.DataLoader(<br>        datasets.MNIST(<span class="hljs-string">'../data/MNIST'</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>,<br>                       transform=transforms.Compose([<br>                           transforms.ToTensor(),<br>                           transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))<br>                       ])),<br>        batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>)<br>    test_loader = torch.utils.data.DataLoader(<br>        datasets.MNIST(<span class="hljs-string">'../data/MNIST'</span>, train=<span class="hljs-literal">False</span>, download=<span class="hljs-literal">True</span>, transform=transforms.Compose([<br>            transforms.ToTensor(),<br>            transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))<br>        ])),<br>        batch_size=<span class="hljs-number">1000</span>, shuffle=<span class="hljs-literal">True</span>)<br><br>    model = StudentNet().to(device)<br>    optimizer = torch.optim.Adadelta(model.parameters())<br>    <br>    student_history = []<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):<br>        train_student_kd(model, device, train_loader, optimizer, epoch)<br>        loss, acc = test_student_kd(model, device, test_loader)<br>        student_history.append((loss, acc))<br><br>    torch.save(model.state_dict(), <span class="hljs-string">"student_kd.pt"</span>)<br>    <span class="hljs-keyword">return</span> model, student_history<br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">student_kd_model, student_kd_history = student_kd_main()<br></code></pre></td></tr></tbody></table></figure><h3 id="绘制结果">绘制结果</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>epochs = <span class="hljs-number">10</span><br>x = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, epochs+<span class="hljs-number">1</span>))<br><br>plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>plt.plot(x, [teacher_history[i][<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs)], label=<span class="hljs-string">'teacher'</span>)<br>plt.plot(x, [student_kd_history[i][<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs)], label=<span class="hljs-string">'student with KD'</span>)<br>plt.plot(x, [student_simple_history[i][<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs)], label=<span class="hljs-string">'student without KD'</span>)<br><br>plt.title(<span class="hljs-string">'Test accuracy'</span>)<br>plt.legend()<br><br><br>plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>plt.plot(x, [teacher_history[i][<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs)], label=<span class="hljs-string">'teacher'</span>)<br>plt.plot(x, [student_kd_history[i][<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs)], label=<span class="hljs-string">'student with KD'</span>)<br>plt.plot(x, [student_simple_history[i][<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs)], label=<span class="hljs-string">'student without KD'</span>)<br><br>plt.title(<span class="hljs-string">'Test loss'</span>)<br>plt.legend()<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/kDistillation-13.png" alt=""></p><p>可以看到在teacher的帮助下，student可以学得更好🐱</p><h3 id="teacher网络的暗知识🎍">teacher网络的暗知识🎍</h3><h4 id="softmax-t">softmax_t</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">softmax_t</span>(<span class="hljs-params">x, t</span>):</span><br>    x_exp = np.exp(x / t)<br>    <span class="hljs-keyword">return</span> x_exp / np.<span class="hljs-built_in">sum</span>(x_exp)<br><br>test_loader_bs1 = torch.utils.data.DataLoader(<br>    datasets.MNIST(<span class="hljs-string">'../data/MNIST'</span>, train=<span class="hljs-literal">False</span>, download=<span class="hljs-literal">True</span>, transform=transforms.Compose([<br>        transforms.ToTensor(),<br>        transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))<br>    ])),<br>    batch_size=<span class="hljs-number">1</span>, shuffle=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></tbody></table></figure><h4 id="推断">推断</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python">teacher_model.<span class="hljs-built_in">eval</span>()<br><span class="hljs-keyword">with</span> torch.no_grad():<br>    data, target = <span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(test_loader_bs1))<br>    data, target = data.to(<span class="hljs-string">'cuda'</span>), target.to(<span class="hljs-string">'cuda'</span>)<br>    output = teacher_model(data)<br><br>test_x = data.cpu().numpy() <span class="hljs-comment">#放进cpu转换成numpy</span><br>y_out = output.cpu().numpy()<br>y_out = y_out[<span class="hljs-number">0</span>, ::]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">'Output (NO softmax):'</span>, y_out)<br><br><br><br>plt.subplot(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>plt.imshow(test_x[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, ::])<br><br>plt.subplot(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>plt.bar(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)), softmax_t(y_out, <span class="hljs-number">1</span>), width=<span class="hljs-number">0.3</span>) <span class="hljs-comment">#直方图</span><br><br>plt.subplot(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br>plt.bar(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)), softmax_t(y_out, <span class="hljs-number">10</span>), width=<span class="hljs-number">0.3</span>)<br>plt.show()<br></code></pre></td></tr></tbody></table></figure><blockquote><p>Output (NO softmax): [-31.14481   -30.600847   -3.2787514 -20.624037  -31.863455  -37.684086 -35.177486  -22.72263   -16.028662  -26.460657 ]</p></blockquote><p><img src="https://picture.mulindya.com/kDistillation-12.png" alt=""></p><p>可以看到数据更加平滑，并且可以体现出这个数字不仅是2还和8有些类似⛄️。</p><h2 id="本质🎈">本质🎈</h2><p><img src="https://picture.mulindya.com/kDistillation-11.png" alt=""></p><p>在知识蒸馏中，本质上就是使用SOFT Loss来替代正则化项，去拟合teacher的效果。</p><p>L2左边是极大似然，右边是先验知识（人为设置）</p><p>这里用teacher的知识去正则化作为先验知识，嗯！nice！</p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>李宏毅</tag>
      
      <tag>知识蒸馏</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>leetcode17 电话号码的字母组合</title>
    <link href="/2022/01/05/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode17/"/>
    <url>/2022/01/05/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode17/</url>
    
    <content type="html"><![CDATA[<blockquote><p>电话号码的字母组合</p></blockquote><h2 id="题目">题目</h2><p>给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。答案可以按 任意顺序 返回。</p><p>给出数字到字母的映射如下（与电话按键相同）。注意 1 不对应任何字母</p><p><img src="https://picture.mulindya.com/leetcode17-1.png" alt=""></p><h3 id="示例-1：">示例 1：</h3><figure class="highlight ada"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ada">输入：<span class="hljs-keyword">digits</span> = <span class="hljs-string">"23"</span><br>输出：[<span class="hljs-string">"ad"</span>,<span class="hljs-string">"ae"</span>,<span class="hljs-string">"af"</span>,<span class="hljs-string">"bd"</span>,<span class="hljs-string">"be"</span>,<span class="hljs-string">"bf"</span>,<span class="hljs-string">"cd"</span>,<span class="hljs-string">"ce"</span>,<span class="hljs-string">"cf"</span>]<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight ada"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ada">输入：<span class="hljs-keyword">digits</span> = <span class="hljs-string">""</span><br>输出：[]<br></code></pre></td></tr></tbody></table></figure><h3 id="示例3">示例3</h3><figure class="highlight ada"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ada">输入：<span class="hljs-keyword">digits</span> = <span class="hljs-string">"2"</span><br>输出：[<span class="hljs-string">"a"</span>,<span class="hljs-string">"b"</span>,<span class="hljs-string">"c"</span>]<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><code>0 &lt;= digits.length &lt;= 4</code></li><li><code>digits[i]</code> 是范围 <code>['2', '9']</code> 的一个数字。</li></ul><h2 id="题解">题解</h2><p>使用树的深度优先遍历算法，digit的字符串相当于给出每一层的节点值（数字对应的字符），按照深度优先算法，遍历到最后一个节点即可添加到result中。</p><p>去掉最后一个字符是<code>word[:-1]</code>，这里 word[-1]表示最后一个字符。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">letterCombinations</span>(<span class="hljs-params">self, digits: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]:</span><br>        record = {<span class="hljs-string">'2'</span>:<span class="hljs-string">'abc'</span>,<span class="hljs-string">'3'</span>:<span class="hljs-string">'def'</span>,<span class="hljs-string">'4'</span>:<span class="hljs-string">'ghi'</span>,<span class="hljs-string">'5'</span>:<span class="hljs-string">'jkl'</span>,<span class="hljs-string">'6'</span>:<span class="hljs-string">'mno'</span>,<span class="hljs-string">'7'</span>:<span class="hljs-string">'pqrs'</span>,<span class="hljs-string">'8'</span>:<span class="hljs-string">'tuv'</span>,<span class="hljs-string">'9'</span>:<span class="hljs-string">'wxyz'</span>}<br>        <span class="hljs-keyword">if</span>(<span class="hljs-keyword">not</span> digits): <span class="hljs-keyword">return</span> []<br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dfs</span>(<span class="hljs-params">rindex</span>):</span><br>            <span class="hljs-keyword">if</span> rindex==<span class="hljs-built_in">len</span>(digits): <br>                self.result.append(self.word)<br>            <span class="hljs-keyword">if</span> rindex&gt;=<span class="hljs-built_in">len</span>(digits): <span class="hljs-keyword">return</span><br>            <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> record[digits[rindex]]:<br>                self.word += x<br>                dfs(rindex+<span class="hljs-number">1</span>)<br>                self.word = self.word[:-<span class="hljs-number">1</span>] <span class="hljs-comment">#切片去掉最后一个字符</span><br><br>        rindex = <span class="hljs-number">0</span><br>        self.result,self.word = [],<span class="hljs-string">""</span><br>        dfs(rindex)<br>        <span class="hljs-keyword">return</span> self.result<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>树</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>generative adversarial nets</title>
    <link href="/2022/01/04/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87/paper-gan/"/>
    <url>/2022/01/04/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87/paper-gan/</url>
    
    <content type="html"><![CDATA[<blockquote><p>笔记记录于pdf中，所以就直接放pdf在此处~ 😉</p></blockquote><h3 id="学习视频链接">学习视频链接</h3><p><a href="https://www.bilibili.com/video/BV1rb4y187vD?spm_id_from=333.999.0.0">https://www.bilibili.com/video/BV1rb4y187vD?spm_id_from=333.999.0.0</a></p><h3 id="pdf链接">pdf链接</h3><p><a href="https://paper.mulindya.com/NIPS-2014-generative-adversarial-nets-Paper.pdf">https://paper.mulindya.com/NIPS-2014-generative-adversarial-nets-Paper.pdf</a></p><h3 id="论文学习链接">论文学习链接</h3><p>更多论文请见：<a href="https://github.com/mli/paper-reading">https://github.com/mli/paper-reading</a></p><h3 id="论文pdf">论文pdf</h3><iframe src="/js/pdfjs_old/web/viewer.html?file=https://paper.mulindya.com/NIPS-2014-generative-adversarial-nets-Paper.pdf" width="100%" height="700"></iframe>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>paper</category>
      
    </categories>
    
    
    <tags>
      
      <tag>学习笔记</tag>
      
      <tag>经典论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer58-1 翻转单词的顺序</title>
    <link href="/2022/01/04/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer58-1/"/>
    <url>/2022/01/04/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer58-1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>翻转单词的顺序</p></blockquote><h2 id="题目">题目</h2><p>输入一个英文句子，翻转句子中单词的顺序，但单词内字符的顺序不变。为简单起见，标点符号和普通字母一样处理。例如输入字符串"I am a student. “，则输出"student. a am I”。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight smalltalk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs smalltalk">输入: <span class="hljs-comment">"the sky is blue"</span><br>输出: <span class="hljs-comment">"blue is sky the"</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入: " &nbsp;hello world! &nbsp;"</span><br><span class="hljs-section">输出:&nbsp;"world! hello"</span><br><span class="hljs-section">解释: 输入字符串可以在前面或者后面包含多余的空格，但是反转后的字符不能包括。</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-3：">示例 3：</h3><figure class="highlight smalltalk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs smalltalk">输入: <span class="hljs-comment">"a good &nbsp; example"</span><br>输出:&nbsp;<span class="hljs-comment">"example good a"</span><br>解释: 如果两个单词间有多余的空格，将反转后单词间的空格减少到只含一个。<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>无空格字符构成一个单词。</li><li>输入字符串可以在前面或者后面包含多余的空格，但是反转后的字符不能包括。</li><li>如果两个单词间有多余的空格，将反转后单词间的空格减少到只含一个。</li></ul><h2 id="题解">题解</h2><p>使用双指针来定位词首尾位置，由于是倒序因此需要从后往前来搜索，先定位词的起始位置再跳过空格定位j的位置，截取单词到列表中，最后使用join连接字符串。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reverseWords</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">str</span>:</span><br>        <span class="hljs-comment">#从后往前 利用双指针来判断单词块</span><br>        s = s.strip() <span class="hljs-comment"># 删除首尾空格</span><br>        <span class="hljs-comment"># Python strip() 方法用于移除字符串头尾指定的字符（默认为空格或换行符）或字符序列。</span><br>        <span class="hljs-comment"># 注意：该方法只能删除开头或是结尾的字符，不能删除中间部分的字符。</span><br>        i,j = <span class="hljs-built_in">len</span>(s)-<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(s)-<span class="hljs-number">1</span><br>        res = []<br>        <span class="hljs-keyword">while</span>(i&gt;=<span class="hljs-number">0</span>):<br>            <span class="hljs-keyword">while</span>(i&gt;=<span class="hljs-number">0</span> <span class="hljs-keyword">and</span> s[i]!=<span class="hljs-string">' '</span>): i -= <span class="hljs-number">1</span> <span class="hljs-comment">#确定词的起始位置</span><br>            res.append(s[i+<span class="hljs-number">1</span>:j+<span class="hljs-number">1</span>])<br>            <span class="hljs-keyword">while</span>(i&gt;=<span class="hljs-number">0</span> <span class="hljs-keyword">and</span> s[i]==<span class="hljs-string">' '</span>): i -= <span class="hljs-number">1</span> <span class="hljs-comment">#确定j的位置</span><br>            j = i<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">' '</span>.join(res)<br></code></pre></td></tr></tbody></table></figure><p>使用内置函数split的话这里直接使用<code>split()</code></p><p>因为<code>s.split(" ")</code>解决不了单词间多空格的问题，<code>s.split()</code>可以解决。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reverseWords</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">str</span>:</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">' '</span>.join(s.strip().split()[::-<span class="hljs-number">1</span>])<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>双指针</category>
      
    </categories>
    
    
    <tags>
      
      <tag>双指针</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>praticalML第二章笔记</title>
    <link href="/2022/01/02/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PracticeML2-2/"/>
    <url>/2022/01/02/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PracticeML2-2/</url>
    
    <content type="html"><![CDATA[<blockquote><p>斯坦福2021秋季的实用机器学习上线啦~ 😉 跟着沐神复习机器学习冲冲冲！ 记录一下笔记和重点，不一定很全哦~，只是记录自我感觉的重点。</p></blockquote><h1>第二章 提升数据质量</h1><blockquote><ul><li><p>噪声多？</p></li><li><p>yes -&gt;数据清理</p></li><li><p>no？ 格式对吗？</p></li><li><p>No -&gt;数据变换</p></li><li><p>yes 适合学习嘛？</p></li><li><p>No -&gt;特征提取</p></li></ul></blockquote><h2 id="2-1-数据清理">2.1 数据清理</h2><h3 id="2-1-1-outlier检测（异常）">2.1.1 outlier检测（异常）</h3><p><img src="https://picture.mulindya.com/pML2-6.png" alt=""></p><h3 id="2-1-2-基于规则的检测">2.1.2 基于规则的检测</h3><p>比如已知x决定y，但是出现了x-&gt;z那么z是一个异常情况。</p><h3 id="2-1-3-基于模式的检测">2.1.3 基于模式的检测</h3><ul><li>Syntactic patterns  （语法模式）</li></ul><p>比如说大多数都是数字，少数是￥+数字，那么可以转换这些少数的字段为数字</p><p>• e.g. Map a column to the most prominent data type and identify values do not fit<br>• eng, en, english -&gt; English</p><ul><li>Semantic patterns （语义模式）<br>• e.g. Add rules through knowledge graph<br>• Values in column “Country” need have capitals, so a value “Stanford” is invalid、</li></ul><h3 id="2-1-4-总结">2.1.4 总结</h3><ul><li>Types of data errors: outliers, rule violations, pattern violations</li><li>Multiple tools exist to help data cleaning<br>• Graphic interface for interactive cleaning<br>• Automatically detect and fix</li></ul><blockquote><p>现在也有很多数据清理的工具，有图形化界面，也可以自动分析处理。</p></blockquote><h2 id="2-2-数据变换">2.2 数据变换</h2><p><strong>机器学习的流程：数据收集-数据标注-数据变换-特征工程-模型构建及训练</strong></p><p>• ML algorithms prefer well defined fixed length, well-conditioned, nicely distributed input<br>• Next, data transformation methods for different data types</p><p><img src="https://picture.mulindya.com/pML2-7.png" alt=""></p><h3 id="2-2-1-对实数归一化（Normalization）">2.2.1 对实数归一化（Normalization）</h3><p>• Normalization makes training more stable</p><p><img src="https://picture.mulindya.com/pML2-8.png" alt=""></p><ul><li>Min-max normalization: linearly map to a new min a and max b也就是通过线性变换把数值变换到a到b之间，先通过min，max的变换到0-1之间然后进行扩增和移动。</li><li>Z-score normalization: 0 mean, 1 standard deviation 其目的是将分布变为均值为0方差为1，减去均值除以标准差。</li><li>Decimal scaling 将数字转换为0.XX (到0-1)</li><li>Log scaling 原始数据比较大（正数）时可以变换到log’空间’，在log中的加减是原始数据的乘除，所以比值类的数据可以变换到这种形式</li></ul><h3 id="2-2-2-图像变换">2.2.2 图像变换</h3><ul><li><p>Our previous web scraping will scrape 15 TB images for a year<br>• 5 millions houses sold in US per year, ~20 images/house, ~153KB per image, ~1041x732 resolution</p></li><li><p>cropping, downsampling, compression<br>• Save storage cost, faster loading at training<br>• At ~320x224 resolution, 15 TB -&gt; 1.4TB<br>• ML is good at low-resolution images<br>• Be aware of lossy compression<br>• Medium (80%-90%) jpeg compression may lead to 1% acc drop in ImageNet</p></li><li><p>Image whitening（数据白化 可以理解为降维）<br>•make input less redundent<br>•model converages faster</p></li></ul><p>机器学习对于低分辨的图片可以做的挺好的。所以剪裁，下采样是可以接受的。<strong>但是要注意下采样之后要使用较高质量的图片格式不要用jpeg。</strong></p><p>白化的目的是去除输入数据的冗余信息。假设训练数据是图像，由于图像中相邻像素之间具有很强的相关性，所以用于训练时输入是冗余的；白化的目的就是降低输入的冗余性。白化分为PCA白化、ZCA白化.<br>输入数据集X，经过白化处理后，新的数据X’满足两个性质：<br>(1)特征之间相关性较低；<br>(2)所有特征具有相同的方差。</p><h3 id="2-2-3-视频变换">2.2.3 视频变换</h3><ul><li>Input variability high<br>• Average video length: Movies ~2h, YouTube videos ~11min, Tiktok short videos ~15sec</li><li>Tractable ML problems with short video clips (&lt;10sec)<br>• Ideally each clip is a coherent event (e.g. a human action)<br>• Semantic segmentation is extremely hard…</li><li>Preprocessing to tradeoff storage, quality and loading speed</li><li>Common practice: decode a playable video clip, sample a sequence of  frames, compute spectrograms for audio<br>• Easy to load to model, increased storage space</li></ul><p>采样关键的帧，图片不需要所有的信息，使用gpu来采样，需要权衡存储和解码。</p><h3 id="2-2-3-文本变换">2.2.3 文本变换</h3><ul><li>Stemming and lemmatization: a word -&gt;  a common base form<br>• E.g. am, are, is   -&gt; be        car, cars, car’s, cars’  -&gt;  car<br>• Example: Topic modeling</li><li>Tokenization: text string  a list of tokens (smallest unit to ML algorithms)<br>• By word: text.split(’ ‘)<br>• By char: text.split(‘’)<br>• By subwords:<br>• e.g. “a new gpu!”   “a”, “new”, “gp”, “##u”, “!”<br>• Custom vocabulary learned from the text corpus  (Unigram, WordPiece)</li></ul><p>方法是忽略语法，词根化，词源化，子词。</p><h3 id="2-2-4-总结">2.2.4 总结</h3><p>主要是格式的转换，需要权衡数据大小，数据质量，存储的方式。</p><ul><li>•Transform data into formats preferred by ML algorithms<br>• Tabular: normalize real value features<br>• Images: cropping, downsampling, whitening<br>• Videos: clipping, sampling frames<br>• Text: stemming, lemmatization, tokenization</li><li>Need to balance storage, quality, and loading speed</li></ul><h2 id="2-3-特征工程">2.3 特征工程</h2><ul><li><p>Before deep learning (DL), feature engineering (FE) was critical to using ML models<br>• Traditional CV: detect corners / interest points…</p></li><li><p>DL train deep neural networks to automatically extract features<br>• Train CNN to replace feature extractor<br>• Features are more relevant to the final task<br>• Limitation: data hungry, computation heavy</p></li></ul><p><img src="https://picture.mulindya.com/pML2-9.png" alt=""></p><p>深度学习出现之前主要是研究特征工程抽取特征；</p><p>深度学习没有改变流程但是现在并不是手动的过程，现在是自动抽取特征。</p><h3 id="2-3-1-Tabular-Data-Features">2.3.1 Tabular Data Features</h3><ul><li>Tabular data are in the form of a table,  feature columns of numeric / categorical / string type</li><li>Int/float: directly use or or bin to   unique int values</li><li>Categorical data: one-hot encoding （独热编码）<br>• Map rare categories into “Unknown”</li><li>Date-time: a feature list such as  日期特征<br>• [year, month, day, day_of_year, week_of_year, day_of_week]</li><li>Feature combination: Cartesian product of two feature groups  特征组合<br>• [cat, dog] x [male, female] -&gt;  [(cat, male), (cat, female), (dog, male), (dog, female)]</li></ul><h3 id="2-3-2-文本特征">2.3.2 文本特征</h3><p>将词源的独热编码加起来</p><p>词表示为向量来表示语义信息</p><p>使用预训练好的语言模型来特定表示（通过自监督学习来训练，可以抽取时序信息）</p><p><img src="https://picture.mulindya.com/pML2-10.png" alt=""></p><h3 id="2-3-3-图像-视频特征">2.3.3 图像/视频特征</h3><p>预训练的模型来抽取特征</p><p><img src="https://picture.mulindya.com/pML2-11.png" alt=""></p><h3 id="2-3-4-总结">2.3.4 总结</h3><ul><li>Features are representations of raw data that are relevant to the target task</li><li>Feature engineering VS Feature learning<br>• The latter is preferred if available (images/videos/audio/text)<br>• Will cover more later in “transfer learning”</li></ul>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>李沐</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PracticeML第二章房价实例笔记</title>
    <link href="/2022/01/02/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PracticeML2-1/"/>
    <url>/2022/01/02/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PracticeML2-1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>斯坦福2021秋季的实用机器学习上线啦~ 😉 跟着沐神复习机器学习冲冲冲！ 记录一下笔记和重点，不一定很全哦~，只是记录自我感觉的重点。</p></blockquote><blockquote><p>本篇笔记主要是实例分析，还有一些小知识点</p><ol><li>字符串前加f，r，b，u</li><li>| &amp; 和 or and</li></ol></blockquote><h1>房价数据分析实例</h1><p>使用<code>numpy，pandas，matplotlib，seaborn</code>来处理和可视化。</p><h2 id="实例（波士顿房价）">实例（波士顿房价）</h2><h3 id="读取">读取</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># !pip install seaborn pandas matplotlib numpy</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><br><span class="hljs-comment">#绘图画质更好</span><br><span class="hljs-keyword">from</span> IPython <span class="hljs-keyword">import</span> display<br>display.set_matplotlib_formats(<span class="hljs-string">'svg'</span>)<br><span class="hljs-comment"># Alternative to set svg for newer versions</span><br><span class="hljs-comment"># import matplotlib_inline</span><br><span class="hljs-comment"># matplotlib_inline.backend_inline.set_matplotlib_formats('svg')</span><br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">data = pd.read_csv(<span class="hljs-string">'house_sales.zip'</span>) <span class="hljs-comment">#可以直接用csv格式读取zip文件</span><br><span class="hljs-comment">#对于文本会快很多</span><br></code></pre></td></tr></tbody></table></figure><h3 id="数据清理">数据清理</h3><p>We drop columns that at least 30% values are null to simplify our EDA.</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#缺失数据</span><br>null_sum = data.isnull().<span class="hljs-built_in">sum</span>() <span class="hljs-comment">#缺失数据个数 为空的个数 是一个键值对</span><br>data.columns[null_sum &lt; <span class="hljs-built_in">len</span>(data) * <span class="hljs-number">0.3</span>]  <span class="hljs-comment"># columns will keep #键值对 返回值满足条件的键</span><br></code></pre></td></tr></tbody></table></figure><blockquote><figure class="highlight sml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sml"><span class="hljs-type">Index</span>([<span class="hljs-symbol">'Id'</span>, <span class="hljs-symbol">'Address'</span>, <span class="hljs-symbol">'Sold</span> <span class="hljs-type">Price'</span>, <span class="hljs-symbol">'Sold</span> <span class="hljs-type">On'</span>, <span class="hljs-symbol">'Summary'</span>, <span class="hljs-symbol">'Type'</span>,<br>       <span class="hljs-symbol">'Year</span> built', <span class="hljs-symbol">'Heating'</span>, <span class="hljs-symbol">'Cooling'</span>, <span class="hljs-symbol">'Parking'</span>, <span class="hljs-symbol">'Bedrooms'</span>, <span class="hljs-symbol">'Bathrooms'</span>,<br>       <span class="hljs-symbol">'Total</span> interior livable area', <span class="hljs-symbol">'Total</span> spaces', <span class="hljs-symbol">'Garage</span> spaces',<br>       <span class="hljs-symbol">'Home</span> type', <span class="hljs-symbol">'Region'</span>, <span class="hljs-symbol">'Elementary</span> <span class="hljs-type">School'</span>, <span class="hljs-symbol">'Elementary</span> <span class="hljs-type">School</span> <span class="hljs-type">Score'</span>,<br>       <span class="hljs-symbol">'Elementary</span> <span class="hljs-type">School</span> <span class="hljs-type">Distance'</span>, <span class="hljs-symbol">'High</span> <span class="hljs-type">School'</span>, <span class="hljs-symbol">'High</span> <span class="hljs-type">School</span> <span class="hljs-type">Score'</span>,<br>       <span class="hljs-symbol">'High</span> <span class="hljs-type">School</span> <span class="hljs-type">Distance'</span>, <span class="hljs-symbol">'Heating</span> features', <span class="hljs-symbol">'Parking</span> features',<br>       <span class="hljs-symbol">'Lot</span> size', <span class="hljs-symbol">'Parcel</span> number', <span class="hljs-symbol">'Tax</span> assessed value', <span class="hljs-symbol">'Annual</span> tax amount',<br>       <span class="hljs-symbol">'Listed</span> <span class="hljs-type">On'</span>, <span class="hljs-symbol">'Listed</span> <span class="hljs-type">Price'</span>, <span class="hljs-symbol">'Zip'</span>],<br>      dtype=<span class="hljs-symbol">'object'</span>)<br></code></pre></td></tr></tbody></table></figure></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.drop(columns=data.columns[null_sum &gt; <span class="hljs-built_in">len</span>(data) * <span class="hljs-number">0.3</span>], inplace=<span class="hljs-literal">True</span>) <span class="hljs-comment">#inplace直接修改</span><br></code></pre></td></tr></tbody></table></figure><h4 id="核对数据类型">核对数据类型</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data.dtypes <span class="hljs-comment">#核对数据类型</span><br></code></pre></td></tr></tbody></table></figure><blockquote><figure class="highlight nim"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs nim"><span class="hljs-type">Id</span>                               <span class="hljs-built_in">int64</span><br><span class="hljs-type">Address</span>                         <span class="hljs-keyword">object</span><br><span class="hljs-type">Sold</span> <span class="hljs-type">Price</span>                      <span class="hljs-keyword">object</span><br><span class="hljs-type">Sold</span> <span class="hljs-type">On</span>                         <span class="hljs-keyword">object</span><br><span class="hljs-type">Summary</span>                         <span class="hljs-keyword">object</span><br><span class="hljs-type">Type</span>                            <span class="hljs-keyword">object</span><br><span class="hljs-type">Year</span> built                      <span class="hljs-keyword">object</span><br><span class="hljs-type">Heating</span>                         <span class="hljs-keyword">object</span><br><span class="hljs-type">Cooling</span>                         <span class="hljs-keyword">object</span><br><span class="hljs-type">Parking</span>                         <span class="hljs-keyword">object</span><br><span class="hljs-type">Bedrooms</span>                        <span class="hljs-keyword">object</span><br><span class="hljs-type">Bathrooms</span>                      <span class="hljs-built_in">float64</span><br><span class="hljs-type">Total</span> interior livable area     <span class="hljs-keyword">object</span><br><span class="hljs-type">Total</span> spaces                   <span class="hljs-built_in">float64</span><br><span class="hljs-type">Garage</span> spaces                  <span class="hljs-built_in">float64</span><br><span class="hljs-type">Home</span> <span class="hljs-keyword">type</span>                       <span class="hljs-keyword">object</span><br><span class="hljs-type">Region</span>                          <span class="hljs-keyword">object</span><br><span class="hljs-type">Elementary</span> <span class="hljs-type">School</span>               <span class="hljs-keyword">object</span><br><span class="hljs-type">Elementary</span> <span class="hljs-type">School</span> <span class="hljs-type">Score</span>        <span class="hljs-built_in">float64</span><br><span class="hljs-type">Elementary</span> <span class="hljs-type">School</span> <span class="hljs-type">Distance</span>     <span class="hljs-built_in">float64</span><br><span class="hljs-type">High</span> <span class="hljs-type">School</span>                     <span class="hljs-keyword">object</span><br><span class="hljs-type">High</span> <span class="hljs-type">School</span> <span class="hljs-type">Score</span>              <span class="hljs-built_in">float64</span><br><span class="hljs-type">High</span> <span class="hljs-type">School</span> <span class="hljs-type">Distance</span>           <span class="hljs-built_in">float64</span><br><span class="hljs-type">Heating</span> features                <span class="hljs-keyword">object</span><br><span class="hljs-type">Parking</span> features                <span class="hljs-keyword">object</span><br><span class="hljs-type">Lot</span> size                        <span class="hljs-keyword">object</span><br><span class="hljs-type">Parcel</span> number                   <span class="hljs-keyword">object</span><br><span class="hljs-type">Tax</span> assessed value              <span class="hljs-keyword">object</span><br><span class="hljs-type">Annual</span> tax amount               <span class="hljs-keyword">object</span><br><span class="hljs-type">Listed</span> <span class="hljs-type">On</span>                       <span class="hljs-keyword">object</span><br><span class="hljs-type">Listed</span> <span class="hljs-type">Price</span>                    <span class="hljs-keyword">object</span><br><span class="hljs-type">Zip</span>                              <span class="hljs-built_in">int64</span><br>dtype: <span class="hljs-keyword">object</span><br></code></pre></td></tr></tbody></table></figure></blockquote><h4 id="修改数据类型">修改数据类型</h4><p>金额为object这是不合常理的</p><p>Convert currency from string format such as <code>$1,000,000</code> to float.</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">currency = [<span class="hljs-string">'Sold Price'</span>, <span class="hljs-string">'Listed Price'</span>, <span class="hljs-string">'Tax assessed value'</span>, <span class="hljs-string">'Annual tax amount'</span>]<br><span class="hljs-comment"># r'[$,-]' r的作用是：去除转义字符，replace可以用正则形式</span><br><span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> currency:<br>    data[c] = data[c].replace(<br>        <span class="hljs-string">r'[$,-]'</span>, <span class="hljs-string">''</span>, regex=<span class="hljs-literal">True</span>).replace( <br>        <span class="hljs-string">r'^\s*$'</span>, np.nan, regex=<span class="hljs-literal">True</span>).astype(<span class="hljs-built_in">float</span>)<br></code></pre></td></tr></tbody></table></figure><p>Convert currency from string format such as <code>$1,000,000</code> to float.</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">areas = [<span class="hljs-string">'Total interior livable area'</span>, <span class="hljs-string">'Lot size'</span>]<br><span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> areas:<br>    acres = data[c].<span class="hljs-built_in">str</span>.contains(<span class="hljs-string">'Acres'</span>) == <span class="hljs-literal">True</span><br>    col = data[c].replace(<span class="hljs-string">r'\b sqft\b|\b Acres\b|\b,\b'</span>,<span class="hljs-string">''</span>, regex=<span class="hljs-literal">True</span>).astype(<span class="hljs-built_in">float</span>)<br>    col[acres] *= <span class="hljs-number">43560</span><br>    data[c] = col<br></code></pre></td></tr></tbody></table></figure><blockquote><p>tips 😉</p><p>字符串前加f，r，b，u</p><p>加f作用：相当于 format() 函数f“{变量名}”</p><p>加r的作用是：去除转义字符； 场景：想复制某个文件夹的目录。</p><p>加b的作用是：后面字符串是bytes 类型bytes；应用场景：像图片、音视频等文件的读写就是用bytes数据。</p><p>加u的作用：后面字符串以 Unicode 格式 进行编码；实际场景：一般用在中文字符串前面，防止因为源码储存格式问题，导致再次使用时出现乱码。</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#Now we can check values of the numerical columns. You could see the min and max values for several columns do not make sense.</span><br>data.describe()<br></code></pre></td></tr></tbody></table></figure><p>可以查看一些不太正常的字段。。。</p><h4 id="数据清理数值">数据清理数值</h4><p>We filter out houses whose living areas are too small or too hard to simplify the visualization later.</p><blockquote><p>| &amp; 和 or and</p><p>DataFrame中切片需要求得满足多个逻辑条件的数据时，要使用&amp; 和|，在某些条件下用and/ or会报错</p><p>一般情况下：</p><ul><li><p><strong>如果a，b是数值变量</strong>， 则&amp;， |表示<a href="https://so.csdn.net/so/search?q=%E4%BD%8D%E8%BF%90%E7%AE%97">位运算</a>， and，or则依据是否非0来决定输出</p></li><li><p><strong>如何a, b是逻辑变量</strong>， 则两类的用法基本一致</p></li></ul></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">abnormal = (data[areas[<span class="hljs-number">1</span>]] &lt; <span class="hljs-number">10</span>) | (data[areas[<span class="hljs-number">1</span>]] &gt; <span class="hljs-number">1e4</span>) <span class="hljs-comment">#不正常的数据</span><br>data = data[~abnormal] <span class="hljs-comment">#使用~来求反</span><br><span class="hljs-built_in">sum</span>(abnormal)<br></code></pre></td></tr></tbody></table></figure><h4 id="查看价格类别图像">查看价格类别图像</h4><p>Let’s check the histogram of the <code>'Sold Price'</code>, which is the target we want to predict.</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">ax = sns.histplot(np.log10(data[<span class="hljs-string">'Sold Price'</span>])) <span class="hljs-comment">#直方图绘制 取log10 这样分布更加均匀</span><br>ax.set_xlim([<span class="hljs-number">3</span>, <span class="hljs-number">8</span>])<br>ax.set_xticks(<span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>, <span class="hljs-number">9</span>))<br>ax.set_xticklabels([<span class="hljs-string">'%.0e'</span>%a <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> <span class="hljs-number">10</span>**ax.get_xticks()]);<br><span class="hljs-comment">#前面的可能有租房噪音</span><br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/pML2-1.png" alt=""></p><p>A house has different types. Here are the top types:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">data[<span class="hljs-string">'Type'</span>].value_counts()[<span class="hljs-number">0</span>:<span class="hljs-number">20</span>] <span class="hljs-comment">#value_counts对应值的个数</span><br></code></pre></td></tr></tbody></table></figure><blockquote><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">SingleFamily</span>            <span class="hljs-number">74318</span><br><span class="hljs-string">Condo</span>                   <span class="hljs-number">18749</span><br><span class="hljs-string">MultiFamily</span>              <span class="hljs-number">6586</span><br><span class="hljs-string">VacantLand</span>               <span class="hljs-number">6199</span><br><span class="hljs-string">Townhouse</span>                <span class="hljs-number">5846</span><br><span class="hljs-string">Unknown</span>                  <span class="hljs-number">5390</span><br><span class="hljs-string">MobileManufactured</span>       <span class="hljs-number">2588</span><br><span class="hljs-string">Apartment</span>                <span class="hljs-number">1416</span><br><span class="hljs-string">Cooperative</span>               <span class="hljs-number">161</span><br><span class="hljs-string">Residential</span> <span class="hljs-string">Lot</span>            <span class="hljs-number">75</span><br><span class="hljs-string">Single</span> <span class="hljs-string">Family</span>              <span class="hljs-number">69</span><br><span class="hljs-string">Single</span> <span class="hljs-string">Family</span> <span class="hljs-string">Lot</span>          <span class="hljs-number">56</span><br><span class="hljs-string">Acreage</span>                    <span class="hljs-number">48</span><br><span class="hljs-number">2</span> <span class="hljs-string">Story</span>                    <span class="hljs-number">39</span><br><span class="hljs-number">3</span> <span class="hljs-string">Story</span>                    <span class="hljs-number">25</span><br><span class="hljs-string">Hi-Rise</span> <span class="hljs-string">(9+),</span> <span class="hljs-string">Luxury</span>       <span class="hljs-number">21</span><br><span class="hljs-string">RESIDENTIAL</span>                <span class="hljs-number">19</span><br><span class="hljs-string">Condominium</span>                <span class="hljs-number">19</span><br><span class="hljs-string">Duplex</span>                     <span class="hljs-number">19</span><br><span class="hljs-string">Mid-Rise</span> <span class="hljs-string">(4-8)</span>             <span class="hljs-number">17</span><br><span class="hljs-attr">Name:</span> <span class="hljs-string">Type,</span> <span class="hljs-attr">dtype:</span> <span class="hljs-string">int64</span><br><span class="hljs-string">下面的一些均为噪音</span><br></code></pre></td></tr></tbody></table></figure></blockquote><p>Price density for different house types.</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">types = data[<span class="hljs-string">'Type'</span>].isin([<span class="hljs-string">'SingleFamily'</span>, <span class="hljs-string">'Condo'</span>, <span class="hljs-string">'MultiFamily'</span>, <span class="hljs-string">'Townhouse'</span>])<br>sns.displot(pd.DataFrame({<span class="hljs-string">'Sold Price'</span>:np.log10(data[types][<span class="hljs-string">'Sold Price'</span>]),<br>                          <span class="hljs-string">'Type'</span>:data[types][<span class="hljs-string">'Type'</span>]}),<br>            x=<span class="hljs-string">'Sold Price'</span>, hue=<span class="hljs-string">'Type'</span>, kind=<span class="hljs-string">'kde'</span>); <span class="hljs-comment">#kde是密度分布，hue指定线颜色按照Type分类</span><br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/pML2-2.png" alt=""></p><p>Another important measurement is the sale price per living sqft. Let’s check the differences between different house types.</p><p><code>boxplot</code>中间横线表示均值，箱型图上四分和下四分，还有max和min值；适合用于表示分布的对比</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">data[<span class="hljs-string">'Price per living sqft'</span>] = data[<span class="hljs-string">'Sold Price'</span>] / data[<span class="hljs-string">'Total interior livable area'</span>] <span class="hljs-comment">#每平米价格</span><br>ax = sns.boxplot(x=<span class="hljs-string">'Type'</span>, y=<span class="hljs-string">'Price per living sqft'</span>, data=data[types], fliersize=<span class="hljs-number">0</span>)<br>ax.set_ylim([<span class="hljs-number">0</span>, <span class="hljs-number">2000</span>]);<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/pML2-3.png" alt=""></p><p>We know the location affect the price. Let’s check the price for the top 20 zip codes.</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">d = data[data[<span class="hljs-string">'Zip'</span>].isin(data[<span class="hljs-string">'Zip'</span>].value_counts()[:<span class="hljs-number">20</span>].keys())]<br>ax = sns.boxplot(x=<span class="hljs-string">'Zip'</span>, y=<span class="hljs-string">'Price per living sqft'</span>, data=d, fliersize=<span class="hljs-number">0</span>)<br>ax.set_ylim([<span class="hljs-number">0</span>, <span class="hljs-number">2000</span>])<br>ax.set_xticklabels(ax.get_xticklabels(), rotation=<span class="hljs-number">90</span>);<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/pML2-4.png" alt=""></p><h3 id="查看协方差">查看协方差</h3><p>Last, we visualize the correlation matrix of several columns.</p><p><code>挑选某些列分布计算计算协方差使用corr()</code>可以查看关联度</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">_, ax = plt.subplots(figsize=(<span class="hljs-number">4</span>,<span class="hljs-number">4</span>))<br>columns = [<span class="hljs-string">'Sold Price'</span>, <span class="hljs-string">'Listed Price'</span>, <span class="hljs-string">'Annual tax amount'</span>, <span class="hljs-string">'Price per living sqft'</span>]<br>sns.heatmap(data[columns].corr(),annot=<span class="hljs-literal">True</span>,cmap=<span class="hljs-string">'RdYlGn'</span>, ax=ax);<br><span class="hljs-comment">#使用热力图绘制</span><br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/pML2-5.png" alt=""></p><h2 id="Summary">Summary</h2><p>This notebook demonstrates the basic technologies for EDA, including</p><ul><li>Understanding column data types, values, and distributions</li><li>Understanding the interactions between columns</li></ul><p>We only explored a small aspect of the data. You are welcome to dive deep into more details.</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>李沐</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>praticalML第一章笔记</title>
    <link href="/2021/12/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PracticeML1/"/>
    <url>/2021/12/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PracticeML1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>斯坦福2021秋季的实用机器学习上线啦~ 😉 跟着沐神复习机器学习冲冲冲！ 记录一下笔记和重点，不一定很全哦~，只是记录自我感觉的重点。</p></blockquote><h1>第一章</h1><h2 id="1-1-课程介绍">1.1 课程介绍</h2><p>介绍机器学习balabala 工业界的机器学习哦</p><h3 id="Role">Role</h3><p>SDE , 领域专家 -&gt; 数据科学家 机器学习专家</p><h3 id="Skill">Skill</h3><p>数据科学家需要的技能：</p><ul><li><strong>数据</strong>： 收集处理数据，独立同分布</li><li><strong>训练</strong>： 模型融合，微调，迁移学习，多模态</li><li><strong>部署</strong>： 蒸馏，模型性能优化</li><li><strong>监控</strong> ：模型公平性，可解释性</li></ul><h2 id="1-2-数据获取">1.2 数据获取</h2><p>第一步是找数据，一般情况数据不够，问两个问题：</p><ul><li><p>是否能到不同的数据源来融合</p></li><li><p>是否可以数据生成</p></li></ul><h3 id="Discover-what-data-is-available">Discover what data is available</h3><ol><li>判断公用数据集</li><li>非常大的数据集</li><li>采集新的数据</li></ol><h3 id="Source">Source</h3><ul><li>mnist</li><li>imageNet</li><li>AudioSet：youtube sound</li><li>Kinetics：youtube video</li><li>KIITI：traffic senarios 自动驾驶</li><li>Amazon Rewiew：用户评论</li><li>SQuAD：维基百科的问答</li><li>LibriSpeech：有声读物 文字&lt;-&gt;语音</li><li>更多数据获取：<a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research">https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research</a></li></ul><h3 id="Where-to-Find-Datasets">Where to Find Datasets</h3><p>• <a href="https://paperswithcode.com/datasets">Paperswithcodes Datasets</a>: academic datasets with leaderboard<br>• <a href="https://www.kaggle.com/datasets">Kaggle Datasets</a>: ML datasets uploaded by data scientists<br>• <a href="https://datasetsearch.research.google.com/">Google Dataset search</a>: search datasets in the Web<br>• Various toolkits datasets: <a href="https://www.tensorflow.org/datasets">tensorflow</a>, <a href="https://huggingface.co/docs/datasets/">huggingface</a>(专注于文本transformer的数据集)<br>• Various conference/company ML competitions<br>• <a href="https://registry.opendata.aws/">Open Data on AWS</a>: 100+ large-scale raw data<br>• Data lakes in your own organization</p><h3 id="数据集比较">数据集比较</h3><table><thead><tr><th style="text-align:center">数据集类别</th><th style="text-align:center">优点</th><th style="text-align:center">缺点</th></tr></thead><tbody><tr><td style="text-align:center">学术</td><td style="text-align:center">干净，难度适中</td><td style="text-align:center">选择面小，小数据集</td></tr><tr><td style="text-align:center">竞赛</td><td style="text-align:center">接近应用</td><td style="text-align:center">偏向于简单，专注于热门业务</td></tr><tr><td style="text-align:center">原始</td><td style="text-align:center">应用灵活</td><td style="text-align:center">需要很多精力预处理</td></tr></tbody></table><h3 id="数据融合">数据融合</h3><ul><li>Combine data from multiple sources into a coherent dataset</li><li>Product data is often stored in multiple tables<br>• E.g. a table for house information, a table for sales, a table for listing agents</li><li>Join tables by keys, which are often entity IDs</li><li>Key issues: identify IDs, missing rows, redundant columns, value conflicts</li></ul><h3 id="数据生成">数据生成</h3><ul><li>Use GANs</li><li>数据增强<ul><li>image augmentation</li><li>Back Translation（中文-英文-中文）</li></ul></li></ul><h2 id="1-3-网页数据抓取">1.3 网页数据抓取</h2><h3 id="Web-Scraping">Web Scraping</h3><p>•The goal is to extract data from website<br>• Noisy, weak labels, can be spammy<br>• Available at scale<br>• E.g. price comparison/tracking website<br>• Many ML datasets are obtained by web scraping<br>• E.g. ImageNet, Kinetics<br>• Web crawling VS scrapping<br>• Crawling: indexing whole pages on Internet  爬取所有信息<br>• Scraping: scraping particular data from web pages of a website 网页数据提取 ；特定的网站 ；特定数据</p><h3 id="Web-Scraping-tools">Web Scraping tools</h3><ul><li><p>“curl” often doesn’t work<br>• Website owners use various ways to stop bots</p></li><li><p>Use headless browser: a web browser without a GUI</p><p>python中可以使用selenium中的webdriver来模拟搜索，取消图形化界面使用命令行:happy:</p>  <figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> selenium <span class="hljs-keyword">import</span> webdriver<br>chrome_options = webdriver.Chromeoptions()<br>chrome_options.headless = <span class="hljs-literal">True</span><br>chrome = webdriver.Chrome(chrome_options = chrome_options) <br><br>page = chrome.get(url)<br></code></pre></td></tr></tbody></table></figure></li><li><p>You need a lot of new IPs, easy to get through public clouds<br>• In all IPv4 IPs, AWS owns 1.75%, Azure 0.55%, GCP 0.25%</p></li></ul><p>最后一点，要注意版权问题哦~</p><h2 id="1-4-数据标注">1.4 数据标注</h2><h3 id="情况描述">情况描述</h3><p><img src="https://picture.mulindya.com/pML1.4-1.png" alt=""></p><h3 id="三种方案">三种方案</h3><h3 id="1-半监督学习-Semi-supervised-learning-SSL">1. 半监督学习(Semi-supervised learning SSL)</h3><p>小部分数据标注了，还有大部分没有标注</p><ul><li>Focus on the scenario where there is a small amount of labeled data, along with large amount of unlabeled data</li><li>Make assumptions on data distribution to use unlabeled data 两者分布假设<br>• <strong>Continuity assumption</strong>（连续性假设）: examples with similar <strong>features</strong> are more likely to have the same <strong>label</strong><br>• <strong>Cluster assumption</strong>（聚类假设）: data have <strong>inherent cluster structure</strong>, examples in the same cluster tend to have the same label<br>• <strong>Manifold assumption</strong>（流型假设）: data lie on a manifold of <strong>much lower dimension</strong> than the input space 降维</li></ul><h4 id="典型算法">典型算法</h4><h5 id="自学习（self-training）">自学习（self-training）</h5><p><img src="https://picture.mulindya.com/pML1.4-2.png" alt=""></p><p>用现有标号的样本训练模型来预测未标号的样本，将所得标号进行筛选，选择置信度高的样本合并继续训练，直到筛掉的剩余样本获得较高的置信度或者某个阈值范围。这个模型可以不计成本同时模型融合。</p><h3 id="2-label-through-crowdsourcing-众包">2. label through crowdsourcing 众包</h3><p>简单来说就是花钱找人标注。😕</p><h4 id="典型算法-2">典型算法</h4><h5 id="主动学习-active-learning">主动学习 active learning</h5><ul><li><p>Focus on same scenario as SSL but with human in the loop<br>• Self training: Model helps propagate labels to unlabeled data<br>• Active learning: Model select the most “interesting” data for labelers</p></li><li><p><strong>Uncertainty sampling</strong><br>• Select examples whose predictions are most uncertain<br>• The highest class prediction score is close to random ( 1/n)</p></li></ul><p>模型选择置信度偏向于随机的样本让人来判断。然后放进模型区训练再预测再判断‘难’的数据。</p><ul><li><strong>Query-by-committee</strong><br>• Trains multiple models and select samples that models disagree with 1/n</li></ul><p>多个模型投票来确定哪些数据比较‘难’</p><h3 id="3-Active-Learning-Self-training">3 Active Learning + Self-training</h3><p>混合使用</p><p><img src="https://picture.mulindya.com/pML1.4-3.png" alt=""></p><h3 id="质量控制">质量控制</h3><p>可能出现误标或者出现标注并不精确的情况</p><h4 id="Weak-Supervision-弱监督学习">Weak Supervision 弱监督学习</h4><ul><li><p>Semi-automatically generate labels<br>• Less accurate than manual ones, but good enough for training</p></li><li><p><strong>Data programming</strong>:</p></li></ul><p>总结规律规则编程<br>• Domain specific heuristics to assign labels<br>• Keyword search, pattern matching, third-party models<br>• E.g. rules to check if YouTube comments are spam or ham</p><blockquote><p>什么是弱监督学习呢？弱监督学习可以分为三种典型的类型，不完全监督（Incomplete supervision），不确切监督（Inexact supervision），不精确监督（Inaccurate supervision）。</p><ul><li><p>不完全监督是指，训练数据中只有一部分数据被给了标签，有一些数据是没有标签的。</p></li><li><p>不确切监督是指，训练数据只给出了粗粒度标签。我们可以把输入想象成一个包，这个包里面有一些示例，我们只知道这个包的标签，Y或N，但是我们不知道每个示例的标签。</p></li><li><p>不精确监督是指，给出的标签不总是正确的，比如本来应该是Y的标签被错误标记成了N。</p></li></ul><h5 id="解决方案">解决方案</h5><ul><li>为了解决不完全监督，我们可以考虑两种主要技术，主动学习和半监督学习。一种是有人类干预的，一种是没有人类干预的。</li><li>为了解决不确切监督，我们可以考虑多示例学习。</li><li>为了解决不精确监督，我们考虑带噪学习。</li></ul></blockquote>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>李沐</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer57-2 和为s的连续正数序列</title>
    <link href="/2021/12/30/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer57-2/"/>
    <url>/2021/12/30/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer57-2/</url>
    
    <content type="html"><![CDATA[<blockquote><p>和为s的连续正数序列</p></blockquote><h2 id="题目">题目</h2><p>输入一个正整数 target ，输出所有和为 target 的连续正整数序列（至少含有两个数）。</p><p>序列内的数字由小到大排列，不同序列按照首个数字从小到大排列。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight lua"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs lua">输入：target = <span class="hljs-number">9</span><br>输出：<span class="hljs-string">[[2,3,4],[4,5]]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight lua"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs lua">输入：target = <span class="hljs-number">15</span><br>输出：<span class="hljs-string">[[1,2,3,4,5],[4,5,6],[7,8]]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= target &lt;= 10^5</li></ul><h2 id="题解">题解</h2><h3 id="遍历解法">遍历解法</h3><p>从1到<code>target//2</code>为首遍历是否存在连续的序列为target。使用两层循环，外层循环确定首元素，内层循环确定尾元素，如果遍历到的和大于target就终止；</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">findContinuousSequence</span>(<span class="hljs-params">self, target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]:</span><br>        limit = <span class="hljs-built_in">int</span>(target/<span class="hljs-number">2</span>)<br>        result = []<br>        <span class="hljs-keyword">for</span> head <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,limit+<span class="hljs-number">1</span>):<br>            temp,t,sumt = [head],head+<span class="hljs-number">1</span>,head<br>            <span class="hljs-keyword">while</span>(<span class="hljs-number">1</span>):<br>                sumt += t<br>                temp.append(t)  <br>                <span class="hljs-keyword">if</span> sumt==target:<br>                    result.append(temp)<br>                    <span class="hljs-keyword">break</span><br>                <span class="hljs-keyword">if</span> sumt&gt;target: <span class="hljs-keyword">break</span><br>                <span class="hljs-keyword">if</span> sumt&lt;target: t += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> result<br><br></code></pre></td></tr></tbody></table></figure><h3 id="滑动窗口">滑动窗口</h3><p>使用滑动窗口来确定序列首尾位置；<br>在这里i，j分别表示首尾元素；</p><ul><li>序列元素和sumt小于target，就右移j；</li><li>序列元素和大于target，就右移i；</li></ul><p>这里不存在左移的情况，不左移i好理解，因为i是从头开始查找的嘛，左移不是重复了嘛，何况还要保证首元素的顺序；那么不左移j的原因是什么呢。也是同样的道理，这个窗口只是负责尾节点右移扩大和首节点右移缩小，是可以遍历所有的情况哒。比如<code>1,2,3,4,5...</code>,target为5，开始就会到<code>1,2,3</code>,然后再到<code>2,3</code>;即尾节点只负责增大序列和，首节点只负责缩小序列和。😉</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">findContinuousSequence</span>(<span class="hljs-params">self, target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]:</span><br>        <span class="hljs-comment">#滑动窗口</span><br>        i,j,sumt,result = <span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,[]<br>        <span class="hljs-keyword">while</span>(i&lt;=target//<span class="hljs-number">2</span>):<br>            <span class="hljs-keyword">if</span>(sumt&lt;target):<br>                j += <span class="hljs-number">1</span><br>                sumt += j<br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-keyword">if</span>(sumt==target):result.append(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(i,j+<span class="hljs-number">1</span>))) <span class="hljs-comment">#需要list转换</span><br>            sumt -= i<br>            i += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>滑动窗口</category>
      
    </categories>
    
    
    <tags>
      
      <tag>滑动窗口</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>足迹检测项目的总结</title>
    <link href="/2021/12/29/project_summary/footprint-summary/"/>
    <url>/2021/12/29/project_summary/footprint-summary/</url>
    
    <content type="html"><![CDATA[<blockquote><p>总结足迹检测项目</p></blockquote><h2 id="简介">简介</h2><p>根据刻度尺上的特征对产生畸变的脚印矫正。实现原图打印和标注；</p><h2 id="技术点">技术点</h2><p>根据刻度尺上的特征对产生畸变的脚印矫正。<br>使用霍夫变换拟合4个圆定位来仿射变换矫正图像</p><ul><li>霍夫变换-&gt;yolov5</li><li>仿射变换</li><li>pyqt5</li></ul><h2 id="难点">难点</h2><p>使用霍夫变换容易定位到背景的圆，并且可能出现圆不全的情况</p><h2 id="解决方案">解决方案</h2><p>使用深度学习的方法目标检测<br>使用多个特征融合选择进行仿射变换</p><h2 id="成果">成果</h2><p>达到不超过15度时，误差在2mm以内</p><h2 id="创新点">创新点</h2><p>使用多个特征融合矫正</p><h2 id="展望和改进">展望和改进</h2><p>尺子矫正后不均衡</p>]]></content>
    
    
    <categories>
      
      <category>项目</category>
      
    </categories>
    
    
    <tags>
      
      <tag>项目</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python-embeded打包文件生成exe</title>
    <link href="/2021/12/29/project_tool/usePyembeded/"/>
    <url>/2021/12/29/project_tool/usePyembeded/</url>
    
    <content type="html"><![CDATA[<blockquote><p>使用pyinstaller打包的文件太大了！！所以！所以！学到了另一招，将所需的环境配置到python-embeded中，然后使用c来调用py的启动文件，再gcc生成exe文件，酱紫工程文件就会小很多；实践证明，pyinstaller打包5.2G，采用这种方式后降低到1.5G哦~ 这种方式主要就是使用python-embeded来配置环境。</p></blockquote><p>参考https://zhuanlan.zhihu.com/p/77028265</p><h2 id="下载embeded版本">下载embeded版本</h2><ul><li>python37的<a href="https://link.zhihu.com/?target=https%3A//www.python.org/downloads/release/python-373/">embedded版本</a></li><li>下载zip文件解压到某处，比如<code>E:\python_embeded\</code></li></ul><p><img src="https://picture.mulindya.com/python-embeded1.png" alt=""></p><h2 id="安装pip">安装pip</h2><ul><li><p>去<a href="https://link.zhihu.com/?target=https%3A//pip.pypa.io/en/stable/installing/%23id7">官网</a><a href="http://xn--get-pip-nw3k7779b.py">下载get-pip.py</a></p></li><li><p>点击installation,下载<a href="https://bootstrap.pypa.io/get-pip.py.">get-pip.py</a>文件到<code>E:\python_embeded\</code></p></li><li><p>运行该文件。注意使用emdeded版本的python来运行配置要<strong>带路径</strong>哦！</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apl">#打开cmd,cd到相应的目录下（E:\python_embeded\），运行下载的文件<br>E:\python_embeded\python.exe  get-pip.py<br></code></pre></td></tr></tbody></table></figure></li></ul><h2 id="修改文件">修改文件</h2><p>找到自己python-embedded文件夹下的<strong>python37.pth</strong>（如果你下载的是27版本那当然就是python27._pth啦）</p><p>把# import site前面的注释符号“#”删除——保存</p><figure class="highlight haskell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-title">python37</span>.zip<br>.<br><br><span class="hljs-meta"># Uncomment to run site.main() automatically</span><br><span class="hljs-keyword">import</span> site<br></code></pre></td></tr></tbody></table></figure><p>这里如果不修改，直接install，就会报错<code>ModuleNotFoundError: No module named 'pip'</code></p><h2 id="配置相关环境">配置相关环境</h2><p>常规配置pytorch时，使用以下代码</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#cpu 版本</span><br>pip install torch==<span class="hljs-number">1.8</span><span class="hljs-number">.1</span> torchvision==<span class="hljs-number">0.9</span><span class="hljs-number">.1</span> torchaudio==<span class="hljs-number">0.8</span><span class="hljs-number">.1</span><br><br><span class="hljs-comment"># CUDA 10.2</span><br>conda install pytorch==<span class="hljs-number">1.8</span><span class="hljs-number">.1</span> torchvision==<span class="hljs-number">0.9</span><span class="hljs-number">.1</span> torchaudio==<span class="hljs-number">0.8</span><span class="hljs-number">.1</span> cudatoolkit=<span class="hljs-number">10.2</span> -c pytorch<br><br><span class="hljs-comment"># CUDA 10.2</span><br>pip install torch==<span class="hljs-number">1.8</span><span class="hljs-number">.1</span>+cu102 torchvision==<span class="hljs-number">0.9</span><span class="hljs-number">.1</span>+cu102 torchaudio==<span class="hljs-number">0.8</span><span class="hljs-number">.1</span> -f https://download.pytorch.org/whl/torch_stable.html<br></code></pre></td></tr></tbody></table></figure><p>在python-embeded中，要带上路径哦！</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#打开cmd,cd到相应的目录下（E:\python_embeded\），运行下载的文件</span><br>这里使用cpu的torch版本，够用了并且文件更小。<br>E:\python_embeded\Scripts\pip.exe  install 相关配置(torch==<span class="hljs-number">1.8</span><span class="hljs-number">.1</span> torchvision==<span class="hljs-number">0.9</span><span class="hljs-number">.1</span> torchaudio==<span class="hljs-number">0.8</span><span class="hljs-number">.1</span> )<br>    <br>E:\python_embeded\Scripts\pip.exe  install -r requirements.txt <span class="hljs-comment">#一样的操作</span><br></code></pre></td></tr></tbody></table></figure><h3 id="配置tkinter">配置tkinter</h3><p>如果项目使用tkinter的话，就单独配置。由于python embedable是不带tkinter的，而且无法通过pip来安装，解决方法：下载一个与python embedable版本相同的python安装包，安装时不要加入环境变量（如果你电脑上已经有anaconda的话），然后将安装路径下的一些文件复制到python embedable的路径下</p><blockquote><p>/tcl 拷贝到 /</p><p>/Lib/tkinter 拷贝到 /Lib/site-packages/</p><p>/DLLs/_tkinter.pyd 拷贝到 /</p><p>/DLLs/tcl86t.dll 拷贝到 /</p><p>/DLLs/tk86t.dll 拷贝到 /</p></blockquote><h3 id="打包">打包</h3><p>然后！把这个配置好的embeded文件直接放进项目文件夹中。把启动程序的py文件头中加入以下代码，它的作用是写入环境变量中，这样如果有自定义的包调用才可以找得到哟。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br>cwd=os.getcwd()<br><span class="hljs-keyword">import</span> sys<br>sys.path.append(cwd)<br></code></pre></td></tr></tbody></table></figure><h4 id="新建-bat文件">新建.bat文件</h4><p>上面是取消黑框命令行，下面是调用启动程序！双击即可运行！</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apl">@echo off <br>if "%1" == "h" goto begin <br>mshta vbscript:createobject("wscript.shell").run("%~nx0 h",0)(window.close)&amp;&amp;exit <br>:begin <br><br>"%CD%\python_embeded\python.exe" footprint.py <br></code></pre></td></tr></tbody></table></figure><p>**注意：**路径带引号可以识别空格和括号</p><h4 id="新建-c文件">新建.c文件</h4><p>使用system来用c调用bat文件，后续把c编译为exe文件大功告成啦！</p><figure class="highlight c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span><span class="hljs-meta-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span><span class="hljs-meta-string">&lt;stdlib.h&gt;</span></span><br><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>{<br>    system(<span class="hljs-string">"footprint.bat"</span>);<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>}<br></code></pre></td></tr></tbody></table></figure><h4 id="新建-rc文件（可选）">新建.rc文件（可选）</h4><p>这个文件指定exe的icon和exe文件的详细信息</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs apl">2 ICON "icon.ico"<br>1 VERSIONINFO<br>FILEVERSION     2,3,3,3<br>PRODUCTVERSION  2,3,3,3<br>FILEOS 0x4L<br>BEGIN<br>BLOCK "StringFileInfo"<br>BEGIN<br>BLOCK "080404E4"<br>BEGIN<br>VALUE "CompanyName", "hust"<br>VALUE "FileDescription", "Project General Launcher"<br>VALUE "FileVersion", "1.0"<br>VALUE "InternalName", "Launcher on Windows"<br>VALUE "LegalCopyright", "GPLv2"<br>VALUE "OriginalFilename", "足迹矫正"<br>VALUE "ProductName", "足迹矫正与标注"<br>VALUE "ProductVersion", "2.3.3 build 42"<br>VALUE "Comments", "足迹矫正"<br>END<br>END<br><br>BLOCK "VarFileInfo"<br>BEGIN<br>VALUE "Translation", 0x0804, 1252<br>END<br>END<br></code></pre></td></tr></tbody></table></figure><h3 id="编译成exe">编译成exe</h3><p>上面命令会生成demo.o目标文件，链接的时候加上这个目标文件编译出来的exe文件就有图标了呀！okk！结束啦~真是艰辛…</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apl">windres -i "footprint.rc" -o "footprint.o"<br>gcc footprint.c footprint.o -o footprint.exe<br></code></pre></td></tr></tbody></table></figure><h4 id="安装gcc">安装gcc</h4><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apl">gcc -v<br></code></pre></td></tr></tbody></table></figure><p>如果没有gcc的话，参考这边博客https://zhuanlan.zhihu.com/p/47935258<br>简单来说就是安装Mingw，然后添加minge32-gcc-g++,点击apply change就可以下载</p>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
      <category>python-embeded</category>
      
    </categories>
    
    
    <tags>
      
      <tag>项目打包</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer45 把数组排成最小的数</title>
    <link href="/2021/12/28/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer45/"/>
    <url>/2021/12/28/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer45/</url>
    
    <content type="html"><![CDATA[<blockquote><p>把数组排成最小的数</p></blockquote><h2 id="题目">题目</h2><p>输入一个非负整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入: [10,2]</span><br><span class="hljs-section">输出: "102"</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight dns"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs dns">输入: [<span class="hljs-number">3,30,34,5</span>,<span class="hljs-number">9</span>]<br>输出: "<span class="hljs-number">3033459</span>"<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>0 &lt; nums.length &lt;= 100</li><li>输出结果可能非常大，所以你需要返回一个字符串而不是整数</li><li>拼接起来的数字可能会有前导 0，最后结果不需要去掉前导 0</li></ul><h2 id="题解">题解</h2><p>方法主要是用到自定义排序；<br>在<code>python3</code>中的自定义排序要重载<code>functools.cmp_to_key</code>函数，但是这里的规则是<strong>默认小的在前面</strong>；所以在比较的时候重载<code>mycmp</code>方法，a,b顺序满足条件时返回-1(num&lt;0)</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">cmp_to_key</span>(<span class="hljs-params">mycmp</span>):</span><br>    <span class="hljs-string">"""Convert a cmp= function into a key= function"""</span><br>    <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">K</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br>        __slots__ = [<span class="hljs-string">'obj'</span>]<br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, obj</span>):</span><br>            self.obj = obj<br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__lt__</span>(<span class="hljs-params">self, other</span>):</span><br>            <span class="hljs-keyword">return</span> mycmp(self.obj, other.obj) &lt; <span class="hljs-number">0</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__gt__</span>(<span class="hljs-params">self, other</span>):</span><br>            <span class="hljs-keyword">return</span> mycmp(self.obj, other.obj) &gt; <span class="hljs-number">0</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__eq__</span>(<span class="hljs-params">self, other</span>):</span><br>            <span class="hljs-keyword">return</span> mycmp(self.obj, other.obj) == <span class="hljs-number">0</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__le__</span>(<span class="hljs-params">self, other</span>):</span><br>            <span class="hljs-keyword">return</span> mycmp(self.obj, other.obj) &lt;= <span class="hljs-number">0</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__ge__</span>(<span class="hljs-params">self, other</span>):</span><br>            <span class="hljs-keyword">return</span> mycmp(self.obj, other.obj) &gt;= <span class="hljs-number">0</span><br>        __hash__ = <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">return</span> K<br></code></pre></td></tr></tbody></table></figure><p>另外，直接将ab拼接进行比较大小，这里直接使用字符串比较大小更快哦~</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">minNumber</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">str</span>:</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">funccmp</span>(<span class="hljs-params">a,b</span>):</span><br>            x,y = a+b,b+a<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">int</span>(x)&lt;<span class="hljs-built_in">int</span>(y): <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>: <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sort_rule</span>(<span class="hljs-params">x, y</span>):</span><br>            a, b = x + y, y + x <span class="hljs-comment">#可以直接对字符串比较，更快</span><br>            <span class="hljs-keyword">if</span> a &gt; b: <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>            <span class="hljs-keyword">elif</span> a &lt; b: <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>: <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><br>        s = [<span class="hljs-built_in">str</span>(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> nums]<br>        t = <span class="hljs-built_in">sorted</span>(s,key = functools.cmp_to_key(sort_rule))    <br>        <span class="hljs-comment">#重载比较函数，在python的重载cmp_to_key时默认是小的元素排在前面，所以在满足条件时返回-1，其他情况大于-1即可</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">''</span>.join(t)<br></code></pre></td></tr></tbody></table></figure><p>还有两个函数需要掌握</p><ul><li><code>''.join(t)</code>可以使用指定的字符串连接数组</li><li>对列表循环操作创建可以使用<code>[func(x) for x in nums]</code></li><li>也可以使用map函数 <code>list(map(func,nums))</code>或者lambda函数<code>list(map(lambda x:...,nums))</code></li></ul>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>排序</category>
      
    </categories>
    
    
    <tags>
      
      <tag>排序</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指leetcode14 最长公共前缀</title>
    <link href="/2021/12/26/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode14/"/>
    <url>/2021/12/26/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode14/</url>
    
    <content type="html"><![CDATA[<blockquote><p>最长公共前缀</p></blockquote><h2 id="题目">题目</h2><p>编写一个函数来查找字符串数组中的最长公共前缀。</p><p>如果不存在公共前缀，返回空字符串 <code>""</code>。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight armasm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs armasm">输入：<span class="hljs-keyword">strs</span> = [<span class="hljs-string">"flower"</span>,<span class="hljs-string">"flow"</span>,<span class="hljs-string">"flight"</span>]<br>输出：<span class="hljs-string">"fl"</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight armasm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs armasm">输入：<span class="hljs-keyword">strs</span> = [<span class="hljs-string">"dog"</span>,<span class="hljs-string">"racecar"</span>,<span class="hljs-string">"car"</span>]<br>输出：<span class="hljs-string">""</span><br>解释：输入不存在公共前缀。<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><code>1 &lt;= strs.length &lt;= 200</code></li><li><code>0 &lt;= strs[i].length &lt;= 200</code></li><li><code>strs[i]</code> 仅由小写英文字母组成</li></ul><h2 id="题解">题解</h2><p>对每一列进行核对是否是相同，如果不是相同的直接return前面的字符串。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">longestCommonPrefix</span>(<span class="hljs-params">self, strs: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]</span>) -&gt; <span class="hljs-built_in">str</span>:</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(strs) == <span class="hljs-number">0</span>:<br>           <span class="hljs-keyword">return</span> <span class="hljs-string">""</span><br><br>        rows, cols = <span class="hljs-built_in">len</span>(strs), <span class="hljs-built_in">len</span>(strs[<span class="hljs-number">0</span>])<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cols):<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(rows):<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(strs[j]) == i <span class="hljs-keyword">or</span> strs[j][i] != strs[<span class="hljs-number">0</span>][i]:<br>                    <span class="hljs-keyword">return</span> strs[<span class="hljs-number">0</span>][:i]<br><br>        <span class="hljs-keyword">return</span> strs[<span class="hljs-number">0</span>]<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>方法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>方法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer 力扣-21</title>
    <link href="/2021/12/23/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-21/"/>
    <url>/2021/12/23/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-21/</url>
    
    <content type="html"><![CDATA[<blockquote><p>合并两个有序链表</p></blockquote><h2 id="题目">题目</h2><p>将两个升序链表合并为一个新的 升序 链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：l1 = <span class="hljs-comment">[1,2,4]</span>, l2 = <span class="hljs-comment">[1,3,4]</span><br>输出：<span class="hljs-comment">[1,1,2,3,4,4]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：l1 = <span class="hljs-comment">[]</span>, l2 = <span class="hljs-comment">[]</span><br>输出：<span class="hljs-comment">[]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：-2">示例 2：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：l1 = <span class="hljs-comment">[]</span>, l2 = <span class="hljs-comment">[0]</span><br>输出：<span class="hljs-comment">[0]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>两个链表的节点数目范围是 [0, 50]</li><li>-100 &lt;= Node.val &lt;= 100</li><li>l1 和 l2 均按 非递减顺序 排列</li></ul><h2 id="题解">题解</h2><p>这里使用的是链表，使用两个变量p1，p2分别指向两个链表，通过比较大小确定p的next的指向。最后将剩余的元素添加至p后。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode:</span><br><span class="hljs-comment">#     def __init__(self, val=0, next=None):</span><br><span class="hljs-comment">#         self.val = val</span><br><span class="hljs-comment">#         self.next = next</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mergeTwoLists</span>(<span class="hljs-params">self, list1: <span class="hljs-type">Optional</span>[ListNode], list2: <span class="hljs-type">Optional</span>[ListNode]</span>) -&gt; <span class="hljs-type">Optional</span>[ListNode]:</span><br>        p1,p2 = list1,list2<br>        l = ListNode()<br>        p = l<br>        <span class="hljs-keyword">while</span>(p1 <span class="hljs-keyword">and</span> p2):<br>            <span class="hljs-keyword">if</span> p1.val&lt;p2.val:<br>                p.<span class="hljs-built_in">next</span> = p1<br>                p1 = p1.<span class="hljs-built_in">next</span><br>            <span class="hljs-keyword">else</span>:<br>                p.<span class="hljs-built_in">next</span> = p2<br>                p2 = p2.<span class="hljs-built_in">next</span><br>            p = p.<span class="hljs-built_in">next</span><br>        p.<span class="hljs-built_in">next</span> = p1 <span class="hljs-keyword">if</span> p1 <span class="hljs-keyword">else</span> p2<br>        <span class="hljs-keyword">return</span> l.<span class="hljs-built_in">next</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>排序</category>
      
    </categories>
    
    
    <tags>
      
      <tag>排序</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pyqt截取窗口</title>
    <link href="/2021/12/16/python/pyqt/pyqt-grabwindow/"/>
    <url>/2021/12/16/python/pyqt/pyqt-grabwindow/</url>
    
    <content type="html"><![CDATA[<blockquote><p>在painter画笔进行绘制之后，需要保存画布图像。一种方法是使用Qpainter p(pixmap)，在指定的map上绘制后保存，可是此方法我保存图片时还是只有原始图片。绘制的图形无法保存；另一种方法时截取窗口保存图片。</p></blockquote><h2 id="介绍QScreen的方法">介绍QScreen的方法</h2><p>代码如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">pqscreen  = QGuiApplication.primaryScreen()<br>pixmap2 = pqscreen.grabWindow(self.winId(), self.x0, self.y0, <span class="hljs-built_in">abs</span>(self.x1-self.x0), <span class="hljs-built_in">abs</span>(self.y1-self.y0)) <span class="hljs-comment">#本控件的id</span><br>pixmap2.save(<span class="hljs-string">'555.png'</span>)<br></code></pre></td></tr></tbody></table></figure><p>截屏的原理主要还是运用QScreen类中的grabWindow方法。</p><h2 id="grabWindow">grabWindow</h2><p><code>QScreen.grabWindow(WId window, int x = 0, int y = 0, int width = -1, int height = -1)</code><br>大致意思是创建并返回通过抓取由QRect（x，y，width，height）限制的给定窗口构造的像素图。</p><h3 id="参数">参数</h3><p>参数（x，y）指定窗口中的偏移量，而（宽度，高度）指定要复制的区域。如果宽度为负数，则该函数将所有内容复制到窗口的右边界。如果高度为负数，则该函数将所有内容复制到窗口的底部。</p><h3 id="Wid">Wid</h3><p>窗口系统标识符（WId）可以使用QWidget.winId（）函数进行检索。grabWindow（）函数从屏幕抓取像素，而不是从窗口抓取像素，即，如果有另一个窗口部分或全部覆盖抓取的像素，则也会从上面的窗口获取像素。鼠标光标一般不会被抓取。</p><p>如果是屏幕截图：id为<code>QtWidgets.QApplication.desktop().winId()</code></p><h2 id="源代码实现">源代码实现</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#!/usr/bin/env python</span><br><span class="hljs-keyword">from</span> PyQt5 <span class="hljs-keyword">import</span> QtCore, QtWidgets,QtGui<br><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Screenshot</span>(<span class="hljs-params">QtWidgets.QWidget</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>(Screenshot, self).__init__()<br>        self.screenshotLabel = QtWidgets.QLabel()<br>        self.screenshotLabel.setSizePolicy(QtWidgets.QSizePolicy.Expanding,<br>                QtWidgets.QSizePolicy.Expanding)<br>        self.screenshotLabel.setAlignment(QtCore.Qt.AlignCenter)<br>        self.screenshotLabel.setMinimumSize(<span class="hljs-number">240</span>, <span class="hljs-number">160</span>)<br>        self.createOptionsGroupBox()<br>        self.createButtonsLayout()<br>        mainLayout = QtWidgets.QVBoxLayout()<br>        mainLayout.addWidget(self.screenshotLabel)<br>        mainLayout.addWidget(self.optionsGroupBox)<br>        mainLayout.addLayout(self.buttonsLayout)<br>        self.setLayout(mainLayout)<br>        self.shootScreen()<br>        self.delaySpinBox.setValue(<span class="hljs-number">0</span>)<span class="hljs-comment">#延迟多少秒后截屏</span><br>        self.setWindowTitle(<span class="hljs-string">"Screenshot"</span>)<br>        self.resize(<span class="hljs-number">300</span>, <span class="hljs-number">200</span>)<br>        <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">resizeEvent</span>(<span class="hljs-params">self, event</span>):</span><br>        scaledSize = self.originalPixmap.size()<br>        scaledSize.scale(self.screenshotLabel.size(), QtCore.Qt.KeepAspectRatio)<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.screenshotLabel.pixmap() <span class="hljs-keyword">or</span> scaledSize != self.screenshotLabel.pixmap().size():<br>            self.updateScreenshotLabel()<br>            <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">newScreenshot</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">if</span> self.hideThisWindowCheckBox.isChecked():<br>            self.hide()<br>        self.newScreenshotButton.setDisabled(<span class="hljs-literal">True</span>)<br>        QtCore.QTimer.singleShot(self.delaySpinBox.value() * <span class="hljs-number">1000</span>,<br>                self.shootScreen)<br>                <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">saveScreenshot</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">format</span> = <span class="hljs-string">'png'</span><br>        initialPath = QtCore.QDir.currentPath() + <span class="hljs-string">"/untitled."</span> + <span class="hljs-built_in">format</span><br>        fileName,filetype = QtWidgets.QFileDialog.getSaveFileName(self, <span class="hljs-string">"Save As"</span>,<br>                initialPath,<br>                <span class="hljs-string">"%s Files (*.%s);;All Files (*)"</span> % (<span class="hljs-built_in">format</span>.upper(), <span class="hljs-built_in">format</span>))<br>        <span class="hljs-keyword">if</span> fileName:<br>            self.originalPixmap.save(fileName, <span class="hljs-built_in">format</span>)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">"file saved as  %s"</span> % fileName)<br>           <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">shootScreen</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">if</span> self.delaySpinBox.value() != <span class="hljs-number">0</span>:<br>            QtWidgets.qApp.beep()<br>        <span class="hljs-comment"># Garbage collect any existing image first.</span><br>        self.originalPixmap = <span class="hljs-literal">None</span><br>        <span class="hljs-comment">#self.originalPixmap = QtGui.QPixmap.grabWindow(QtWidgets.QApplication.desktop().winId())#PyQt4</span><br>       <br>        screen= QtWidgets.QApplication.primaryScreen()<span class="hljs-comment">#PyQt5</span><br>        self.originalPixmap = screen.grabWindow(QtWidgets.QApplication.desktop().winId())<span class="hljs-comment">#PyQt5</span><br>       <br>        self.updateScreenshotLabel()<br>        self.newScreenshotButton.setDisabled(<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">if</span> self.hideThisWindowCheckBox.isChecked():<br>            self.show()<br>            <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">updateCheckBox</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">if</span> self.delaySpinBox.value() == <span class="hljs-number">0</span>:<br>            self.hideThisWindowCheckBox.setDisabled(<span class="hljs-literal">True</span>)<br>        <span class="hljs-keyword">else</span>:<br>            self.hideThisWindowCheckBox.setDisabled(<span class="hljs-literal">False</span>)<br>            <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">createOptionsGroupBox</span>(<span class="hljs-params">self</span>):</span><br>        self.optionsGroupBox = QtWidgets.QGroupBox(<span class="hljs-string">"Options"</span>)<br>        self.delaySpinBox = QtWidgets.QSpinBox()<br>        self.delaySpinBox.setSuffix(<span class="hljs-string">" s"</span>)<br>        self.delaySpinBox.setMaximum(<span class="hljs-number">60</span>)<br>        self.delaySpinBox.valueChanged.connect(self.updateCheckBox)<br>        self.delaySpinBoxLabel = QtWidgets.QLabel(<span class="hljs-string">"Screenshot Delay:"</span>)<br>        self.hideThisWindowCheckBox = QtWidgets.QCheckBox(<span class="hljs-string">"Hide This Window"</span>)<br>        optionsGroupBoxLayout = QtWidgets.QGridLayout()<br>        optionsGroupBoxLayout.addWidget(self.delaySpinBoxLabel, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>)<br>        optionsGroupBoxLayout.addWidget(self.delaySpinBox, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br>        optionsGroupBoxLayout.addWidget(self.hideThisWindowCheckBox, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>        self.optionsGroupBox.setLayout(optionsGroupBoxLayout)<br>        <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">createButtonsLayout</span>(<span class="hljs-params">self</span>):</span><br>        self.newScreenshotButton = self.createButton(<span class="hljs-string">"New Screenshot"</span>,<br>                self.newScreenshot)<br>        self.saveScreenshotButton = self.createButton(<span class="hljs-string">"Save Screenshot"</span>,<br>                self.saveScreenshot)<br>        self.quitScreenshotButton = self.createButton(<span class="hljs-string">"Quit"</span>, self.close)<br>        self.buttonsLayout = QtWidgets.QHBoxLayout()<br>        self.buttonsLayout.addStretch()<br>        self.buttonsLayout.addWidget(self.newScreenshotButton)<br>        self.buttonsLayout.addWidget(self.saveScreenshotButton)<br>        self.buttonsLayout.addWidget(self.quitScreenshotButton)<br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">createButton</span>(<span class="hljs-params">self, text, member</span>):</span><br>        button = QtWidgets.QPushButton(text)<br>        button.clicked.connect(member)<br>        <span class="hljs-keyword">return</span> button<br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">updateScreenshotLabel</span>(<span class="hljs-params">self</span>):</span><br>        self.screenshotLabel.setPixmap(self.originalPixmap.scaled(<br>                self.screenshotLabel.size(), QtCore.Qt.KeepAspectRatio,<br>                QtCore.Qt.SmoothTransformation))<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:<br>    <span class="hljs-keyword">import</span> sys<br>    app = QtWidgets.QApplication(sys.argv)<br>    screenshot = Screenshot()<br>    screenshot.show()<br>    sys.exit(app.exec_())<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
      <category>pyqt</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>pyqt</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>正则表达式中的括号</title>
    <link href="/2021/12/15/python/re/re-bracket/"/>
    <url>/2021/12/15/python/re/re-bracket/</url>
    
    <content type="html"><![CDATA[<blockquote><p>总结正则表达式中的各种括号，主要是小括号，方括号，大括号的区别。</p></blockquote><h2 id="小括号">小括号</h2><p>小括号（）：多个匹配，<strong>将括号中的内容作为一组来处理</strong>，限制多选的范围。譬如<code>*.(png|jpg)</code>可标识末尾为png，jpg结尾的字符串，只能是png或者jpg，将括号中内容作为一组。</p><h2 id="方括号">方括号</h2><p>方括号【】：方括号是<strong>单个匹配</strong>，比如[abc]的含义是匹配abc其中的一个字符，并不是作为一组；<br>常见的用法：[a-zA-Z0-9]可以匹配所有英文字母和数字。</p><h2 id="大括号">大括号</h2><p>大括号{}：大括号的用法是填入数字，<strong>表示匹配次数</strong>，他需要和其他有意义的正则表达式一起使用。<br>比如</p><ul><li>[a-c]{2} : 含义是匹配a到c之间的一个字母出现同时至出现两次；</li><li>(com){1}: 含义是匹配出现一次的com；</li><li>\W{1,3}: 含义是非字母数字的字符最少出现1次，最多出现3次，匹配的字符串出现此类字符的个数也就是1到3次；</li></ul>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
      <category>re</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>re</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>将图像保存至Word中</title>
    <link href="/2021/12/10/python/img/imageTodocx/"/>
    <url>/2021/12/10/python/img/imageTodocx/</url>
    
    <content type="html"><![CDATA[<blockquote><p>利用python，向Word中保存信息，这里主要是记录对图像的保存；</p></blockquote><h2 id="按照python-docx">按照python-docx</h2><p>python-docx is a Python library for creating and updating Microsoft Word (.docx) files.</p><figure class="highlight cmake"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip <span class="hljs-keyword">install</span> python-docx<br></code></pre></td></tr></tbody></table></figure><h2 id="文档相关操作">文档相关操作</h2><h3 id="插入图片">插入图片</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入模块</span><br><span class="hljs-keyword">from</span> docx <span class="hljs-keyword">import</span> Document<br><span class="hljs-comment"># 此模块中包含 docx 中各类单位方法</span><br><span class="hljs-keyword">from</span> docx <span class="hljs-keyword">import</span> shared<br><br>doc = Document()<br>doc.add_heading(<span class="hljs-string">'python-docx 基础讲解（二）'</span>)<br><br><span class="hljs-comment"># 在文档中增加图片,并对设置图片大小</span><br><span class="hljs-comment"># 当只设置一个方向的长度（宽或高）时，另一方向会自动缩放</span><br>doc.add_picture(<span class="hljs-string">'1.png'</span>,width=shared.Inches(<span class="hljs-number">1</span>))  <span class="hljs-comment"># 按英寸设置</span><br>doc.add_picture(<span class="hljs-string">'1.png'</span>,height=shared.Cm(<span class="hljs-number">2</span>))  <span class="hljs-comment"># 按厘米设置</span><br><span class="hljs-comment">#也可以按照毫米设置shared.Mm(2)</span><br><br><span class="hljs-comment"># 保存文件</span><br>doc.save(<span class="hljs-string">'test2.docx'</span>)<br></code></pre></td></tr></tbody></table></figure><h3 id="页面大小设置">页面大小设置</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> docx <span class="hljs-keyword">import</span> Document <span class="hljs-comment"># 导入docx包</span><br><span class="hljs-keyword">from</span> docx.shared <span class="hljs-keyword">import</span> Cm, Inches, Pt <span class="hljs-comment"># 导入单位换算函数</span><br>document = Document() <span class="hljs-comment"># 新建word文档</span><br>section = document.sections[<span class="hljs-number">0</span>] <span class="hljs-comment"># 获取section对象</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">'默认页面的宽度和高度：'</span>, section.page_width.cm,<br>section.page_height.cm) <span class="hljs-comment"># 打印默认页面宽度和高度</span><br>section.page_width = Cm(<span class="hljs-number">40</span>)<br>section.page_height = Cm(<span class="hljs-number">40</span>)<br><br><span class="hljs-comment">#A3纸的格式是297*420mm</span><br></code></pre></td></tr></tbody></table></figure><h2 id="其他功能">其他功能</h2><h3 id="打开文档">打开文档</h3><p>你需要的第一件事是工作的文档。最简单的方法是：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> docx <span class="hljs-keyword">import</span> Document<br>document = Document()<br></code></pre></td></tr></tbody></table></figure><p>这将打开一个基于默认“模板”的空白文档，您可以打开并使用现有的Word文档的工作<code>python-docx</code>，我们会让事情变得简单。</p><h3 id="增加一段">增加一段</h3><p>段落是Word的基础。它们用于正文文本，但也用于标题和列表项目（如项目符号）。</p><p>这里是添加一个最简单的方法：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">paragraph = document.add_paragraph(<span class="hljs-string">'Lorem ipsum dolor sit amet.'</span>)<br></code></pre></td></tr></tbody></table></figure><p>此方法返回对段落的引用，新添加的段落在文档的结尾。新的段落引用被分配给<code>paragraph</code> 在这种情况下，我将要离开了这一点在下面的例子中，除非我有一个需要它。在你的代码中，通常你不会对项目做任何事情，在添加它，所以没有什么意义，保持引用它挂在周围。</p><p>还可以使用一个段落作为“光标”，并在其上直接插入一个新段落：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">prior_paragraph = paragraph.insert_paragraph_before(<span class="hljs-string">'Lorem ipsum'</span>)<br></code></pre></td></tr></tbody></table></figure><p>这允许将一个段落插入到文档的中间，这在修改现有文档时通常很重要，而不是从头开始生成。</p><h3 id="添加标题">添加标题</h3><p>在除了最短文档之外的任何内容中，正文文本被分成多个部分，每个部分以一个标题开始。以下是如何添加一个：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">document.add_heading(<span class="hljs-string">'The REAL meaning of the universe'</span>)<br></code></pre></td></tr></tbody></table></figure><p>默认情况下，这会添加顶级标题，Word中显示为“标题1”。当您需要子节的标题时，只需指定所需的级别为1到9之间的整数：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">document.add_heading(<span class="hljs-string">'The role of dolphins'</span>, level=<span class="hljs-number">2</span>)<br></code></pre></td></tr></tbody></table></figure><p>如果指定级别0，将添加“标题”段落。这可以方便地启动一个相对较短的文档，没有单独的标题页。</p><h3 id="添加分页符">添加分页符</h3><p>每隔一段时间，你想要下一个文本在一个单独的页面，即使你所在的一个不是满的。“hard”分页符可以做到这一点：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">document.add_page_break()<br></code></pre></td></tr></tbody></table></figure><p>如果你发现自己经常使用它，这可能是一个标志，你可以通过更好地了解段落样式受益。可设置的一个段落样式属性是在包含该样式的每个段落之前立即断开页面。因此，您可以将标题设置为某个级别，以便始终启动新页面。更多风格后。它们对于真正充分利用Word至关重要。</p><h3 id="添加表">添加表</h3><p>一个经常遇到的内容，它自己的表格呈现，排列在整齐的行和列。Word在这方面做得相当不错。以下是添加表格的方法：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">table = document.add_table(rows=<span class="hljs-number">2</span>, cols=<span class="hljs-number">2</span>)<br></code></pre></td></tr></tbody></table></figure><p>表具有几个属性和方法，您将需要它们来填充它们。访问单个单元格可能是一个好的开始的地方。作为基线，您可以始终按其行和列指示访问单元格：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">cell = table.cell(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>) <span class="hljs-comment">#根据行列指定</span><br></code></pre></td></tr></tbody></table></figure><p>这就给出了我们刚刚创建的表格最上面一行的右边单元格。注意，行和列指示是基于零的，就像在列表访问中一样。</p><p>一旦你有一个单元格，你可以把东西在它：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">cell.text = <span class="hljs-string">'parrot, possibly dead'</span><br></code></pre></td></tr></tbody></table></figure><p>通常，一次访问一行单元格更容易，例如，当从数据源填充可变长度的表时。在<code>.rows</code> 一个表中的属性提供给单独的行，每个都具有一个 <code>.cells</code>属性。该<code>.cells</code>两个物业<code>Row</code>和<code>Column</code> 支持索引访问，就像一个列表：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">row = table.rows[<span class="hljs-number">1</span>]<br>row.cells[<span class="hljs-number">0</span>].text = <span class="hljs-string">'Foo bar to you.'</span><br>row.cells[<span class="hljs-number">1</span>].text = <span class="hljs-string">'And a hearty foo bar to you too sir!'</span><br></code></pre></td></tr></tbody></table></figure><p>在<code>.rows</code>和<code>.columns</code>桌子上的集合是可迭代的，这样你就可以直接在使用它们<code>for</code>循环。相同的<code>.cells</code>上行或列序列：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> table.rows:<br>    <span class="hljs-keyword">for</span> cell <span class="hljs-keyword">in</span> row.cells:<br>        <span class="hljs-built_in">print</span>(cell.text)<br></code></pre></td></tr></tbody></table></figure><p>如果你想在表中的行或列的计数，只要使用<code>len()</code>的顺序：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">row_count = <span class="hljs-built_in">len</span>(table.rows)<br>col_count = <span class="hljs-built_in">len</span>(table.columns)<br></code></pre></td></tr></tbody></table></figure><p>您还可以以递增方式向表中添加行，如下所示：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">row = table.add_row()<br></code></pre></td></tr></tbody></table></figure><p>这对于我们上面提到的可变长度表场景非常方便：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># get table data -------------</span><br>items = get_things_from_database_or_something()<br> <br><span class="hljs-comment"># add table ------------------</span><br>table = document.add_table(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br> <br><span class="hljs-comment"># populate header row --------</span><br>heading_cells = table.rows[<span class="hljs-number">0</span>].cells<br>heading_cells[<span class="hljs-number">0</span>].text = <span class="hljs-string">'Qty'</span><br>heading_cells[<span class="hljs-number">1</span>].text = <span class="hljs-string">'SKU'</span><br>heading_cells[<span class="hljs-number">2</span>].text = <span class="hljs-string">'Description'</span><br> <br><span class="hljs-comment"># add a data row for each item</span><br><span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> items:<br>    cells = table.add_row().cells<br>    cells[<span class="hljs-number">0</span>].text = <span class="hljs-built_in">str</span>(item.qty)<br>    cells[<span class="hljs-number">1</span>].text = item.sku<br>    cells[<span class="hljs-number">2</span>].text = item.desc<br></code></pre></td></tr></tbody></table></figure><p>同样的工作对列，虽然我还没有看到它的一个用例。</p><p>Word具有一组预格式化的表格样式，您可以从其表格样式库中选择。您可以将其中的一个应用于表格，如下所示：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">table.style = <span class="hljs-string">'LightShading-Accent1'</span><br></code></pre></td></tr></tbody></table></figure><p>通过从表样式名称中删除所有空格形成样式名称。通过将鼠标悬停在Word的表样式库中的缩略图上，可以找到表样式名称。</p><h3 id="添加图片">添加图片</h3><p>Word中，您可以将图像使用的文档中的菜单项。以下是如何做到这一点的：<code>Insert &gt; Photo &gt; Picture fromfile...``python-docx</code></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">document.add_picture(<span class="hljs-string">'image-filename.png'</span>)<br></code></pre></td></tr></tbody></table></figure><p>此示例使用路径，从本地文件系统加载图像文件。你也可以使用一个<em>类文件对象</em>，本质上就像一个打开的文件的任何对象。如果您从数据库或网络检索图像，并且不想获取涉及的文件系统，这可能很方便。</p><h4 id="图像大小">图像大小</h4><p>默认情况下，添加图像出现在<em>本地</em>的大小。这通常比你想要的更大。本机大小的计算方法。因此，具有300dpi分辨率的300×300像素图像出现在一平方英寸。问题是大多数图像不包含dpi属性，它默认为72 dpi。这将使同一图像在一边，在一半左右的某处出现4.167英寸。<code>pixels / dpi</code></p><p>要获得所需的图像大小，您可以以方便的单位指定其宽度或高度，如英寸或厘米：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> docx.shared <span class="hljs-keyword">import</span> Inches<br>document.add_picture(<span class="hljs-string">'image-filename.png'</span>, width=Inches(<span class="hljs-number">1.0</span>))<br></code></pre></td></tr></tbody></table></figure><p>你可以自由地指定宽度和高度，但通常你不想要。如果仅指定一个，<code>python-docx</code>用它来计算出其他的适当换算值。这样的<em>高宽比</em>是保留的，你的图像看起来不拉伸。</p><p>在<code>Inches</code>和<code>Cm</code>提供课程，让你指定派上用场单位进行测量。在内部，<code>python-docx</code>使用英语公制单位，914400为英寸。所以，如果你忘记了，只是把喜欢的东西<code>width=2</code>，你会得到一个非常小的图像:)。你需要从导入<code>docx.shared</code> 子包。你可以在算术中使用它们，就像它们是一个整数，事实上它们是。因此，像一个表达式的作品就好了。<code>width = Inches(3) /thing_count</code></p><h3 id="应用段落样式">应用段落样式</h3><p>如果你不知道一个Word段落风格是你应该肯定检查出来。基本上，它允许您将一整套格式化选项立即应用到段落。这很像CSS样式，如果你知道那些是。</p><p>您可以在创建段落时应用段落样式：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">document.add_paragraph(<span class="hljs-string">'Lorem ipsum dolor sit amet.'</span>, style=<span class="hljs-string">'ListBullet'</span>)<br></code></pre></td></tr></tbody></table></figure><p>这种特殊的风格导致段落显示为一个子弹，一个非常方便的东西。您也可以在之后应用样式。这两行相当于上面的一行：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">paragraph = document.add_paragraph(<span class="hljs-string">'Lorem ipsum dolor sit amet.'</span>)<br>paragraph.style = <span class="hljs-string">'ListBullet'</span><br></code></pre></td></tr></tbody></table></figure><p>在此示例中，样式使用其样式ID“ListBullet”指定。通常，通过去除样式名称中出现在Word用户界面（UI）中的空格来形成样式ID。所以风格’列表3号’将被指定为<code>'ListNumber3'</code>。但是，请注意，如果您使用的是本地化版本的Word，则样式ID可能来自英语样式名称，并且可能不会完全对应于其在Word UI中的样式名称。</p>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
      <category>图像</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>图像</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer2_085 生成匹配的括号</title>
    <link href="/2021/12/09/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer2-085/"/>
    <url>/2021/12/09/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer2-085/</url>
    
    <content type="html"><![CDATA[<blockquote><p>生成匹配的括号</p></blockquote><h2 id="题目">题目</h2><p>正整数 <code>n</code> 代表生成括号的对数，请设计一个函数，用于能够生成所有可能的并且 <strong>有效的</strong> 括号组合。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight excel"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs excel">输入：<span class="hljs-built_in">n</span> = <span class="hljs-number">3</span><br>输出：[<span class="hljs-string">"((()))"</span>,<span class="hljs-string">"(()())"</span>,<span class="hljs-string">"(())()"</span>,<span class="hljs-string">"()(())"</span>,<span class="hljs-string">"()()()"</span>]<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight excel"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs excel">输入：<span class="hljs-built_in">n</span> = <span class="hljs-number">1</span><br>输出：[<span class="hljs-string">"()"</span>]<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= n &lt;= 8</li></ul><h2 id="题解">题解</h2><p>巧妙的深度优先算法，记录生成当前的字符串，左括号，右括号的数目；<br>如果左括号个数不超，就增加左括号，如果可以增加右括号（<strong>现有的右括号小于左括号数目</strong>），那么增加右括号。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">generateParenthesis</span>(<span class="hljs-params">self, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]:</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dfs</span>(<span class="hljs-params">s,left,right</span>):</span><br>            <span class="hljs-keyword">if</span>(<span class="hljs-built_in">len</span>(s)==<span class="hljs-number">2</span>*n):<br>                result.append(s)<br>            <span class="hljs-keyword">if</span>(left&lt;n):dfs(s+<span class="hljs-string">"("</span>,left+<span class="hljs-number">1</span>,right) <span class="hljs-comment">#如果left数组少于n个就增加左括号</span><br>            <span class="hljs-keyword">if</span>(left&gt;right):dfs(s+<span class="hljs-string">")"</span>,left,right+<span class="hljs-number">1</span>) <span class="hljs-comment">#如果可以匹配左括号，可以增加右括号区匹配</span><br>        result = []<br>        dfs(<span class="hljs-string">""</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>树</tag>
      
      <tag>剑指</tag>
      
      <tag>idea</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer56-2 数组中数字出现的次数Ⅱ</title>
    <link href="/2021/12/08/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer56-2/"/>
    <url>/2021/12/08/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer56-2/</url>
    
    <content type="html"><![CDATA[<blockquote><p>数组中数字出现的次数Ⅱ</p></blockquote><h2 id="题目">题目</h2><p>在一个数组 <code>nums</code> 中除一个数字只出现一次之外，其他数字都出现了三次。请找出那个只出现一次的数字。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight dns"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs dns">输入：nums = [<span class="hljs-number">3,4,3,3</span>]<br>输出：<span class="hljs-number">4</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight accesslog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">输入：nums = <span class="hljs-string">[9,1,7,9,7,9,7]</span><br>输出：<span class="hljs-number">1</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><p><code>1 &lt;= nums.length &lt;= 10000</code></p></li><li><p><code>1 &lt;= nums[i] &lt; 2^31</code></p></li></ul><h2 id="题解">题解</h2><p>使用哈希表记录次数，然后再寻找次数为1的数字。此时的时间复杂度为O(N),空间复杂度为O(N)。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">singleNumber</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        tmap = {}<br>        <span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> nums:<br>            tmap[num] = tmap[num]+<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> num <span class="hljs-keyword">in</span> tmap <span class="hljs-keyword">else</span> <span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> tmap:<br>            <span class="hljs-keyword">if</span> tmap[num] == <span class="hljs-number">1</span>:<br>                <span class="hljs-keyword">return</span> num<br></code></pre></td></tr></tbody></table></figure><p>还有一种方法可以达到时间复杂度为O(N),空间复杂度为O(1);</p><p>其思想是每一位的二进制位对于出现3次的数字相加是3的倍数。这样可以把每一位相加对 3 除余数，可以得到出现一次的数字。</p><p><img src="https://picture.mulindya.com/leetcode-offer56-2.png" alt=""></p><p>实际上修改余数m，可以得到通用解法：**除了一个数字以外，其余数字都出现 m 次 **</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">singleNumber</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        counts = [<span class="hljs-number">0</span>] * <span class="hljs-number">32</span> <span class="hljs-comment">#记录每一位的和</span><br>        <span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> nums:<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">32</span>):<br>                counts[j] += num &amp; <span class="hljs-number">1</span><br>                num &gt;&gt;= <span class="hljs-number">1</span> <span class="hljs-comment">#右移1位</span><br>        res, m = <span class="hljs-number">0</span>, <span class="hljs-number">3</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">32</span>):<br>            res &lt;&lt;= <span class="hljs-number">1</span><br>            res |= counts[<span class="hljs-number">31</span> - i] % m  <span class="hljs-comment"># 位或运算 从高位开始然后左移运算</span><br>        <span class="hljs-keyword">return</span> res <span class="hljs-comment"># if counts[31] % m == 0 else ~(res ^ 0xffffffff) #最高位为0则为正数，否则为负数</span><br></code></pre></td></tr></tbody></table></figure><p>负数此处的操作没有看懂。经测试，直接return res即可。</p><blockquote><p>由于 Python 的存储负数的特殊性，需要先将 0 - 32 位取反（即 res ^ 0xffffffff ），再将所有位取反（即 ~ ）。<strong>^表示二进制异或运算</strong><br>两个组合操作实质上是将数字 32 以上位取反， 0 - 32 位不变。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>数组</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>数组</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指53-1 数组中数字出现的次数</title>
    <link href="/2021/12/07/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode53-1/"/>
    <url>/2021/12/07/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode53-1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>数组中数字出现的次数</p></blockquote><h2 id="题目">题目</h2><p>一个整型数组 <code>nums</code> 里除两个数字之外，其他数字都出现了两次。请写程序找出这两个只出现一次的数字。要求时间复杂度是O(n)，空间复杂度是O(1)。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：nums = <span class="hljs-comment">[4,1,4,6]</span><br>输出：<span class="hljs-comment">[1,6]</span> 或 <span class="hljs-comment">[6,1]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：nums = <span class="hljs-comment">[1,2,10,4,1,4,3,3]</span><br>输出：<span class="hljs-comment">[2,10]</span> 或 <span class="hljs-comment">[10,2]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><code>2 &lt;= nums.length &lt;= 10000</code></li></ul><h2 id="题解">题解</h2><p>利用map来记录每个数出现的次数，再遍历map得到次数为1的数，这样的时间复杂度为O(N),空间复杂度为O(N)；</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">singleNumbers</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:</span><br>        info = {}<br>        result = []<br>        <span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> nums:<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span>(num <span class="hljs-keyword">in</span> info):info[num]=<span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:info[num] += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> info:<br>            <span class="hljs-keyword">if</span>(info[key]==<span class="hljs-number">1</span>):result.append(key)<br>        <span class="hljs-keyword">return</span> result<br>        <span class="hljs-comment">#这样的时间复杂度为O(N),空间复杂度为O(N)</span><br></code></pre></td></tr></tbody></table></figure><p>因为要保证空间复杂度为O(1),需要另辟蹊径，注意到一个定理，a⊕a = 0 0⊕a=a，并且满足交换律，因此如果只有一个数字x只出现一次，那么将所有的数字进行异或操作得到的结果就是x</p><p>单个数字：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">singleNumber</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:</span><br>    x = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> nums:  <span class="hljs-comment"># 1. 遍历 nums 执行异或运算</span><br>        x ^= num      <br>    <span class="hljs-keyword">return</span> x;         <span class="hljs-comment"># 2. 返回出现一次的数字 x</span><br></code></pre></td></tr></tbody></table></figure><p>现在是两个数字，因此所有数字的异或是x⊕y，这两个数字怎么区分呢，可以找到这两个数字不同的一位（利用&amp;）。然后再进行异或分类，找到两个值。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">singleNumbers</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:</span><br>        <span class="hljs-comment">#x1异或x2.... 结果可以得到最终的两个不同的数异或 x异或y</span><br>        a,x,y = <span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> nums:<br>            a = a^num<br>        m = <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> m&amp;a==<span class="hljs-number">0</span>: m = m&lt;&lt;<span class="hljs-number">1</span> <span class="hljs-comment">#找到不同位</span><br>        <span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> nums:<br>            <span class="hljs-keyword">if</span>(m&amp;num):x^=num<br>            <span class="hljs-keyword">else</span>:y^=num<br>        <span class="hljs-keyword">return</span> [x,y]<br></code></pre></td></tr></tbody></table></figure><p>还不清楚的话，可以参考解释代码哦~</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span> </span>{<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span>[] singleNumbers(<span class="hljs-keyword">int</span>[] nums) {<br>        <span class="hljs-comment">//因为相同的数字异或为0，任何数字与0异或结果是其本身。</span><br>        <span class="hljs-comment">//所以遍历异或整个数组最后得到的结果就是两个只出现一次的数字异或的结果：即 z = x ^ y</span><br>        <span class="hljs-keyword">int</span> z = <span class="hljs-number">0</span>;  <br>        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i : nums) z ^= i;<br>        <span class="hljs-comment">//我们根据异或的性质可以知道：z中至少有一位是1，否则x与y就是相等的。</span><br>        <span class="hljs-comment">//我们通过一个辅助变量m来保存z中哪一位为1.（可能有多个位都为1，我们找到最低位的1即可）。</span><br>        <span class="hljs-comment">//举个例子：z = 10 ^ 2 = 1010 ^ 0010 = 1000,第四位为1.</span><br>        <span class="hljs-comment">//我们将m初始化为1，如果（z &amp; m）的结果等于0说明z的最低为是0</span><br>        <span class="hljs-comment">//我们每次将m左移一位然后跟z做与操作，直到结果不为0.</span><br>        <span class="hljs-comment">//此时m应该等于1000，同z一样，第四位为1.</span><br>        <span class="hljs-keyword">int</span> m = <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">while</span>((z &amp; m) == <span class="hljs-number">0</span>) m &lt;&lt;= <span class="hljs-number">1</span>;<br>        <span class="hljs-comment">//我们遍历数组，将每个数跟m进行与操作，结果为0的作为一组，结果不为0的作为一组</span><br>        <span class="hljs-comment">//例如对于数组：[1,2,10,4,1,4,3,3]，我们把每个数字跟1000做与操作，可以分为下面两组：</span><br>        <span class="hljs-comment">//nums1存放结果为0的: [1, 2, 4, 1, 4, 3, 3]</span><br>        <span class="hljs-comment">//nums2存放结果不为0的: [10] (碰巧nums2中只有一个10，如果原数组中的数字再大一些就不会这样了)</span><br>        <span class="hljs-comment">//此时我们发现问题已经退化为数组中有一个数字只出现了一次</span><br>        <span class="hljs-comment">//分别对nums1和nums2遍历异或就能得到我们预期的x和y</span><br>        <span class="hljs-keyword">int</span> x = <span class="hljs-number">0</span>, y = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i : nums) {<br>            <span class="hljs-comment">//这里我们是通过if...else将nums分为了两组，一边遍历一遍异或。</span><br>            <span class="hljs-comment">//跟我们创建俩数组nums1和nums2原理是一样的。</span><br>            <span class="hljs-keyword">if</span>((i &amp; m) == <span class="hljs-number">0</span>) x ^= i;<br>            <span class="hljs-keyword">else</span> y ^= i;<br>        }<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-keyword">int</span>[]{x, y};<br>    }<br>}<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>数组</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>数组</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer34 二叉树中和为某一值的路径</title>
    <link href="/2021/12/06/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer34/"/>
    <url>/2021/12/06/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer34/</url>
    
    <content type="html"><![CDATA[<blockquote><p>二叉树中和为某一值的路径</p></blockquote><h2 id="题目">题目</h2><p>给你二叉树的根节点 root 和一个整数目标和 targetSum ，找出所有 从根节点到叶子节点 路径总和等于给定目标和的路径。</p><p>叶子节点 是指没有子节点的节点。</p><h3 id="示例-1：">示例 1：</h3><p><img src="https://picture.mulindya.com/leetcode34-1.jpg" alt=""></p><figure class="highlight lua"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs lua">输入：root = [<span class="hljs-number">5</span>,<span class="hljs-number">4</span>,<span class="hljs-number">8</span>,<span class="hljs-number">11</span>,null,<span class="hljs-number">13</span>,<span class="hljs-number">4</span>,<span class="hljs-number">7</span>,<span class="hljs-number">2</span>,null,null,<span class="hljs-number">5</span>,<span class="hljs-number">1</span>], targetSum = <span class="hljs-number">22</span><br>输出：<span class="hljs-string">[[5,4,11,2],[5,8,4,5]]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><p><img src="https://picture.mulindya.com/leetcode34-2.jpg" alt=""></p><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：root = <span class="hljs-comment">[1,2,3]</span>, targetSum = 5<br>输出：<span class="hljs-comment">[]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例4：">示例4：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：root = <span class="hljs-comment">[1,2]</span>, targetSum = 0<br>输出：<span class="hljs-comment">[]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>树中节点总数在范围 <code>[0, 5000]</code> 内</li><li><code>-1000 &lt;= Node.val &lt;= 1000</code></li><li><code>-1000 &lt;= targetSum &lt;= 1000</code></li></ul><h2 id="题解">题解</h2><p>注存在节点的值是负数，因此<strong>不能按照当前得到的和进行剪枝操作</strong>，另一个需要注意的点是<strong>不能将对象append</strong>，对象的append直接引用的，再后续修改会影响到result的内容，所以可以将其进行copy，深拷贝，或者list实例化一下。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for a binary tree node.</span><br><span class="hljs-comment"># class TreeNode:</span><br><span class="hljs-comment">#     def __init__(self, val=0, left=None, right=None):</span><br><span class="hljs-comment">#         self.val = val</span><br><span class="hljs-comment">#         self.left = left</span><br><span class="hljs-comment">#         self.right = right</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">pathSum</span>(<span class="hljs-params">self, root: TreeNode, target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]:</span><br>        <span class="hljs-keyword">if</span>(<span class="hljs-keyword">not</span> root): <span class="hljs-keyword">return</span> []<br>        result,nowlist = [],[]<br><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">findPath</span>(<span class="hljs-params">root,nowsum</span>):</span><br>            <span class="hljs-comment"># if(not root or (root and root.val + nowsum&gt;target)): return #还存在负数的情况因此不能剪枝</span><br>            <span class="hljs-keyword">if</span>(<span class="hljs-keyword">not</span> root): <span class="hljs-keyword">return</span><br>            tsum = root.val + nowsum<br>            nowlist.append(root.val)<br>            <span class="hljs-keyword">if</span>(<span class="hljs-keyword">not</span> root.left <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> root.right <span class="hljs-keyword">and</span> tsum==target):<br>                result.append(nowlist.copy()) <span class="hljs-comment">#不能随便将一个对象append进去，后续此对象出现变化，会影响到result</span><br>            findPath(root.left,tsum)<br>            findPath(root.right,tsum)<br>            nowlist.pop()<br>               <br>        findPath(root,<span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>树</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer372 超级次方</title>
    <link href="/2021/12/05/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer372/"/>
    <url>/2021/12/05/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer372/</url>
    
    <content type="html"><![CDATA[<blockquote><p>超级次方</p></blockquote><h2 id="题目">题目</h2><p>你的任务是计算 ab 对 1337 取模，a 是一个正整数，b 是一个非常大的正整数且会以数组形式给出。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight stylus"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">输入：<span class="hljs-selector-tag">a</span> = <span class="hljs-number">2</span>, <span class="hljs-selector-tag">b</span> = <span class="hljs-selector-attr">[3]</span><br>输出：<span class="hljs-number">8</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight stylus"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">输入：<span class="hljs-selector-tag">a</span> = <span class="hljs-number">2</span>, <span class="hljs-selector-tag">b</span> = <span class="hljs-selector-attr">[1,0]</span><br>输出：<span class="hljs-number">1024</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-3：">示例 3：</h3><figure class="highlight stylus"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">输入：<span class="hljs-selector-tag">a</span> = <span class="hljs-number">1</span>, <span class="hljs-selector-tag">b</span> = <span class="hljs-selector-attr">[4,3,3,8,5,2]</span><br>输出：<span class="hljs-number">1</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-4：">示例 4：</h3><figure class="highlight stylus"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">输入：<span class="hljs-selector-tag">a</span> = <span class="hljs-number">2147483647</span>, <span class="hljs-selector-tag">b</span> = <span class="hljs-selector-attr">[2,0,0]</span><br>输出：<span class="hljs-number">1198</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= a &lt;= 231 - 1</li><li>1 &lt;= b.length &lt;= 2000</li><li>0 &lt;= b[i] &lt;= 9</li><li>b 不含前导 0</li></ul><h2 id="题解">题解</h2><p>使用math模块</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br>math.<span class="hljs-built_in">pow</span>( x, y )<br></code></pre></td></tr></tbody></table></figure><p>内置的pow方法<br><code>pow(x, y[, z])</code></p><p>函数是计算 x 的 y 次方，如果 z 在存在，则再对结果进行取模，其结果等效于 pow(x,y) %z。</p><p><strong>注意：pow() 通过内置的方法直接调用，内置方法会把参数作为整型，而 math 模块则会把参数转换为 float。</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">superPow</span>(<span class="hljs-params">self, a: <span class="hljs-built_in">int</span>, b: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        result = <span class="hljs-number">1</span><br>        mod = <span class="hljs-number">1337</span><br>        <span class="hljs-keyword">for</span> i,x <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(b):<br>            temp = <span class="hljs-built_in">pow</span>(a,x,mod)<br>            result = result*temp%mod <br>            <span class="hljs-keyword">if</span>(i&lt;<span class="hljs-built_in">len</span>(b)-<span class="hljs-number">1</span>):result = <span class="hljs-built_in">pow</span>(result,<span class="hljs-number">10</span>,mod)<br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></tbody></table></figure><p>和二进制求十进制的思想类似，当前位求得之后再乘以10的基底，继续重复,</p>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>数组</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>数组</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer33</title>
    <link href="/2021/12/04/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer33/"/>
    <url>/2021/12/04/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer33/</url>
    
    <content type="html"><![CDATA[<blockquote><p>二叉搜索树的后续遍历序列</p></blockquote><h2 id="题目">题目</h2><p>输入一个整数数组，判断该数组是不是某二叉搜索树的后序遍历结果。如果是则返回 <code>true</code>，否则返回 <code>false</code>。假设输入的数组的任意两个数字都互不相同。</p><p>参考以下这颗二叉搜索树</p><figure class="highlight livescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs livescript">    <span class="hljs-number">5</span><br>   / <span class="hljs-string">\</span><br>  <span class="hljs-number">2</span>   <span class="hljs-number">6</span><br> / <span class="hljs-string">\</span><br><span class="hljs-number">1</span>   <span class="hljs-number">3</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-1：">示例 1：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入: [1,6,3,2,5]</span><br><span class="hljs-section">输出: false</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入: [1,3,2,6,5]</span><br><span class="hljs-section">输出: true</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><code>数组长度 &lt;= 1000</code></li></ul><h2 id="题解">题解</h2><p>采用递归的方式，最后一个元素作为root，找到第一个比root大的值，作为左子树的区域，比较左子树区域的值核对是否大于root即可，然后比较左右子树。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">verifyPostorder</span>(<span class="hljs-params">self, postorder: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">bool</span>:</span><br>        <span class="hljs-keyword">if</span>(<span class="hljs-keyword">not</span> postorder <span class="hljs-keyword">or</span> <span class="hljs-built_in">len</span>(postorder)==<span class="hljs-number">1</span>): <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>        root = postorder[<span class="hljs-built_in">len</span>(postorder)-<span class="hljs-number">1</span>]<br>        result,flag = <span class="hljs-literal">True</span>,<span class="hljs-literal">True</span><br>        index = <span class="hljs-built_in">len</span>(postorder)-<span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> i,x <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(postorder):<br>            result = x&gt;=root <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> flag <span class="hljs-keyword">and</span> result <span class="hljs-keyword">else</span> result<br>            <span class="hljs-comment"># if(not flag and x&lt;root):</span><br>            <span class="hljs-comment">#     result = False</span><br>            <span class="hljs-comment">#     break</span><br>            <span class="hljs-comment"># result = x&gt;root if not flag else True</span><br>            <span class="hljs-keyword">if</span>(flag <span class="hljs-keyword">and</span> x&gt;root):<br>                index = i<br>                flag = <span class="hljs-literal">False</span><br>        <span class="hljs-keyword">return</span> result <span class="hljs-keyword">and</span> self.verifyPostorder(postorder[:index-<span class="hljs-number">1</span>]) <span class="hljs-keyword">and</span> self.verifyPostorder(postorder[index:<span class="hljs-built_in">len</span>(postorder)-<span class="hljs-number">1</span>])<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>树</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>dcm文件转换为3D的nii文件</title>
    <link href="/2021/11/26/python/img/dcm2nii/"/>
    <url>/2021/11/26/python/img/dcm2nii/</url>
    
    <content type="html"><![CDATA[<blockquote><p>记录dcm文件转换为nii文件的代码</p></blockquote><h1>前言</h1><p>NIfTI 中的图像原始数据一般被存储成了三维图像，而dicom存储为二维图层，所以相对于DICOM文件，NIFTI文件更加易用于机器学习，因为NIfTI 是三维图像，处理一个单独的NIfTI 文件要比处理成百上千个DICOM文件更加容易一些。</p><h1>医学图像格式</h1><p>DICOM 和 NIFTI 是最常用的格式，下面对其进行简单介绍。</p><h2 id="DICOM">DICOM</h2><p>DICOM 代表的是医疗数字成像和通信。DICOM 是由美国国家电气制造商协会（NEMA）制定的标准。它定义了医疗成像领域中关于信息处理、存储、打印以及传输的标准，这些都是你在扫描仪或者某家医院的图片归档和通信系统（PACS）能够立即得到的文件格式。<br>它包括了文件格式和能够接收图像以及 DICOM 格式的病人数据的实体之间使用 TCP/IP 进行通信的协议。</p><p>一个 DICOM 文件包含文件头部和同文件名的*.dcm 图像数据。文件头部的大小取决于它所提供的信息的多少。文件头包含以下信息：病人的 ID，病人的姓名，图像的模态以及其他信息。它定义了帧的数量以及图像的精度。这些信息会被图像浏览器在显示图像时用到。对于一个图像采样，会有很多个 DICOM 文件。</p><h2 id="NIFTI">NIFTI</h2><p>Nifti 格式最初是为神经影像学发明的。神经影像信息学技术计划（NIFTI）将 NIfTI 格式预设为 ANALYZE7.5 格式的替代品。它最初的应用领域是神经影像，但是也被用在其他领域。这种格式的主要特点就是它包含两个能够将每个体素的索引（i,j,k）和它的空间位置（x,y,z）关联起来的仿射坐标。</p><h4 id="代码">代码</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#coding=utf-8</span><br><span class="hljs-keyword">import</span> SimpleITK <span class="hljs-keyword">as</span> sitk<br><span class="hljs-keyword">import</span> os,glob<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dcm2nii</span>(<span class="hljs-params">dcms_path, nii_path</span>):</span><br>    <span class="hljs-comment"># 1.构建dicom序列文件阅读器，并执行（即将dicom序列文件“打包整合”）</span><br>    reader = sitk.ImageSeriesReader()<br>    dicom_names = reader.GetGDCMSeriesFileNames(dcms_path)<br>    reader.SetFileNames(dicom_names)<br>    image2 = reader.Execute()<br>    <span class="hljs-comment"># 2.将整合后的数据转为array，并获取dicom文件基本信息</span><br>    image_array = sitk.GetArrayFromImage(image2)  <span class="hljs-comment"># z, y, x</span><br>    origin = image2.GetOrigin()  <span class="hljs-comment"># x, y, z</span><br>    spacing = image2.GetSpacing()  <span class="hljs-comment"># x, y, z</span><br>    direction = image2.GetDirection()  <span class="hljs-comment"># x, y, z</span><br>    <span class="hljs-comment"># 3.将array转为img，并保存为.nii.gz</span><br>    image3 = sitk.GetImageFromArray(image_array)<br>    image3.SetSpacing(spacing)<br>    image3.SetDirection(direction)<br>    image3.SetOrigin(origin)<br>    sitk.WriteImage(image3, nii_path)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:<br>    filelist = glob.glob(<span class="hljs-string">"./data/AD_result/I*"</span>)<br>    save_path = <span class="hljs-string">"./data/AD_nii"</span><br>    os.makedirs(save_path,exist_ok=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">for</span> dcms_path <span class="hljs-keyword">in</span> filelist:<br>        dirname = dcms_path.split(os.path.sep)[-<span class="hljs-number">1</span>]<br>        nii_path = os.path.join(save_path,dirname+ <span class="hljs-string">".nii"</span>)<br>        <span class="hljs-built_in">print</span>(nii_path)<br>       <span class="hljs-comment"># r'.\test.nii.gz'  # 所需.nii.gz文件保存路径</span><br>        dcm2nii(dcms_path, nii_path)<br><br></code></pre></td></tr></tbody></table></figure><h1>图像自动处理工具SimpleITK的使用</h1><p>参考：<a href="https://www.ebaina.com/articles/140000012739">https://www.ebaina.com/articles/140000012739</a></p><h4 id="安装SimpleITK库">安装SimpleITK库</h4><figure class="highlight cmake"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cmake">命令行模式下，任意位置输入：<br>  pip <span class="hljs-keyword">install</span> SimpleITK<br></code></pre></td></tr></tbody></table></figure><h3 id="SimpleITK处理医学图像">SimpleITK处理医学图像</h3><p>做医学图像时，SimpleITK是一个很常用的库。实际上大家往往喜欢把不同类型的数据割裂开，nrrd用pynrrd处理，dicom用dicom处理，nii用nibabel处理……实际上根本没必要，SimpleITK完全可以统一处理，各种类型的读取和保存一步搞定。</p><h4 id="读取">读取</h4><h5 id="DICOM-2">DICOM</h5><p>首先是最常见的DICOM。这个文件格式是CT机器直接输出的结果，每个病人会是一个文件夹，里面有若干个DICOM文件，每个DICOM文件都是一个切片，可以被单独查阅（通过SimpleITK的ReadImage）。但是，处理起来一般我们会希望把这些DICOM组合起来形成一个3D的矩阵，这样就可以用到SimpltITK里的<code>ImageSeriesReader()</code>来实现：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> SimpleITK <span class="hljs-keyword">as</span> sitk<br>reader = sitk.ImageSeriesReader() <br>img_names = reader.GetGDCMSeriesFileNames(img_path) <br>reader.SetFileNames(img_names) <br>image = reader.Execute() <br>image_array = sitk.GetArrayFromImage(image) <span class="hljs-comment"># z, y, x </span><br></code></pre></td></tr></tbody></table></figure><h5 id="MHD">MHD</h5><p>然后还有就是。这种格式的文件由一个MHD文件和一个RAW文件组成，其中MHD里面是病人和CT扫描结果的相关信息，RAW里面存的是真正的数组，对于这种格式，SimpleITK可以这样读取：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> SimpleITK <span class="hljs-keyword">as</span> sitk<br>itk_img = sitk.ReadImage(filename) <br>img_array = sitk.GetArrayFromImage(itk_img) <br></code></pre></td></tr></tbody></table></figure><h5 id="NII">NII</h5><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> SimpleITK <span class="hljs-keyword">as</span> sitk<br>itk_img = sitk.ReadImage(filename)<br>img_array = sitk.GetArrayFromImage(itk_img) <br></code></pre></td></tr></tbody></table></figure><p>不过，对于NII类型的文件，SimpleITK在保存上会有一些问题（读取没问题保存上竟然有问题我真是服了），如果slice的数量很大（之前有碰到过300多个slice的），保存起来会直接报错，所以如果碰到这种情况我会选择保存成nrrd（用pynrrd库）</p><h4 id="保存">保存</h4><p>说到保存，有几个天坑一定要说一下。</p><p>首先，保存的通用代码是：</p><figure class="highlight reasonml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">savedImg = sitk.<span class="hljs-constructor">GetImageFromArray(<span class="hljs-params">outputs3D</span>)</span> <br>savedImg.<span class="hljs-constructor">SetSpacing(<span class="hljs-params">spacing</span>)</span><br>savedImg.<span class="hljs-constructor">SetOrigin(<span class="hljs-params">origin</span>)</span> <br>sitk.<span class="hljs-constructor">WriteImage(<span class="hljs-params">savedImg</span>, <span class="hljs-params">input_nii</span>[:-4]+'<span class="hljs-params">_liverSegResult</span>.<span class="hljs-params">nii</span>')</span><br><br></code></pre></td></tr></tbody></table></figure><p>这个里面，SetOrigin和SetSpacing我常常会忘记，所以导致保存的CT用ITKsnap看会变形。这里面的spacing和origin均可以从之前ReadImage()返回的对象上通过GetOrigin()和GetSpacing()获取，千万别忘了。当然，除了这两个之外还有个direction也是可以get和set的，不过一般情况下只要你代码没有搞一些矩阵的翻转等操作这个是不用管的。</p><h3 id="使用SimpleITK读取和保存Nii-gz文件">使用SimpleITK读取和保存Nii.gz文件</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">## using simpleITK to load and save data.</span><br><span class="hljs-keyword">import</span> SimpleITK <span class="hljs-keyword">as</span> sitk<br>itk_img = sitk.ReadImage(<span class="hljs-string">'./nifti.nii.gz'</span>)<br>img = sitk.GetArrayFromImage(itk_img)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"img shape:"</span>,img.shape)<br><br><span class="hljs-comment">## save </span><br>out = sitk.GetImageFromArray(img)<br><span class="hljs-comment"># # out.SetSpacing(itk_img.GetSpacing())</span><br><span class="hljs-comment"># # out.SetOrigin(itk_img.GetOrigin())</span><br>sitk.WriteImage(out,<span class="hljs-string">'simpleitk_save.nii.gz'</span>)<br></code></pre></td></tr></tbody></table></figure><h3 id="可视化一层">可视化一层</h3><p>下面的程序挑取一层进行可视化，并标注结节位置。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">a = image_array.transpose(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>)[:,:,<span class="hljs-number">0</span>]  <span class="hljs-comment"># transpose是将(z,x,y)的三维矩阵转为(x,y,z)的矩阵</span><br>plt.gca().add_patch( plt.Rectangle((<span class="hljs-number">147</span>,<span class="hljs-number">297</span>), <span class="hljs-number">24</span>,<span class="hljs-number">24</span>, fill=<span class="hljs-literal">False</span>,edgecolor=<span class="hljs-string">'r'</span>, linewidth=<span class="hljs-number">3</span>))<br>plt.imshow(a[:,:,<span class="hljs-number">1</span>]*<span class="hljs-number">255</span>)  <span class="hljs-comment"># 在图中画框</span><br>plt.show()<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
      <category>图像</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>图像</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>文件处理（复制，移动）</title>
    <link href="/2021/11/25/python/file/fileprocess/"/>
    <url>/2021/11/25/python/file/fileprocess/</url>
    
    <content type="html"><![CDATA[<blockquote><p>整理文件的复制，移动等相关操作。相关的模块涉及shuti和os包，针对这两个包对文件操作进行整理。</p></blockquote><h2 id="shutil">shutil</h2><p>shutil模块包含了一些用于复制文件和文件夹，和文件压缩的函数.<br>os模块是Python标准库中一个重要的模块，里面提供了对目录和文件的一般常用操作。而Python另外一个标准库——shutil库，它作为os模块的补充，提供了复制、移动、删除、压缩、解压等操作，</p><h3 id="拷贝">拷贝</h3><h4 id="常规复制方法">常规复制方法</h4><table><thead><tr><th style="text-align:center">函数</th><th style="text-align:center">作用</th></tr></thead><tbody><tr><td style="text-align:center">copyfile( src, dst)</td><td style="text-align:center">从源src复制到dst中去。当然前提是目标地址是具备可写权限。抛出的异常信息为IOException. 当前的dst已存在的话就会被覆盖掉</td></tr><tr><td style="text-align:center">copy( src, dst)</td><td style="text-align:center">复制一个文件到一个文件或一个目录</td></tr><tr><td style="text-align:center">copy2( src, dst)</td><td style="text-align:center">在copy上的基础上再复制文件最后访问时间与修改时间也复制过来了，也就是包含文件的属性信息，类似于cp–p的东西</td></tr></tbody></table><ul><li>dst：复制至dst文件夹或文件</li></ul><p>一般dst填写相应的文件夹，就会建立同名文件，就会复制文件到对应的文件夹下，如果要复制文件夹就不能用以上函数了。dst可以是个目录，会在该目录下创建与src同名的文件，<strong>若该目录下存在同名文件，将会报错提示已经存在同名文件</strong>。</p><h4 id="复制文件内容">复制文件内容</h4><p>如果是复制文件内容到某文件中，则使用<code>copyfile</code>，如果存在同名文件，可以覆盖同名文件夹。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">shutil.copyfile(src, dst)<br>功能：将src文件内容复制至dst文件<br><br>src： 源文件路径<br>dst： 复制至dst文件，若dst文件不存在，将会生成一个dst文件；若存在将会被覆盖<br>follow_symlinks：设置为<span class="hljs-literal">True</span>时，若src为软连接，则当成文件复制；如果设置为<span class="hljs-literal">False</span>，复制软连接。默认为<span class="hljs-literal">True</span>。Python3新增参数<br><br><span class="hljs-keyword">import</span> shutil<br>shutil.copyfile(<span class="hljs-string">"./资料/1.txt"</span>,<span class="hljs-string">"./资料/1_empty.txt"</span>)<br></code></pre></td></tr></tbody></table></figure><h4 id="复制目录">复制目录</h4><p><code>shutil.copytree(src, dst, symlinks=False, ignore=None)</code><br>功能：复制整个文件目录(无论文件夹是否为空，均可以复制，而且会复制文件夹中的所有内容)</p><figure class="highlight ada"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs ada">src：源文件夹<br>dst：复制至dst文件夹，该文件夹会自动创建，需保证此文件夹不存在，否则将报错<br>symlinks：是否复制软连接，<span class="hljs-literal">True</span>复制软连接，<span class="hljs-literal">False</span>不复制，软连接会被当成文件复制过来，默认<span class="hljs-literal">False</span><br>ignore：忽略模式，可传入ignore_patterns()<br>copy_function：拷贝文件的方式，可以传入一个可执行的处理函数，默认为copy2，Python3新增参数<br>ignore_dangling_symlinks：sysmlinks设置为<span class="hljs-literal">False</span>时，拷贝指向文件已删除的软连接时，将会报错，如果想消除这个异常，可以设置此值为<span class="hljs-literal">True</span>。默认为<span class="hljs-literal">False</span>,Python3新增参数<br></code></pre></td></tr></tbody></table></figure><h5 id="示例">示例</h5><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> shutil,os<br>shutil.copytree(<span class="hljs-string">"./资料/ceshi"</span>,<span class="hljs-string">"./资料/taiget/"</span>,ignore=shutil.ignore_patterns(<span class="hljs-string">"abc.txt"</span>,<span class="hljs-string">"bcd.txt"</span>))<span class="hljs-comment">#忽略哪些文件</span><br></code></pre></td></tr></tbody></table></figure><h3 id="移动">移动</h3><p><code>shutil.move(src, dst)</code><br>功能：文件移动,可重命名，会删除原文件，新路径需<strong>指定文件名</strong>，注意需要指定文件名，要么可以剪裁文件夹或者文件，要么可以重命名。</p><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">src</span>：**源文件夹或文件**<br><span class="hljs-attribute">dst</span>：**移动至dst文件夹，或将文件改名为dst文件。**如果src为文件夹，而dst为文件将会报错<br><span class="hljs-attribute">copy_function</span>：拷贝文件的方式，可以传入一个可执行的处理函数。默认为copy<span class="hljs-number">2</span>，Python<span class="hljs-number">3</span>新增参数<br></code></pre></td></tr></tbody></table></figure><h5 id="示例-2">`示例</h5><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> shutil<br><span class="hljs-comment">#重命名文件夹</span><br>shutil.move(<span class="hljs-string">'./资料/ceshi'</span>, <span class="hljs-string">'./资料/ceshi1'</span>)<br><span class="hljs-comment">#移动文件进入新移动的文件夹</span><br>shutil.move(<span class="hljs-string">'./资料/1-2.txt'</span>, <span class="hljs-string">'./资料/ceshi1'</span>)<br></code></pre></td></tr></tbody></table></figure><h3 id="删除文件夹">删除文件夹</h3><p>函数：shutil.rmtree(src)<br>含义：删除文件夹；<br>参数：src表示源文件夹；<br>注意：区别这里和os模块中remove()、rmdir()的用法，remove()方法<strong>只能删除某个文件</strong>，<strong>rmdir()只能删除某个空文件夹</strong>。但是shutil模块中的rmtree()可以递归彻底<strong>删除非空文件夹；</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 将c文件夹彻底删除</span><br>src = <span class="hljs-string">r".\publish\os模块\test_shutil_c"</span><br>shutil.rmtree(src)<br></code></pre></td></tr></tbody></table></figure><h3 id="删除文件">删除文件</h3><p>函数：删除文件使用<code>os.remove()</code>函数进行操作</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os  <span class="hljs-comment"># 导入模块</span><br><br><span class="hljs-comment"># 删除目标文件的根目录</span><br>movabs_path = <span class="hljs-string">"删除文件的目录"</span> <br><br><span class="hljs-comment"># 删除操作</span><br>os.remove(rawabs_path+<span class="hljs-string">"test.txt"</span>)<br></code></pre></td></tr></tbody></table></figure><h3 id="解压和压缩文件">解压和压缩文件</h3><p>函数：<code>make_archive(base_name, format, root_dir, …)</code><br>功能：生成压缩文件</p><figure class="highlight stylus"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus">base_name：压缩文件的文件名，不允许有扩展名，因为会根据压缩格式生成相应的扩展名<br>format：压缩格式<br>root_dir：将制定文件夹进行压缩<br><span class="hljs-function"><span class="hljs-title">get_archive_formats</span><span class="hljs-params">()</span></span>： 获取支持的压缩文件格式。目前支持的有：tar、zip、gztar、bztar。在Python3还多支持一种格式xztar<br></code></pre></td></tr></tbody></table></figure><h4 id="示例-3">示例</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> shutil<br><span class="hljs-comment">#指定要压缩的文件</span><br>base_name = <span class="hljs-string">"./资料/2.txt"</span><br><span class="hljs-comment">#指定压缩形式</span><br><span class="hljs-built_in">format</span> = <span class="hljs-string">"zip"</span><br><span class="hljs-comment">#指定压缩后放在哪里</span><br>root_dir = <span class="hljs-string">"./资料/"</span><br><br>shutil.make_archive(base_name, <span class="hljs-built_in">format</span>, root_dir)<br></code></pre></td></tr></tbody></table></figure><p>函数：<code>unpack_archive(filename, extract_dir=None, format=None)</code><br>功能：解压操作</p><figure class="highlight fortran"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs fortran">filename：文件路径<br>extract_dir：解压至的文件夹路径。文件夹可以不存在，会自动生成<br><span class="hljs-keyword">format</span>：解压格式，默认为<span class="hljs-keyword">None</span>，会根据扩展名自动选择解压格式<br></code></pre></td></tr></tbody></table></figure><h4 id="示例-4">示例</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> shutil<br><span class="hljs-comment">#指定压缩文件的地址</span><br>zip_path = <span class="hljs-string">"./资料/2.txt.zip"</span><br><span class="hljs-comment">#指定解压缩到哪里</span><br>extract_dir = <span class="hljs-string">"./资料/ceshi1/"</span><br>shutil.unpack_archive(zip_path, extract_dir)<br></code></pre></td></tr></tbody></table></figure><h2 id="os">os</h2><p>在这里整理os的相关操作哦，粗略记录一下</p><p>参考：<a href="https://blog.csdn.net/silentwolfyh/article/details/74931123">https://blog.csdn.net/silentwolfyh/article/details/74931123</a></p><h3 id="os目录操作">os目录操作</h3><p>1.得到当前工作目录，即当前Python脚本工作的目录路径: os.getcwd()</p><p>2.返回指定目录下的所有文件和目录名:os.listdir()</p><p>3.函数用来删除一个文件:os.remove()</p><p>4.删除多个目录：os.removedirs(r“c：\python”)</p><p>5.检验给出的路径是否是一个文件：os.path.isfile()</p><p>6.检验给出的路径是否是一个目录：os.path.isdir()</p><p>7.判断是否是绝对路径：os.path.isabs()</p><p>8.检验给出的路径是否真地存:os.path.exists()</p><p>9.返回一个路径的目录名和文件名:os.path.split() eg os.path.split(‘/home/swaroop/byte/code/poem.txt’) 结果：(‘/home/swaroop/byte/code’, ‘poem.txt’)</p><p>10.分离扩展名：os.path.splitext()</p><p>11.获取路径名：os.path.dirname()</p><p>12.获取文件名：os.path.basename()</p><p>13.运行shell命令: os.system()</p><p>14.读取和设置环境变量:os.getenv() 与os.putenv()</p><p>15.给出当前平台使用的行终止符:os.linesep Windows使用’\r\n’，Linux使用’\n’而Mac使用’\r’</p><p>16.指示你正在使用的平台：<a href="http://os.name">os.name</a> 对于Windows，它是’nt’，而对于Linux/Unix用户，它是’posix’</p><p>17.重命名：os.rename(old， new)</p><p>18.创建多级目录：os.makedirs(r“c：\python\test”)</p><p>19.创建单个目录：os.mkdir(“test”)</p><p>20.获取文件属性：os.stat(file)</p><p>21.修改文件权限与时间戳：os.chmod(file)</p><p>22.终止当前进程：os.exit()</p><p>23.获取文件大小：os.path.getsize(filename)</p><h3 id="2、文件操作方法大全：">2、文件操作方法大全：</h3><p>1.os.mknod(“test.txt”) #创建空文件</p><p>2.fp = open(“test.txt”,w) #直接打开一个文件，如果文件不存在则创建文件</p><p>3.关于open 模式：</p><p>w：以写方式打开，</p><p>a：以追加模式打开 (从 EOF 开始, 必要时创建新文件)</p><p>r+：以读写模式打开</p><p>w+：以读写模式打开 (参见 w )</p><p>a+：以读写模式打开 (参见 a )</p><p>rb：以二进制读模式打开</p><p>wb：以二进制写模式打开 (参见 w )</p><p>ab：以二进制追加模式打开 (参见 a )</p><p>rb+：以二进制读写模式打开 (参见 r+ )</p><p>wb+：以二进制读写模式打开 (参见 w+ )</p><p>ab+：以二进制读写模式打开 (参见 a+ )</p><p>fp.read([size]) #size为读取的长度，以byte为单位</p><p>fp.readline([size]) #读一行，如果定义了size，有可能返回的只是一行的一部分</p><p>fp.readlines([size]) #把文件每一行作为一个list的一个成员，并返回这个list。其实它的内部是通过循环调用readline()来实现的。如果提供size参数，size是表示读取内容的总长，也就是说可能只读到文件的一部分。</p><p>fp.write(str) #把str写到文件中，write()并不会在str后加上一个换行符</p><p>fp.writelines(seq) #把seq的内容全部写到文件中(多行一次性写入)。这个函数也只是忠实地写入，不会在每行后面加上任何东西。</p><p>fp.close() #关闭文件。python会在一个文件不用后自动关闭文件，不过这一功能没有保证，最好还是养成自己关闭的习惯。 如果一个文件在关闭后还对其进行操作会产生ValueError</p><p>fp.flush() #把缓冲区的内容写入硬盘</p><p>fp.fileno() #返回一个长整型的”文件标签“</p><p>fp.isatty() #文件是否是一个终端设备文件(unix系统中的)</p><p>fp.tell() #返回文件操作标记的当前位置，以文件的开头为原点</p><p>fp.next() #返回下一行，并将文件操作标记位移到下一行。把一个file用于for … in file这样的语句时，就是调用next()函数来实现遍历的。</p><p>fp.seek(offset[,whence]) #将文件打操作标记移到offset的位置。这个offset一般是相对于文件的开头来计算的，一般为正数。但如果提供了whence参数就不一定了，whence可以为0表示从头开始计算，1表示以当前位置为原点计算。2表示以文件末尾为原点进行计算。需要注意，如果文件以a或a+的模式打开，每次进行写操作时，文件操作标记会自动返回到文件末尾。</p><h3 id="3、目录操作方法大全">3、目录操作方法大全</h3><p>1.创建目录</p><p>os.mkdir(“file”)</p>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
      <category>文件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>文件</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer20 有效的括号</title>
    <link href="/2021/11/24/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode20/"/>
    <url>/2021/11/24/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode20/</url>
    
    <content type="html"><![CDATA[<blockquote><p>有效的括号</p></blockquote><h2 id="题目">题目</h2><p>给定一个只包括 ‘(’，‘)’，‘{’，‘}’，‘[’，‘]’&nbsp;的字符串 s ，判断字符串是否有效。</p><p>有效字符串需满足：</p><p>左括号必须用相同类型的右括号闭合。<br>左括号必须以正确的顺序闭合。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">s</span> = <span class="hljs-string">"()"</span><br>输出：<span class="hljs-literal">true</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">s</span> = <span class="hljs-string">"()[]{}"</span><br>输出：<span class="hljs-literal">true</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-3：">示例 3：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">s</span> = <span class="hljs-string">"(]"</span><br>输出：<span class="hljs-literal">false</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-4：">示例 4：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">s</span> = <span class="hljs-string">"([)]"</span><br>输出：<span class="hljs-literal">false</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-5：">示例 5：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">s</span> = <span class="hljs-string">"{[]}"</span><br>输出：<span class="hljs-literal">true</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= s.length &lt;= 104</li><li>s 仅由括号 ‘()[]{}’ 组成</li></ul><h2 id="题解">题解</h2><p>使用<code>栈和字典</code>辅助判断，如果字符是对应括号的右括号，就弹出，否则压入，最后查看栈中是否还剩元素。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">isValid</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">bool</span>:</span><br>        stack = []<br>        mmap = {<span class="hljs-string">'('</span>:<span class="hljs-string">')'</span>,<span class="hljs-string">')'</span>:<span class="hljs-string">'a'</span>,<span class="hljs-string">'{'</span>:<span class="hljs-string">'}'</span>,<span class="hljs-string">'}'</span>:<span class="hljs-string">'b'</span>,<span class="hljs-string">'['</span>:<span class="hljs-string">']'</span>,<span class="hljs-string">']'</span>:<span class="hljs-string">'c'</span>}<br>        <span class="hljs-keyword">for</span> ch <span class="hljs-keyword">in</span> s:<br>            <span class="hljs-keyword">if</span>(stack):<br>                top = stack[<span class="hljs-built_in">len</span>(stack)-<span class="hljs-number">1</span>]<br>            <span class="hljs-keyword">if</span>(<span class="hljs-keyword">not</span> stack <span class="hljs-keyword">or</span> mmap[top] != ch):<br>                stack.append(ch)<br>            <span class="hljs-keyword">elif</span>(stack <span class="hljs-keyword">and</span>  mmap[top] == ch):<br>                stack.pop()<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">not</span> stack<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>栈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>栈</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer859 亲密字符串</title>
    <link href="/2021/11/23/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer859/"/>
    <url>/2021/11/23/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer859/</url>
    
    <content type="html"><![CDATA[<blockquote><p>亲密字符串</p></blockquote><h2 id="题目">题目</h2><p>给你两个字符串 s 和 goal ，只要我们可以通过交换 s 中的两个字母得到与 goal 相等的结果，就返回 true ；否则返回 false 。</p><p>交换字母的定义是：取两个下标 i 和 j （下标从 0 开始）且满足 i != j ，接着交换 s[i] 和 s[j] 处的字符。</p><ul><li>例如，在 “abcd” 中交换下标 0 和下标 2 的元素可以生成 “cbad” 。</li></ul><h3 id="示例-1：">示例 1：</h3><figure class="highlight mel"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mel">输入：s = <span class="hljs-string">"ab"</span>, <span class="hljs-keyword">goal</span> = <span class="hljs-string">"ba"</span><br>输出：true<br>解释：你可以交换 s[<span class="hljs-number">0</span>] = <span class="hljs-string">'a'</span> 和 s[<span class="hljs-number">1</span>] = <span class="hljs-string">'b'</span> 生成 <span class="hljs-string">"ba"</span>，此时 s 和 <span class="hljs-keyword">goal</span> 相等。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight mel"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mel">输入：s = <span class="hljs-string">"ab"</span>, <span class="hljs-keyword">goal</span> = <span class="hljs-string">"ab"</span><br>输出：false<br>解释：你只能交换 s[<span class="hljs-number">0</span>] = <span class="hljs-string">'a'</span> 和 s[<span class="hljs-number">1</span>] = <span class="hljs-string">'b'</span> 生成 <span class="hljs-string">"ba"</span>，此时 s 和 <span class="hljs-keyword">goal</span> 不相等。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-3：">示例 3：</h3><figure class="highlight mel"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mel">输入：s = <span class="hljs-string">"aa"</span>, <span class="hljs-keyword">goal</span> = <span class="hljs-string">"aa"</span><br>输出：true<br>解释：你可以交换 s[<span class="hljs-number">0</span>] = <span class="hljs-string">'a'</span> 和 s[<span class="hljs-number">1</span>] = <span class="hljs-string">'a'</span> 生成 <span class="hljs-string">"aa"</span>，此时 s 和 <span class="hljs-keyword">goal</span> 相等。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-4：">示例 4：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">s</span> = <span class="hljs-string">"aaaaaaabc"</span>, <span class="hljs-attr">goal</span> = <span class="hljs-string">"aaaaaaacb"</span><br>输出：<span class="hljs-literal">true</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= s.length, goal.length &lt;= 2 * 104</li><li>s 和 goal 由小写英文字母组成</li></ul><h2 id="题解">题解</h2><p>首先判断两个字符串的长度，如果长度不一致就直接返回False，diff用来存储两个字符串不同的字符的相应下标；然后判断diff的元素是否满足要求：</p><p>1，diff有两个元素并且这两个元素在列表中对应相等；</p><p>2，diff中元素为空（两个字符串相等），同时s中有重复字符（使用set来判断）；</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">buddyStrings</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span>, goal: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">bool</span>:</span><br>        <span class="hljs-keyword">if</span>(<span class="hljs-built_in">len</span>(s)!=<span class="hljs-built_in">len</span>(goal)):<span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>        <span class="hljs-comment"># if(s==goal and len(set(s))!=len(s)): return True #放在前面会增加判断时间 相当于O(2N)</span><br>        diff = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(s)):<br>            <span class="hljs-keyword">if</span>(s[i]!=goal[i]):diff.append(i)<br>        <span class="hljs-keyword">if</span>(<span class="hljs-built_in">len</span>(diff)==<span class="hljs-number">2</span> <span class="hljs-keyword">and</span> s[diff[<span class="hljs-number">0</span>]]==goal[diff[<span class="hljs-number">1</span>]] <span class="hljs-keyword">and</span> s[diff[<span class="hljs-number">1</span>]]==goal[diff[<span class="hljs-number">0</span>]]): <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>        <span class="hljs-keyword">if</span>(<span class="hljs-built_in">len</span>(diff)==<span class="hljs-number">0</span> <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(<span class="hljs-built_in">set</span>(s))!=<span class="hljs-built_in">len</span>(s)): <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>字符串</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>字符串</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer32-3 从上到下打印二叉树 Ⅲ</title>
    <link href="/2021/11/22/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer32-3/"/>
    <url>/2021/11/22/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer32-3/</url>
    
    <content type="html"><![CDATA[<blockquote><p>从上到下打印二叉树 Ⅲ</p></blockquote><h2 id="题目">题目</h2><p>请实现一个函数按照之字形顺序打印二叉树，即第一行按照从左到右的顺序打印，第二层按照从右到左的顺序打印，第三行再按照从左到右的顺序打印，其他行以此类推。</p><h3 id="示例-1：">示例 1：</h3><p>例如:<br>给定二叉树: <code>[3,9,20,null,null,15,7]</code>,</p><figure class="highlight livescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs livescript">  <span class="hljs-number">3</span><br> / <span class="hljs-string">\</span><br><span class="hljs-number">9</span>  <span class="hljs-number">20</span><br>  /  <span class="hljs-string">\</span><br> <span class="hljs-number">15</span>   <span class="hljs-number">7</span><br></code></pre></td></tr></tbody></table></figure><p>返回其层次遍历结果：</p><figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs json">[<br>  [<span class="hljs-number">3</span>],<br>  [<span class="hljs-number">20</span>,<span class="hljs-number">9</span>],<br>  [<span class="hljs-number">15</span>,<span class="hljs-number">7</span>]<br>]<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><code>节点总数 &lt;= 1000</code></li></ul><h2 id="题解">题解</h2><h4 id="解法一">解法一</h4><p>记录本层的数字个数，将本层的元素全部弹出到列表中，同时将下层元素压进队列中；只是要根据flag，来将列表倒序 。</p><blockquote><p>列表倒叙的方法：</p><p>1，temp.reverse()  直接原地修改哦~</p><p>2，temp = temp[::-1]</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for a binary tree node.</span><br><span class="hljs-comment"># class TreeNode:</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.left = None</span><br><span class="hljs-comment">#         self.right = None</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">levelOrder</span>(<span class="hljs-params">self, root: TreeNode</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]:</span><br>        <span class="hljs-keyword">if</span>(<span class="hljs-keyword">not</span> root):<span class="hljs-keyword">return</span> []<br>        queue ,result,flag = deque(),[],<span class="hljs-literal">False</span><br>        queue.append(root)<br>        <span class="hljs-keyword">while</span>(queue):<br>            tmp = []<br>            num = <span class="hljs-built_in">len</span>(queue)<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num):<br>                top = queue.popleft()<br>                tmp.append(top.val)<br>                <span class="hljs-keyword">if</span>(top.left): queue.append(top.left)<br>                <span class="hljs-keyword">if</span>(top.right): queue.append(top.right)<br>            <span class="hljs-keyword">if</span> flag: tmp = tmp[::-<span class="hljs-number">1</span>] <span class="hljs-comment">#tmp.reverse() # tmp = tmp[::-1]</span><br>            flag = <span class="hljs-keyword">not</span> flag<br>            result.append(<span class="hljs-built_in">list</span>(tmp))<br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></tbody></table></figure><h4 id="解法二">解法二</h4><p>去掉倒叙的操作，根据flag的值更改tmp的插入方向，将tmp声明为<code>deque()</code>，右插为<code>append</code>,左插为<code>appendleft</code>；</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for a binary tree node.</span><br><span class="hljs-comment"># class TreeNode:</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.left = None</span><br><span class="hljs-comment">#         self.right = None</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">levelOrder</span>(<span class="hljs-params">self, root: TreeNode</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]:</span><br>        <span class="hljs-keyword">if</span>(<span class="hljs-keyword">not</span> root):<span class="hljs-keyword">return</span> []<br>        queue ,result,flag = deque(),[],<span class="hljs-literal">False</span><br>        queue.append(root)<br>        <span class="hljs-keyword">while</span>(queue):<br>            tmp = deque()<br>            num = <span class="hljs-built_in">len</span>(queue)<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num):<br>                top = queue.popleft()<br>                <span class="hljs-keyword">if</span> flag: tmp.appendleft(top.val)<br>                <span class="hljs-keyword">else</span>:tmp.append(top.val)<br>                <span class="hljs-keyword">if</span>(top.left): queue.append(top.left)<br>                <span class="hljs-keyword">if</span>(top.right): queue.append(top.right)<br>            flag = <span class="hljs-keyword">not</span> flag<br>            result.append(<span class="hljs-built_in">list</span>(tmp))<br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>树</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer32-1 从上到下打印二叉树</title>
    <link href="/2021/11/21/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer32-1/"/>
    <url>/2021/11/21/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer32-1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>从上到下打印二叉树</p></blockquote><h2 id="题目">题目</h2><p>从上到下打印出二叉树的每个节点，同一层的节点按照从左到右的顺序打印。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight livescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs livescript">例如:<br>给定二叉树: [<span class="hljs-number">3</span>,<span class="hljs-number">9</span>,<span class="hljs-number">20</span>,<span class="hljs-literal">null</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">15</span>,<span class="hljs-number">7</span>],<br>    <span class="hljs-number">3</span><br>   / <span class="hljs-string">\</span><br>  <span class="hljs-number">9</span>  <span class="hljs-number">20</span><br>    /  <span class="hljs-string">\</span><br>   <span class="hljs-number">15</span>   <span class="hljs-number">7</span><br> 返回：  <br>   [<span class="hljs-number">3</span>,<span class="hljs-number">9</span>,<span class="hljs-number">20</span>,<span class="hljs-number">15</span>,<span class="hljs-number">7</span>]<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>节点总数 &lt;= 1000</li></ul><h2 id="题解">题解</h2><p>常规的层序遍历</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for a binary tree node.</span><br><span class="hljs-comment"># class TreeNode:</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.left = None</span><br><span class="hljs-comment">#         self.right = None</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">levelOrder</span>(<span class="hljs-params">self, root: TreeNode</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root:<span class="hljs-keyword">return</span> []<br>        queue = deque()<br>        result = []<br>        queue.append(root)<br>        <span class="hljs-keyword">while</span>(queue):<br>            top = queue.popleft()<br>            result.append(top.val)<br>            <span class="hljs-keyword">if</span> top.left:queue.append(top.left)<br>            <span class="hljs-keyword">if</span> top.right:queue.append(top.right)<br>        <span class="hljs-keyword">return</span> result<br><br><span class="hljs-comment">#如果按照层数来打印，那么记录每次的queue长度（本层长度），按照现有队列中的元素来（本层）压入后续元素（下一层）。就可以分层次打印</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>树</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer38 字符串的排列</title>
    <link href="/2021/11/20/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer38/"/>
    <url>/2021/11/20/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer38/</url>
    
    <content type="html"><![CDATA[<blockquote><p>字符串的排列</p></blockquote><h2 id="题目">题目</h2><p>输入一个字符串，打印出该字符串中字符的所有排列。</p><p>你可以以任意顺序返回这个字符串数组，但里面不能有重复元素。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">s</span> = <span class="hljs-string">"abc"</span><br>输出：[<span class="hljs-string">"abc"</span>,<span class="hljs-string">"acb"</span>,<span class="hljs-string">"bac"</span>,<span class="hljs-string">"bca"</span>,<span class="hljs-string">"cab"</span>,<span class="hljs-string">"cba"</span>]<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= s 的长度 &lt;= 8</li></ul><h2 id="题解">题解</h2><h4 id="思路一">思路一</h4><p>固定s的第一个元素,得到去掉这个元素的后续元素的全排列情况（递归调用）;</p><p>第一个元素的确定方法使用循环遍历，但是这里要s中可能存在重复元素，因此需要使用set去掉重复元素，也有剪枝的作用；</p><blockquote><p>去掉字符串的某元素（或者字符串）的方法</p><p>使用replace函数替换字符为空–<strong><code>s.replace(x,'',1)</code></strong></p><ul><li><p>replace方法</p><p><code>str.replace(old,new,max=string.count(old)）</code></p></li></ul><p>最多替换max个old字符为new字符，默认全部替换，这里只替换1个哦~</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">permutation</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]:</span><br>        <span class="hljs-keyword">if</span>(<span class="hljs-keyword">not</span> s): <span class="hljs-keyword">return</span> [] <br>        <span class="hljs-keyword">if</span>(<span class="hljs-built_in">len</span>(s)==<span class="hljs-number">1</span>): <span class="hljs-keyword">return</span> [s]<br>        result = []<br>        sset = <span class="hljs-built_in">set</span>(s)<br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> sset:<br>           temp = [x + item <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> self.permutation(s.replace(x,<span class="hljs-string">''</span>,<span class="hljs-number">1</span>))]<br>           result += temp<br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></tbody></table></figure><h4 id="思路二">思路二</h4><p>使用深度优先遍历的思想，模拟为树的遍历节点，遍历x位置处为x及x之后索引元素的情况，dfs(x) 是固定前面0到x，来深优x此元素情况。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">permutation</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]:</span><br>        c, res = <span class="hljs-built_in">list</span>(s), []<br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dfs</span>(<span class="hljs-params">x</span>):</span><br>            <span class="hljs-keyword">if</span> x == <span class="hljs-built_in">len</span>(c) - <span class="hljs-number">1</span>:<br>                res.append(<span class="hljs-string">''</span>.join(c))   <span class="hljs-comment"># 添加排列方案</span><br>                <span class="hljs-keyword">return</span><br>            dic = <span class="hljs-built_in">set</span>()<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(x, <span class="hljs-built_in">len</span>(c)):<br>                <span class="hljs-keyword">if</span> c[i] <span class="hljs-keyword">in</span> dic: <span class="hljs-keyword">continue</span> <span class="hljs-comment"># 重复，因此剪枝</span><br>                dic.add(c[i])<br>                c[i], c[x] = c[x], c[i]  <span class="hljs-comment"># 交换，将 c[i] 固定在第 x 位</span><br>                dfs(x + <span class="hljs-number">1</span>)               <span class="hljs-comment"># 开启固定第 x + 1 位字符</span><br>                c[i], c[x] = c[x], c[i]  <span class="hljs-comment"># 恢复交换</span><br>        dfs(<span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> res<br><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>递归</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>递归</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer31 栈的压入，弹出序列</title>
    <link href="/2021/11/19/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer31/"/>
    <url>/2021/11/19/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer31/</url>
    
    <content type="html"><![CDATA[<blockquote><p>栈的压入，弹出序列</p></blockquote><h2 id="题目">题目</h2><p>输入两个整数序列，第一个序列表示栈的压入顺序，请判断第二个序列是否为该栈的弹出顺序。假设压入栈的所有数字均不相等。例如，序列 {1,2,3,4,5} 是某栈的压栈序列，序列 {4,5,3,2,1} 是该压栈序列对应的一个弹出序列，但 {4,3,5,1,2} 就不可能是该压栈序列的弹出序列。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight livescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs livescript">输入：pushed = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>], popped = [<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>]<br>输出：<span class="hljs-literal">true</span><br>解释：我们可以按以下顺序执行：<br>push<span class="hljs-function"><span class="hljs-params">(<span class="hljs-number">1</span>)</span>, <span class="hljs-title">push</span><span class="hljs-params">(<span class="hljs-number">2</span>)</span>, <span class="hljs-title">push</span><span class="hljs-params">(<span class="hljs-number">3</span>)</span>, <span class="hljs-title">push</span><span class="hljs-params">(<span class="hljs-number">4</span>)</span>, <span class="hljs-title">pop</span><span class="hljs-params">()</span> -&gt;</span> <span class="hljs-number">4</span>,<br>push<span class="hljs-function"><span class="hljs-params">(<span class="hljs-number">5</span>)</span>, <span class="hljs-title">pop</span><span class="hljs-params">()</span> -&gt;</span> <span class="hljs-number">5</span>, pop<span class="hljs-function"><span class="hljs-params">()</span> -&gt;</span> <span class="hljs-number">3</span>, pop<span class="hljs-function"><span class="hljs-params">()</span> -&gt;</span> <span class="hljs-number">2</span>, pop<span class="hljs-function"><span class="hljs-params">()</span> -&gt;</span> <span class="hljs-number">1</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">pushed</span> = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>], <span class="hljs-attr">popped</span> = [<span class="hljs-number">4</span>,<span class="hljs-number">3</span>,<span class="hljs-number">5</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]<br>输出：<span class="hljs-literal">false</span><br>解释：<span class="hljs-number">1</span> 不能在 <span class="hljs-number">2</span> 之前弹出。<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>0 &lt;= pushed.length == popped.length &lt;= 1000</li><li>0 &lt;= pushed[i], popped[i] &lt; 1000</li><li>pushed&nbsp;是&nbsp;popped&nbsp;的排列。</li></ul><h2 id="题解">题解</h2><p>按照压入和弹出序列可以双向唯一确定栈的压入弹出的顺序，所以按照对应的此序列，可以模拟压出和弹出的场景，最终如果可以成立，那么栈中的数据应该全部弹出了。<br>具体的做法就是按照压入序列的顺序，每压入一个数值，就比对弹出序列的值，查看是否可以弹出，等到压入的数值都处理完成，查看栈是否为空，如果不是空就说明弹出序列时不能匹配的。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">validateStackSequences</span>(<span class="hljs-params">self, pushed: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], popped: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">bool</span>:</span><br>        <span class="hljs-comment">#模拟场景</span><br>        stack = []<br>        i = <span class="hljs-number">0</span><br>        j = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">while</span>(i&lt;<span class="hljs-built_in">len</span>(pushed)):<br>            stack.append(pushed[i])<br>            <span class="hljs-keyword">while</span>(<span class="hljs-built_in">len</span>(stack) <span class="hljs-keyword">and</span> stack[<span class="hljs-built_in">len</span>(stack)-<span class="hljs-number">1</span>]==popped[j]):<br>                j += <span class="hljs-number">1</span><br>                stack.pop()<br>            i += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">not</span> stack<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>栈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>栈</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offerleetcode-offer563 二叉树的坡度</title>
    <link href="/2021/11/18/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer563/"/>
    <url>/2021/11/18/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer563/</url>
    
    <content type="html"><![CDATA[<blockquote><p>二叉树的坡度</p></blockquote><h2 id="题目">题目</h2><p>给定一个二叉树，计算 整个树 的坡度 。<br>一个树的 节点的坡度 定义即为，该节点左子树的节点之和和右子树节点之和的 差的绝对值 。如果没有左子树的话，左子树的节点之和为 0 ；没有右子树的话也是一样。空结点的坡度是 0 。</p><p>整个树 的坡度就是其所有节点的坡度之和。</p><h3 id="示例-1：">示例 1：</h3><p><img src="https://assets.leetcode.com/uploads/2020/10/20/tilt1.jpg" alt="img"></p><figure class="highlight tap"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs tap">输入：root = [1,2,3]<br>输出：1<br>解释：<br>节点<span class="hljs-number"> 2 </span>的坡度：|0-0| = 0（没有子节点）<br>节点<span class="hljs-number"> 3 </span>的坡度：|0-0| = 0（没有子节点）<br>节点<span class="hljs-number"> 1 </span>的坡度：|2-3| = 1（左子树就是左子节点，所以和是<span class="hljs-number"> 2 </span>；右子树就是右子节点，所以和是<span class="hljs-number"> 3 </span>）<br>坡度总和：0 +<span class="hljs-number"> 0 </span>+<span class="hljs-number"> 1 </span>= 1<br><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><p><img src="https://assets.leetcode.com/uploads/2020/10/20/tilt1.jpg" alt="img"></p><figure class="highlight tap"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs tap">输入：root = [4,2,9,3,5,null,7]<br>输出：15<br>解释：<br>节点<span class="hljs-number"> 3 </span>的坡度：|0-0| = 0（没有子节点）<br>节点<span class="hljs-number"> 5 </span>的坡度：|0-0| = 0（没有子节点）<br>节点<span class="hljs-number"> 7 </span>的坡度：|0-0| = 0（没有子节点）<br>节点<span class="hljs-number"> 2 </span>的坡度：|3-5| = 2（左子树就是左子节点，所以和是<span class="hljs-number"> 3 </span>；右子树就是右子节点，所以和是<span class="hljs-number"> 5 </span>）<br>节点<span class="hljs-number"> 9 </span>的坡度：|0-7| = 7（没有左子树，所以和是<span class="hljs-number"> 0 </span>；右子树正好是右子节点，所以和是<span class="hljs-number"> 7 </span>）<br>节点<span class="hljs-number"> 4 </span>的坡度：|(3+5+2)-(9+7)| = |10-16| = 6（左子树值为 3、5 和<span class="hljs-number"> 2 </span>，和是<span class="hljs-number"> 10 </span>；右子树值为<span class="hljs-number"> 9 </span>和<span class="hljs-number"> 7 </span>，和是<span class="hljs-number"> 16 </span>）<br>坡度总和：0 +<span class="hljs-number"> 0 </span>+<span class="hljs-number"> 0 </span>+<span class="hljs-number"> 2 </span>+<span class="hljs-number"> 7 </span>+<span class="hljs-number"> 6 </span>= 15<br><br><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-3：">示例 3：</h3><p><img src="https://assets.leetcode.com/uploads/2020/10/20/tilt3.jpg" alt="img"></p><figure class="highlight dns"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs dns">输入：root = [<span class="hljs-number">21,7,14,1</span>,<span class="hljs-number">1,2,2,3</span>,<span class="hljs-number">3</span>]<br>输出：<span class="hljs-number">9</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>树中节点数目的范围在 <code>[0, 104]</code> 内</li><li><code>-1000 &lt;= Node.val &lt;= 1000</code></li></ul><h2 id="题解">题解</h2><p>可以使用两个函数，一个计算树的各个节点的子树之和，一个用于计算对应的差值之和。在计算子树之和时可以直接用后序遍历，<strong>更新节点的val值为子树和</strong>。此时的时间复杂度为O(2N)。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for a binary tree node.</span><br><span class="hljs-comment"># class TreeNode:</span><br><span class="hljs-comment">#     def __init__(self, val=0, left=None, right=None):</span><br><span class="hljs-comment">#         self.val = val</span><br><span class="hljs-comment">#         self.left = left</span><br><span class="hljs-comment">#         self.right = right</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">findTilt</span>(<span class="hljs-params">self, root: TreeNode</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">setaddTree</span>(<span class="hljs-params">root</span>):</span> <span class="hljs-comment">#后序遍历</span><br>            <span class="hljs-keyword">if</span>(<span class="hljs-keyword">not</span> root):<span class="hljs-keyword">return</span> <br>            setaddTree(root.left)<br>            setaddTree(root.right)<br>            Tleft = root.left.val <span class="hljs-keyword">if</span> root.left <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>            Tright = root.right.val <span class="hljs-keyword">if</span> root.right <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>            root.val = root.val + Tleft + Tright<br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">minasTree</span>(<span class="hljs-params">root</span>):</span><br>            <span class="hljs-keyword">if</span>(<span class="hljs-keyword">not</span> root): <span class="hljs-keyword">return</span> <br>            Tleft = root.left.val <span class="hljs-keyword">if</span> root.left <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>            Tright = root.right.val <span class="hljs-keyword">if</span> root.right <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>            self.sumResult += <span class="hljs-built_in">abs</span>(Tleft - Tright)<br>            minasTree(root.left)<br>            minasTree(root.right)<br>        self.sumResult = <span class="hljs-number">0</span><br>        setaddTree(root)<br>        minasTree(root)<br>        <span class="hljs-keyword">return</span> self.sumResult<br></code></pre></td></tr></tbody></table></figure><p>实际上无需两个函数，<strong>在后序遍历求和的时候就可以得到子树的差值</strong>，将其累加即可。时间复杂度为O(N)，空间复杂度为O(1)。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for a binary tree node.</span><br><span class="hljs-comment"># class TreeNode:</span><br><span class="hljs-comment">#     def __init__(self, val=0, left=None, right=None):</span><br><span class="hljs-comment">#         self.val = val</span><br><span class="hljs-comment">#         self.left = left</span><br><span class="hljs-comment">#         self.right = right</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">findTilt</span>(<span class="hljs-params">self, root: TreeNode</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">setaddTree</span>(<span class="hljs-params">root</span>):</span> <span class="hljs-comment">#后序遍历</span><br>            <span class="hljs-keyword">if</span>(<span class="hljs-keyword">not</span> root):<span class="hljs-keyword">return</span> <br>            setaddTree(root.left)<br>            setaddTree(root.right)<br>            Tleft = root.left.val <span class="hljs-keyword">if</span> root.left <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>            Tright = root.right.val <span class="hljs-keyword">if</span> root.right <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>            root.val = root.val + Tleft + Tright<br>            self.sumResult += <span class="hljs-built_in">abs</span>(Tleft - Tright)<br><br>        self.sumResult = <span class="hljs-number">0</span><br>        setaddTree(root)<br>        <span class="hljs-keyword">return</span> self.sumResult<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>树</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer57 和为s的两个数字</title>
    <link href="/2021/11/17/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer57/"/>
    <url>/2021/11/17/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer57/</url>
    
    <content type="html"><![CDATA[<blockquote><p>和为s的两个数字</p></blockquote><h2 id="题目">题目</h2><p>输入一个递增排序的数组和一个数字s，在数组中查找两个数，使得它们的和正好是s。如果有多对数字的和等于s，则输出任意一对即可。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：nums = <span class="hljs-comment">[2,7,11,15]</span>, target = 9<br>输出：<span class="hljs-comment">[2,7]</span> 或者 <span class="hljs-comment">[7,2]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：nums = <span class="hljs-comment">[10,26,30,31,47,60]</span>, target = 40<br>输出：<span class="hljs-comment">[10,30]</span> 或者 <span class="hljs-comment">[30,10]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= nums.length &lt;= 10^5</li><li>1 &lt;= nums[i] &lt;= 10^6</li></ul><h2 id="题解">题解</h2><p>因为时单调递增的数组，那么可以直接从两端找起，向中间收缩。可以用递归的双指针，也可以使用while循环遍历，时间复杂度为O(N)。</p><h4 id="递归">递归</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">twoSum</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">find</span>(<span class="hljs-params">left,right</span>):</span><br>            <span class="hljs-keyword">if</span>(left&gt;=right): <span class="hljs-keyword">return</span><br>            <span class="hljs-keyword">if</span>(nums[left]+nums[right]==target): <br>                self.result = [nums[left],nums[right]]<br>                <span class="hljs-keyword">return</span><br>            <span class="hljs-keyword">if</span>(nums[left]+nums[right]&gt;target): find(left,right-<span class="hljs-number">1</span>)<br>            <span class="hljs-keyword">else</span>: find(left+<span class="hljs-number">1</span>,right)<br>        self.result = []<br>        find(<span class="hljs-number">0</span>,<span class="hljs-built_in">len</span>(nums)-<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> self.result<br></code></pre></td></tr></tbody></table></figure><h4 id="循环">循环</h4><p>使用while循环比使用递归的方法，空间复杂度更小，更快。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">twoSum</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:</span><br>        left,right = <span class="hljs-number">0</span>,<span class="hljs-built_in">len</span>(nums)-<span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span>(left&lt;right):<br>            <span class="hljs-keyword">if</span>(nums[left]+nums[right]==target): <span class="hljs-keyword">return</span> [nums[left],nums[right]]<br>            <span class="hljs-keyword">elif</span>(nums[left]+nums[right]&lt;target): left+=<span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>: right -= <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> []<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>双指针</category>
      
    </categories>
    
    
    <tags>
      
      <tag>双指针</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer55-Ⅰ 二叉树的深度</title>
    <link href="/2021/11/16/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer55-1/"/>
    <url>/2021/11/16/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer55-1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>二叉树的深度</p></blockquote><h2 id="题目">题目</h2><p>输入一棵二叉树的根节点，求该树的深度。从根节点到叶节点依次经过的节点（含根、叶节点）形成树的一条路径，最长路径的长度为树的深度。</p><h3 id="示例-1：">示例 1：</h3><p>例如：</p><p>给定二叉树<code> [3,9,20,null,null,15,7]</code>,</p><figure class="highlight livescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs livescript"> <span class="hljs-number">3</span><br> / <span class="hljs-string">\</span><br><span class="hljs-number">9</span>  <span class="hljs-number">20</span><br>  /  <span class="hljs-string">\</span><br> <span class="hljs-number">15</span>   <span class="hljs-number">7</span><br></code></pre></td></tr></tbody></table></figure><p>返回它的最大深度 3 。</p><h3 id="提示：">提示：</h3><ul><li>节点总数 &lt;= 10000</li></ul><h2 id="题解">题解</h2><h4 id="解法一">解法一</h4><p>直接深度优先遍历即可，直接利用<code>maxDepth</code>函数，注意在内部调用<code>maxDepth</code>函数时要使用<code>self</code>来调用本函数。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for a binary tree node.</span><br><span class="hljs-comment"># class TreeNode:</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.left = None</span><br><span class="hljs-comment">#         self.right = None</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maxDepth</span>(<span class="hljs-params">self, root: TreeNode</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root:<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> + <span class="hljs-built_in">max</span>(self.maxDepth(root.left),self.maxDepth(root.right))<br><br></code></pre></td></tr></tbody></table></figure><h4 id="解法二">解法二</h4><p>直接使用层序遍历得到深度。使用两个列表<code>tmp</code>和<code>queue</code>结合实现“队列”的作用。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maxDepth</span>(<span class="hljs-params">self, root: TreeNode</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root: <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>        queue, res = [root], <span class="hljs-number">0</span>        <span class="hljs-comment">#使用列表实现queue</span><br>        <span class="hljs-keyword">while</span> queue:<br>            tmp = []                  <span class="hljs-comment">#初始化 保存一层的信息</span><br>            <span class="hljs-keyword">for</span> node <span class="hljs-keyword">in</span> queue:        <span class="hljs-comment">#将queue的下一层都添加到tmp中</span><br>                <span class="hljs-keyword">if</span> node.left: tmp.append(node.left)<br>                <span class="hljs-keyword">if</span> node.right: tmp.append(node.right)<br>            queue = tmp               <span class="hljs-comment">#更新</span><br>            res += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> res<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>树</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer50 第一个只出现一次的字符</title>
    <link href="/2021/11/15/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer50/"/>
    <url>/2021/11/15/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer50/</url>
    
    <content type="html"><![CDATA[<blockquote><p>第一个只出现一次的字符</p></blockquote><h2 id="题目">题目</h2><p>在字符串 s 中找出第一个只出现一次的字符。如果没有，返回一个单空格。 s 只包含小写字母。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight 1c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs 1c">输入：s = <span class="hljs-string">"abaccdeff"</span><br>输出：'b'<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight 1c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs 1c">输入：s = <span class="hljs-string">""</span> <br>输出：' '<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>0 &lt;= s 的长度 &lt;= 50000</li></ul><h2 id="题解">题解</h2><p>方法是使用哈希表记录字符状态。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">firstUniqChar</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">str</span>:</span><br>        flag = {}<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> s:<br>            <span class="hljs-comment"># if(i in flag):</span><br>            <span class="hljs-comment">#     flag[i] += 1</span><br>            <span class="hljs-comment"># else:</span><br>            <span class="hljs-comment">#     flag[i] = 1</span><br>            flag[i] = <span class="hljs-keyword">not</span> i <span class="hljs-keyword">in</span> flag <span class="hljs-comment">#可以直接标记 没出现则为真</span><br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> flag:<br>            <span class="hljs-keyword">if</span>(flag[x]): <span class="hljs-keyword">return</span> x<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">' '</span><br></code></pre></td></tr></tbody></table></figure><p>在查看字典中是否存在k键时，python2可以使用<code>dict.has_key(k)</code>,但是python3已经删除此函数，直接使用<code>k in dict</code>，同时如果遍历dict，也是返回的key哦。<br>另外，这里无需记录每个字符的个数，只需要标记真假即可。</p>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>哈希表</category>
      
    </categories>
    
    
    <tags>
      
      <tag>哈希表</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指leetcode-offer32-Ⅱ 从上到下打印二叉树Ⅱ</title>
    <link href="/2021/11/12/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer32/"/>
    <url>/2021/11/12/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer32/</url>
    
    <content type="html"><![CDATA[<blockquote><p>从上到下打印二叉树Ⅱ</p></blockquote><h2 id="题目">题目</h2><p>从上到下按层打印二叉树，同一层的节点按从左到右的顺序打印，每一层打印到一行。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight livescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs livescript">例如:<br>给定二叉树: [<span class="hljs-number">3</span>,<span class="hljs-number">9</span>,<span class="hljs-number">20</span>,<span class="hljs-literal">null</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">15</span>,<span class="hljs-number">7</span>],<br>    <span class="hljs-number">3</span><br>   / <span class="hljs-string">\</span><br>  <span class="hljs-number">9</span>  <span class="hljs-number">20</span><br>    /  <span class="hljs-string">\</span><br>   <span class="hljs-number">15</span>   <span class="hljs-number">7</span><br></code></pre></td></tr></tbody></table></figure><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs inform7">返回其层次遍历结果：<br><br><span class="hljs-comment">[</span><br><span class="hljs-comment">  <span class="hljs-comment">[3]</span>,</span><br><span class="hljs-comment">  <span class="hljs-comment">[9,20]</span>,</span><br><span class="hljs-comment">  <span class="hljs-comment">[15,7]</span></span><br><span class="hljs-comment">]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>节点总数 &lt;= 1000</li></ul><h2 id="题解">题解</h2><h4 id="解法一">解法一</h4><p>其实是层序遍历，注意是按照深度标识的层序遍历。在python中是使用deque这个数据结构实现的，是一个双向队列。<br>在右端输出输出是采用<code>append</code> 和<code>pop</code>，在左端输入输出采用的是<code>appendleft</code>和<code>popleft</code>。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for a binary tree node.</span><br><span class="hljs-comment"># class TreeNode:</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.left = None</span><br><span class="hljs-comment">#         self.right = None</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">levelOrder</span>(<span class="hljs-params">self, root: TreeNode</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]:</span><br>        <span class="hljs-keyword">if</span>(<span class="hljs-keyword">not</span> root):<br>            <span class="hljs-keyword">return</span> []<br>        x = deque()<br>        result = []<br>        temp = []<br>        depth = -<span class="hljs-number">1</span><br>        x.append((root,<span class="hljs-number">0</span>))<br>        <span class="hljs-keyword">while</span>(<span class="hljs-built_in">len</span>(x)):<br>            item = x.popleft()<br>            <span class="hljs-keyword">if</span>(depth!=-<span class="hljs-number">1</span> <span class="hljs-keyword">and</span> depth!=item[<span class="hljs-number">1</span>]):<br>                result.append(temp)<br>                temp = []<br>                <span class="hljs-comment"># temp.clear() # temp.clear()很危险，append就应该使用result.append(temp.copy()) 因为append进去的是引用格式的 或者重新初始化temp</span><br>            temp.append(item[<span class="hljs-number">0</span>].val)  <br>            depth = item[<span class="hljs-number">1</span>]<br>            <span class="hljs-keyword">if</span> item[<span class="hljs-number">0</span>].left: x.append((item[<span class="hljs-number">0</span>].left,item[<span class="hljs-number">1</span>]+<span class="hljs-number">1</span>))<br>            <span class="hljs-keyword">if</span> item[<span class="hljs-number">0</span>].right: x.append((item[<span class="hljs-number">0</span>].right,item[<span class="hljs-number">1</span>]+<span class="hljs-number">1</span>))<br>        <span class="hljs-keyword">if</span>(temp):<br>            result.append(temp)<br>        <span class="hljs-keyword">return</span> result<br><br></code></pre></td></tr></tbody></table></figure><p>python要注意的坑点是在如果将temp加到列表之后，将temp清空，随之list中的列表内容也会清空，相当于说在两个temp是指向同一个地址块，所以需要重新temp初始化，或者在append时使用copy函数进行深拷贝。</p><h4 id="解法二">解法二</h4><p>更简便的方法是可以直接把每一轮的输出到result中。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">levelOrder</span>(<span class="hljs-params">self, root: TreeNode</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]:</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root: <span class="hljs-keyword">return</span> []<br>        res, queue = [], collections.deque()<br>        queue.append(root)<br>        <span class="hljs-keyword">while</span> queue:<br>            tmp = []<br>            <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(queue)):<br>                node = queue.popleft()<br>                tmp.append(node.val)<br>                <span class="hljs-keyword">if</span> node.left: queue.append(node.left)<br>                <span class="hljs-keyword">if</span> node.right: queue.append(node.right)<br>            res.append(tmp)<br>        <span class="hljs-keyword">return</span> res<br><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>队列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>队列</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer39 数组中出现次数超过一半的数字</title>
    <link href="/2021/11/04/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer39/"/>
    <url>/2021/11/04/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer39/</url>
    
    <content type="html"><![CDATA[<blockquote><p>数组中出现次数超过一半的数字</p></blockquote><h2 id="题目">题目</h2><p>数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。</p><p>你可以假设数组是非空的，并且给定的数组总是存在多数元素。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入: [1, 2, 3, 2, 2, 2, 5, 4, 2]</span><br><span class="hljs-section">输出: 2</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= 数组长度 &lt;= 50000</li></ul><h2 id="题解">题解</h2><p>本题可以遍历数组哈希表统计时间和空间复杂度均为O(N)。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">majorityElement</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        countlist = {}<br>        length = <span class="hljs-built_in">len</span>(nums)<br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> nums:<br>            <span class="hljs-keyword">if</span> countlist.get(x): <span class="hljs-comment">#可以用内置的get方法或者用has_key()</span><br>                countlist[x]+=<span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                countlist[x] = <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span>(countlist[x]&gt;length/<span class="hljs-number">2</span>):<br>                <span class="hljs-keyword">return</span> x<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br></code></pre></td></tr></tbody></table></figure><p>字典的相关方法：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">dict</span> = {<span class="hljs-string">'Name'</span>: <span class="hljs-string">'Zara'</span>, <span class="hljs-string">'Age'</span>: <span class="hljs-number">7</span>, <span class="hljs-string">'Class'</span>: <span class="hljs-string">'First'</span>}<br> <br><span class="hljs-keyword">del</span> <span class="hljs-built_in">dict</span>[<span class="hljs-string">'Name'</span>]  <span class="hljs-comment"># 删除键是'Name'的条目</span><br><span class="hljs-built_in">dict</span>.clear()      <span class="hljs-comment"># 清空字典所有条目</span><br><span class="hljs-keyword">del</span> <span class="hljs-built_in">dict</span>          <span class="hljs-comment"># 删除字典</span><br></code></pre></td></tr></tbody></table></figure><p>Python字典包含了以下内置方法：</p><table><thead><tr><th style="text-align:left">序号</th><th style="text-align:left">函数及描述</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left"><a href="https://www.runoob.com/python/att-dictionary-clear.html">dict.clear()</a> 删除字典内所有元素</td></tr><tr><td style="text-align:left">2</td><td style="text-align:left"><a href="https://www.runoob.com/python/att-dictionary-copy.html">dict.copy()</a> 返回一个字典的浅复制</td></tr><tr><td style="text-align:left">3</td><td style="text-align:left">[dict.fromkeys(seq<a href="https://www.runoob.com/python/att-dictionary-fromkeys.html">, val])</a> 创建一个新字典，以序列 seq 中元素做字典的键，val 为字典所有键对应的初始值</td></tr><tr><td style="text-align:left">4</td><td style="text-align:left"><strong><a href="https://www.runoob.com/python/att-dictionary-get.html">dict.get(key, default=None)</a> 返回指定键的值，如果值不在字典中返回default值</strong></td></tr><tr><td style="text-align:left">5</td><td style="text-align:left"><strong><a href="https://www.runoob.com/python/att-dictionary-has_key.html">dict.has_key(key)</a> 如果键在字典dict里返回true，否则返回false</strong></td></tr><tr><td style="text-align:left">6</td><td style="text-align:left"><a href="https://www.runoob.com/python/att-dictionary-items.html">dict.items()</a> 以列表返回可遍历的(键, 值) 元组数组</td></tr><tr><td style="text-align:left">7</td><td style="text-align:left"><a href="https://www.runoob.com/python/att-dictionary-keys.html">dict.keys()</a> 以列表返回一个字典所有的键</td></tr><tr><td style="text-align:left">8</td><td style="text-align:left"><a href="https://www.runoob.com/python/att-dictionary-setdefault.html">dict.setdefault(key, default=None)</a> 和get()类似, 但如果键不存在于字典中，将会添加键并将值设为default</td></tr><tr><td style="text-align:left">9</td><td style="text-align:left"><a href="https://www.runoob.com/python/att-dictionary-update.html">dict.update(dict2)</a> 把字典dict2的键/值对更新到dict里</td></tr><tr><td style="text-align:left">10</td><td style="text-align:left"><a href="https://www.runoob.com/python/att-dictionary-values.html">dict.values()</a> 以列表返回字典中的所有值</td></tr><tr><td style="text-align:left">11</td><td style="text-align:left">[pop(key<a href="https://www.runoob.com/python/python-att-dictionary-pop.html">,default])</a> 删除字典给定键 key 所对应的值，返回值为被删除的值。key值必须给出。 否则，返回default值。</td></tr><tr><td style="text-align:left">12</td><td style="text-align:left"><a href="https://www.runoob.com/python/python-att-dictionary-popitem.html">popitem()</a> 返回并删除字典中的最后一对键和值。</td></tr></tbody></table><h5 id="摩尔投票法：核心理念为票数正负抵消，时间复杂度为O-N-空间复杂度为O-1-。">摩尔投票法：核心理念为票数正负抵消，时间复杂度为O(N),空间复杂度为O(1)。</h5><ul><li>推论1：将指定的众数元素标记为+1，其他元素标记为-1，则所有数字的票数和大于0.</li><li>推论2:  若数组的前a个数字的票数和为0，则剩余的n-a个数字的票数之和一定大于0，即（n-a）个数字的众数仍为x，可以直接不考虑前面a个数字了。</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">majorityElement</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        votes = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> nums:<br>            <span class="hljs-keyword">if</span> votes == <span class="hljs-number">0</span>: x = num<br>            votes += <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> num == x <span class="hljs-keyword">else</span> -<span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> x<br><br></code></pre></td></tr></tbody></table></figure><p><strong>拓展</strong>： 由于题目说明 给定的数组总是存在多数元素 ，因此本题不用考虑 数组不存在众数 的情况。若考虑，需要加入一个 “验证环节” ，遍历数组 nums 统计 x 的数量。</p><p><strong>若 x 的数量超过数组长度一半，则返回 x ；</strong><br>否则，返回未找到众数；<br>时间和空间复杂度不变，仍为 O(N) 和 O(1) 。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">majorityElement</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        votes, count = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> nums:<br>            <span class="hljs-keyword">if</span> votes == <span class="hljs-number">0</span>: x = num<br>            votes += <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> num == x <span class="hljs-keyword">else</span> -<span class="hljs-number">1</span><br>        <span class="hljs-comment"># 验证 x 是否为众数</span><br>        <span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> nums:<br>            <span class="hljs-keyword">if</span> num == x: count += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> x <span class="hljs-keyword">if</span> count &gt; <span class="hljs-built_in">len</span>(nums) // <span class="hljs-number">2</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span> <span class="hljs-comment"># 当无众数时返回 0</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>字典</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>字典</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文总结&lt;Anatomical-guided attention enhances unsupervised PET image denoising performance&gt;</title>
    <link href="/2021/11/03/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/pet/brain-pet-paper1/"/>
    <url>/2021/11/03/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/pet/brain-pet-paper1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>2021年2月投稿的一篇论文《Anatomical-guided attention enhances unsupervised PET image denoising performance》提出使用Anatomical-guided的注意力加强非监督的PET图像降噪性能。</p></blockquote><h2 id="ABSTRACT">ABSTRACT</h2><blockquote><p>Although supervised convolutional neural networks (CNNs) often outperform conventional alternatives for denoising positron emission tomography (PET) images, they require many low- and high-quality reference PET image pairs. Herein, we propose an unsupervised 3D PET image denoising method based on an anatomical information-guided attention mechanism. The proposed magnetic resonance-guided deep decoder (MR-GDD) utilizes the spatial details and semantic features of MR-guidance image more effectively by introducing encoder-decoder and deep decoder subnetworks. Moreover, the specific shapes and patterns of the guidance image do not affect the denoised PET image, because the guidance image is input to the network through an attention gate. In a Monte Carlo simulation of [18F]fluoro-2-deoxy-D-glucose (FDG), the proposed method achieved the highest peak signal-to-noise ratio and structural similarity (27.92 ± 0.44 dB/0.886 ± 0.007), as compared with Gaussian filtering (26.68 ± 0.10 dB/0.807 ± 0.004), image guided filtering (27.40 ± 0.11 dB/0.849 ± 0.003), deep image prior (DIP) (24.22 ± 0.43 dB/0.737 ± 0.017), and MR-DIP (27.65 ± 0.42 dB/0.879 ± 0.007). Furthermore, we experimentally visualized the behavior of the optimization process, which is often unknown in unsupervised CNN-based restoration problems. For preclinical (using [18F]FDG and [11C]raclopride) and clinical (using [18F]florbetapir) studies, the proposed method demonstrates state-of-the-art denoising performance while retaining spatial resolution and quantitative accuracy, despite using a common network architecture for various noisy PET images with 1/10th of the full counts. These results suggest that the proposed MR-GDD can reduce PET scan times and PET tracer doses considerably without impacting patients.</p></blockquote><h5 id="总结">总结</h5><p>使用监督训练CNN网络比传统的方法在PET降噪处理上效果表现的更好，但是需要 low- and high-quality reference PET image pairs作为label。因此基于解剖学信息指引的注意力机制提出了无监督的3D的PET图像的重建。</p><ul><li>此网络（MR-GDD）引入了两个子网络（encoder-decoder and deep decoder subnetworks）更效率地利用MR（核磁共振）图像的空间信息和语义特征。</li><li>同时，由于guidance image通过attention gate后再输入网络，特定的guidance image的shapes和patterns不会影响降噪的PET图像。</li><li>并且，我们通过实验可视化了优化过程的行为。这在无监督卷积图像重建通常是无法表示的。</li></ul><h2 id="Introduction">Introduction</h2><blockquote><p>Positron emission tomography (PET) is a functional imaging modality that observes the molecular-level activity in tissues caused by radioactive tracers. It offers excellent diagnostic accuracy both for observing normal tissues and for detecting specific diseases such as cancer and neurodegenerative disorders (Phelps, 2012). In response to the increased demand for more accurate dementia diagnosis in recent years, brain-dedicated PET scanners with enhanced sensitivity that are capable of acquiring high-resolution brain images have been developed (Tashima et al., 2019; Watanabe et al., 2017). The acquisition of high-quality diagnostic PET images requires the administration of high dose or a long scan time. However, massive radiation exposure to PET tracers may induce genetic damage and cancerous growths, thereby raising health risk concerns (ICRP, 2017). Therefore, to mitigate the radiation exposure-related risk, it is desirable to administer low-dose PET tracers. Unfortunately, this increases the statistical noise, thus degrading the quality of PET images and potentially affecting the diagnostic accuracy. Thus, improved noise suppression methods for PET images are essential.</p></blockquote><h5 id="逻辑">逻辑</h5><p>为了治疗疾病 —&gt;  需要获取高像素的脑PET图像 —&gt;  需要高剂量&amp;长时间的扫描时间 —&gt; 引发健康风险 —&gt; 只能使用低剂量的PET示踪剂 —&gt; 改进用于 PET 图像的噪声抑制方法是必不可少的。</p><blockquote><p>Conventionally, Gaussian filtering (GF) is applied as a basic post-denoising method, despite compromising the spatial resolution and, thus, the quantitative accuracy of PET images. To avoid such compromises, various denoising algorithms, such as bilateral filtering (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0018">Hoifheinz et al., 2011</a>), non-local means filtering (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0001">Arabi and Zaidi, 2020</a>), image-guided filtering (IGF) (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0017">He et al., 2013</a>; <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0016">Hashimoto et al., 2018</a>), and block-matching filtering (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0027">Ote et al., 2020</a>) have been developed and applied to PET images. These post-denoising algorithms provide a better denoising performance than GF while retaining spatial resolution and quantitative accuracy.</p></blockquote><h5 id="传统降噪方法">传统降噪方法</h5><p>高斯滤波 (GF) 被用作基本的后去噪方法，尽管会影响空间分辨率，从而影响 PET 图像的定量精度。后来使用双边滤波、非局部均值滤波、图像引导过滤（IGF）和块匹配过滤的去噪方法。这些去噪算法提供了比 GF 更好的去噪性能，同时保留了空间分辨率和定量精度。</p><blockquote><p>Aside from the above mentioned conventional <a href="https://www.sciencedirect.com/topics/engineering/filtering-algorithm">filtering algorithms</a>, methods based on deep learning (DL) have been applied in various medical fields (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0023">Litjens et al., 2017</a>), and the use of <a href="https://www.sciencedirect.com/topics/engineering/convolutional-neural-networks">convolutional neural networks</a> (CNNs) has been reported to improve the quality of PET images (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0010">Gong et al., 2019</a>a; <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0012">Häggström et al., 2019</a>; <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0024">Liu and Qi, 2019</a>; <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0030">Sanaat et al., 2020</a>; <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0034">Sphuler et al., 2020</a>; <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0047">Zhou et al., 2020</a>). However, the general CNN-based denoising methods typically require a pair of large reference datasets comprising high-quality images. This is a major problem in clinical usage owing to the difficulty of preparing huge sets of low-noise PET data without unduly burdening patients. In addition, the huge volume of novel PET tracers being developed, makes it difficult to collect large amounts of training data for each domain. The interpretation of denoised PET images may suffer inherent biases if unknown cases are excluded from the <a href="https://www.sciencedirect.com/topics/computer-science/training-dataset">training dataset</a>. Despite these challenges, DL algorithms often outperform conventional denoising algorithms. Therefore, there is a need for technology that can be uniformly adapted to various domains without using high-quality PET data.</p></blockquote><h5 id="深度学习方法的难题">深度学习方法的难题</h5><p>除了上述传统过滤算法之外，基于深度学习 (DL) 的方法已应用于各个医学领域，使用卷积神经网络 (CNN) 可以提高PET 图像质量。而深度学习的去噪方法需要高质量图像的大型参考数据集。但是在不给患者造成过度负担的情况下准备大量的低噪声 PET 数据是一个难题，因此目标是需要能够在不使用高质量 PET 数据的情况下，统一适应各种情况的方法。</p><blockquote><p>In recent years, unsupervised or self-supervised DL approaches such as Noise2Noise and deep image prior (DIP) have demonstrated the potential to overcome these challenges (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0021">Lehtinen et al., 2018</a>; <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0040">Ulyanov et al., 2018</a>). In particular, the DIP algorithm is a powerful noise suppression method that does not require the preparation of a prior training dataset (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0015">Hashimoto et al., 2019</a>, <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0014">2020</a>; <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0022">Lin and Huang, 2020</a>). Furthermore, PET reconstruction and denoising methods in which <a href="https://www.sciencedirect.com/topics/engineering/computed-tomography">computed tomography</a> (CT) and magnetic resonance (MR) images serve as the prior images input to the DIP framework have been developed (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0008">Cui et al., 2019</a>; <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0011">Gong et al., 2019</a>b). Compared to PET alone, the denoising performance has been improved by using multi-modal data combined with anatomical information. However, while this method shows potential for adapting various PET image denoising approaches, the <a href="https://www.sciencedirect.com/topics/computer-science/network-architecture">network architecture</a> does not fully utilize the <a href="https://www.sciencedirect.com/topics/computer-science/semantic-feature">semantic features</a> or image details of anatomical-guidance images. Furthermore, the process of converting the guidance image to the PET image can result in the shape and pattern of the guidance image remaining in the output PET image, with the extent to which the features of the guidance image affect PET image denoising is yet to be elucidated. Moreover, the process by which the DIP algorithm optimizes the denoising remains unclear. Therefore, these issues must be clarified for future development.</p></blockquote><h5 id="深度学习改进方法：Noise2Noise；DIP；">深度学习改进方法：Noise2Noise；DIP；</h5><h5 id="DIP的优点：">DIP的优点：</h5><ul><li>一种强大的噪声抑制方法，不需要准备先验训练数据集；</li><li>其中计算机断层扫描 (CT) 和磁共振 (MR) 图像作为输入到 DIP 框架的先验图像；</li><li>与单独的 PET 相比，通过使用多模态数据结合解剖信息，去噪性能得到了提高。</li></ul><h5 id="DIP的问题：">DIP的问题：</h5><ul><li>网络架构并没有充分利用解剖指导图像的语义特征或图像细节；</li><li>引导图像转换为PET图像的过程会导致输出PET图像中保留引导图像的形状和图案；</li><li>引导图像的特征对PET图像去噪的影响程度尚待确定且阐明；</li><li>DIP算法优化去噪的过程仍不清楚。</li></ul><blockquote><p>In this study, we propose an unsupervised 3D PET image denoising method that incorporates anatomical information into the DIP architecture via an attention mechanism. The attention gates (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0009">Fukui et al., 2019</a>; <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0032">Schlemper et al., 2019</a>) used in the proposed network help optimize a noisy PET image using multi-scale semantic features extracted from the guidance image. As such, this method can prevent the leakage of guidance image features. The guidance of multi-scale features can lead to an effective regularizer for PET image denoising. The main contributions of this study are as follows:</p><ul><li>We propose a new PET image denoising method guided by anatomical information using an unsupervised <a href="https://www.sciencedirect.com/topics/computer-science/deep-learning-method">DL method</a>.</li><li>We demonstrate that the proposed network has the flexibility to handle the different PET tracer domains used to show the distribution of various tissues in the brains of human and non-human primates.</li><li>The behavior of the optimization process is visualized experimentally, thereby providing useful insights that were unresolved in unsupervised CNN-based restoration problems.</li></ul></blockquote><h5 id="本文的方法：">本文的方法：</h5><p>使用了无监督的3D的PET图像降噪方法，该方法通过<strong>注意机制将解剖信息整合到 DIP 架构中</strong>，使用从引导图像中提取的多尺度语义特征来优化嘈杂的 PET 图像。多尺度特征的引导可以为 PET 图像去噪提供有效的正则化器。</p><h5 id="贡献：">贡献：</h5><ul><li><p>我们提出了一种新的 PET 图像去噪方法，该方法使用无监督的 DL 方法<strong>以解剖信息为指导</strong>；</p></li><li><p>具有处理不同PET 示踪域的<strong>灵活性</strong>，可以用于显示人类和非人类灵长类动物大脑中各种组织的分布；</p></li><li><p>优化过程的行为通过实验进行<strong>可视化</strong>，从而提供在基于 CNN 的无监督重建问题中未解决问题的相关见解。</p></li></ul><h2 id="2-Related-work">2. Related work</h2><blockquote><p>The <a href="https://www.sciencedirect.com/topics/engineering/positron-emission-tomography">PET</a> image restoration process is further complicated by the limited availability of information that can be extracted from noisy PET data. Another approach adopted for PET image denoising is to use anatomical prior extracted from the <a href="https://www.sciencedirect.com/topics/engineering/computed-tomography">CT</a> or MR images of the patient for <a href="https://www.sciencedirect.com/topics/engineering/regularization">regularization</a>. Because multi-modal images have become easier to obtain owing to the increasing availability of PET/CT and PET/MR scanners, various <a href="https://www.sciencedirect.com/topics/engineering/hybrid-method">hybrid methods</a> using anatomical priors have been developed to facilitate PET image denoising.</p></blockquote><p>PET 图像去噪采用的另一种方法是<strong>使用从患者的 CT 或 MR 图像中提取的解剖先验</strong>进行正则化。由于 PET/CT 和 PET/MR 扫描仪的可用性不断提高，多模态图像变得更容易获得，因此开发了各种使用解剖学先验的混合方法来促进 PET 图像去噪。</p><h3 id="2-1-Classical-approach">2.1. Classical approach</h3><blockquote><p>Conventionally, hybrid denoising methods using anatomical priors have been adopted for PET image reconstruction and post-filtering. For example, <a href="https://www.sciencedirect.com/topics/engineering/maximum-a-posteriori">maximum a posteriori</a> image reconstruction has been incorporated alongside anatomical priors (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0007">Comtat et al., 2002</a>; <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0041">Vunckx et al., 2012</a>). In addition, <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0035">Sudarshan et al. (2020)</a> proposed joint PET and MR image reconstruction using a patch-based joint-dictionary prior. <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0003">Bland et al. (2018)</a> introduced MR-derived kernels to the kernel expectation maximization reconstruction. Although advanced image reconstruction algorithms can provide better denoising performance, they require significant computational resources and it is often difficult to set optimal parameters. Therefore, anatomically-guided post-denoising is often performed separately from the image reconstruction process. <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0004">Chan et al. (2014)</a> proposed incorporating CT information and applying median non-local mean filtering to achieve PET denoising. Alternatively, <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0045">Yan et al. (2015)</a> proposed MR-guided PET filtering by adapting a local linear model. In addition, the authors performed partial volume correction without MR image <a href="https://www.sciencedirect.com/topics/engineering/parcellation">parcellation</a> by incorporating <a href="https://www.sciencedirect.com/topics/engineering/partial-volume-effect">partial volume effects</a> into the model.</p></blockquote><h5 id="经典方法：">经典方法：</h5><p>将解剖先验的混合去噪方法应用于PET图像重建和后滤波处理，将最大后验图像重建与解剖先验结合在一起。基于a patch-based joint-dictionary prior联合PET和MR图像重建</p><h3 id="2-2-Supervised-DL-approach">2.2. Supervised DL approach</h3><p>The supervised DL approach has recently demonstrated state-of-the-art performance in PET image denoising. When large amounts of training and label PET data pairs are available, the general <a href="https://www.sciencedirect.com/topics/engineering/convolutional-neural-networks">CNN</a> can be trained according to the following operation:</p>$$θ^*=argmin_θ \frac{1}{N_t}∑_{i∈D_t}∥x_{ref}^i−f_θ(x_0^i)∥$$<p>where ∥·∥ is the L2 norm, f represents the CNN, θ denotes the trainable parameters contained in the weights and biases, Dt is a mini-batch sample of size Nt, x0i is the <em>i</em>th element in the training data (noisy PET images), and xrefi is the <em>i</em>th element in the label data (clean PET images). Regarding supervised PET image denoising using anatomical information, in separate studies, <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0024">Liu and Qi et al. (2019)</a>, <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0033">Schramm et al. (2021)</a>, and <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0005">Chen et al. (2019)</a> trained CNNs to map multi-modal images, including noisy PET and MR images, to obtain clean PET images. In accordance with these methods, the mapping function, fθ(x0i), in <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#eqn0001">Eq. (1)</a> is represented by fθ(x0i,gi) using anatomical-guidance images, g. The supervised DL approach requires a vast number of low-dose (or short-time scan), high-dose (or long-time scan), and guidance image pairs.</p><h3 id="2-3-Unsupervised-DL-approach">2.3. Unsupervised DL approach</h3><p>Unsupervised DL approaches such as DIP do not require label data for PET image denoising. The DIP training process is optimized as follows (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0040">Ulyanov et al., 2018</a>):</p>$$θ^*=argmin_θ∥x_0−f_θ(z)∥,x^*=f_{θ^*}(z)$$<p>where x0 is a <a href="https://www.sciencedirect.com/topics/engineering/noisy-image">noisy image</a>, x* is the final <a href="https://www.sciencedirect.com/topics/engineering/denoised-image">denoised image</a> output, and the network input z is random noise. The DIP algorithm uses a CNN to map a <a href="https://www.sciencedirect.com/topics/engineering/degraded-image">degraded image</a>, x0, and obtains the optimal denoised image by regularization of the architecture via moderate iteration. This is based purely on the prior information included in the CNN structure. <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0015">Hashimoto et al. (2019</a>), (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0014">2020</a>) proposed dynamic PET image denoising by directly inputting static PET images into 3D and 4D DIP as prior information. In contrast, <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0008">Cui et al. (2019)</a> and <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0010">Gong et al. (2019</a>a) both proposed PET denoising methods that rely on inputting anatomical-guidance images, g (e.g., CT and MR images), instead of the DIP input, z. In these methods, the mapping function, fθ(z), in <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#eqn0002">Eq. (2)</a> is represented by fθ(g).</p><p>The unsupervised DL approach can bridge the technical gap between the classical and supervised DL approaches for PET image denoising based on anatomical information. Nevertheless, previous methods often fail to clarify how the <a href="https://www.sciencedirect.com/topics/computer-science/semantic-feature">semantic features</a> of the guidance image affect PET image denoising.</p><h2 id="3-Methodology">3. Methodology</h2><h3 id="3-1-MR-guided-deep-decoder">3.1. MR-guided deep decoder</h3><p>To explicitly utilize the <a href="https://www.sciencedirect.com/topics/computer-science/semantic-feature">semantic features</a> of anatomical-guidance image for <a href="https://www.sciencedirect.com/topics/engineering/positron-emission-tomography">PET</a> image denoising, we propose a method for unsupervised 3D PET image denoising based on anatomical information that uses an MR-guided deep decoder (MR-GDD), which is inspired by <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0039">Uezato et al. (2020)</a>. <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#fig0001">Fig. 1</a> shows the <a href="https://www.sciencedirect.com/topics/computer-science/network-structure">network structure</a> of the proposed MR-GDD, which comprises two <a href="https://www.sciencedirect.com/topics/engineering/subnetwork">subnetworks</a>: an encoder-decoder subnetwork with a skip connection and a deep decoder subnetwork. The two subnetworks are connected by an upsampling refinement unit (URU) and a feature refinement unit (FRU), which incorporate an attention gate to weight the multi-scale features extracted from the MR image to the deep decoder subnetwork. This combined network performs end-to-end learning from scratch.</p><p><img src="https://picture.mulindya.com/MR-guided-deep-decoder.jpg" alt=""></p><p>Fig. 1. Overview of the proposed MR-GDD used for unsupervised 3D <a href="https://www.sciencedirect.com/topics/engineering/positron-emission-tomography">PET</a> image denoising. This architecture consists of two <a href="https://www.sciencedirect.com/topics/engineering/subnetwork">subnetworks</a> connected by attention gates: an encoder-decoder subnetwork with a skip connection (top) and a deep decoder subnetwork (bottom). This combined architecture is optimized using end-to-end learning. The attention gates in the upsampling refinement unit (URU) and the feature refinement unit (FRU) guide the optimization of noisy PET image using the multi-scale <a href="https://www.sciencedirect.com/topics/computer-science/semantic-feature">semantic features</a> extracted from the MR image. This architecture can prevent the semantic features of the MR image from leaking.</p><h4 id="3-1-1-Encoder-decoder-subnetwork">3.1.1. Encoder-decoder subnetwork</h4><p>The encoder-decoder subnetwork is designed to extract low-scale to high-scale hierarchical semantic features from the MR image. It is based on the 3D U-Net architecture (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0006">Çiçek et al., 2016</a>) and consists of encoding and decoding paths. In the encoding path, the combination of a 3 × 3 × 3 3D <a href="https://www.sciencedirect.com/topics/computer-science/convolution-layer">convolution layer</a> with <a href="https://www.sciencedirect.com/topics/computer-science/batch-normalization">batch normalization</a> (BN) and a leaky rectified linear unit (LReLU) is repeated twice, before being constructed by a 3 × 3 × 3 3D convolution layer with two strides for downsampling, followed by the BN and LReLU. At each downsampling step, the size of the feature maps is halved. In the decoding path, the outputs of the upsampling layer and the skip connection supplied from the encoding path are added, before the combination of the 3 × 3 × 3 3D convolution layer with the BN and LReLU is repeated twice. At each upsampling step, the size of the feature maps is doubled.</p><h4 id="3-1-2-Deep-decoder-subnetwork">3.1.2. Deep decoder subnetwork</h4><p>The deep decoder subnetwork reconstructs the denoised PET image from the network input filled with uniform noise. Each step in the deep decoder subnetwork is upsampled first by the URU, then by a 3 × 3 × 3 3D convolution layer, and finally by the BN, LReLU, and FRU. Owing to the presence the attention gates, the URU and FRU can generate conditional weights using the MR image features via a 1 × 1 × 1 3D convolution layer, LReLU, and <a href="https://www.sciencedirect.com/topics/engineering/sigmoid-function">sigmoid function</a>, and then weights the features obtained from the pre-layer in the deep decoder. The URU promotes the <a href="https://www.sciencedirect.com/topics/computer-science/spatial-locality">spatial locality</a> of MR image features, whereas the FRU promotes similar semantic alignment. Finally, a 1 × 1 × 1 3D convolution layer outputs a denoised PET image.</p><h3 id="3-2-Loss-function-and-optimization">3.2. Loss function and optimization</h3><p>To denoise the PET image, the training process of the proposed MR-GDD, which utilizes <a href="https://www.sciencedirect.com/topics/computer-science/unsupervised-learning">unsupervised learning</a> that does not require PET reference data, is optimized as follows:</p>$$θ^*=argmin_θ∥x_0−f_θ(z,g)∥,x^*=f_{θ^*}(z,g)$$<p>where ∥·∥ is the L2 norm, f represents the proposed MR-GDD network, the training label x0 represents the noisy PET image, and the network inputs z and g are the random noise and the MR-guidance image, respectively. The input noise was generated by adding a fixed uniform random noise and <a href="https://www.sciencedirect.com/topics/engineering/gaussian-white-noise">Gaussian noise</a> with different seed for each epoch. The attention gates used in the proposed architecture help optimize the noisy PET image by using the multi-scale semantic features extracted from a <a href="https://www.sciencedirect.com/topics/medicine-and-dentistry/image-guided-intervention">guidance image</a> g. If the <em>k</em>-th scale feature of the encoder path in the encoder-decoder subnetwork is defined as Γk and the <em>k</em>-th scale features of the decoder path are defined as Ξk, the influence on the mapping function, f, can be expressed as follows:</p>$$f=f_θ(z|Γ1,⋯Γk,Ξ1,⋯Ξk).$$<p>In this method, the limited memory BFGS (L-BFGS) algorithm (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0048">Zhu et al., 1997</a>), which is a quasi-Newtonian method, is introduced to solve the nonlinear <a href="https://www.sciencedirect.com/topics/engineering/least-square-problem">least squares problem</a> described by <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#eqn0003">Eq. (3)</a>. By considering the approximate <a href="https://www.sciencedirect.com/topics/engineering/hessian-matrix">Hessian matrix</a> based on the second-order gradient, the L2 norm converges more stably and quickly than first-order <a href="https://www.sciencedirect.com/topics/engineering/gradient-descent">gradient descent</a> algorithms, such as the stochastic gradient descent algorithm or Adam. In addition, because a small amount of data is generated as a result of using the unsupervised architecture, which does not require a prior <a href="https://www.sciencedirect.com/topics/computer-science/training-dataset">training dataset</a>, the MR-GDD can reduce the computational complexity and load required to performed denoising. We used the L-BFGS algorithm at a learning rate of 0.01 without line search to minimize the processing time. The proposed architecture was processed using PyTorch 1.6.0 on Ubuntu 16.04 with acceleration by a <a href="https://www.sciencedirect.com/topics/engineering/graphics-processing-unit">graphics processing unit</a> (NVIDIA Quadro RTX8000 with 48 GB memory).</p><h2 id="4-Experimental-setup">4. Experimental setup</h2><p>A simulation study using [18F]fluoro-2-deoxy-D-glucose (FDG), a preclinical study using [18F]FDG and [11C]raclopride, and a clinical study using [18F]florbetapir (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0043">Wong et al., 2010</a>) were performed to verify the effectiveness of the proposed <a href="https://www.sciencedirect.com/topics/engineering/positron-emission-tomography">PET</a> image denoising method. In addition, the denoising performance of the proposed MR-GDD was compared against four other unsupervised algorithms under the same conditions as the proposed MR-GDD;</p><ul><li><em>Gaussian filtering (GF).</em> GF is a basic post-denoising method for suppressing noise in PET images. We used a 3D <a href="https://www.sciencedirect.com/topics/engineering/gaussian-kernel">Gaussian kernel</a>.</li><li><em>Image guided filtering (IGF).</em> IGF performs PET image denoising by adapting a local linear model using a <a href="https://www.sciencedirect.com/topics/medicine-and-dentistry/image-guided-intervention">guidance image</a> (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0016">Hashimoto et al., 2018</a>; <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0017">He et al., 2013</a>). We used the MR image as the guidance image.</li><li><em>Deep image prior (DIP).</em> The general DIP algorithm uses random noise as the network input (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0040">Ulyanov et al., 2018</a>). We used the encoder-decoder network in the proposed MR-GDD as the DIP architecture.</li><li><em>MR-DIP.</em> MR-DIP uses an MR prior as a direct input in the DIP architecture (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0008">Cui et al., 2019</a>; <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0010">Gong et al., 2019</a>a). We used the same architecture as in the DIP algorithm.</li></ul><p>As a pre-processing step for all the data, voxel intensity normalization was performed on each of the MR and PET images. The MR image intensity was normalized in the [0, 1] range using a min-max normalization technique. Furthermore, the 99.95th <a href="https://www.sciencedirect.com/topics/engineering/percentile">percentile</a> was defined for PET image intensity, which was also normalized in the [0, 1] range using a min-max normalization technique.</p><h3 id="4-1-Simulation-study">4.1. Simulation study</h3><p>We performed a <a href="https://www.sciencedirect.com/topics/medicine-and-dentistry/monte-carlo-method">Monte Carlo simulation</a> using the 3D brain phantom from BrainWeb (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0002">Aubert-Broche et al., 2006</a>). The Monte Carlo simulation modeled the geometry of a brain-dedicated PET scanner (HITS-655000 (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0042">Watanabe et al., 2017</a>), <a href="https://www.sciencedirect.com/topics/computer-science/hamamatsu-photonics">Hamamatsu Photonics</a> K.K., Japan). The scanner consists of 32 detector blocks with <a href="https://www.sciencedirect.com/topics/engineering/cerium">cerium</a> doped <a href="https://www.sciencedirect.com/topics/engineering/lutetium">lutetium</a> <a href="https://www.sciencedirect.com/topics/engineering/yttrium">yttrium</a> <a href="https://www.sciencedirect.com/topics/engineering/orthosilicates">orthosilicate</a> crystals per ring, with 5 of these blocks aligned to the scanner axis. To ensure a mismatch between the MR and PET images, two hot spheres (with radii of 10 and 12 mm, respectively) were inserted exclusively into the PET image to present tumor regions. Then, we simulated a static [18F]FDG scan equivalent to 150 M counts, including attenuation and scattering effects. An attenuation map was created from the segmented MR image, and the attenuation effects of water and bone were considered. The gray matter:white matter:cerebrospinal fluid:left tumor:right tumor activity ratio was set to 1:0.25:0.05:2:2 based on the [18F]FDG contrast. We also simulated low-activity tumor data (left tumor:right tumor activity ratio was set to 1.5:1.2) for some low-grade tumors or pathology linked to <a href="https://www.sciencedirect.com/topics/medicine-and-dentistry/degenerative-disease">neurodegenerative disease</a>. To generate the reference PET image, the simulated list-mode data were reconstructed using a 3D list-mode dynamic row-action maximum-likelihood algorithm (DRAMA) (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0037">Tanaka and Kudo, 2010</a>) with two iterations and 40 subsets. The reconstructed image measured 128 × 128 × 83 voxels (2.6 × 2.6 × 2.4 mm/voxel). The reference image was reconstructed using all the list-mode data. The noisy PET image was obtained by periodically downsampling to 1/30th of the reference list-mode data (see Supplementary Material 0.1) and reconstructing the low-count image (5 M counts). The corresponding T1-weighted MR image was used as the guidance image.</p><h3 id="4-2-Preclinical-study">4.2. Preclinical study</h3><p>A preclinical study was conducted using monkeys and was approved by the Animal Ethics Committees of the Central <a href="https://www.sciencedirect.com/topics/engineering/research-laboratories">Research Laboratory</a>, Hamamatsu Photonics K.K. PET scans using [18F]FDG and [11C]raclopride imaged the brains of conscious <a href="https://www.sciencedirect.com/topics/engineering/rhesus-monkey">rhesus monkeys</a>, whose bodies and heads were fixed using an animal PET scanner (SHR-38000 (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0013">Hamamatsu 2021</a>), Hamamatsu Photonics K.K., Japan). After a 30 min transmission scan using a 68Ge-68Ga source, doses of [18F]FDG (113 MBq) and [11C]raclopride (282 MBq) were injected into each monkey, before dynamic PET scans were performed for 120 and 90 min, respectively. We performed image reconstruction using 3D DRAMA with two iterations and 60 subsets that incorporated attenuation correction via transmission scan data. The reconstructed images measured 256 × 256 × 103 voxels (0.65 × 0.65 × 1.0167 mm/voxel) and were cropped <a href="https://www.sciencedirect.com/topics/medicine-and-dentistry/pamicogrel">to 192</a> × 192 × 64 voxels to reduce the demand on the <a href="https://www.sciencedirect.com/topics/engineering/graphics-processing-unit">GPU</a> memory. The reference images were reconstructed using all the list-mode data for [18F]FDG and the list mode data for the 60 min period between 30 and 90 min of the scan such that the contrast created by the distribution of [11C]raclopride in the striatum to be observed clearly. Each noisy PET image was obtained by periodically downsampling to 1/10th of the reference list-mode data. The corresponding T1-weighted MR images were taken on another day and registered manually by two radiological <a href="https://www.sciencedirect.com/topics/engineering/technologist">technologists</a>.</p><h3 id="4-3-Clinical-study">4.3. Clinical study</h3><p>An amyloid scan using [18F]florbetapir was conducted on the human brain of a cognitive normal subject using a Biograph mMR scanner (Siemens Healthineers, Germany) as part of the “Insight 46″ sub-study of the MRC National Survey of Health and Development (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0020">Lane et al., 2017</a>; <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0025">Markiewicz et al., 2018</a>a). The PET data were acquired dynamically for 60 min using a [18F]florbetapir dose of 409 MBq. During PET image reconstruction, attenuation correction was performed via a pseudo-CT image, which was synthesized using T1- and T2-weighted MR images that were acquired simultaneously, and enabled an μ-map to be was calculated. Image reconstruction was performed using an ordered subset expectation maximization (OS-EM) algorithm involving four iterations and 14 subsets using the NiftyPET package (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0026">Markiewicz et al., 2018</a>b). The reconstructed images comprised 334 × 334 × 127 voxels (2 × 2 × 2 mm/voxel), which were cropped to 128 × 128 × 83 voxels to reduce the demand on the GPU memory. The reference image was reconstructed using the list-mode data for the period from 30 to 60 min to observe the contrast between gray and white matter clearly. The noisy PET image was obtained by periodically downsampling to 1/10th of the reference list-mode data.</p><h3 id="4-4-Evaluation-metrics">4.4. Evaluation metrics</h3><p>To quantitatively evaluate the performance of different denoising methods, for the simulation study, we calculated the peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) of the target image, x, and the reference image, xref, which are defined as</p>$$PSNR=10log_{10}(\frac{max(x^{ref})^2}{\frac{1}{N_R}∑_{j∈R}(x_j−x_j^{ref})^2})$$<p>and</p>$$SSIM=\frac{1}{N_R}∑_{j∈R}\frac{(2μ_{jx}μ_{jx^{ref}}+c_1)(2σ_{jxx^{ref}}+c_2)}{(μ_{jx}^2+μ_{jx^{ref}}^2+c_1)(σ_{jx}^2+σ_{jx^{ref}}^2+c^2)}$$<p>respectively. Here, R and NR represent the brain region in the PET image and the number of voxels, respectively, μ and σ are the mean and standard deviation of the square window corresponding to the <em>j</em>-th voxel, respectively, and σjxxref is the covariance between x and xref. Furthermore, c1=(0.01L)2 and c2=(0.03L)2 where L represents the dynamic range of the reference. The contrast-to-noise ratio (CNR) between gray matter and white matter was calculated as(7)CNR=|Sg¯−Sw¯|σg2+σw2,where Sg¯, Sw¯ and σg, σw are the mean activity and standard deviation corresponding to the regions of interest (ROIs) in the gray and white matter, respectively. The ROIs were constructed in the gray matter regions on the left and right brains of different slices, whereas the white matter regions were selected within the centrum semiovale (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0028">Paxinos et al., 2000</a>). In the [11C]raclopride calculation, the ROIs were set on the <a href="https://www.sciencedirect.com/topics/medicine-and-dentistry/putamen">putamen</a> instead of the gray matter. A Wilcoxon signed-rank test was performed on the PSNR, SSIM, and CNR to compare the performance of different denoising methods. As the noisy PET data were generated by downsampling the reference list-mode data, we generated multiple independent noisy samples (10 samples) to examine the uncertainty and test the statistical significance.</p><p>We also evaluated the tradeoffs between noise and quantitative information of the <a href="https://www.sciencedirect.com/topics/engineering/denoised-image">denoised images</a> when FWHM (GF), ε (IGF), and epochs (CNNs) are changed. For the simulation study, we calculated the tradeoff between the mean squared bias and the variance in the ROI:(8)Bias2=∑j∈R(xj−xjref)2∑j∈R(xjref)2,(7)Variance=∑j∈R(xj−x¯)2∑j∈R(xjref)2,where R denotes the tumor regions, x¯ is the average pixel value inside the ROI. For preclinical study, we calculated the tradeoff between the mean uptake (putamen and caudate and striatum) and the standard deviation (white matter). Each ROI used for the evaluation was set manually to include any partial volume voxels on the MR image and was calculated via superimposition on the co-registered PET image.</p><p>Thus far, the optimization process for the DIP algorithm has only been reported as a conceptual diagram (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0014">Hashimoto et al., 2020</a>; <a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0040">Ulyanov et al., 2018</a>), with several aspects such as the actual behavior remaining unclarified. To elucidate the DIP optimization process, we visualized it by performing nonlinear dimensionally reduction using the locally linear embedding (LLE) algorithm (<a href="https://www.sciencedirect.com/science/article/pii/S1361841521002711#bib0031">Saul and Roweis, 2003</a>), which implements manifold learning. We projected the PET data used for optimization under different training conditions onto a three-dimensional manifold, considering a neighborhood of 15 for each point.</p>]]></content>
    
    
    <categories>
      
      <category>文献</category>
      
      <category>pet</category>
      
    </categories>
    
    
    <tags>
      
      <tag>文献</tag>
      
      <tag>pet</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>图像合成视频</title>
    <link href="/2021/10/30/python/img/pic2video/"/>
    <url>/2021/10/30/python/img/pic2video/</url>
    
    <content type="html"><![CDATA[<blockquote><p>在微生物项目中，需要将视频中的微生物检测识别出来，并且生成视频的格式保存，其中需要将检测的annotation图片合成为视频格式。<strong>大致流程：使用cv库，首先读取图片，resize到指定大小，存储到Video实例中；</strong></p></blockquote><blockquote><p>OpenCV 底层是用 FFMEPG 进行多媒体开发的，所以 OpenCV 它的长项不在于此，它只是提供了这种能力而已，如果要针对多媒体文件做复杂的处理，推荐的还是 FFMEPG 专业库。OpenCV 用来创建视频文件的类是 VideoWriter。首先普及一些视频类相关的知识点。</p></blockquote><h2 id="视频有关知识">视频有关知识</h2><h3 id="1-文件后缀名">1. 文件后缀名</h3><p>我们一般都知道视频文件是 .mp4、.3gp、.rmvb 等等格式的，但一个文件取这样的后缀名是为了告诉用户或者操作系统，它的内容是什么格式的。我们也可以将 rmvb 格式的文件取名为 ***.avi。后缀的目的是为了方便用专业的工具或者软件操作它们。</p><h3 id="2-文件格式">2. 文件格式</h3><p>我们可以将一个视频文件看做一个容器。</p><p>简单地说就是可以看做是一个盒子。</p><p><strong>这个盒子里面有视频画面数据、音频数据、字幕数据等等。</strong></p><p>不同的文件格式如 mp4、avi、mkv 等等，它们存放 打包数据的方式不一样，文件内部文件编码方式也可能不一样。</p><h3 id="3-编码格式">3. 编码格式</h3><p>视频容器中，一般有视频和音频数据，它们采取的编码方式不一样。</p><p>视频常见的编码方式通常有： x264、h264、mpeg-4</p><p>音频常见的编码方式通常有： mp3、AAC、flac</p><p>编码的目的主要是为了高效存储和传输，如果你不采用编码压缩的话，那么视频可以看做是一系列的图片序列，体积会非常大。</p><h3 id="4-编码器和解码器">4. 编码器和解码器</h3><p>把视频或者音频按照编码格式，编码成特定文件格式需要编码器的参与，不然每次开发重新写代码代价很高。</p><p>把特定文件格式解码成特定的编码格式数据，这个过程称为解码，需要解码器的存在。</p><p>解码器和编码器都有开源的或者收费的工具库，极大方便了开发者。</p><h3 id="5-FPS-帧率">5. FPS 帧率</h3><p>我们读初中物理时，大概了解过电影画面一秒钟 24 帧，其实对应的就是 24 fps，frame per second，有些手机有高速摄像的功能，原理就是能够 1 秒钟拍摄 960 张图片，然后用正常的速度放映出来，所以细节比较多。</p><p>fps 越高，细节越好，体验也越好，但是文件容量也越高。</p><h2 id="函数原型-cv2-VideoWriter">函数原型 cv2.VideoWriter()</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">VideoWriter(filename, fourcc, fps, frameSize[, isColor]) -&gt; &lt;VideoWriter <span class="hljs-built_in">object</span>&gt;<br></code></pre></td></tr></tbody></table></figure><ul><li>filename:要保存的文件的路径</li><li>fourcc: 指定编码器</li><li>fps: 要保存的视频的帧率</li><li>frameSize: 要保存的文件的画面尺寸</li><li>isColor: 指示是黑白画面还是彩色的画面</li></ul><h3 id="fourcc的设置">fourcc的设置</h3><blockquote><p>fourcc意为四字符代码（Four-Character Codes），顾名思义，该编码由四个字符组成,下面是VideoWriter_fourcc对象一些常用的参数，注意：字符顺序不能弄混。</p></blockquote><ul><li><p>cv2.VideoWriter_fourcc(‘D’, ‘I’, ‘V’, ‘X’) 对应格式 mp4</p></li><li><p>cv2.VideoWriter_fourcc(‘I’,‘4’,‘2’,‘0’)—未压缩的YUV颜色编码，4:2:0色度子采样。兼容性好，但文件较大，注意是很大。文件扩展名.avi。</p></li><li><p>cv2.VideoWriter_focurcc(‘P’,‘I’,‘M’,‘1’)—MPEG-1编码类型。随机访问，灵活的帧率、可变的图像尺寸、定义了I帧、P帧和B帧、运动补偿可跨越多个帧、半像素精度的运动向量、量化矩阵、GOF结构、slice结构、技术细节、输入视频格式。文件扩展名.avi。</p></li><li><p>cv2.VideoWriter_fourcc(‘X’,‘V’,‘I’,‘D’)—MPEG-4编码类型，视频大小为平均值，MPEG4所需要的空间是MPEG1或M-JPEG的1/10，它对运动物体可以保证良好的清晰度，间/时间/画质具有可调性。文件扩展名.avi。</p></li><li><p>cv2.VideoWriter_fourcc(‘T’,‘H’,‘E’,‘O’)—OGGVorbis，音频压缩格式，有损压缩，类似于MP3等的音乐格式。兼容性差，文件扩展名为.ogv。</p></li><li><p>**cv2.VideoWriter_focurcc(‘F’,‘L’,‘V’,‘1’)—FLV是FLASH VIDEO的简称，FLV流媒体格式是一种新的视频格式。**由于它形成的文件极小、加载速度极快，使得网络观看视频文件成为可能，它的出现有效的解决了视频文件导入Flash后，使导出的SWF文件体积庞大，不能在网络上很好的使用等缺点。文件扩展名为.flv</p></li></ul><p>视频编码方式还有很多，具体可参考http://www.fourcc.org/codecs.php。</p><h2 id="实现代码">实现代码</h2><p><code>flv2jpg.py</code>:切分视频，按照指定帧频率保存图片。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> os<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">flv2jpg</span>(<span class="hljs-params">videopath, mytimeF=<span class="hljs-number">1</span>, save_flag = <span class="hljs-literal">False</span></span>):</span><br>    <span class="hljs-string">"""</span><br><span class="hljs-string">    将flv格式视频每隔mytimeF个帧保存一张图片</span><br><span class="hljs-string">    :param videopath: 存储flv视频的文件夹</span><br><span class="hljs-string">    :param mytimeF: 间隔帧数</span><br><span class="hljs-string">    :return:</span><br><span class="hljs-string">    """</span><br>    save_dir = os.path.join(os.path.dirname(videopath), <span class="hljs-string">"images"</span>)<br>    os.makedirs(save_dir, exist_ok=<span class="hljs-literal">True</span>)<br>    num = <span class="hljs-number">1</span>  <span class="hljs-comment"># 保存图片计数</span><br>    <span class="hljs-built_in">print</span>(videopath)<br>    vc = cv2.VideoCapture(videopath)<br>    <span class="hljs-keyword">if</span> vc.isOpened():<br>        rval, frame = vc.read()<br>    <span class="hljs-keyword">else</span>:<br>        rval = <span class="hljs-literal">False</span><br>    timeF = mytimeF  <span class="hljs-comment"># 每隔mytimeF帧</span><br>    count = <span class="hljs-number">1</span>  <span class="hljs-comment"># 帧计数</span><br>    <span class="hljs-keyword">while</span> rval:<br>        rval, frame = vc.read()<br>        <span class="hljs-keyword">if</span> count % timeF == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> frame <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">"current frame count:"</span>, count)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">"num:"</span>, num)<br><br>            <span class="hljs-keyword">if</span> save_flag:<br>                save_path = os.path.join(save_dir, <span class="hljs-built_in">str</span>(num) + <span class="hljs-string">"_"</span> + videopath.split(<span class="hljs-string">"/"</span>)[-<span class="hljs-number">1</span>] + <span class="hljs-string">".jpg"</span>)<br>                cv2.imwrite(save_path, frame)<br>                <span class="hljs-built_in">print</span>(save_path)<br>                num += <span class="hljs-number">1</span><br>        count += <span class="hljs-number">1</span><br>    vc.release()<br>    <span class="hljs-keyword">return</span> save_dir<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:<br>    test_video = <span class="hljs-string">"./data/lunchong3.flv"</span><br>    flv2jpg(test_video,save_flag=<span class="hljs-literal">True</span>)<br><br></code></pre></td></tr></tbody></table></figure><p><code>main.py</code> ：保存处理后的视频</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flv2jpg <span class="hljs-keyword">import</span> flv2jpg<br><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> os,glob<br><span class="hljs-keyword">from</span> detectInfo <span class="hljs-keyword">import</span> Detect_img<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">makeVideo</span>(<span class="hljs-params">Video_img_list,fps,size,save_dir</span>):</span><br>    <span class="hljs-string">"""</span><br><span class="hljs-string">    func:由切分好的视频帧图像得到检测后的视频</span><br><span class="hljs-string">    input: 待合成的图片list，视频的fps，size设置 视频保存路径</span><br><span class="hljs-string">    return: 无返回</span><br><span class="hljs-string">    """</span><br>    <span class="hljs-comment"># video = cv2.VideoWriter(save_dir, cv2.VideoWriter_fourcc('I', '4', '2', '0'), fps, size)</span><br>    video = cv2.VideoWriter(save_dir, cv2.VideoWriter_fourcc(*<span class="hljs-string">'mp4v'</span>), fps, size)<br><br>    <span class="hljs-keyword">for</span> img <span class="hljs-keyword">in</span> Video_img_list:<br>        img = cv2.resize(img, size)  <span class="hljs-comment"># 将图片转换为1280*720</span><br>        video.write(img)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">detectVideo</span>(<span class="hljs-params">test_video_path,detect_img,fps=<span class="hljs-number">24</span>,size=(<span class="hljs-params"><span class="hljs-number">640</span>,<span class="hljs-number">480</span></span>),sift_thres = <span class="hljs-number">0.5</span></span>):</span><br>    <span class="hljs-string">"""</span><br><span class="hljs-string">    将输入的视频，切分图像，使用模型检测，返回合成的视频结果</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        test_video_path: 视频路径 </span><br><span class="hljs-string">        detect_img: 模型实例</span><br><span class="hljs-string">        fps: 视频帧</span><br><span class="hljs-string">        size: 视频图像大小</span><br><span class="hljs-string">        sift_thres: 筛选显示的检测阈值</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Returns: None</span><br><span class="hljs-string"></span><br><span class="hljs-string">    """</span><br>    img_root = flv2jpg(test_video_path,save_flag=<span class="hljs-literal">True</span>) <span class="hljs-comment">#读取路径</span><br>    save_dir_anno = os.path.join(os.path.dirname(test_video_path),<span class="hljs-string">"annotation/"</span>)<br>    <span class="hljs-comment">#获取批量数据的检测信息</span><br>    Video_img_list = detect_img.get_info(source=img_root, save_img=<span class="hljs-literal">True</span>, save_dir=save_dir_anno,sift_thres=sift_thres)<br>    save_dir = os.path.join(os.path.dirname(test_video_path),<span class="hljs-string">"VideoDetect.mp4"</span>)<br>    makeVideo(Video_img_list, fps, size, save_dir)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:<br>    detect_img = Detect_img(weights=<span class="hljs-string">"./weights/best.pt"</span>)<br>    test_video_path = <span class="hljs-string">"./data/lunchong3.flv"</span><br>    detectVideo(test_video_path, detect_img, fps=<span class="hljs-number">120</span>, size=(<span class="hljs-number">640</span>, <span class="hljs-number">480</span>), sift_thres=<span class="hljs-number">0</span>)<br></code></pre></td></tr></tbody></table></figure><h2 id="YoLov5中的实现">YoLov5中的实现</h2><p>实际上在yolov5的detect脚本中，包含了处理输入为视频格式文件的检测代码，可以直接使用。</p><h3 id="相关代码">相关代码</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs python">datasets.py<br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LoadImages</span>:</span>  <span class="hljs-comment"># for inference</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, path, img_size=<span class="hljs-number">640</span>, stride=<span class="hljs-number">32</span></span>):</span><br>        p = <span class="hljs-built_in">str</span>(Path(path).absolute())  <span class="hljs-comment"># os-agnostic absolute path</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-string">'*'</span> <span class="hljs-keyword">in</span> p:<br>            files = <span class="hljs-built_in">sorted</span>(glob.glob(p, recursive=<span class="hljs-literal">True</span>))  <span class="hljs-comment"># glob</span><br>        <span class="hljs-keyword">elif</span> os.path.isdir(p):<br>            files = <span class="hljs-built_in">sorted</span>(glob.glob(os.path.join(p, <span class="hljs-string">'*.*'</span>)))  <span class="hljs-comment"># dir</span><br>        <span class="hljs-keyword">elif</span> os.path.isfile(p):<br>            files = [p]  <span class="hljs-comment"># files</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> Exception(<span class="hljs-string">f'ERROR: <span class="hljs-subst">{p}</span> does not exist'</span>)<br><br>        images = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> files <span class="hljs-keyword">if</span> x.split(<span class="hljs-string">'.'</span>)[-<span class="hljs-number">1</span>].lower() <span class="hljs-keyword">in</span> img_formats]<br>        videos = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> files <span class="hljs-keyword">if</span> x.split(<span class="hljs-string">'.'</span>)[-<span class="hljs-number">1</span>].lower() <span class="hljs-keyword">in</span> vid_formats]<br>        ni, nv = <span class="hljs-built_in">len</span>(images), <span class="hljs-built_in">len</span>(videos)<br><br>        self.img_size = img_size<br>        self.stride = stride<br>        self.files = images + videos<br>        self.nf = ni + nv  <span class="hljs-comment"># number of files</span><br>        self.video_flag = [<span class="hljs-literal">False</span>] * ni + [<span class="hljs-literal">True</span>] * nv<br>        self.mode = <span class="hljs-string">'image'</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">any</span>(videos):<br>            self.new_video(videos[<span class="hljs-number">0</span>])  <span class="hljs-comment"># 如果为路径则读取打开视频</span><br>        <span class="hljs-keyword">else</span>:<br>            self.cap = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">assert</span> self.nf &gt; <span class="hljs-number">0</span>, <span class="hljs-string">f'No images or videos found in <span class="hljs-subst">{p}</span>. '</span> \<br>                            <span class="hljs-string">f'Supported formats are:\nimages: <span class="hljs-subst">{img_formats}</span>\nvideos: <span class="hljs-subst">{vid_formats}</span>'</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__iter__</span>(<span class="hljs-params">self</span>):</span><br>        self.count = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">return</span> self<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__next__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">if</span> self.count == self.nf:<br>            <span class="hljs-keyword">raise</span> StopIteration<br>        path = self.files[self.count]<br><br>        <span class="hljs-keyword">if</span> self.video_flag[self.count]:<br>            <span class="hljs-comment"># Read video</span><br>            self.mode = <span class="hljs-string">'video'</span><br>            ret_val, img0 = self.cap.read() <span class="hljs-comment">#按帧读取视频，ret,frame是获cap.read()方法的两个返回值。其中ret是布尔值，如果读取帧是正确的则返回True，如果文件读取到结尾，它的返回值就为False。frame就是每一帧的图像，是个三维矩阵。</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> ret_val:<br>                self.count += <span class="hljs-number">1</span><br>                self.cap.release()<br>                <span class="hljs-keyword">if</span> self.count == self.nf:  <span class="hljs-comment"># last video</span><br>                    <span class="hljs-keyword">raise</span> StopIteration<br>                <span class="hljs-keyword">else</span>:<br>                    path = self.files[self.count]<br>                    self.new_video(path) <br>                    ret_val, img0 = self.cap.read()<br><br>            self.frame += <span class="hljs-number">1</span><br>            <span class="hljs-comment"># print(f'video {self.count + 1}/{self.nf} ({self.frame}/{self.frames}) {path}: ', end='')</span><br><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># Read image</span><br>            self.count += <span class="hljs-number">1</span><br>            img_path_code = np.fromfile(path, dtype=np.uint8)  <span class="hljs-comment"># 含有中文路径时</span><br>            img0 = cv2.imdecode(img_path_code,<span class="hljs-number">1</span>)  <span class="hljs-comment"># path，，，，BGR</span><br>            <span class="hljs-keyword">assert</span> img0 <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>, <span class="hljs-string">'Image Not Found '</span> + path<br>            <span class="hljs-comment"># print(f'image {self.count}/{self.nf} {path}: ', end='')</span><br><br>        <span class="hljs-comment"># Padded resize</span><br>        img = letterbox(img0, self.img_size, stride=self.stride)[<span class="hljs-number">0</span>]<br><br>        <span class="hljs-comment"># Convert</span><br>        img = img[:, :, ::-<span class="hljs-number">1</span>].transpose(<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)  <span class="hljs-comment"># BGR to RGB and HWC to CHW</span><br>        img = np.ascontiguousarray(img)<br><br>        <span class="hljs-keyword">return</span> path, img, img0, self.cap<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">new_video</span>(<span class="hljs-params">self, path</span>):</span><br>        self.frame = <span class="hljs-number">0</span><br>        self.cap = cv2.VideoCapture(path) <span class="hljs-comment">#VideoCapture()中参数是0，表示打开笔记本的内置摄像头，参数是视频文件路径则打开视频</span><br>        self.frames = <span class="hljs-built_in">int</span>(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">return</span> self.nf  <span class="hljs-comment"># number of files</span><br></code></pre></td></tr></tbody></table></figure><p>detect.py中涉及视频的处理代码：在上述的loaddata中的cap.read()会默认得到的帧图像为640*480，可以使用cap.get()函数得到视频相关属性，使用cap.set()函数设置3，4id的参数值（3，4对应的是宽高属性）</p><blockquote><p>cv2.VideoCapture().set(propId, value)<br>功能：设置摄像头<br>参数：propId：设置的视频参数，<br>　　　　　　　类型：整数，<br>　　　　　　　可以参考 ：cv2.VideoCapture().get()中的参数<br>　　　　　　　value： 设置的参数<br>返回值：bool值：<br>　　　　true:不能确保摄像头已接受属性值<br>　　　　flase:摄像头未接受属性值</p><p>举例：<br>cap.set(3, 480)<br>参数：3：在视频流的帧的宽度<br>　　　480：高度的数值<br>功能：把视频流的帧(图片)的宽度调成480</p><p>cap.set(4, 480)<br>参数：4：在视频流的帧的高度<br>　　　480：宽度的数值<br>功能：把视频流的帧(图片)的高度调成480</p></blockquote><table><thead><tr><th>param</th><th>define</th></tr></thead><tbody><tr><td>cv2.VideoCapture.get(0)</td><td>CV_CAP_PROP_POS_MSEC 视频文件的当前位置（播放）以毫秒为单位</td></tr><tr><td>cv2.VideoCapture.get(1)</td><td>CV_CAP_PROP_POS_FRAMES 基于以0开始的被捕获或解码的帧索引</td></tr><tr><td>cv2.VideoCapture.get(2)</td><td>CV_CAP_PROP_POS_AVI_RATIO 视频文件的相对位置（播放）：0=电影开始，1=影片的结尾。</td></tr><tr><td>cv2.VideoCapture.get(3)</td><td>CV_CAP_PROP_FRAME_WIDTH 在视频流的帧的宽度</td></tr><tr><td>cv2.VideoCapture.get(4)</td><td>CV_CAP_PROP_FRAME_HEIGHT 在视频流的帧的高度</td></tr><tr><td>cv2.VideoCapture.get(5)</td><td>CV_CAP_PROP_FPS 帧速率</td></tr><tr><td>cv2.VideoCapture.get(6)</td><td>CV_CAP_PROP_FOURCC 编解码的4字-字符代码</td></tr><tr><td>cv2.VideoCapture.get(7)</td><td>CV_CAP_PROP_FRAME_COUNT 视频文件中的帧数</td></tr><tr><td>cv2.VideoCapture.get(8)</td><td>CV_CAP_PROP_FORMAT 返回对象的格式</td></tr><tr><td>cv2.VideoCapture.get(9)</td><td>CV_CAP_PROP_MODE 返回后端特定的值，该值指示当前捕获模式</td></tr><tr><td>cv2.VideoCapture.get(10)</td><td>CV_CAP_PROP_BRIGHTNESS 图像的亮度(仅适用于照相机)</td></tr><tr><td>cv2.VideoCapture.get(11)</td><td>CV_CAP_PROP_CONTRAST 图像的对比度(仅适用于照相机)</td></tr><tr><td>cv2.VideoCapture.get(12)</td><td>CV_CAP_PROP_SATURATION 图像的饱和度(仅适用于照相机)</td></tr><tr><td>cv2.VideoCapture.get(13)</td><td>CV_CAP_PROP_HUE 色调图像(仅适用于照相机)</td></tr><tr><td>cv2.VideoCapture.get(14)</td><td>CV_CAP_PROP_GAIN 图像增益(仅适用于照相机)（Gain在摄影中表示白平衡提升）</td></tr><tr><td>cv2.VideoCapture.get(15)</td><td>CV_CAP_PROP_EXPOSURE 曝光(仅适用于照相机)</td></tr><tr><td>cv2.VideoCapture.get(16)</td><td>CV_CAP_PROP_CONVERT_RGB 指示是否应将图像转换为RGB布尔标志</td></tr><tr><td>cv2.VideoCapture.get(17)</td><td>CV_CAP_PROP_WHITE_BALANCE × 暂时不支持</td></tr><tr><td>cv2.VideoCapture.get(18)</td><td>CV_CAP_PROP_RECTIFICATION 立体摄像机的矫正标注（目前只有DC1394 v.2.x后端支持这个功能）</td></tr></tbody></table><table><thead><tr><th>capture.set</th><th>作用</th></tr></thead><tbody><tr><td>capture.set(CV_CAP_PROP_FRAME_WIDTH, 1080);</td><td>宽度</td></tr><tr><td>capture.set(CV_CAP_PROP_FRAME_HEIGHT, 960);</td><td>高度</td></tr><tr><td>capture.set(CV_CAP_PROP_FPS, 30);</td><td>帧率 帧/秒</td></tr><tr><td>capture.set(CV_CAP_PROP_BRIGHTNESS, 1);</td><td>亮度</td></tr><tr><td>capture.set(CV_CAP_PROP_CONTRAST,40)</td><td>对比度 40</td></tr><tr><td>capture.set(CV_CAP_PROP_SATURATION, 50);</td><td>饱和度 50</td></tr><tr><td>capture.set(CV_CAP_PROP_HUE, 50);</td><td>色调 50</td></tr><tr><td>capture.set(CV_CAP_PROP_EXPOSURE, 50);</td><td>曝光 50 获取摄像头参数</td></tr></tbody></table><h3 id="具体代码">具体代码</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Set Dataloader</span><br>vid_path, vid_writer = <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span><br><span class="hljs-keyword">if</span> webcam:<br>    view_img = check_imshow()<br>    cudnn.benchmark = <span class="hljs-literal">True</span>  <span class="hljs-comment"># set True to speed up constant image size inference</span><br>    dataset = LoadStreams(source, img_size=imgsz, stride=stride)<br><span class="hljs-keyword">else</span>:<br>    dataset = LoadImages(source, img_size=imgsz, stride=stride)<br><br><span class="hljs-keyword">for</span> path, img, im0s, vid_cap <span class="hljs-keyword">in</span> tqdm(dataset): <span class="hljs-comment">#一个batch的信息</span><br>    img_path_list.append(path)<br>    img = torch.from_numpy(img).to(device)<br>    img = img.half() <span class="hljs-keyword">if</span> half <span class="hljs-keyword">else</span> img.<span class="hljs-built_in">float</span>()  <span class="hljs-comment"># uint8 to fp16/32</span><br>    img /= <span class="hljs-number">255.0</span>  <span class="hljs-comment"># 0 - 255 to 0.0 - 1.0</span><br>    <span class="hljs-keyword">if</span> img.ndimension() == <span class="hljs-number">3</span>:<br>        img = img.unsqueeze(<span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment"># Inference</span><br>    t1 = time_synchronized()<br>    pred = model(img, augment=augment)[<span class="hljs-number">0</span>]<br><br>    <span class="hljs-comment"># Apply NMS</span><br>    pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)<br>    t2 = time_synchronized()<br><br>    <span class="hljs-comment"># Process detections</span><br>    <span class="hljs-comment"># imgbox_list = [] #一张图的box信息</span><br>    Vorticella_list = []<br>    Rotifera_list = []<br><br><br>    <span class="hljs-keyword">for</span> i, det <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(pred):  <span class="hljs-comment"># detections per image 一张图信息</span><br>        <span class="hljs-keyword">if</span> webcam:  <span class="hljs-comment"># batch_size &gt;= 1</span><br>            p, s, im0, frame = path[i], <span class="hljs-string">f'<span class="hljs-subst">{i}</span>: '</span>, im0s[i].copy(), dataset.count<br>        <span class="hljs-keyword">else</span>:<br>            p, s, im0, frame = path, <span class="hljs-string">''</span>, im0s.copy(), <span class="hljs-built_in">getattr</span>(dataset, <span class="hljs-string">'frame'</span>, <span class="hljs-number">0</span>) <br>        s += <span class="hljs-string">'%gx%g '</span> % img.shape[<span class="hljs-number">2</span>:]  <span class="hljs-comment"># print string</span><br>        p = Path(p)  <span class="hljs-comment"># to Path</span><br>        save_path = save_dir+p.name <span class="hljs-comment"># img.jpg</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(det):<br>            <span class="hljs-comment"># Rescale boxes from img_size to im0 size</span><br>            <span class="hljs-comment"># 调整预测框的坐标：基于resize+pad的图片的坐标--&gt;基于原size图片的坐标</span><br>            <span class="hljs-comment"># 此时坐标格式为xyxy</span><br>            det[:, :<span class="hljs-number">4</span>] = scale_coords(img.shape[<span class="hljs-number">2</span>:], det[:, :<span class="hljs-number">4</span>], im0.shape).<span class="hljs-built_in">round</span>()<br><br>            <span class="hljs-comment"># Print results</span><br>            <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> det[:, -<span class="hljs-number">1</span>].unique():<br>                n = (det[:, -<span class="hljs-number">1</span>] == c).<span class="hljs-built_in">sum</span>()  <span class="hljs-comment"># detections per class</span><br>                s += <span class="hljs-string">f"<span class="hljs-subst">{n}</span> <span class="hljs-subst">{names[<span class="hljs-built_in">int</span>(c)]}</span><span class="hljs-subst">{<span class="hljs-string">'s'</span> * (n &gt; <span class="hljs-number">1</span>)}</span>, "</span>  <span class="hljs-comment"># add to string</span><br>            <span class="hljs-comment"># ["Vorticella", "Rotifera"]</span><br>            <span class="hljs-comment"># Write results</span><br>            <span class="hljs-comment"># for *xyxy, conf, cls in reversed(det):</span><br>            <span class="hljs-keyword">for</span> *xyxy, conf, cls <span class="hljs-keyword">in</span> det: <span class="hljs-comment">#置信度从大到小 #图中的所有框信息</span><br>                xywh_no_norm = xyxy2xywh(torch.tensor(xyxy).view(<span class="hljs-number">1</span>, <span class="hljs-number">4</span>)).view(-<span class="hljs-number">1</span>).tolist()<br>                box = (cls, xywh_no_norm, conf) <span class="hljs-comment">#存储类别 xywh 置信度</span><br>                <span class="hljs-keyword">if</span>(conf&lt;sift_thres):<span class="hljs-keyword">continue</span> <span class="hljs-comment">#过滤置信度小于0.7的框</span><br>                <span class="hljs-keyword">if</span>(cls==<span class="hljs-number">0</span>):<br>                    Vorticella_list.append(box)<br>                <span class="hljs-keyword">elif</span>(cls==<span class="hljs-number">1</span>):<br>                    Rotifera_list.append(box)<br>                <span class="hljs-comment"># imgbox_list.append(box)</span><br>                c = <span class="hljs-built_in">int</span>(cls)  <span class="hljs-comment"># integer class</span><br>                label = <span class="hljs-string">f'<span class="hljs-subst">{names[c]}</span> <span class="hljs-subst">{conf:<span class="hljs-number">.2</span>f}</span>'</span><br>                plot_one_box(xyxy, im0, label=label, color=colors(c, <span class="hljs-literal">True</span>), line_thickness=<span class="hljs-number">3</span>)<br><br>        <span class="hljs-comment"># Save results (image with detections)</span><br>        <span class="hljs-keyword">if</span> save_img:<br>            <span class="hljs-keyword">if</span> dataset.mode == <span class="hljs-string">'image'</span>:<br>                cv2.imwrite(save_path, im0)<br>            <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># 'video' or 'stream'</span><br>                <span class="hljs-keyword">if</span> vid_path != save_path:  <span class="hljs-comment"># new video</span><br>                    vid_path = save_path<br>                    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(vid_writer, cv2.VideoWriter):<br>                        vid_writer.release()  <span class="hljs-comment"># release previous video writer</span><br>                    <span class="hljs-keyword">if</span> vid_cap:  <span class="hljs-comment"># video</span><br>                        fps = vid_cap.get(cv2.CAP_PROP_FPS) <span class="hljs-comment">#获取原始视频的帧率</span><br>                        <span class="hljs-comment"># w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH)) #获取原始视频帧宽</span><br>                        <span class="hljs-comment"># h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) #获取原始视频的高</span><br>                        w, h =  im0.shape[<span class="hljs-number">1</span>], im0.shape[<span class="hljs-number">0</span>] <span class="hljs-comment">#更新为原始图像的宽高</span><br>                    <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># stream</span><br>                        fps, w, h = <span class="hljs-number">30</span>, im0.shape[<span class="hljs-number">1</span>], im0.shape[<span class="hljs-number">0</span>]<br>                        <span class="hljs-comment"># save_path += '.mp4'</span><br>                        save_path += <span class="hljs-string">'.flv'</span><br>                    <span class="hljs-comment"># vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))</span><br><br>                    vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(<span class="hljs-string">'F'</span>, <span class="hljs-string">'L'</span>, <span class="hljs-string">'V'</span>, <span class="hljs-string">'1'</span>), fps, (w, h))<br>                vid_writer.write(im0)<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
      <category>图像</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>图像</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>np.squeeze的用法</title>
    <link href="/2021/10/29/python/func/squeeze/"/>
    <url>/2021/10/29/python/func/squeeze/</url>
    
    <content type="html"><![CDATA[<blockquote><p>记录squeeze() 的相关用法，以及pytorch学习 中 torch.squeeze() 和torch.unsqueeze()的用法。</p></blockquote><h3 id="numpy的squeeze函数">numpy的squeeze函数</h3><h4 id="函数说明">函数说明</h4><p>适用于一处数组中的单一维度，也就是去掉数组轴中维度为1的维度，函数说明如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs python">np.squeeze()<br>---------------------------------------------------------------------------<br>TypeError                                 Traceback (most recent call last)<br>&lt;ipython-<span class="hljs-built_in">input</span>-<span class="hljs-number">3</span>-c5986a7939bf&gt; <span class="hljs-keyword">in</span> &lt;module&gt;<br>----&gt; <span class="hljs-number">1</span> np.squeeze()<br><br>&lt;__array_function__ internals&gt; <span class="hljs-keyword">in</span> squeeze(*args, **kwargs)<br><br>TypeError: _squeeze_dispatcher() missing <span class="hljs-number">1</span> required positional argument: <span class="hljs-string">'a'</span><br><br>​<br>Signature: np.squeeze(a, axis=<span class="hljs-literal">None</span>)<br>Docstring:<br>Remove single-dimensional entries <span class="hljs-keyword">from</span> the shape of an array.<br><br>Parameters<br>----------<br>a : array_like<br>    Input data.<br>axis : <span class="hljs-literal">None</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">int</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">tuple</span> of ints, optional<br>    .. versionadded:: <span class="hljs-number">1.7</span><span class="hljs-number">.0</span><br><br>    Selects a subset of the single-dimensional entries <span class="hljs-keyword">in</span> the<br>    shape. If an axis <span class="hljs-keyword">is</span> selected <span class="hljs-keyword">with</span> shape entry greater than<br>    one, an error <span class="hljs-keyword">is</span> raised.<br><br>Returns<br>-------<br>squeezed : ndarray<br>    The <span class="hljs-built_in">input</span> array, but <span class="hljs-keyword">with</span> <span class="hljs-built_in">all</span> <span class="hljs-keyword">or</span> a subset of the<br>    dimensions of length <span class="hljs-number">1</span> removed. This <span class="hljs-keyword">is</span> always `a` itself<br>    <span class="hljs-keyword">or</span> a view into `a`.<br><br>Raises<br>------<br>ValueError<br>    If `axis` <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>, <span class="hljs-keyword">and</span> an axis being squeezed <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> of length <span class="hljs-number">1</span><br><br>See Also<br>--------<br>expand_dims : The inverse operation, adding singleton dimensions<br>reshape : Insert, remove, <span class="hljs-keyword">and</span> combine dimensions, <span class="hljs-keyword">and</span> resize existing ones<br><br>Examples<br>--------<br><span class="hljs-meta">&gt;&gt;&gt; </span>x = np.array([[[<span class="hljs-number">0</span>], [<span class="hljs-number">1</span>], [<span class="hljs-number">2</span>]]])<br><span class="hljs-meta">&gt;&gt;&gt; </span>x.shape<br>(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>np.squeeze(x).shape<br>(<span class="hljs-number">3</span>,)<br><span class="hljs-meta">&gt;&gt;&gt; </span>np.squeeze(x, axis=<span class="hljs-number">0</span>).shape<br>(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>np.squeeze(x, axis=<span class="hljs-number">1</span>).shape<br>Traceback (most recent call last):<br>...<br>ValueError: cannot select an axis to squeeze out which has size <span class="hljs-keyword">not</span> equal to one<br><span class="hljs-meta">&gt;&gt;&gt; </span>np.squeeze(x, axis=<span class="hljs-number">2</span>).shape<br>(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br></code></pre></td></tr></tbody></table></figure><h4 id="举例">举例</h4><p>指定轴进行压缩单一的维度，如果指定轴维度不为1，就会返回ValueError。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python">b = a.reshape(<span class="hljs-number">5</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>) <span class="hljs-comment">#axis 分别为0，1，2，3</span><br>b<br>array([[[[ <span class="hljs-number">1</span>],<br>         [ <span class="hljs-number">2</span>]]],<br><br><br>       [[[ <span class="hljs-number">3</span>],<br>         [ <span class="hljs-number">4</span>]]],<br><br><br>       [[[ <span class="hljs-number">5</span>],<br>         [ <span class="hljs-number">6</span>]]],<br><br><br>       [[[ <span class="hljs-number">7</span>],<br>         [ <span class="hljs-number">8</span>]]],<br><br><br>       [[[ <span class="hljs-number">9</span>],<br>         [<span class="hljs-number">10</span>]]]])<br>np.squeeze(b,axis=<span class="hljs-number">3</span>) <span class="hljs-comment">#指定维度为1的axis进行squeeze</span><br>array([[[ <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>]],<br><br>       [[ <span class="hljs-number">3</span>,  <span class="hljs-number">4</span>]],<br><br>       [[ <span class="hljs-number">5</span>,  <span class="hljs-number">6</span>]],<br><br>       [[ <span class="hljs-number">7</span>,  <span class="hljs-number">8</span>]],<br><br>       [[ <span class="hljs-number">9</span>, <span class="hljs-number">10</span>]]])<br><br>np.squeeze(b,axis=<span class="hljs-number">1</span>)<br>array([[[ <span class="hljs-number">1</span>],<br>        [ <span class="hljs-number">2</span>]],<br><br>       [[ <span class="hljs-number">3</span>],<br>        [ <span class="hljs-number">4</span>]],<br><br>       [[ <span class="hljs-number">5</span>],<br>        [ <span class="hljs-number">6</span>]],<br><br>       [[ <span class="hljs-number">7</span>],<br>        [ <span class="hljs-number">8</span>]],<br><br>       [[ <span class="hljs-number">9</span>],<br>        [<span class="hljs-number">10</span>]]])<br>        <br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">如果指定轴为<span class="hljs-number">1</span>，就会报错ValueError<br>ValueError                                Traceback (most recent call last)<br>&lt;ipython-<span class="hljs-built_in">input</span>-<span class="hljs-number">27</span>-5187bab4a1cf&gt; <span class="hljs-keyword">in</span> &lt;module&gt;<br>----&gt; <span class="hljs-number">1</span> np.squeeze(b,axis=<span class="hljs-number">0</span>)<br><br>&lt;__array_function__ internals&gt; <span class="hljs-keyword">in</span> squeeze(*args, **kwargs)<br><br>D:\Anaconda3\lib\site-packages\numpy\core\fromnumeric.py <span class="hljs-keyword">in</span> squeeze(a, axis)<br>   <span class="hljs-number">1481</span>         <span class="hljs-keyword">return</span> squeeze()<br>   <span class="hljs-number">1482</span>     <span class="hljs-keyword">else</span>:<br>-&gt; <span class="hljs-number">1483</span>         <span class="hljs-keyword">return</span> squeeze(axis=axis)<br>   <span class="hljs-number">1484</span> <br>   <span class="hljs-number">1485</span> <br><br>ValueError: cannot select an axis to squeeze out which has size <span class="hljs-keyword">not</span> equal to one<br></code></pre></td></tr></tbody></table></figure><h3 id="pytorch中的squeeze和unsqueeze函数">pytorch中的squeeze和unsqueeze函数</h3><p>在pytorch中也有相关的函数，与numpy中的函数类似。</p><p>squeeze的用法主要就是对数据的维度进行压缩或者解压。</p><p>先看<code>torch.squeeze()</code> 这个函数主要对数据的维度进行压缩，<strong>去掉维数为1的的维度</strong>，比如是一行或者一列这种，一个一行三列（1,3）的数去掉第一个维数为一的维度之后就变成（3）行。squeeze(a)就是将a中所有为1的维度删掉。不为1的维度没有影响。a.squeeze(N) 就是去掉a中指定的维数为一的维度。还有一种形式就是b=torch.squeeze(a，N) a中去掉指定的定的维数为一的维度。</p><p>再看<code>torch.unsqueeze()</code>这个函数主要是对数据维度进行扩充。<strong>给指定位置加上维数为一的维度</strong>，比如原本有个三行的数据（3），在0的位置加了一维就变成一行三列（1,3）。a.squeeze(N) 就是在a中指定位置N加上一个维数为1的维度。还有一种形式就是b=torch.squeeze(a，N) a就是在a中指定位置N加上一个维数为1的维度</p>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>获得电脑的ppi</title>
    <link href="/2021/10/26/python/getppi/"/>
    <url>/2021/10/26/python/getppi/</url>
    
    <content type="html"><![CDATA[<blockquote><p>获取电脑的分辨率，物理尺寸，PPI<br>首先介绍一下PPI和DPI：<br>PPI（Pixels Per Inch）每一英寸长度上有多少像素点；计算方式可以使用像素点除以屏幕尺寸。<br>分辨率DPI（Dots Per Inch）每一英寸有多少点，这里的点是可以改变的，可以是 1Dot = 1Pixel，也可以是 1Dot = N Pixel。在电脑里，分辩率是可以调节的，这里用的就是Dot ，密度用DPI描述；只有当使用屏幕最大分辩率的时候（即 1Dot = 1Pixel），这个时候 DPI = PPI。</p></blockquote><p>搜集了很多代码和方法，最后找到一个比较精准的方法是使用Tkinter。</p><ul><li>可以得到显示屏的尺寸，获取以毫米为单位宽高（winfo_screenmmheight()，winfo_screenmmwidth()），获取显示屏的pixels数目（winfo_screenheight()，winfo_screenwidth()）。</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># tk获取屏幕的分辨率和尺寸</span><br><span class="hljs-keyword">from</span> tkinter <span class="hljs-keyword">import</span> Tk<br><span class="hljs-comment"># creating tkinter window</span><br>base = Tk()<br><span class="hljs-comment">#screen's length and width in pixels and mm</span><br>length_1= base.winfo_screenheight()<br>width_1= base.winfo_screenwidth()<br>length_2 = base.winfo_screenmmheight()<br>width_2 = base.winfo_screenmmwidth()<br><span class="hljs-comment">#screen Depth</span><br>screendepth = base.winfo_screendepth()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"width x length (in pixels) ="</span>,(width_1,length_1))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"width x length (in mm) ="</span>, (width_2, length_2))<br>width_ppn = width_1/width_2<br>length_ppn = length_1/length_2<br>ppn = <span class="hljs-built_in">round</span>((width_ppn+length_ppn)/<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(width_1/width_2,length_1/length_2,ppn)<br><br></code></pre></td></tr></tbody></table></figure><ul><li>使用win32库中的分辨率方法win32print.GetDeviceCaps()，缩放后的分辨率GetSystemMetrics。</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">## 获取分辨率</span><br><span class="hljs-keyword">from</span> win32 <span class="hljs-keyword">import</span> win32api, win32gui, win32print<br><span class="hljs-keyword">from</span> win32.lib <span class="hljs-keyword">import</span> win32con<br><br><span class="hljs-keyword">from</span> win32.win32api <span class="hljs-keyword">import</span> GetSystemMetrics<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_real_resolution</span>():</span><br>    <span class="hljs-string">"""获取真实的分辨率"""</span><br>    hDC = win32gui.GetDC(<span class="hljs-number">0</span>)<br>    <span class="hljs-comment"># 横向分辨率</span><br>    w = win32print.GetDeviceCaps(hDC, win32con.DESKTOPHORZRES)<br>    <span class="hljs-comment"># 纵向分辨率</span><br>    h = win32print.GetDeviceCaps(hDC, win32con.DESKTOPVERTRES)<br>    <span class="hljs-keyword">return</span> w, h<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_screen_size</span>():</span><br>    <span class="hljs-string">"""获取缩放后的分辨率"""</span><br>    w = GetSystemMetrics (<span class="hljs-number">0</span>)<br>    h = GetSystemMetrics (<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> w, h<br><br>real_resolution = get_real_resolution()<br>screen_size = get_screen_size()<br><span class="hljs-built_in">print</span>(real_resolution)<br><span class="hljs-built_in">print</span>(screen_size)<br><br>screen_scale_rate = <span class="hljs-built_in">round</span>(real_resolution[<span class="hljs-number">0</span>] / screen_size[<span class="hljs-number">0</span>], <span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(screen_scale_rate)<br></code></pre></td></tr></tbody></table></figure><ul><li>多屏的分辨率获取的方法。</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#屏幕的尺寸</span><br><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-string">"""</span><br><span class="hljs-string">功能：识别两块显示器各自的分辨率</span><br><span class="hljs-string">"""</span><br><span class="hljs-string">"""模块导入"""</span><br><span class="hljs-keyword">from</span> win32api <span class="hljs-keyword">import</span> GetSystemMetrics<br><span class="hljs-keyword">from</span> win32con <span class="hljs-keyword">import</span> SM_CMONITORS, SM_CXVIRTUALSCREEN, SM_CYVIRTUALSCREEN<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Display_Detection</span>():</span><br>    <span class="hljs-comment"># 显示器数量检测</span><br>    MonitorNumber = GetSystemMetrics(SM_CMONITORS)<br>    <span class="hljs-comment"># 主屏幕尺寸检测</span><br>    MajorScreenWidth = GetSystemMetrics(<span class="hljs-number">0</span>)  <span class="hljs-comment"># 主屏幕宽</span><br>    MajorScreenHeight = GetSystemMetrics(<span class="hljs-number">1</span>)  <span class="hljs-comment"># 主屏幕高</span><br>    <span class="hljs-comment"># print("主屏幕尺寸：", GetSystemMetrics(0), "*", GetSystemMetrics(1))</span><br>    <span class="hljs-comment"># 屏幕最大尺寸</span><br>    aScreenWidth = GetSystemMetrics(SM_CXVIRTUALSCREEN)  <span class="hljs-comment"># 屏幕最大宽度</span><br>    aScreenHeight = GetSystemMetrics(SM_CYVIRTUALSCREEN)  <span class="hljs-comment"># 屏幕最大高度</span><br>    AllScreen=(aScreenWidth, aScreenHeight)<br>    <span class="hljs-comment"># print("屏幕总尺寸:", aScreenWidth, "*", aScreenHeight)</span><br>    <span class="hljs-comment"># 当前主流的分辨率基数是宽，偶数是高</span><br>    ResolvingPower = [<span class="hljs-number">1280</span>, <span class="hljs-number">720</span>, <span class="hljs-number">1920</span>, <span class="hljs-number">1080</span>, <span class="hljs-number">2560</span>, <span class="hljs-number">1440</span>, <span class="hljs-number">3840</span>, <span class="hljs-number">2160</span>, <span class="hljs-number">4096</span>, <span class="hljs-number">2160</span>, <span class="hljs-number">7680</span>, <span class="hljs-number">4320</span>]<br><br>    <span class="hljs-keyword">if</span> MonitorNumber &gt; <span class="hljs-number">1</span>:  <span class="hljs-comment"># 屏幕数量判断print(MonitorNumber)就可以知道有多少块屏幕</span><br>        SecondaryScreenWidth = aScreenWidth - MajorScreenWidth  <span class="hljs-comment"># 副屏宽=总屏幕宽-当前屏幕宽</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">"副屏宽"</span>,SecondaryScreenWidth)<br><br>        <span class="hljs-comment"># 主屏横竖屏检测</span><br>        <span class="hljs-keyword">if</span> GetSystemMetrics(<span class="hljs-number">0</span>) &gt; GetSystemMetrics(<span class="hljs-number">1</span>):<br>            MianScreen = (GetSystemMetrics(<span class="hljs-number">0</span>), GetSystemMetrics(<span class="hljs-number">1</span>))<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">"主屏(横屏)尺寸："</span>, GetSystemMetrics(<span class="hljs-number">0</span>), <span class="hljs-string">"*"</span>, GetSystemMetrics(<span class="hljs-number">1</span>))<br>        <span class="hljs-keyword">else</span>:<br>            MianScreen = (GetSystemMetrics(<span class="hljs-number">0</span>), GetSystemMetrics(<span class="hljs-number">1</span>))<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">"主屏(竖屏)尺寸："</span>, GetSystemMetrics(<span class="hljs-number">0</span>), <span class="hljs-string">"*"</span>, GetSystemMetrics(<span class="hljs-number">1</span>))<br><br>        <span class="hljs-comment"># 横屏状态</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(ResolvingPower) - <span class="hljs-number">1</span>, <span class="hljs-number">2</span>):<br>            <span class="hljs-comment"># print("i",ResolvingPower[i])</span><br>            <span class="hljs-keyword">if</span> SecondaryScreenWidth == ResolvingPower[i]:<br>                SecondaryScreen = (ResolvingPower[i], ResolvingPower[i + <span class="hljs-number">1</span>])<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">"副屏(横屏)尺寸："</span>, ResolvingPower[i], ResolvingPower[i + <span class="hljs-number">1</span>])<br>                <span class="hljs-comment"># return "副屏(竖屏)尺寸：",SecondaryScreen</span><br>                <span class="hljs-keyword">break</span><br>        <span class="hljs-comment"># 竖屏状态</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(ResolvingPower) - <span class="hljs-number">1</span>, <span class="hljs-number">2</span>):<br>            <span class="hljs-comment"># print("i",ResolvingPower[i])</span><br>            <span class="hljs-keyword">if</span> SecondaryScreenWidth == ResolvingPower[i]:<br>                SecondaryScreen = (ResolvingPower[i], ResolvingPower[i + <span class="hljs-number">1</span>])<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">"副屏(竖屏)尺寸："</span>, ResolvingPower[i], ResolvingPower[i - <span class="hljs-number">1</span>])<br>                <span class="hljs-comment"># return "副屏(竖屏)尺寸",SecondaryScreen</span><br>                <span class="hljs-keyword">break</span><br>    <span class="hljs-keyword">return</span> MonitorNumber,AllScreen,MianScreen,SecondaryScreen<br><br><span class="hljs-comment">#调用</span><br>a=Display_Detection()<br><span class="hljs-built_in">print</span>(a)<span class="hljs-comment">#a可以任意遍历其中的内容a[0]代表屏幕数量等等...</span><br><br>主屏(横屏)尺寸： <span class="hljs-number">1920</span> * <span class="hljs-number">1080</span><br>副屏(竖屏)尺寸： <span class="hljs-number">1440</span> <span class="hljs-number">2560</span><br>(<span class="hljs-number">2</span>, (<span class="hljs-number">3360</span>, <span class="hljs-number">1080</span>), (<span class="hljs-number">1920</span>, <span class="hljs-number">1080</span>), (<span class="hljs-number">1440</span>, <span class="hljs-number">3840</span>))<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Sartorius竞赛数据说明</title>
    <link href="/2021/10/21/kaggle/kaggle-data-intro/"/>
    <url>/2021/10/21/kaggle/kaggle-data-intro/</url>
    
    <content type="html"><![CDATA[<blockquote><p>数据说明</p></blockquote><p>Data Description</p><p>In this competition we are segmenting neuronal cells in images. The training annotations are provided as run length encoded masks, and the images are in PNG format. The number of images is small, but the number of annotated objects is quite high. The hidden test set is roughly 240 images.</p><p><strong>Note: while predictions are not allowed to overlap, the training labels are provided in full (with overlapping portions included). This is to ensure that models are provided the full data for each object. Removing overlap in predictions is a task for the competitor.</strong></p><h2 id="Files">Files</h2><p><strong>train.csv</strong> - IDs and masks for all training objects. None of this metadata is provided for the test set.</p><ul><li><code>id</code> - unique identifier for object</li><li><code>annotation</code> - run length encoded pixels for the identified neuronal cell</li><li><code>width</code> - source image width</li><li><code>height</code> - source image height</li><li><code>cell_type</code> - the cell line</li><li><code>plate_time</code> - time plate was created</li><li><code>sample_date</code> - date sample was created</li><li><code>sample_id</code> - sample identifier</li><li><code>elapsed_timedelta</code> - time since first image taken of sample</li></ul><p><strong>sample_submission.csv</strong> - a sample submission file in the correct format</p><p><strong>train</strong> - train images in PNG format</p><p><strong>test</strong> - test images in PNG format. Only a few test set images are available for download; the remainder can only be accessed by your notebooks when you submit.</p><p><strong>train_semi_supervised</strong> - unlabeled images offered in case you want to use additional data for a semi-supervised approach.</p><p><strong>LIVECell_dataset_2021</strong> - A mirror of the data from <a href="https://github.com/sartorius-research/LIVECell">the LIVECell dataset</a>. LIVECell is the predecessor dataset to this competition. You will find extra data for the <code>SH-SHY5Y</code> cell line, plus several other cell lines not covered in the competition dataset that may be of interest for transfer learning.</p>]]></content>
    
    
    <categories>
      
      <category>kaggle</category>
      
    </categories>
    
    
    <tags>
      
      <tag>kaggle</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>kaggle比赛介绍--Sartorius - Cell Instance Segmentation</title>
    <link href="/2021/10/21/kaggle/kaggle-intro/"/>
    <url>/2021/10/21/kaggle/kaggle-intro/</url>
    
    <content type="html"><![CDATA[<blockquote><p>最近参赛Sartorius - Cell Instance Segmentation，对竞赛题目和相关注意点进行梳理记录，以便后续回顾。</p></blockquote><h2 id="竞赛说明">竞赛说明</h2><p>Sartorius - Cell Instance Segmentation，是一个有关医学图像<strong>实例分割</strong>的竞赛</p><p>地址： <a href="https://www.kaggle.com/c/sartorius-cell-instance-segmentation/overview">https://www.kaggle.com/c/sartorius-cell-instance-segmentation/overview</a></p><h3 id="Description">Description</h3><p>Neurological disorders, including neurodegenerative diseases such as Alzheimer’s and brain tumors, are a leading cause of death and disability across the globe. However, it is hard to quantify how well these deadly disorders respond to treatment. <strong>One accepted method is to review neuronal cells via light microscopy,</strong> which is both accessible and non-invasive. Unfortunately, <strong>segmenting individual neuronal cells</strong> in microscopic images can be challenging and time-intensive. Accurate instance segmentation of these cells—with the help of computer vision—could lead to new and effective drug discoveries to treat the millions of people with these disorders.</p><p><img src="https://storage.googleapis.com/kaggle-media/competitions/Sartorius/Sartorius_Competition%20Description%20Image%20350x379.png" alt="img"></p><p>Current solutions have limited accuracy for neuronal cells in particular. In internal studies to develop cell instance segmentation models, the neuroblastoma cell line SH-SY5Y consistently exhibits the lowest precision scores out of eight different cancer cell types tested. This could be because neuronal cells have a very <strong>unique, irregular and concave morphology</strong> associated with them, making them challenging to segment with commonly used mask heads.</p><p>Sartorius is a partner of the life science research and the biopharmaceutical industry. They empower scientists and engineers to simplify and accelerate progress in life science and bioprocessing, enabling the development of new and better therapies and more affordable medicine. They’re a magnet and dynamic platform for pioneers and leading experts in the field. They bring creative minds together for a common goal: technological breakthroughs that lead to better health for more people.</p><p><font color="purple"> <strong>In this competition, you’ll detect and delineate distinct objects of interest in biological images depicting neuronal cell types commonly used in the study of neurological disorders.</strong> More specifically, you’ll use phase contrast microscopy images to train and test your model for instance segmentation of neuronal cells. Successful models will do this with a high level of accuracy.</font></p><p>If successful, you’ll help further research in neurobiology thanks to the collection of robust quantitative data. Researchers may be able to use this to more easily measure the effects of disease and treatment conditions on neuronal cells. As a result, new drugs could be discovered to treat the millions of people with these leading causes of death and disability.</p><h4 id="个人理解">个人理解</h4><p>也就是说为了量化神经系统类的致命疾病对治疗的反应。一种方法是通过光学显微镜检查神经元细胞，因为这种方法既方便又非侵入性。但是，在显微图像中分割单个神经元细胞可能具有挑战性且耗时。所以需要采取计算机视觉的方法提高精度和效率。由于神经母细胞瘤细胞系（SH-SY5Y）独特，不规则，凹形的形态（unique, irregular and concave morphology），使用常规的分割模型进行分割效果不好。</p><h3 id="Evaluation">Evaluation</h3><p>This competition is evaluated on the mean average precision at different intersection over union IUO thresholds. The IoU of a proposed set of object pixels and a set of true object pixels is calculated as:</p><p>$$<br>IoU(A,B) = \frac{A \cap B}{A \cup B}<br>$$</p><p>The metric sweeps over a range of IoU thresholds, at each point calculating an average precision value. The threshold values range from 0.5 to 0.95 with a step size of 0.05: <code>(0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95)</code>. In other words, at a threshold of 0.5, a predicted object is considered a “hit” if its intersection over union with a ground truth object is greater than 0.5.</p><p>At each threshold value <strong>t</strong>, a precision value is calculated based on the number of true positives <strong>TP</strong>, false negatives <strong>FN</strong>, and false positives <strong>FP</strong> resulting from comparing the predicted object to all ground truth objects:</p><p>$$<br>\frac{TP(t)}{TP(t)+FP(t)+FN(t)}<br>$$</p><p>A true positive is counted when a single predicted object matches a ground truth object with an IoU above the threshold. A false positive indicates a predicted object had no associated ground truth object. A false negative indicates a ground truth object had no associated predicted object. The average precision of a single image is then calculated as the mean of the above precision values at each IoU threshold:<br>$$<br>\frac{1}{\vert thresholds \vert} \sum_t \frac{TP(t)}{TP{t}+FP(t)+FN(t)}<br>$$<br>Lastly, the score returned by the competition metric is the mean taken over the individual average precisions of each image in the test dataset.</p><h4 id="个人理解-2">个人理解</h4><p>此处介绍了评估指标，以及最后排名score的度量方式。人为设置prediction和ground truth的IoU的thresholds，这样可以度量TP，FN，FP（正确实例分割object个数，没有检测到的object个数，误检出的object个数），进而得到score。</p><h5 id="疑问">疑问</h5><ul><li>这里评估指标中没有提到分类，实例分割除了分割前景和背景，不应该还需要评估类别吗？还是说在度量IOU的时候已经包含了对类别的判断。</li><li>最后的score中为什么要除以thresholds，意义何在？</li></ul><h2 id="Submission-File">Submission File</h2><p>In order to reduce the submission file size, our metric uses run-length encoding on the pixel values. Instead of submitting an exhaustive list of indices for your segmentation, you will submit pairs of values that contain a start position and a run length. E.g. ‘1 3’ implies starting at pixel 1 and running a total of 3 pixels 1,2,3.</p><p>The competition format requires a space delimited list of pairs. <strong>For example, ‘1 3 10 5’ implies pixels 1,2,3,10,11,12,13,14 are to be included in the mask. The pixels are one-indexed</strong><br><strong>and numbered from top to bottom, then left to right: 1 is pixel 1,1, 2 is pixel 2,1, etc.</strong></p><p>The metric checks that the pairs are sorted, positive, and the decoded pixel values are not duplicated. <font color="purple"><strong>It also checks that no two predicted masks for the same image are overlapping.</strong></font></p><p>The file should contain a header and have the following format. Each row in your submission represents a single predicted nucleus segmentation for the given <code>ImageId</code>.</p><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">id</span>,predicted  <br><span class="hljs-attribute">0114f484a16c152baa2d82fdd43740880a762c93f436c8988ac461c5c9dbe7d5</span>,<span class="hljs-number">1</span> <span class="hljs-number">1</span>  <br><span class="hljs-attribute">0999dab07b11bc85fb8464fc36c947fbd8b5d6ec49817361cb780659ca805eac</span>,<span class="hljs-number">1</span> <span class="hljs-number">1</span>  <br><span class="hljs-attribute">0999dab07b11bc85fb8464fc36c947fbd8b5d6ec49817361cb780659ca805eac</span>,<span class="hljs-number">2</span> <span class="hljs-number">3</span> <span class="hljs-number">8</span> <span class="hljs-number">9</span>  <br><span class="hljs-attribute">etc</span>...<br></code></pre></td></tr></tbody></table></figure><p>Submission files may take several minutes to process due to the size.</p><h4 id="个人理解-3">个人理解</h4><p>这里说明了提交的文件格式。</p><ul><li><p>不同与一般的图像文件，首先需要将图片的像素点从上到下，从左到右标号为1，2，3…,然后将图片的分割得到的像素点标识为<code>'起始点1 个数1 起始点2 个数2 .....'</code>，</p></li><li><p>注意点是提交的预测在同一张图中预测的mask不允许有重合像素。也就是说该竞赛涉及对于不同的细胞系实例分割，并且在一张图上分割的细胞系mask，不能有交点。<strong>训练数据中label是会出现重叠部分的，在预测的结果中需要消除预测重叠部分。</strong></p><blockquote><p>Note: while predictions are not allowed to overlap, the training labels are provided in full (with overlapping portions included). This is to ensure that models are provided the full data for each object. Removing overlap in predictions is a task for the competitor.</p></blockquote></li></ul><h5 id="attention（待尝试）">attention（待尝试）</h5><p>在讨论区中有人说mask实际上要 (left -&gt; right, top -&gt; bottom) 标号，不知道后续主办方有没有更换内部测试代码。</p><h5 id="Mask-encoding">Mask encoding</h5><p>In submission, we have to encoding mask. Evaluation page show the pixels are numbered from top to bottom, then left to right. But, this is not correct. As you know, the training annotations provided are numbered from left to right, then top to bottom, and this is also the case with submission.<br>An LB score with encoded mask (top -&gt; bottom, left -&gt; right) was 0.0000, but a score with (left -&gt; right, top -&gt; bottom) was over 0.22.<br>Unfortunately, the evaluation page is just a copy from Data Science Bowl 2018. I hope that the competition hosts will update the evaluation page for this competition.<br><a href="https://www.kaggle.com/christoffersartorius">@christoffersartorius</a> <a href="https://www.kaggle.com/addisonhoward">@addisonhoward</a></p><h4 id="tips">tips</h4><p><strong>后续可参考</strong></p><p><strong>RLE</strong>相关代码说明（<a href="https://www.kaggle.com/c/sartorius-cell-instance-segmentation/discussion/278663%EF%BC%89">https://www.kaggle.com/c/sartorius-cell-instance-segmentation/discussion/278663）</a></p><p>In this great <a href="https://www.kaggle.com/ihelon/cell-segmentation-run-length-decoding">EDA notebook</a> created by <a href="https://www.kaggle.com/ihelon">@ihelon</a>, I found Inversion’s classical <a href="https://www.kaggle.com/ihelon/cell-segmentation-run-length-decoding">RLE encoding function</a>. The function has definitely stood the test of time and works great here, but I had a bit of difficulty understanding it, so I refactored it to be a bit easier for beginners. Here’s the code (with some personal notes):</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># modified from: https://www.kaggle.com/inversion/run-length-decoding-quick-start</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">rle_decode_refactored</span>(<span class="hljs-params">mask_rle, shape, color=<span class="hljs-number">1</span></span>):</span><br>    <span class="hljs-string">'''</span><br><span class="hljs-string">    mask_rle: run-length as string formated (start length)</span><br><span class="hljs-string">    shape: (height,width) of array to return </span><br><span class="hljs-string">    Returns numpy array, 1 - mask, 0 - background</span><br><span class="hljs-string">    '''</span><br>    <span class="hljs-comment"># Split the string by space, then convert it into a integer array</span><br>    s = np.array(mask_rle.split(), dtype=<span class="hljs-built_in">int</span>)<br><br>    <span class="hljs-comment"># Every even value is the start, every odd value is the "run" length</span><br>    starts = s[<span class="hljs-number">0</span>::<span class="hljs-number">2</span>] - <span class="hljs-number">1</span><br>    lengths = s[<span class="hljs-number">1</span>::<span class="hljs-number">2</span>]<br>    ends = starts + lengths<br><br>    <span class="hljs-comment"># The image image is actually flattened since RLE is a 1D "run"</span><br>    h, w, d = shape<br>    img = np.zeros((h * w, d), dtype=np.float32)<br><br>    <span class="hljs-comment"># The color here is actually just any integer you want!</span><br>    <span class="hljs-keyword">for</span> lo, hi <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(starts, ends):<br>        img[lo : hi] = color<br>    <span class="hljs-comment"># Don't forget to change the image back to the original shape</span><br>    <span class="hljs-keyword">return</span> img.reshape(shape)<br></code></pre></td></tr></tbody></table></figure><h3 id="Timeline">Timeline</h3><p>12月30号是最终的截止日期，冲冲冲！</p><ul><li><strong>October 14, 2021</strong> - Start Date.</li><li><strong>December 23, 2021</strong> - Entry Deadline. You must accept the competition rules before this date in order to compete.</li><li><strong>December 23, 2021</strong> - Team Merger Deadline. This is the last day participants may join or merge teams.</li><li><strong>December 30, 2021</strong> - Final Submission Deadline.</li></ul><p>All deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.</p><h2 id="相关paper">相关paper</h2><p>参考 <a href="https://www.kaggle.com/c/sartorius-cell-instance-segmentation/discussion/278716">https://www.kaggle.com/c/sartorius-cell-instance-segmentation/discussion/278716</a></p><p><strong>Papers:</strong></p><ul><li><a href="https://www.researchgate.net/publication/329933921_Instance_Segmentation_of_Neural_Cells">Instance Segmentation of Neural Cells</a> - Instance segmentation of neural cells plays an important role in brain study. However, this task is challenging due to the special shapes and behaviors of neural cells. Existing methods are not precise enough to capture their tiny structures, e.g., filopodia and lamellipodia, which are critical to the understanding of cell interaction and behavior. To this end, we propose a novel deep multi-task learning model to jointly detect and segment neural cells instance-wise. Our method is built upon SSD, with ResNet101 as the backbone to achieve both high detection accuracy and fast speed. Furthermore, unlike existing works which tend to produce wavy and inaccurate boundaries, we embed a deconvolution module into SSD to better capture details. Experiments on a dataset of neural cell microscopic images show that our method is able to achieve better performance in terms of accuracy and efficiency, comparing favorably with current state-of-the-art methods.</li><li><a href="https://www.researchgate.net/publication/340998089_Rank_6_Mask-RCNN_for_Cell_Instance_Segmentation">Mask-RCNN for Cell Instance Segmentation</a> - We proposed an automatic nucleus segmentation algorithm of H&amp;E stained tissue microscopy images. Mask-RCNN is a recently proposed state-of-the-art algorithm for object detection and object instance segmentation of natural images. In this paper, we demonstrate that Mask-RCNN can be used to perform highly effective and efficient automatic segmentation of H&amp;E microscopy images for cell nuclei. We propose a novel MASK Non-maximum suppression (NMS) module which can automatically ensemble classifiers results and increase the robustness of model.</li><li><a href="https://arxiv.org/abs/1908.06623">IRNet: Instance Relation Network for Overlapping Cervical Cell Segmentation</a> - Cell instance segmentation in Pap smear image remains challenging due to the wide existence of occlusion among translucent cytoplasm in cell clumps. Conventional methods heavily rely on accurate nuclei detection results and are easily disturbed by miscellaneous objects. In this paper, we propose a novel Instance Relation Network (IRNet) for robust overlapping cell segmentation by exploring instance relation interaction. Specifically, we propose the Instance Relation Module to construct the cell association matrix for transferring information among individual cell-instance features. With the collaboration of different instances, the augmented features gain benefits from contextual information and improve semantic consistency. Meanwhile, we proposed a sparsity constrained Duplicate Removal Module to eliminate the misalignment between classification and localization accuracy for candidates selection. The largest cervical Pap smear (CPS) dataset with more than 8000 cell annotations in Pap smear image was constructed for comprehensive evaluation. Our method outperforms other methods by a large margin, demonstrating the effectiveness of exploring instance relation.</li><li><a href="https://www.researchgate.net/publication/336392797_Weakly_Supervised_Cell_Instance_Segmentation_by_Propagating_from_Detection_Response">Weakly Supervised Cell Instance Segmentation by Propagating from Detection Response</a> - Cell shape analysis is important in biomedical research. Deep learning methods may perform to segment individual cells if they use sufficient training data that the boundary of each cell is annotated. However, it is very time-consuming for preparing such detailed annotation for many cell culture conditions. In this paper, we propose a weakly supervised method that can segment individual cell regions who touch each other with unclear boundaries in dense conditions without the training data for cell regions. We demonstrated the efficacy of our method using several data-set including multiple cell types captured by several types of microscopy. Our method achieved the highest accuracy compared with several conventional methods. In addition, we demonstrated that our method can perform without any annotation by using fluorescence images that cell nuclear were stained as training data.</li><li><a href="https://arxiv.org/abs/2007.10787">Deep Semi-supervised Knowledge Distillation for Overlapping Cervical Cell Instance Segmentation</a> - Deep learning methods show promising results for overlapping cervical cell instance segmentation. However, in order to train a model with good generalization ability, voluminous pixel-level annotations are demanded which is quite expensive and time-consuming for acquisition. In this paper, we propose to leverage both labeled and unlabeled data for instance segmentation with improved accuracy by knowledge distillation. We propose a novel Mask-guided Mean Teacher framework with Perturbation-sensitive Sample Mining (MMT-PSM), which consists of a teacher and a student network during training. Two networks are encouraged to be consistent both in feature and semantic level under small perturbations. The teacher’s self-ensemble predictions from K-time augmented samples are used to construct the reliable pseudolabels for optimizing the student. We design a novel strategy to estimate the sensitivity to perturbations for each proposal and select informative samples from massive cases to facilitate fast and effective semantic distillation. In addition, to eliminate the unavoidable noise from the background region, we propose to use the predicted segmentation mask as guidance to enforce the feature distillation in the foreground region. Experiments show that the proposed method improves the performance significantly compared with the supervised method learned from labeled data only, and outperforms state-of-the-art semi-supervised methods.</li><li><a href="https://www.sciencedirect.com/science/article/pii/S1361841518308442">Attentive neural cell instance segmentation</a> - Neural cell instance segmentation, which aims at joint detection and segmentation of every neural cell in a microscopic image, is essential to many neuroscience applications. The challenge of this task in- volves cell adhesion, cell distortion, unclear cell contours, low-contrast cell protrusion structures, and background impurities. Consequently, current instance segmentation methods generally fall short of pre- cision. In this paper, we propose an attentive instance segmentation method that accurately predicts the bounding box of each cell as well as its segmentation mask simultaneously. In particular, our method builds on a joint network that combines a single shot multi-box detector (SSD) and a U-net. Furthermore, we employ the attention mechanism in both detection and segmentation modules to focus the model on the useful features. The proposed method is validated on a dataset of neural cell microscopic images. Experimental results demonstrate that our approach can accurately detect and segment neural cell in- stances at a fast speed, comparing favorably with the state-of-the-art methods.</li></ul><p>📌 <a href="https://github.com/milesial/Pytorch-UNet">U-net with Pytorch</a><br>📌 <a href="https://github.com/Fpiotro/MOLECULAR-TRANSLATION">Using U-net for a Kaggle competition (AutoEncoder)</a></p><h4 id="attention">attention</h4><p><strong>主办方有关LIVECell的论文</strong></p><p>Edlund, C., Jackson, T.R., Khalid, N. et al.<br>LIVECell-A large-scale dataset for label-free live cell segmentation.<br>Nat Methods 18, 1038 -1045 (2021).<br>Available at: <a href="https://doi.org/10.1038/s41592-021-01249-6">https://doi.org/10.1038/s41592-021-01249-6</a></p><p>Their paper is not just a dataset paper, <strong>it evaluates the performance of both recent anchor-free and anchor-based models for each cell type under four task conditions</strong>, which I think is very informative.<br>Within their paper, it is shown that <font color="purple"><strong>the results are better when other cell types not included in the test data are also included in the training</strong></font>. This may be because using even unrelated cell types in the training data allows the model to learn morphology and other factors.</p><p>Therefore, in addition to the dataset provided in Kaggle, transfer learning using other cell types in LIVECell, the predecessor of the data, will be important for this competition.</p><p>If you want to use the model trained by LIVECell for transfer learning, this page on GitHub may be useful.<br>👉 <a href="https://github.com/sartorius-research/LIVECell/tree/main/model">https://github.com/sartorius-research/LIVECell/tree/main/model</a></p><p>The models are based on PyTorch, but are from FIAR’s Dectron 2 library.<br>Dectron2: <a href="https://github.com/facebookresearch/detectron2">https://github.com/facebookresearch/detectron2</a></p>]]></content>
    
    
    <categories>
      
      <category>kaggle</category>
      
    </categories>
    
    
    <tags>
      
      <tag>kaggle</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyQt5中放置图片</title>
    <link href="/2021/10/21/python/pyqt/pyqtimg/"/>
    <url>/2021/10/21/python/pyqt/pyqtimg/</url>
    
    <content type="html"><![CDATA[<blockquote><p>在pyqt中使用label显示图片，或者使用继承了QLabel的类显示图片，实现在图片上进行长度，角度测量，标注，画板等功能。</p></blockquote><h2 id="QLabel">QLabel</h2><p>Qlabel部件时用于提供文本或者图像显示。Qlabel可以包含纯文本（将字符串传递给setText），富文本（将富文本传递给setText），图像（将QPixmap对象传递setPixmap），动画（将QMovie对象传递给setMovie），数字（将int或在double数字传递给setNum），空（默认，由clear设置）。</p><ul><li>当Qlabel使用setText设置文本内容，因为Qlabel会判断其为纯文本还是作为HTML标记的富文本，想明确显示文本格式，则调用setTextFormat。</li></ul><h2 id="图片插入">图片插入</h2><p>首先使用QPixmap()创建一个QPixmap对象，使用setPixmap函数插入图片，若使用setScaledContents（True）可以设置将图片填充该label的所有可用空间，此参数默认是False。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Example</span>(<span class="hljs-params">QWidget</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">initUI</span>(<span class="hljs-params">self</span>):</span><br><span class="hljs-comment">#lb1是直接插入；lb2是缩放图片填充label区域；</span><br>        pix = QPixmap(<span class="hljs-string">'sexy.jpg'</span>)<br><br>        lb1 = QLabel(self)<br>        lb1.setGeometry(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">300</span>,<span class="hljs-number">200</span>)<br>        lb1.setStyleSheet(<span class="hljs-string">"border: 2px solid red"</span>)<br>        lb1.setPixmap(pix)<br><br>        lb2 = QLabel(self)<br>        lb2.setGeometry(<span class="hljs-number">0</span>,<span class="hljs-number">250</span>,<span class="hljs-number">300</span>,<span class="hljs-number">200</span>)<br>        lb2.setPixmap(pix)<br>        lb2.setStyleSheet(<span class="hljs-string">"border: 2px solid red"</span>)<br>        lb2.setScaledContents(<span class="hljs-literal">True</span>)<br></code></pre></td></tr></tbody></table></figure><h2 id="项目实例">项目实例</h2><p>在项目代码中有</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">self.lab = MyLabel(self.widget)<br><span class="hljs-comment"># self.lab.setStyleSheet("QLabel{background:black;}")</span><br>img_width = <span class="hljs-number">1102</span><br>img_height = <span class="hljs-number">629</span><br>self.image_list = [<span class="hljs-string">"./temp.jpg"</span>]<br>self.image = QPixmap(self.image_list[<span class="hljs-number">0</span>])<br>self.image = self.image.scaled(img_width, img_height)<br>self.lab.setPixmap(self.image)<br>self.lab.setMinimumSize(img_width, img_height)<br></code></pre></td></tr></tbody></table></figure><ul><li><p>首先创建Qpixmap(path)</p></li><li><p>对Qpixmap对象scaled调整图片大小</p></li><li><p>我们通常会使用Qt自带的scaled()函数；QImage、QPixmap等绘图设备类都提供scaled()函数。</p><p>scaled()是一个重载函数，按照指定的宽和高，根据给的size和aspectRatioMode从原有图像返回一个经过比例转换的图像，如果宽高为0，返回一个空图像<br>所以，获取控件的改变后的宽高，就能设定图像转换的宽高转换比例，用scaled()的返回重新进行绘图即可自适应窗口。</p><p>项目中这里使用 <code>Qt.IgnoreAspectRatio</code></p></li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">QPixmap::scaled(const QSize &amp; size, Qt::AspectRatioMode aspectRatioMode = Qt::IgnoreAspectRatio, Qt::TransformationMode transformMode = Qt::FastTransformation) const<br>其中aspectRatioMode<br>IgnoreAspectRatio  <span class="hljs-comment">#矩形框有多大，图片就缩放成多大，不限制原图片的长宽比</span><br>KeepAspectRatio    <span class="hljs-comment">#保持原图片的长宽比，且不超过矩形框的大小</span><br>KeepAspectRatioByExpanding   <span class="hljs-comment">#根据矩形框的大小最大缩放图片</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">scaled</span>(<span class="hljs-params">self, *__args</span>):</span> <span class="hljs-comment"># real signature unknown; restored from __doc__ with multiple overloads</span><br>    <span class="hljs-string">"""</span><br><span class="hljs-string">        scaled(self, int, int, aspectRatioMode: Qt.AspectRatioMode = Qt.IgnoreAspectRatio, transformMode: Qt.TransformationMode = Qt.FastTransformation) -&gt; QPixmap</span><br><span class="hljs-string">        scaled(self, QSize, aspectRatioMode: Qt.AspectRatioMode = Qt.IgnoreAspectRatio, transformMode: Qt.TransformationMode = Qt.FastTransformation) -&gt; QPixmap</span><br><span class="hljs-string">        """</span><br>    <span class="hljs-keyword">return</span> QPixmap<br><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>cv读取带有中文路径的图片</title>
    <link href="/2021/10/20/python/img/cvread/"/>
    <url>/2021/10/20/python/img/cvread/</url>
    
    <content type="html"><![CDATA[<blockquote><p>常规在读取图片时使用的代码是<code>cv.imread(path)</code>，但是路径中出现中文时就会出现，读取为空的情况，以下给出解决方法。</p></blockquote><h2 id="背景">背景</h2><p>首先介绍一下<code>cv2.imread()函数</code></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">cv2.imread(filepath,flags)<br>filepath:是要读入的图片路径<br>flags: 读入图片的格式<br>cv2.IMRAED_COLOR:默认选择此参数，读入彩色图片，BGR的格式，忽略了alpha通道，也可以使用数字<span class="hljs-number">1</span>代替。<br>cv2.IMREAD_GRAYSCALE:读入灰度图片，可以直接写<span class="hljs-number">0</span><br>cv2.IMREAD_UNCHANGED:顾名思义，读入完整图片，包括alpha通道，可以直接写-<span class="hljs-number">1</span>（BGRA）<br><br>cv2.COLOR_BGR2GRAY:可以转换颜色空间，由BGR转换为RGB<br>cv2.COLOR_RGB2GRAY:有RGB转换为灰度图格式<br></code></pre></td></tr></tbody></table></figure><blockquote><p>alpha通道，又称A通道，是一个8位的灰度通道，该通道用256级灰度来记录图像中的透明度复信息，定义透明、不透明和半透明区域，其中黑表示全透明，白表示不透明，灰表示半透明。如果读取的图片没有alpha通道则还是按照三通道读取。</p></blockquote><h2 id="解决方案">解决方案</h2><p><strong>原因：</strong>  在读取含有中文字符的路径图片时会返回None，这是由于opencv不接受non-ascii的路径。</p><p><strong>方法：</strong> 先使用numpy的fromfile将图片读取为np.uint8的格式，再使用cv的imdecode函数解码。</p><p><strong>具体代码</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>im_path = <span class="hljs-string">'./测试数据/temp_long.jpg'</span><br>im = cv2.imdecode(np.fromfile(im_path, dtype=np.uint8))<br>cv2.imshow(<span class="hljs-string">"显示图片"</span>,im)<br><span class="hljs-built_in">print</span>(im.shape)<br>cv2.waitKey(<span class="hljs-number">0</span>)<br></code></pre></td></tr></tbody></table></figure><p><strong>代码具体分析：</strong><br>先不直接读取图片，而是采用<code>numpy</code>中的<code>fromfile</code>读取文件，将图片按照int类型读入数据，读入的是一维数组，然后通过cv中<code>imdecode</code>来对数组解码得到图片，<code>imdecode</code>函数的作用是<code>从内存缓冲区中读取图像</code>，如果缓冲区太短或包含无效数据时，函数返回一个空矩阵(Mat::data==NULL)。如果是彩色图像，解码后的图像将按照B G R顺序存储通道。这函数有两个参数<code>imdecode(buf,flags)</code>，buf是输入数组或字节向量，flags 与cv::imread相同的flag。</p><blockquote><p>cv2.IMREAD_COLOR：加载彩色图片，这个是默认参数，可以直接写1 （BGR形式）<br>cv2.IMREAD_GRAYSCALE：以灰度模式加载图片，可以直接写0<br>cv2.IMREAD_UNCHANGED：包括alpha，可以直接写-1</p></blockquote><p><strong>保存</strong></p><p>'.jpg’表示把当前图片img按照jpg格式编码，按照不同格式编码的结果不一样</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>im_path = <span class="hljs-string">'./测试数据/temp_long.jpg'</span><br>im = cv2.imdecode(np.fromfile(im_path, dtype=np.uint8))<br>cv2.imshow(<span class="hljs-string">"显示图片"</span>,im)<br>cv2.imencode(<span class="hljs-string">'.jpg'</span>, im)[<span class="hljs-number">1</span>].tofile(<span class="hljs-string">'E:\测试路径/frameTest.jpg'</span>)<span class="hljs-comment">#英文或中文路径均适用</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
      <category>图像</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>图像</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer36 二叉搜索树和双向链表</title>
    <link href="/2021/10/08/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer36/"/>
    <url>/2021/10/08/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer36/</url>
    
    <content type="html"><![CDATA[<blockquote><p>二叉搜索树和双向链表</p></blockquote><h2 id="题目">题目</h2><p>输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的循环双向链表。要求不能创建任何新的节点，只能调整树中节点指针的指向<br>为了让您更好地理解问题，以下面的二叉搜索树为例：</p><p><img src="https://picture.mulindya.com/leetcode-offer36-1.png" alt=""></p><p>我们希望将这个二叉搜索树转化为双向循环链表。链表中的每个节点都有一个前驱和后继指针。对于双向循环链表，第一个节点的前驱是最后一个节点，最后一个节点的后继是第一个节点。</p><p>下图展示了上面的二叉搜索树转化成的链表。“head” 表示指向链表中有最小元素的节点。</p><p><img src="https://picture.mulindya.com/leetcode-offer36-2.png" alt=""></p><p>特别地，我们希望可以就地完成转换操作。当转化完成以后，树中节点的左指针需要指向前驱，树中节点的右指针需要指向后继。还需要返回链表中的第一个节点的指针。</p><h3 id="提示：">提示：</h3><ul><li><p>注意：本题与主站 426 题相同：<a href="https://leetcode-cn.com/problems/convert-binary-search-tree-to-sorted-doubly-linked-list/">https://leetcode-cn.com/problems/convert-binary-search-tree-to-sorted-doubly-linked-list/</a></p></li><li><p>注意：此题对比原题有改动。</p></li></ul><h2 id="题解">题解</h2><p>本题的算法思想是在中序遍历的基础上，涉及对链表的处理，但是还是按照中序递归遍历的逻辑，使用self可以全局设置pre和head，pre是用来更新节点的左右指向，head是用于后续的头尾节点的处理，函数结束时的pre即为尾节点。</p><p>中序遍历代码结构：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dfs</span>(<span class="hljs-params">root</span>):</span><br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root:<br><span class="hljs-keyword">return</span><br>dfs(root.left)<br><span class="hljs-built_in">print</span>(root)<br>dfs(root.right)<br></code></pre></td></tr></tbody></table></figure><p>注意边界条件的处理，以及self.pre和self.head的更新。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">"""</span><br><span class="hljs-string"># Definition for a Node.</span><br><span class="hljs-string">class Node:</span><br><span class="hljs-string">    def __init__(self, val, left=None, right=None):</span><br><span class="hljs-string">        self.val = val</span><br><span class="hljs-string">        self.left = left</span><br><span class="hljs-string">        self.right = right</span><br><span class="hljs-string">"""</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">treeToDoublyList</span>(<span class="hljs-params">self, root: <span class="hljs-string">'Node'</span></span>) -&gt; 'Node':</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mediumfunc</span>(<span class="hljs-params">root</span>):</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root:<span class="hljs-keyword">return</span><br>            mediumfunc(root.left)<br>            <span class="hljs-keyword">if</span>(self.pre):<br>                self.pre.right = root<br>                root.left = self.pre<br>            <span class="hljs-keyword">else</span>:<br>                self.head = root<br>            self.pre = root <span class="hljs-comment">#注意在判断之后必须要更新pre</span><br>            mediumfunc(root.right)<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span>(root):<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br>        self.head = root<br>        self.pre = <span class="hljs-literal">None</span><br>        mediumfunc(root)<br>        self.head.left = self.pre<br>        self.pre.right = self.head<br>        <span class="hljs-keyword">return</span> self.head<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>树</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pipenv的安装和使用</title>
    <link href="/2021/10/08/project_tool/pipenv/"/>
    <url>/2021/10/08/project_tool/pipenv/</url>
    
    <content type="html"><![CDATA[<blockquote><p>pipenv 是Kenneth Reitz大神的作品，能够有效管理Python多个环境，各种包。过去我们一般用virtualenv搭建虚拟环境，管理python版本，但是跨平台的使用不太一致，且有时候处理包之间的依赖总存在问题；过去也常常用 pip进行包的管理，pip已经足够好，但是仍然推荐pipenv，相当于virtualenv和pip的合体，且更加强大。pipenv开源之后，在GitHub上有很高人气（截止于现在有9600多星）。</p></blockquote><blockquote><p>在项目打包时，项目文件104M打包之后文件5.8G，有人说，Anaconda里内置了很多库，打包的时候打包了很多不必要的模块进去，要用纯净的Python来打包。于是尝试使用pipenv虚拟环境来打包，emmm最后完成是5.2G，感觉，也，没有，多大改变吖，尤其是torch包直接占到了2.8G(这还是改了from import之后呢)。 哎 😣</p></blockquote><p><strong>pipenv主要有以下特性：</strong></p><p>（1）pipenv集成了pip，virtualenv两者的功能，且完善了两者的一些缺陷。</p><p>（2）过去用virtualenv管理requirements.txt文件可能会有问题，Pipenv使用Pipfile和Pipfile.lock，后者存放将包的依赖关系，查看依赖关系是十分方便。</p><p>（3）各个地方使用了哈希校验，无论安装还是卸载包都十分安全，且会自动公开安全漏洞。。</p><p>（4）通过加载.env文件简化开发工作流程。</p><p>（5）支持Python2 和 Python3，在各个平台的命令都是一样的。</p><p>下面快速介绍pipenv的基本使用，文章末尾有其github链接。本文的测试环境是windows下的Python3.6，对于其他平台同样适用。</p><h2 id="1-安装pipenv">1 安装pipenv</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pip install pipenv<br></code></pre></td></tr></tbody></table></figure><h2 id="2-创建虚拟环境">2 创建虚拟环境</h2><p>新建文件夹在文件夹中建立虚拟环境。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">mkdir envfile<br>cd envfile<br>pipenv install<br></code></pre></td></tr></tbody></table></figure><p>初始化好虚拟环境后，会在项目目录下生成2个文件<code>Pipfile</code>和<code>Pipfile.lock</code>。为pipenv包的配置文件，代替原来的 requirement.txt。</p><p>项目提交时，可将<code>Pipfile</code> 文件和<code>Pipfile.lock</code>文件一并提交，待其他开发克隆下载，根据此Pipfile 运行命令<code>pipenv install --dev</code>生成自己的虚拟环境。</p><p><code>Pipfile.lock</code> 文件是通过hash算法将包的名称和版本，及依赖关系生成哈希值，可以保证包的完整性。</p><h2 id="3-安装包">3 安装包</h2><p>在虚拟环境下安装包</p><p>可以使用</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pipenv install package<br></code></pre></td></tr></tbody></table></figure><p>或者先进入虚拟环境中再安装包。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">pipenv shell  <span class="hljs-comment">#激活虚拟环境</span><br>pip install package<br></code></pre></td></tr></tbody></table></figure><p>也可使用txt文件来安装包</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pipenv install -r requirements.txt <span class="hljs-comment">#通过requirements文件安装包</span><br></code></pre></td></tr></tbody></table></figure><p>requirements.txt文件形如</p><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># pip install -r requirements.txt</span><br><br><span class="hljs-comment"># base ----------------------------------------</span><br><span class="hljs-attribute">matplotlib</span>&gt;=<span class="hljs-number">3</span>.<span class="hljs-number">2</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">numpy</span>&gt;=<span class="hljs-number">1</span>.<span class="hljs-number">18</span>.<span class="hljs-number">5</span><br><span class="hljs-attribute">opencv</span>-python&gt;=<span class="hljs-number">4</span>.<span class="hljs-number">1</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">Pillow</span><br><span class="hljs-attribute">PyYAML</span>&gt;=<span class="hljs-number">5</span>.<span class="hljs-number">3</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">scipy</span>&gt;=<span class="hljs-number">1</span>.<span class="hljs-number">4</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">8</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">torchvision</span>&gt;=<span class="hljs-number">0</span>.<span class="hljs-number">9</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">tqdm</span>&gt;=<span class="hljs-number">4</span>.<span class="hljs-number">41</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">PyQt5</span><br><span class="hljs-attribute">fpdf</span><br><span class="hljs-comment"># logging -------------------------------------</span><br><span class="hljs-comment">#tensorboard&gt;=2.4.1</span><br><span class="hljs-comment"># wandb</span><br><br><span class="hljs-comment"># plotting ------------------------------------</span><br><span class="hljs-attribute">seaborn</span>&gt;=<span class="hljs-number">0</span>.<span class="hljs-number">11</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">pandas</span><br><span class="hljs-attribute">requests</span><br></code></pre></td></tr></tbody></table></figure><h2 id="4-相关的命令">4 相关的命令</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">pipenv --py    <span class="hljs-comment">#显示python解释器信息</span><br>pipenv --where <span class="hljs-comment">#显示本地工程路径</span><br>pipenv --venv  <span class="hljs-comment">#显示虚拟环境信息</span><br>pipenv graph   <span class="hljs-comment">#显示目前安装的库以及依赖关系</span><br>pipenv uninstrall package <span class="hljs-comment">#卸载依赖包</span><br>pipenv uninstall --<span class="hljs-built_in">all</span>    <span class="hljs-comment">#卸载全部依赖包</span><br>exit                      <span class="hljs-comment">#退出虚拟环境</span><br>pipenv --rm               <span class="hljs-comment">#删除虚拟环境</span><br></code></pre></td></tr></tbody></table></figure><h4 id="运行代码">运行代码</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">pipenv run python XXX.py<br>或者<br>pipenv shell<br>python XXX.py<br></code></pre></td></tr></tbody></table></figure><h2 id="5-pyinstaller打包压缩">5 pyinstaller打包压缩</h2><h3 id="第一次打包">第一次打包</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">pip install pipenv        <span class="hljs-comment">#安装pipenv库</span><br>pipenv install            <span class="hljs-comment">#新建环境，cd进入，建立虚拟环境</span><br>pipenv shell              <span class="hljs-comment">#进入虚拟环境</span><br>pip install [...]         <span class="hljs-comment">#安装项目所需的模块</span><br>pip install pyinstaller   <span class="hljs-comment">#安装打包的模块</span><br>pyinstaller 参数 [..]      <span class="hljs-comment">#打包</span><br></code></pre></td></tr></tbody></table></figure><p>生成dist文件夹和结果。</p><h3 id="再次打包">再次打包</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">pipenv shell               <span class="hljs-comment">#cd进入之前创建的虚拟环境文件夹，进入虚拟环境</span><br>pip install [new package]  <span class="hljs-comment">#安装新模块</span><br>pyinstaller 参数 [...]      <span class="hljs-comment">#再次打包</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
    </categories>
    
    
    <tags>
      
      <tag>项目打包</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分割文件名相关操作</title>
    <link href="/2021/10/07/python/file/split-filename/"/>
    <url>/2021/10/07/python/file/split-filename/</url>
    
    <content type="html"><![CDATA[<blockquote><p>对文件名的相关操作总结</p></blockquote><h3 id="函数介绍">函数介绍</h3><p><code>os.path</code>相关函数</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">os.path.split() <span class="hljs-comment">#分割文件名</span><br>os.path.splitdrive() <span class="hljs-comment">#分割盘符</span><br>os.path.splitext() <span class="hljs-comment">#分割扩展名</span><br>os.path.basename() <span class="hljs-comment">#获取文件名，split的后一元素</span><br>os.path.dirname()  <span class="hljs-comment">#获取路径名，split的前一元素</span><br>os.path.join()     <span class="hljs-comment">#连接path字符串</span><br></code></pre></td></tr></tbody></table></figure><p><code>os</code>相关函数</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">os.walk()     <span class="hljs-comment">#遍历路径下的文件信息和子文件信息（root，dir，file的形式）</span><br>os.listdir()  <span class="hljs-comment">#返回路径下的文件信息</span><br></code></pre></td></tr></tbody></table></figure><h3 id="具体介绍">具体介绍</h3><h4 id="os-path-split">os.path.split()</h4><p><code>os.path.split()</code>函数返回路径的元组信息（父路径，文件名）</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: os.path.split(p)<br>Docstring:<br>Split a pathname.<br><br>Return <span class="hljs-built_in">tuple</span> (head, tail) where tail <span class="hljs-keyword">is</span> everything after the final slash.<br>Either part may be empty.<br>File:      d:\anaconda3\lib\ntpath.py<br><span class="hljs-type">Type</span>:      function<br>    <br>例如：<br>spath = <span class="hljs-string">"./a/b/c/name.txt"</span><br>path,filename = os.path.split(spath)<br>path,filename为(<span class="hljs-string">'./a/b/c'</span>, <span class="hljs-string">'name.txt'</span>)<br></code></pre></td></tr></tbody></table></figure><h4 id="os-path-splitdrive">os.path.splitdrive()</h4><p><code>os.path.splitdrive()</code>函数返回元组信息（盘符，路径（除去盘符））</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: os.path.splitdrive(p)<br>Docstring:<br>Split a pathname into drive/UNC sharepoint <span class="hljs-keyword">and</span> relative path specifiers.<br>Returns a <span class="hljs-number">2</span>-<span class="hljs-built_in">tuple</span> (drive_or_unc, path); either part may be empty.<br><br>If you assign<br>    result = splitdrive(p)<br>It <span class="hljs-keyword">is</span> always true that:<br>    result[<span class="hljs-number">0</span>] + result[<span class="hljs-number">1</span>] == p<br><br>If the path contained a drive letter, drive_or_unc will contain everything<br>up to <span class="hljs-keyword">and</span> including the colon.  e.g. splitdrive(<span class="hljs-string">"c:/dir"</span>) returns (<span class="hljs-string">"c:"</span>, <span class="hljs-string">"/dir"</span>)<br><br>If the path contained a UNC path, the drive_or_unc will contain the host name<br><span class="hljs-keyword">and</span> share up to but <span class="hljs-keyword">not</span> including the fourth directory separator character.<br>e.g. splitdrive(<span class="hljs-string">"//host/computer/dir"</span>) returns (<span class="hljs-string">"//host/computer"</span>, <span class="hljs-string">"/dir"</span>)<br><br>Paths cannot contain both a drive letter <span class="hljs-keyword">and</span> a UNC path.<br>File:      d:\anaconda3\lib\ntpath.py<br><span class="hljs-type">Type</span>:      function<br>    <br>例如：  <br>cpath = <span class="hljs-string">"C:/a/b/a.csv"</span><br>os.path.splitdrive(cpath)<br>(<span class="hljs-string">'C:'</span>, <span class="hljs-string">'/a/b/a.csv'</span>)<br></code></pre></td></tr></tbody></table></figure><h4 id="os-path-splitext">os.path.splitext()</h4><p><code>os.path.splitext()</code>返回路径的元组信息（路径及文件名，扩展名）</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: os.path.splitext(p)<br>Docstring:<br>Split the extension <span class="hljs-keyword">from</span> a pathname.<br></code></pre></td></tr></tbody></table></figure><h4 id="os-path-dirname-与os-path-basename">os.path.dirname()与os.path.basename()</h4><p><code>os.path.dirname()</code>和<code>os.path.basename()</code>分别返回<code>split</code>函数的前后元素。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: os.path.basename(p)<br>Docstring: Returns the final component of a pathname<br>File:      d:\anaconda3\lib\ntpath.py<br><span class="hljs-type">Type</span>:      function<br>    <br>例如：<br>cpath = <span class="hljs-string">"C:/a/b/a.csv"</span><br>os.path.dirname(cpath) <span class="hljs-comment">#dirpath</span><br><span class="hljs-string">'C:/a/b'</span><br>os.path.basename(cpath) <span class="hljs-comment">#filename</span><br><span class="hljs-string">'a.csv'</span><br>相当于split的分解：<br>os.path.split(cpath)<br>(<span class="hljs-string">'C:/a/b'</span>, <span class="hljs-string">'a.csv'</span>)<br></code></pre></td></tr></tbody></table></figure><h4 id="os-path-join">os.path.join()</h4><p><code>os.path.join()</code>使用特定的分隔符连接路径。Windows下默认使用<code>\\</code>。Linux下默认使用<code>/</code>。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: os.path.join(path, *paths)<br>Docstring: &lt;no docstring&gt;<br>File:      d:\anaconda3\lib\ntpath.py<br><span class="hljs-type">Type</span>:      function<br>    <br>例如：<br>os.path.join(<span class="hljs-string">'./a/b/c'</span>, <span class="hljs-string">"a123"</span>, <span class="hljs-string">'name.txt'</span>) <br><span class="hljs-string">'./a/b/c\\a123\\name.txt'</span><br></code></pre></td></tr></tbody></table></figure><h4 id="os-walk">os.walk()</h4><p><code>os.walk()</code>遍历文件夹下的文件和子文件夹，然后递归遍历下列子文件夹。<code>for root,dirs,files in os.walk(temp)</code></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: os.walk(top, topdown=<span class="hljs-literal">True</span>, onerror=<span class="hljs-literal">None</span>, followlinks=<span class="hljs-literal">False</span>)<br>Docstring:<br>Directory tree generator.<br><br>For each directory <span class="hljs-keyword">in</span> the directory tree rooted at top (including top<br>itself, but excluding <span class="hljs-string">'.'</span> <span class="hljs-keyword">and</span> <span class="hljs-string">'..'</span>), yields a <span class="hljs-number">3</span>-<span class="hljs-built_in">tuple</span><br>    dirpath, dirnames, filenames<br>dirpath <span class="hljs-keyword">is</span> a string, the path to the directory.  dirnames <span class="hljs-keyword">is</span> a <span class="hljs-built_in">list</span> of<br>the names of the subdirectories <span class="hljs-keyword">in</span> dirpath (excluding <span class="hljs-string">'.'</span> <span class="hljs-keyword">and</span> <span class="hljs-string">'..'</span>).<br>filenames <span class="hljs-keyword">is</span> a <span class="hljs-built_in">list</span> of the names of the non-directory files <span class="hljs-keyword">in</span> dirpath.<br>Note that the names <span class="hljs-keyword">in</span> the lists are just names, <span class="hljs-keyword">with</span> no path components.<br>To get a full path (which begins <span class="hljs-keyword">with</span> top) to a file <span class="hljs-keyword">or</span> directory <span class="hljs-keyword">in</span><br>dirpath, do os.path.join(dirpath, name).<br><br>If optional arg <span class="hljs-string">'topdown'</span> <span class="hljs-keyword">is</span> true <span class="hljs-keyword">or</span> <span class="hljs-keyword">not</span> specified, the triple <span class="hljs-keyword">for</span> a<br>directory <span class="hljs-keyword">is</span> generated before the triples <span class="hljs-keyword">for</span> <span class="hljs-built_in">any</span> of its subdirectories<br>(directories are generated top down).  If topdown <span class="hljs-keyword">is</span> false, the triple<br><span class="hljs-keyword">for</span> a directory <span class="hljs-keyword">is</span> generated after the triples <span class="hljs-keyword">for</span> <span class="hljs-built_in">all</span> of its<br>subdirectories (directories are generated bottom up).<br><br>Caution:  <span class="hljs-keyword">if</span> you <span class="hljs-keyword">pass</span> a relative pathname <span class="hljs-keyword">for</span> top, don<span class="hljs-string">'t change the</span><br><span class="hljs-string">current working directory between resumptions of walk.  walk never</span><br><span class="hljs-string">changes the current directory, and assumes that the client doesn'</span>t<br>either.<br>例如：<br>temp = <span class="hljs-string">"E:\迅雷下载"</span><br><span class="hljs-keyword">for</span> root,dirs,files <span class="hljs-keyword">in</span> os.walk(temp,topdown=<span class="hljs-literal">False</span>):<br>    <span class="hljs-comment">#遍历文件夹下的文件和子目录 root,dirs,files,topdown为false时表示从底向上，为true是从顶向下</span><br>    <span class="hljs-keyword">for</span> name <span class="hljs-keyword">in</span> files:<br>        <span class="hljs-built_in">print</span>(os.path.join(root,name))<br>    <span class="hljs-keyword">for</span> name <span class="hljs-keyword">in</span> dirs:<br>        <span class="hljs-built_in">print</span>(os.path.join(root,name))<br>        <br>E:\迅雷下载\Suplicant_for_Campus_Network_For_Windows_V6<span class="hljs-number">.61</span>\Suplicant_for_Campus_Network_For_Windows_V6<span class="hljs-number">.61</span>.exe<br>E:\迅雷下载\cuda_10<span class="hljs-number">.2</span><span class="hljs-number">.89_441</span><span class="hljs-number">.22</span>_win10.exe<br>E:\迅雷下载\Git-<span class="hljs-number">2.33</span><span class="hljs-number">.0</span><span class="hljs-number">.2</span>-<span class="hljs-number">64</span>-bit.exe<br>E:\迅雷下载\ide-<span class="hljs-built_in">eval</span>-resetter-<span class="hljs-number">2.1</span><span class="hljs-number">.13</span>.<span class="hljs-built_in">zip</span><br>E:\迅雷下载\npp<span class="hljs-number">.8</span><span class="hljs-number">.1</span><span class="hljs-number">.4</span>.Installer.exe<br>E:\迅雷下载\sogou_explorer_11<span class="hljs-number">.0</span><span class="hljs-number">.0</span><span class="hljs-number">.33862_7793</span>.exe<br>E:\迅雷下载\windows_v6<span class="hljs-number">.61</span>.rar<br>E:\迅雷下载\Suplicant_for_Campus_Network_For_Windows_V6<span class="hljs-number">.61</span> <br></code></pre></td></tr></tbody></table></figure><h4 id="os-listdir">os.listdir()</h4><p><code>os.listdir()</code>返回文件夹下的所有一级文件夹和文件。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python">Signature: os.listdir(path=<span class="hljs-literal">None</span>)<br>Docstring:<br>Return a <span class="hljs-built_in">list</span> containing the names of the files <span class="hljs-keyword">in</span> the directory.<br><br>path can be specified <span class="hljs-keyword">as</span> either <span class="hljs-built_in">str</span>, <span class="hljs-built_in">bytes</span>, <span class="hljs-keyword">or</span> a path-like <span class="hljs-built_in">object</span>.  If path <span class="hljs-keyword">is</span> <span class="hljs-built_in">bytes</span>,<br>  the filenames returned will also be <span class="hljs-built_in">bytes</span>; <span class="hljs-keyword">in</span> <span class="hljs-built_in">all</span> other circumstances<br>  the filenames returned will be <span class="hljs-built_in">str</span>.<br>If path <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>, uses the path=<span class="hljs-string">'.'</span>.<br>On some platforms, path may also be specified <span class="hljs-keyword">as</span> an <span class="hljs-built_in">open</span> file descriptor;\<br>  the file descriptor must refer to a directory.<br>  If this functionality <span class="hljs-keyword">is</span> unavailable, using it raises NotImplementedError.<br><br>The <span class="hljs-built_in">list</span> <span class="hljs-keyword">is</span> <span class="hljs-keyword">in</span> arbitrary order.  It does <span class="hljs-keyword">not</span> include the special<br>entries <span class="hljs-string">'.'</span> <span class="hljs-keyword">and</span> <span class="hljs-string">'..'</span> even <span class="hljs-keyword">if</span> they are present <span class="hljs-keyword">in</span> the directory.<br><span class="hljs-type">Type</span>:      builtin_function_or_method<br>    <br>例如：<br>temp = <span class="hljs-string">"E:\迅雷下载"</span><br>os.listdir(temp) <span class="hljs-comment">#列出dirname下的目录和文件</span><br>[<span class="hljs-string">'cuda_10.2.89_441.22_win10.exe'</span>,<br> <span class="hljs-string">'Git-2.33.0.2-64-bit.exe'</span>,<br> <span class="hljs-string">'ide-eval-resetter-2.1.13.zip'</span>,<br> <span class="hljs-string">'npp.8.1.4.Installer.exe'</span>,<br> <span class="hljs-string">'sogou_explorer_11.0.0.33862_7793.exe'</span>,<br> <span class="hljs-string">'Suplicant_for_Campus_Network_For_Windows_V6.61'</span>,<br> <span class="hljs-string">'windows_v6.61.rar'</span>]<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
      <category>文件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>文件</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用python删除文件和文件夹</title>
    <link href="/2021/10/06/python/file/delete-file/"/>
    <url>/2021/10/06/python/file/delete-file/</url>
    
    <content type="html"><![CDATA[<blockquote><p>总结删除文件和文件夹的相关操作和函数。</p></blockquote><h3 id="删除单个文件">删除单个文件</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">os.remove(path)<br><span class="hljs-comment"># 如果path是一个目录，抛出OSError错误，如果文件不在或者路径错误，会抛出错误</span><br></code></pre></td></tr></tbody></table></figure><h3 id="删除文件夹">删除文件夹</h3><p>空文件夹</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">os.rmdir(dirName)<br>os.removedirs(dirName)<br><span class="hljs-comment"># 删除目录 dirName，要求dirName必须是个空目录，否则抛出OSError错误</span><br></code></pre></td></tr></tbody></table></figure><h3 id="递归删除文件夹">递归删除文件夹</h3><p>非空文件夹</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> shutil<br>shutil.rmtree()<br></code></pre></td></tr></tbody></table></figure><p>遍历一个文件夹，先删除子文件，再删除文件夹。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> root, dirs, files <span class="hljs-keyword">in</span> os.walk(<span class="hljs-string">"filename"</span>, topdown=<span class="hljs-literal">False</span>):<br>    <span class="hljs-keyword">for</span> name <span class="hljs-keyword">in</span> files:<br>        os.remove(os.path.join(root, name))<br>    <span class="hljs-keyword">for</span> name <span class="hljs-keyword">in</span> dirs:<br>        os.rmdir(os.path.join(root, name))<br> <br><span class="hljs-comment"># os.walk的第一个参数是要遍历并删除子文件夹和文件的目录</span><br><span class="hljs-comment"># 上面的代码运行后，文件夹"filename"里的文件夹和文件全被删除，但是文件夹"filename"还存在</span><br><span class="hljs-comment"># 具体可以查下os.walk()的用法，以及其参数topdown的功能</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
      <category>文件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>文件</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer42 连续子数组最大和</title>
    <link href="/2021/10/06/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer42/"/>
    <url>/2021/10/06/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer42/</url>
    
    <content type="html"><![CDATA[<blockquote><p>连续子数组最大和</p></blockquote><h2 id="题目">题目</h2><p>输入一个整型数组，数组中的一个或连续多个整数组成一个子数组。求所有子数组的和的最大值。</p><p>要求时间复杂度为O(n)。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight subunit"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs subunit">输入: nums = [<span class="hljs-string">-2</span>,1,<span class="hljs-string">-3</span>,4,<span class="hljs-string">-1</span>,2,1,<span class="hljs-string">-5</span>,4]<br>输出: 6<br>解释: 连续子数组 [4,<span class="hljs-string">-1</span>,2,1] 的和最大，为 6。<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= arr.length &lt;= 10^5</li><li>-100 &lt;= arr[i] &lt;= 100</li></ul><h2 id="题解">题解</h2><p>使用数组dp[i]用来表示从0到i下标元素的子数组中，包含i元素的最大和，例如：原始数列num=[-2,1,-3,4,-1,2,1,-5,4]，dp为[-2, 1, -2, 4, 3, 5, 6, 1, 5]。注意从下标1开始，dp[i] = num[i] + max(0, dp[i-1])，如果前项的最大和(相邻的子数组)对此项<strong>有增益</strong>就添加进去，否则就直接num[i]。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maxSubArray</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(nums)):<br>            nums[i] += <span class="hljs-built_in">max</span>(nums[i - <span class="hljs-number">1</span>], <span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(nums)<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>动态规划</category>
      
    </categories>
    
    
    <tags>
      
      <tag>动态规划</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python将图片存进PDF中</title>
    <link href="/2021/10/06/python/img/FPDF/"/>
    <url>/2021/10/06/python/img/FPDF/</url>
    
    <content type="html"><![CDATA[<blockquote><p>在公安部足迹项目中，需要将矫正的足迹图片打印出来，所有首先转成pdf文件中再进行打印。就涉及到将图片存入pdf中，这里使用的工具是FPDF。FPDF是一个pdf文件的处理库，我们可以个性化创建和规范设定pdf文件。</p></blockquote><h3 id="安装">安装</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pip install fpdf<br></code></pre></td></tr></tbody></table></figure><h3 id="具体内容">具体内容</h3><h4 id="实现代码">实现代码</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> fpdf <span class="hljs-keyword">import</span> FPDF<br><span class="hljs-keyword">import</span> glob<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">imagesTopdf</span>(<span class="hljs-params">imagesPath,pdfName</span>):</span><br>    pdf = FPDF()<br>    <span class="hljs-keyword">for</span> imagePath <span class="hljs-keyword">in</span> imagesPath:<br>        pdf.add_page()<br>        pdf.image(imagePath,x=<span class="hljs-number">0</span>,y=<span class="hljs-number">0</span>,w=<span class="hljs-number">170</span>,h=<span class="hljs-number">297</span>)<br>    pdf.output(pdfName,<span class="hljs-string">"F"</span>)<br><br>images = glob.glob(<span class="hljs-string">"current_revise/"</span>+<span class="hljs-string">"*.jpg"</span>)<br><span class="hljs-comment"># jpg_path = "test.jpg"</span><br>pdf_path = <span class="hljs-string">"test_file3.pdf"</span><br>imagesTopdf(images,pdf_path)<br></code></pre></td></tr></tbody></table></figure><h4 id="相关参数">相关参数</h4><p>1，其中<code>pdf = FPDF()</code>是创建对象，默认是：</p><p>2，<code>orientation</code>为竖向（P：竖向，L横向）；</p><p>3，<code>unit</code>为mm毫米。用于表示文档中位置的计量单元。可用的值有以下四种:</p><ul><li>pt: 点</li><li>mm: 毫米</li><li>cm: 厘米</li><li>in: 英寸</li></ul><p>4，<code>format</code>用于表示创建的PDF文档的纸张类型。可用值可以是用于表示纸的字符串，如"A4"、“A5”、"Letter"等。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FPDF</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br>    <span class="hljs-string">"PDF Generation class"</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, orientation=<span class="hljs-string">'P'</span>,unit=<span class="hljs-string">'mm'</span>,<span class="hljs-built_in">format</span>=<span class="hljs-string">'A4'</span></span>)</span><br></code></pre></td></tr></tbody></table></figure><h4 id="相关函数">相关函数</h4><p><code>pdf.add_page()</code>用于创建新页。</p><p><code> pdf.image(imagePath,x=0,y=0,w=170,h=297)</code>是用于添加图像，其中<code>x</code>和<code>y</code>表示图片所在的坐标，<code>width</code>和<code>height</code>表示图片的宽度和高度。如果需要图片保持原来的大小，只需要将<code>width</code>和<code>height</code>设置成<code>0</code>即可。矫正后的图片是1700，2981；A4纸的尺寸是210*297，所以只能设置为297，也就是说这里误差至少有1.1mm</p><p>image源代码如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">image</span>(<span class="hljs-params">self, name, x=<span class="hljs-literal">None</span>, y=<span class="hljs-literal">None</span>, w=<span class="hljs-number">0</span>,h=<span class="hljs-number">0</span>,<span class="hljs-built_in">type</span>=<span class="hljs-string">''</span>,link=<span class="hljs-string">''</span></span>):</span><br>    <span class="hljs-string">"Put an image on the page"</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> name <span class="hljs-keyword">in</span> self.images:<br>        <span class="hljs-comment">#First use of image, get info</span><br>        <span class="hljs-keyword">if</span>(<span class="hljs-built_in">type</span>==<span class="hljs-string">''</span>):<br>            pos=name.rfind(<span class="hljs-string">'.'</span>)<br>            <span class="hljs-keyword">if</span>(<span class="hljs-keyword">not</span> pos):<br>                self.error(<span class="hljs-string">'image file has no extension and no type was specified: '</span>+name)<br>            <span class="hljs-built_in">type</span>=substr(name,pos+<span class="hljs-number">1</span>)<br>        <span class="hljs-built_in">type</span>=<span class="hljs-built_in">type</span>.lower()<br>        <span class="hljs-keyword">if</span>(<span class="hljs-built_in">type</span>==<span class="hljs-string">'jpg'</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">type</span>==<span class="hljs-string">'jpeg'</span>):<br>            info=self._parsejpg(name)<br>        <span class="hljs-keyword">elif</span>(<span class="hljs-built_in">type</span>==<span class="hljs-string">'png'</span>):<br>            info=self._parsepng(name)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment">#Allow for additional formats</span><br>            <span class="hljs-comment">#maybe the image is not showing the correct extension,</span><br>            <span class="hljs-comment">#but the header is OK,</span><br>            succeed_parsing = <span class="hljs-literal">False</span><br>            <span class="hljs-comment">#try all the parsing functions</span><br>            parsing_functions = [self._parsejpg,self._parsepng,self._parsegif]<br>            <span class="hljs-keyword">for</span> pf <span class="hljs-keyword">in</span> parsing_functions:<br>                <span class="hljs-keyword">try</span>:<br>                    info = pf(name)<br>                    succeed_parsing = <span class="hljs-literal">True</span><br>                    <span class="hljs-keyword">break</span>;<br>                <span class="hljs-keyword">except</span>:<br>                    <span class="hljs-keyword">pass</span><br>            <span class="hljs-comment">#last resource</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> succeed_parsing:<br>                mtd=<span class="hljs-string">'_parse'</span>+<span class="hljs-built_in">type</span><br>                <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">hasattr</span>(self,mtd):<br>                    self.error(<span class="hljs-string">'Unsupported image type: '</span>+<span class="hljs-built_in">type</span>)<br>                info=<span class="hljs-built_in">getattr</span>(self, mtd)(name)<br>            mtd=<span class="hljs-string">'_parse'</span>+<span class="hljs-built_in">type</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">hasattr</span>(self,mtd):<br>                self.error(<span class="hljs-string">'Unsupported image type: '</span>+<span class="hljs-built_in">type</span>)<br>            info=<span class="hljs-built_in">getattr</span>(self, mtd)(name)<br>        info[<span class="hljs-string">'i'</span>]=<span class="hljs-built_in">len</span>(self.images)+<span class="hljs-number">1</span><br>        self.images[name]=info<br>    <span class="hljs-keyword">else</span>:<br>        info=self.images[name]<br>    <span class="hljs-comment">#Automatic width and height calculation if needed</span><br>    <span class="hljs-keyword">if</span>(w==<span class="hljs-number">0</span> <span class="hljs-keyword">and</span> h==<span class="hljs-number">0</span>):<br>        <span class="hljs-comment">#Put image at 72 dpi</span><br>        w=info[<span class="hljs-string">'w'</span>]/self.k<br>        h=info[<span class="hljs-string">'h'</span>]/self.k<br>    <span class="hljs-keyword">elif</span>(w==<span class="hljs-number">0</span>):<br>        w=h*info[<span class="hljs-string">'w'</span>]/info[<span class="hljs-string">'h'</span>]<br>    <span class="hljs-keyword">elif</span>(h==<span class="hljs-number">0</span>):<br>        h=w*info[<span class="hljs-string">'h'</span>]/info[<span class="hljs-string">'w'</span>]<br>    <span class="hljs-comment"># Flowing mode</span><br>    <span class="hljs-keyword">if</span> y <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-keyword">if</span> (self.y + h &gt; self.page_break_trigger <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> self.in_footer <span class="hljs-keyword">and</span> self.accept_page_break()):<br>            <span class="hljs-comment">#Automatic page break</span><br>            x = self.x<br>            self.add_page(self.cur_orientation)<br>            self.x = x<br>        y = self.y<br>        self.y += h<br>    <span class="hljs-keyword">if</span> x <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        x = self.x<br>    self._out(sprintf(<span class="hljs-string">'q %.2f 0 0 %.2f %.2f %.2f cm /I%d Do Q'</span>,w*self.k,h*self.k,x*self.k,(self.h-(y+h))*self.k,info[<span class="hljs-string">'i'</span>]))<br>    <span class="hljs-keyword">if</span>(link):<br>        self.link(x,y,w,h,link)<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
      <category>图像</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
      <tag>图像</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pyinstaller打包问题</title>
    <link href="/2021/09/29/project_tool/pyinstaller-spec-problem/"/>
    <url>/2021/09/29/project_tool/pyinstaller-spec-problem/</url>
    
    <content type="html"><![CDATA[<blockquote><p>在使用pyinstaller打包的过程中的坑点，记录一下<br>参考大佬：<a href="https://blog.csdn.net/u012219045/article/details/115397646">https://blog.csdn.net/u012219045/article/details/115397646</a></p></blockquote><figure class="highlight vhdl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><code class="hljs vhdl">在使用pyinstaller打包的整个过程中，遇到不少问题，在此总结一下。后面遇到会继续更新！<br><br><span class="hljs-number">1</span>. 在<span class="hljs-number">64</span>下可运行，不能在<span class="hljs-number">32</span>位下运行<br>   解决：在<span class="hljs-number">32</span>位系统下打包，可以参考 https://blog.csdn.net/u012219045/article/details/<span class="hljs-number">115320619</span><br><br><span class="hljs-number">2</span>. RecursionError:maximum recursion depth<br>   解决：在xxx.spec文件开始增加两行：<br><br>    import sys<br>    sys.setrecursionlimit(<span class="hljs-number">5000</span>)<br>再执行打包：pyinstaller xxx.spec <br><br><span class="hljs-number">3</span>. UnicodeDecodeError:<span class="hljs-symbol">'utf</span>-<span class="hljs-number">8</span>' codec can<span class="hljs-symbol">'t</span> decode byte <span class="hljs-number">0</span>xce <span class="hljs-keyword">in</span> position <span class="hljs-number">122</span>:invalid continuation byte<br>   解决：在你打包的命令行中先输入chcp <span class="hljs-number">65001</span> 然后再输入打包命令。<br><br><span class="hljs-number">4</span>. 使用了多进程 multiprocessing 模块<br>   解决：必须调用 multiprocessing.freeze_support()，直接在“<span class="hljs-keyword">if</span> __name__ == '__main__'”之后调用<br><br><span class="hljs-number">5</span>. 打包PyQt5闪退<br>   原因：可能未找到某个文件<br>   解决办法：<br>        <span class="hljs-number">1</span>. 把需要读取的文件及其其他资源 都放到dist中。<br>        <span class="hljs-number">2</span>. 打包成exe的话，需使用 <span class="hljs-comment">--add-data 附加。可参考：https://blog.csdn.net/u012219045/article/details/114841287</span><br><br><span class="hljs-number">6</span>. <span class="hljs-literal">WARNING</span>:<span class="hljs-keyword">file</span> already exists but should <span class="hljs-keyword">not</span>：_C.cp37-win_amd64<br>   解决：报错内容可能不同，但都是xxx已存在，问题的原因是pyinstaller打包时多打了一次，所以会报已经存在了。<br>   这个解决方案就是把多余的去掉。在自动生成的xxx.spec中，在 a 和 PYZ 中间添加如下代码，去掉多余依赖项<br><br>    <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> a.datas:<br>        <span class="hljs-keyword">if</span> '_C.cp37-win_amd64' <span class="hljs-keyword">in</span> d[<span class="hljs-number">0</span>]:<br>            a.datas.remove(d)<br>            break<br><span class="hljs-number">7</span>. Hidden import <span class="hljs-string">"xxx"</span>  <span class="hljs-keyword">not</span> found!<br>    Hidden import <span class="hljs-string">"pkg_resources.markers"</span> <span class="hljs-keyword">not</span> found!<br>    Hidden import <span class="hljs-string">"pkg_resources.py2_warn"</span> <span class="hljs-keyword">not</span> found!<br>    Hidden import <span class="hljs-string">"MySQLdb"</span> <span class="hljs-keyword">not</span> found!<br>    Hidden import <span class="hljs-string">"sqlalchemy.sql.functions.func"</span> <span class="hljs-keyword">not</span> found!<br>    Hidden import <span class="hljs-string">"mx.DateTime"</span> <span class="hljs-keyword">not</span> found!<br>    解决： hiddenimports=[<span class="hljs-symbol">'pkg_resources</span>.markers', <span class="hljs-symbol">'pkg_resources</span>.py2_warn', '...']<br><br><span class="hljs-number">8</span>.  打包的时候出现了很多<span class="hljs-literal">warning</span>：lib <span class="hljs-keyword">not</span> found...dll, 原因是pyinstaller 没有办法识别到这些dll<br>    解决办法：copy <span class="hljs-literal">warning</span>中一些dll文件的名字，再电脑中搜索到他们的路径！添加到环境变量里面<br>    <span class="hljs-literal">WARNING</span>:lib <span class="hljs-keyword">not</span> found:msmpi.dll dependency <span class="hljs-keyword">of</span> d:\programdata\anaconda3\<span class="hljs-keyword">Library</span>\bin\mkl_blacs_msmpi_ilp64.dll<br>    <span class="hljs-literal">WARNING</span>:lib <span class="hljs-keyword">not</span> found:impi.dll dependency <span class="hljs-keyword">of</span> d:\programdata\anaconda3\<span class="hljs-keyword">Library</span>\bin\mkl_blacs_intelmpi_lp64.dll<br>    <span class="hljs-literal">WARNING</span>:lib <span class="hljs-keyword">not</span> found:msmpi.dll dependency <span class="hljs-keyword">of</span> d:\programdata\anaconda3\<span class="hljs-keyword">Library</span>\bin\mkl_blacs_msmpi_lp64.dll<br>    <span class="hljs-literal">WARNING</span>:lib <span class="hljs-keyword">not</span> found:impi.dll dependency <span class="hljs-keyword">of</span> d:\programdata\anaconda3\<span class="hljs-keyword">Library</span>\bin\mkl_blacs_intelmpi_ilp64.dll<br>    <span class="hljs-literal">WARNING</span>:lib <span class="hljs-keyword">not</span> found:mpich2mpi.dll dependency <span class="hljs-keyword">of</span> d:\programdata\anaconda3\<span class="hljs-keyword">Library</span>\bin\mkl_blacs_mpich2_lp64.dll<br>    <span class="hljs-literal">WARNING</span>:lib <span class="hljs-keyword">not</span> found:mpich2mpi.dll dependency <span class="hljs-keyword">of</span> d:\programdata\anaconda3\<span class="hljs-keyword">Library</span>\bin\mkl_blacs_mpich2_ilp64.dll<br>    <span class="hljs-literal">WARNING</span>:lib <span class="hljs-keyword">not</span> found:pgf90.dll dependency <span class="hljs-keyword">of</span> d:\programdata\anaconda3\<span class="hljs-keyword">Library</span>\bin\mkl_pgi_thread.dll<br>    <span class="hljs-literal">WARNING</span>:lib <span class="hljs-keyword">not</span> found:pgf90rtl.dll dependency <span class="hljs-keyword">of</span> d:\programdata\anaconda3\<span class="hljs-keyword">Library</span>\bin\mkl_pgi_thread.dll<br>    <span class="hljs-literal">WARNING</span>:lib <span class="hljs-keyword">not</span> found:pgc14.dll dependency <span class="hljs-keyword">of</span> d:\programdata\anaconda3\<span class="hljs-keyword">Library</span>\bin\mkl_pgi_thread.dll<br>    <span class="hljs-literal">WARNING</span>:lib <span class="hljs-keyword">not</span> found:torch_python.dll dependency <span class="hljs-keyword">of</span> d:\programdata\anaconda3\lib\site-packages\torch\_C.cp37-win_amd64.pyd<br><br><span class="hljs-number">9</span>. 切换了虚拟环境打包，报DLL无法导入，实际是打包时还在使用旧的虚拟环境<br>    解决： 打包时指定虚拟环境：-p。可参考： https://blog.csdn.net/u012219045/article/details/<span class="hljs-number">113612475</span><br><br><span class="hljs-number">10</span>. DecodeEncodeError<br>    解决： 检查执行路径中是否有中文，非Acsii码，换成英文路径。Python文件开头加 #-*-coding:utf-<span class="hljs-number">8</span>-*-<br><br><span class="hljs-number">11</span>. Pyqt5 打包后会出现错误:<span class="hljs-string">"QThread:Destroyed while thread is still running"</span><br>    解决办法<span class="hljs-number">1</span>：启动QThread使用了start(), 改为run() 可解决，但这样会卡主UI线程<br>    解决办法<span class="hljs-number">2</span>：依然使用start()，再追加一句 exec()。推荐这样！<br><br><span class="hljs-number">12</span>. No module named <span class="hljs-symbol">'sklearn</span>.xx'<br>    <span class="hljs-number">43852</span> <span class="hljs-literal">WARNING</span>: Hidden import <span class="hljs-string">"sklearn.utils.sparsetools._graph_validation"</span> <span class="hljs-keyword">not</span> found!<br>    <span class="hljs-number">43854</span> <span class="hljs-literal">WARNING</span>: Hidden import <span class="hljs-string">"sklearn.utils.sparsetools._graph_tools"</span> <span class="hljs-keyword">not</span> found!<br>    <span class="hljs-number">43866</span> <span class="hljs-literal">WARNING</span>: Hidden import <span class="hljs-string">"sklearn.utils.lgamma"</span> <span class="hljs-keyword">not</span> found!<br>    No module named <span class="hljs-symbol">'sklearn</span>.utils._cython_blas'<br>    No module named <span class="hljs-symbol">'sklearn</span>.neighbors._typedefs'<br>    No module named <span class="hljs-symbol">'sklearn</span>.neighbors._quad_tree'<br>    No module named <span class="hljs-symbol">'sklearn</span>.tree'<br>    No module named <span class="hljs-symbol">'sklearn</span>.tree._utils'<br>    解决：hiddenimports=[<span class="hljs-symbol">'sklearn</span>', <span class="hljs-symbol">'sklearn</span>.tree', <span class="hljs-symbol">'sklearn</span>.tree._utils', <span class="hljs-symbol">'sklearn</span>.neighbors._quad_tree',<br>                       <span class="hljs-symbol">'sklearn</span>.neighbors._typedefs', <span class="hljs-symbol">'sklearn</span>.utils._cython_blas',<br>                       <span class="hljs-symbol">'sklearn</span>.utils.sparsetools._graph_validation',<br>                       <span class="hljs-symbol">'sklearn</span>.utils.sparsetools._graph_tools', <span class="hljs-symbol">'sklearn</span>.utils.lgamma']<br><span class="hljs-number">13</span>. No module named <span class="hljs-symbol">'scipy</span>.special.cython_special'<br>   解决: 使用scipy==<span class="hljs-number">1.4</span>.<span class="hljs-number">1</span> 或者 <span class="hljs-comment">--hidden-import scipy.special.cython_special</span><br><br><span class="hljs-number">14</span>. No such <span class="hljs-keyword">file</span> <span class="hljs-keyword">or</span> directory: <span class="hljs-symbol">'xxx\\</span>librosa\\util\\example_data\\registry.txt'<br>   解决: 使用<span class="hljs-comment">--add-data或者直接拷贝librosa下的对应文件到dist。</span><br>   <br><span class="hljs-number">15</span>. fatal <span class="hljs-literal">error</span>:zmq.h:No such <span class="hljs-keyword">file</span> <span class="hljs-keyword">or</span> directory<br>    解决: sudo apt install libzmq3-dev<br><br><span class="hljs-number">16</span>. <span class="hljs-literal">Error</span> loading <span class="hljs-string">"xxx\torch\lib\caffe2_detectron_ops_gpu.dll"</span> <span class="hljs-keyword">or</span> one <span class="hljs-keyword">of</span> its dependencies<br>    开始使用pytorch==<span class="hljs-number">1.6</span>.<span class="hljs-number">0</span> torchvision==<span class="hljs-number">0.7</span>.<span class="hljs-number">0</span> cudatoolkit=<span class="hljs-number">10.1</span>，后来更换高版本torch1.<span class="hljs-number">7.0</span>解决！<br>    # pip install torch===<span class="hljs-number">1.7</span>.<span class="hljs-number">0</span>+cu110 torchvision===<span class="hljs-number">0.8</span>.<span class="hljs-number">1</span>+cu110 torchaudio===<span class="hljs-number">0.7</span>.<span class="hljs-number">0</span> -f https://download.pytorch.org/whl/torch_stable.html<br><br><span class="hljs-number">17</span>. unhandled exception <br>    <span class="hljs-literal">Error</span> loading <span class="hljs-string">"xxx\torch\lib\caffe2_nvrtc.dll"</span> <span class="hljs-keyword">or</span> one <span class="hljs-keyword">of</span> its dependencies<br>    开始使用pytorch降版本到<span class="hljs-number">1.8</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
      <category>pyinstaller</category>
      
    </categories>
    
    
    <tags>
      
      <tag>项目打包</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>利用spec文件打包</title>
    <link href="/2021/09/28/project_tool/spec/"/>
    <url>/2021/09/28/project_tool/spec/</url>
    
    <content type="html"><![CDATA[<blockquote><p>pyinstaller打包方式一般可以分为<strong>直接输入指令</strong>和<strong>利用spec文件</strong>进行打包两种方式，直接输入指令就是根据指令生成spec文件，再根据spec文件的内容进行打包操作，因此spec文件就是核心部分，在此对其内容的相关配置进行归纳。</p></blockquote><h3 id="spec文件参数">spec文件参数</h3><p>spec文件参数：a，pyz，exe，coll，block_cipher;</p><table><thead><tr><th style="text-align:center">变量</th><th style="text-align:left">含义</th></tr></thead><tbody><tr><td style="text-align:center">a</td><td style="text-align:left">Analysis类的实例,要求传入各种脚本用于分析程序的导入和依赖，a中的内容主要包括四部分：scripts：可以在命令行中输入的python脚本；pure，程序代码文件中的纯python模块；binaries：程序代码文件中需要的非python模块，包括add-binary参数指定的内容；datas：非二进制文件，包括add-data参数指定的内容</td></tr><tr><td style="text-align:center">pyz</td><td style="text-align:left">pyz的实例，是一个.pyz文件，包含了所有pure的所有python模块</td></tr><tr><td style="text-align:center">exe</td><td style="text-align:left">exe类的实例，这个类是用来处理Analysis和PYZ的结果。也是用来生成最后的exe可执行程序</td></tr><tr><td style="text-align:center">coll</td><td style="text-align:left">collect类的实例，用于创建输出目录，在-F模式（单一exe程序）下，是没有collect实例的，并且所有脚本，模块和二进制文件都包含在最终生成的exe文件中</td></tr><tr><td style="text-align:center">block_cipher</td><td style="text-align:left">加密密钥</td></tr></tbody></table><p>以上内容中修改比较多的是a,exe的内容，coll和pyz基本上没有遇到需要修改的情况。</p><h3 id="参数a，exe的说明">参数a，exe的说明</h3><p>下面对a和exe参数内容进行详细介绍：</p><table><thead><tr><th style="text-align:center">参数</th><th style="text-align:center">子参数</th><th style="text-align:left">具体含义</th></tr></thead><tbody><tr><td style="text-align:center">Analysis参数</td><td style="text-align:center">scripts</td><td style="text-align:left">第一个参数，他是一个脚本列表，可以传入多个py脚本，效果与命令行中指定多个py文件相同，比如说“pyinstaller <a href="http://XXX1.py">XXX1.py</a> <a href="http://XXX2.py">XXX2.py</a>”，pyinstaller会依次分析执行，并且把第一个py文件的名称作为spec和dist下的文件夹及程序名称</td></tr><tr><td style="text-align:center">Analysis参数</td><td style="text-align:center">pathex</td><td style="text-align:left">默认有一个spec目录，当我们有一些模块不在该项目路径下的时候，可以将使用到的模块路径添加到pathex变量中，相当于“-p DIR/-paths DIR”</td></tr><tr><td style="text-align:center">Analysis参数</td><td style="text-align:center">datas</td><td style="text-align:left">作用是将本地文件打包时拷贝到目标路径下。datas是一个元素为元组的列表，每个元组有两个元素，都必须是字符串类型，元组的第一个元素是数据文件（文件夹），元组的第二个元素为运行时这些文件（文件夹）的位置。例如：datas = [(‘./src/a.txt’,‘./dst’)]表示打包时将’./src/a.txt’文件添加到相对exe目录先的dist目录中，也可以使用通配符datas = [(‘./myfile/*.mp3’,‘sfx’)]，表示将myfile下的所有mp3文件都copy到sfx文件夹中，也可以添加整个文件夹：datas = [(‘./myfile/data’,‘data’)]，表示将myfile下的data文件夹下所有文件都copy到data文件夹下，同命令“-add-data”</td></tr><tr><td style="text-align:center">Analysis参数</td><td style="text-align:center">binaries</td><td style="text-align:left">添加二进制文件，也是一个列表，定义方式与datas参数一样，同命令“-add-binary”</td></tr><tr><td style="text-align:center">Analysis参数</td><td style="text-align:center">hiddenimports</td><td style="text-align:left">指定脚本中需要隐式导入的模块，比如在import、imp.find_module()、exec、eval等语句中导入模块，这些模块PyInstaller是找不到的，需要手动指定导入，这个选项可以使用多次。同命令“–hidden-import MODULENAME/–hiddenimport MODULENAME”。</td></tr><tr><td style="text-align:center">Analysis参数</td><td style="text-align:center">hookspath</td><td style="text-align:left">指定额外的hook文件（可以是py文件）的查找路径，这些文件的作用是在pyinstaller运行时改变一些python或者其他库原有的函数或者变量的执行逻辑（并不会改变这些库本身的代码），以便能顺利的打包完成，这个选项可以使用多次。同命令“–additional-hooks-dir HOOKSPATH”。</td></tr><tr><td style="text-align:center">Analysis参数</td><td style="text-align:center">runtime_hooks</td><td style="text-align:left">指定自定义的运行hook文件路径（可以时py文件），在打包好的exe程序中，运行这个exe程序时，指定的hook文件会在所有代码和模块之前运行，包括main文件，以满足一些运行环境的特殊要求，这个选项可以使用多次，同命令“-runtime-hook RUNTIME_HOOKS”.</td></tr><tr><td style="text-align:center">Analysis参数</td><td style="text-align:center">excludes</td><td style="text-align:left">指定可以被忽略的可选的模块或包，因为某些模块只是PyInstaller根据自身的逻辑去查找的，这些模块对于exe程序本身并没有用到，但是在日志中还是会提示“module not found”，这种日志可以不用管，或者使用这个参数选项来指定不用导入，这个选项可以使用多次。同命令“–exclude-module EXCLUDES”。</td></tr><tr><td style="text-align:center">exe参数</td><td style="text-align:center">console</td><td style="text-align:left">设置是否显示命令行窗口，同命令 “-W/-c”</td></tr><tr><td style="text-align:center">exe参数</td><td style="text-align:center">icon</td><td style="text-align:left">设置程序图标，默认spec是没有图标的，需要手动添加，参数值就是图片路径的字符串，同命令“-i/-icon”</td></tr></tbody></table><h3 id="我的记录">我的记录</h3><p>在此记录一下detectui的spec文件呢~~~</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># -*- mode: python ; coding: utf-8 -*-</span><br><br><br>block_cipher = <span class="hljs-literal">None</span><br><br><br>a = Analysis([<span class="hljs-string">'detectui.py'</span>,<br>              <span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\utils\\__init__.py'</span>,<br>              <span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\utils\\torch_utils.py'</span>,<br>              <span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\utils\\autoanchor.py'</span>,<br>              <span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\utils\\datasets.py'</span>,<br>              <span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\utils\\general.py'</span>,<br>              <span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\utils\\google_utils.py'</span>,<br>              <span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\utils\\metrics.py'</span>,<br>              <span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\utils\\plots.py'</span>,<br>              <span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\models\\__init__.py'</span>,<br>              <span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\models\\common.py'</span>,<br>              <span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\models\\experimental.py'</span>,<br>              <span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\models\\yolo.py'</span>,<br>              <span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\detectInfo.py'</span>,<br>              ],<br>             pathex=[<span class="hljs-string">'E:\\masterProjects\\foot\\footRevise'</span>,<br>             <span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\models'</span>,<br>             <span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\utils'</span>,<br>             <span class="hljs-string">'D:\\anaconda3\\envs\\torch\\Lib\\site-packages\\scipy\\.libs'</span>,<br>             <span class="hljs-string">'D:\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\lib'</span>,<br>              ],<br>             binaries=[],<br>             datas=[<br>             (<span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\weights\\best.pt'</span>,<span class="hljs-string">'.\\weights'</span>),<br>             (<span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\models\\*.yaml'</span>,<span class="hljs-string">'.\\models'</span>),<br>             (<span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\models\\hub\\*.yaml'</span>,<span class="hljs-string">'.\\models\\hub'</span>),<br>             (<span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\icon.jpg'</span>,<span class="hljs-string">'.'</span>),<br>             (<span class="hljs-string">'E:\\masterProjects\\foot\\footRevise\\utils\\__pycache__\\torch_utils.pyc'</span>,<span class="hljs-string">'.\\utils'</span>),<br>             ],<br>             hiddenimports=[<span class="hljs-string">'pkg_resources.py2_warn'</span>,<span class="hljs-string">'pkg_resources.markers'</span>],<br>             hookspath=[],<br>             hooksconfig={},<br>             runtime_hooks=[],<br>             excludes=[],<br>             win_no_prefer_redirects=<span class="hljs-literal">False</span>,<br>             win_private_assemblies=<span class="hljs-literal">False</span>,<br>             cipher=block_cipher,<br>             noarchive=<span class="hljs-literal">False</span>)<br><span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> a.datas:<br>    <span class="hljs-keyword">if</span> <span class="hljs-string">'_C.cp38-win_amd64.pyd'</span> <span class="hljs-keyword">in</span> d[<span class="hljs-number">0</span>]:<br>    a.datas.remove(d)<br>    <span class="hljs-keyword">break</span><br>pyz = PYZ(a.pure, a.zipped_data,<br>             cipher=block_cipher)<br><br>exe = EXE(pyz,<br>          a.scripts,<br>          [],<br>          exclude_binaries=<span class="hljs-literal">True</span>,<br>          name=<span class="hljs-string">'detectui'</span>,<br>          debug=<span class="hljs-literal">False</span>,<br>          bootloader_ignore_signals=<span class="hljs-literal">False</span>,<br>          strip=<span class="hljs-literal">False</span>,<br>          upx=<span class="hljs-literal">True</span>,<br>          console=<span class="hljs-literal">False</span>,<br>          icon=<span class="hljs-string">'icon.ico'</span>)<br>coll = COLLECT(exe,<br>               a.binaries,<br>               a.zipfiles,<br>               a.datas,<br>               strip=<span class="hljs-literal">False</span>,<br>               upx=<span class="hljs-literal">True</span>,<br>               name=<span class="hljs-string">'detectui'</span>)<br><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
      <category>pyinstaller</category>
      
    </categories>
    
    
    <tags>
      
      <tag>项目打包</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pyinstaller打包exe</title>
    <link href="/2021/09/26/project_tool/pyinstaller/"/>
    <url>/2021/09/26/project_tool/pyinstaller/</url>
    
    <content type="html"><![CDATA[<blockquote><p>pyinstaller的作用是可以将python应用程序打包为独立的可执行文件，相对与同类工具而言，其优势在于可以和python配合使用，构建较小的可执行文件并且完全多平台，完全兼容性。</p></blockquote><blockquote><p>pyinstaller的主要目标是与第三方软件包兼容，因此在使用pyinstaller会将所有的外部包继承在pyinstaller本身中。</p></blockquote><h2 id="安装">安装</h2><p>直接从pypi安装pyinstaller：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pip install pyinstaller<br></code></pre></td></tr></tbody></table></figure><p>然后在自己的程序目录中运行</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pyinstaller yourprogram.py<br></code></pre></td></tr></tbody></table></figure><p>就会生成dist文件夹，在dist文件夹下可以找到对应的exe文件。</p><h2 id="命令选项说明">命令选项说明</h2><p>PyInstaller 支持如表所示的常用选项。</p><table><thead><tr><th style="text-align:center">选项</th><th style="text-align:center">含义</th></tr></thead><tbody><tr><td style="text-align:center">-h，–help</td><td style="text-align:center">查看该模块的帮助信息</td></tr><tr><td style="text-align:center">-F，-onefile</td><td style="text-align:center">产生单个的可执行文件</td></tr><tr><td style="text-align:center">-D，–onedir</td><td style="text-align:center">产生一个目录（包含多个文件）作为可执行程序（默认）</td></tr><tr><td style="text-align:center">-a，–ascii</td><td style="text-align:center">不包含 Unicode 字符集支持</td></tr><tr><td style="text-align:center">-d，–debug</td><td style="text-align:center">产生 debug 版本的可执行文件</td></tr><tr><td style="text-align:center">-w，–windowed，–noconsolc</td><td style="text-align:center">指定程序运行时不显示命令行窗口（仅对 Windows 有效）</td></tr><tr><td style="text-align:center">-c，–nowindowed，–console</td><td style="text-align:center">指定使用命令行窗口运行程序（仅对 Windows 有效）</td></tr><tr><td style="text-align:center">-o DIR，–out=DIR</td><td style="text-align:center">指定 spec 文件的生成目录。如果没有指定，则默认使用当前目录来生成 spec 文件</td></tr><tr><td style="text-align:center">-p DIR，–path=DIR</td><td style="text-align:center">设置 Python 导入模块的路径（和设置 PYTHONPATH 环境变量的作用相似）。也可使用路径分隔符（Windows 使用分号，Linux 使用冒号）来分隔多个路径</td></tr><tr><td style="text-align:center">-n NAME，–name=NAME</td><td style="text-align:center">指定项目（产生的 spec）名字。如果省略该选项，那么第一个脚本的主文件名将作为 spec 的名字</td></tr></tbody></table><p>在此表列出的只是 PyInstaller 模块所支持的常用选项，如果需要了解 PyInstaller 选项的详细信息，则可通过 pyinstaller -h 或者–help查看帮助</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pyinstaller --<span class="hljs-built_in">help</span><br></code></pre></td></tr></tbody></table></figure><h2 id="使用pyinstaller">使用pyinstaller</h2><ul><li><p>打包成一个单一可执行文件</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pyinstaller -F &lt;options&gt; test.py<br></code></pre></td></tr></tbody></table></figure></li><li><p>打包成一个文件夹</p><figure class="highlight vim"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim">pyinstaller --onefile/-D <span class="hljs-symbol">&lt;options&gt;</span> test.<span class="hljs-keyword">py</span> （默认）<br></code></pre></td></tr></tbody></table></figure></li></ul><p>默认情况下打包会在当前目录下生成dist和build文件夹以及.spec文件，dist中即打包出来的可执行文件目录，build文件夹下为构建过程临时文件目录，.spec为打包的配置文件。</p><h3 id="各自的优缺点">各自的优缺点</h3><ul><li><p>启动时间</p><p>单一可执行文件比文件夹的启动时间要长很多，因为当程序运行时，单一的可执行文件需要解压程序的第三方依赖文件到临时文件夹，会耗费一定的不必要时间。</p></li><li><p>文件结构</p><p>单一可执行文件的文件结构和工程目录是一样的，其路径与工程目录的效果是一样的，但是生成文件夹就不一样了，若程序中包含相对路径，这个相对路径是基于该文件夹目录的。</p></li></ul><h2 id="spec文件">spec文件</h2><p>.spec文件类似于cmake的.makefile文件，都是用于<code>控制编译构建过程</code>的配置文件。正常使用实际上不需要管spec文件的，但是下面几种情况需要修改spec文件：</p><ul><li><p>需要打包资源文件</p></li><li><p>需要include一些pyinstaller不知道的run-time库</p></li><li><p>为可执行文件添加run-time选项</p></li><li><p>多程序打包</p></li></ul><p>后面可以直接通过.spec文件来打包</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pyinstaller &lt;options&gt; test.spec<br></code></pre></td></tr></tbody></table></figure><p>当通过spec文件来生成app文件时只有下面参数是有用的：</p><ul><li><code>-upx-dir</code>  Path to UPX utility (default: search the execution path)</li><li><code>-distpath</code>   Where to put the bundled app (default: .\dist)</li><li><code>-y –noconfirm</code>  Replace output directory (default: SPECPATH\dist\SPECNAME) without asking for confirmation</li><li><code>-a –ascii</code> Do not include unicode encoding support (default: included if available)</li></ul>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
      <category>pyinstaller</category>
      
    </categories>
    
    
    <tags>
      
      <tag>项目打包</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer30 包含min函数的栈</title>
    <link href="/2021/09/17/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer30/"/>
    <url>/2021/09/17/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer30/</url>
    
    <content type="html"><![CDATA[<blockquote><p>包含min函数的栈</p></blockquote><h2 id="题目">题目</h2><p>定义栈的数据结构，请在该类型中实现一个能够得到栈的最小元素的 min 函数在该栈中，调用 min、push 及 pop 的时间复杂度都是 O(1)。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight pf"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs pf">M<span class="hljs-keyword">in</span>Stack <span class="hljs-keyword">min</span>Stack = new M<span class="hljs-keyword">in</span>Stack();<br><span class="hljs-keyword">min</span>Stack.push(-<span class="hljs-number">2</span>);<br><span class="hljs-keyword">min</span>Stack.push(<span class="hljs-number">0</span>);<br><span class="hljs-keyword">min</span>Stack.push(-<span class="hljs-number">3</span>);<br><span class="hljs-keyword">min</span>Stack.<span class="hljs-keyword">min</span>();   --&gt; 返回 -<span class="hljs-number">3</span>.<br><span class="hljs-keyword">min</span>Stack.pop();<br><span class="hljs-keyword">min</span>Stack.top();      --&gt; 返回 <span class="hljs-number">0</span>.<br><span class="hljs-keyword">min</span>Stack.<span class="hljs-keyword">min</span>();   --&gt; 返回 -<span class="hljs-number">2</span>.<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>各函数的调用总次数不超过 20000 次</li></ul><h2 id="题解">题解</h2><p>emm这样子使用min函数，不太科学，时间复杂度为O(N)</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MinStack</span>:</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-string">"""</span><br><span class="hljs-string">        initialize your data structure here.</span><br><span class="hljs-string">        """</span><br>        self.stack = []<br>        self.minnum = sys.maxsize <span class="hljs-comment">#float("inf")</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">push</span>(<span class="hljs-params">self, x: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-literal">None</span>:</span><br>        <span class="hljs-keyword">if</span>(self.minnum&gt;x): self.minnum = x<br>        self.stack.append(x)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">pop</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-literal">None</span>:</span><br>        item = self.top()<br>        self.stack.pop()<br>        <span class="hljs-keyword">if</span>(<span class="hljs-built_in">len</span>(self.stack) == <span class="hljs-number">0</span>): <br>            self.minnum = sys.maxsize <span class="hljs-comment">#float("inf")</span><br>        <span class="hljs-keyword">elif</span>(item==self.minnum):<br>            self.minnum = <span class="hljs-built_in">min</span>(self.stack)<br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">top</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-keyword">return</span> self.stack[-<span class="hljs-number">1</span>]<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">min</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-keyword">return</span> self.minnum<br><br><span class="hljs-comment"># Your MinStack object will be instantiated and called as such:</span><br><span class="hljs-comment"># obj = MinStack()</span><br><span class="hljs-comment"># obj.push(x)</span><br><span class="hljs-comment"># obj.pop()</span><br><span class="hljs-comment"># param_3 = obj.top()</span><br><span class="hljs-comment"># param_4 = obj.min()</span><br></code></pre></td></tr></tbody></table></figure><p>-实际上应该创建两个栈，一个作为普通的栈A记录数据，另一个B用于辅助栈min的实现；使得A中的最小元素始终对应于B的栈顶元素。<strong>栈B的主要目的是记录最小值，所以不一定是需要所有完整的数据。</strong></p><ul><li>在调用push函数时，注意要维护好栈B，也就是说判断x时小于等于栈顶元素，才压入栈B；</li><li>在调用pop函数时，要保持A，B元素的一致性，在A中pop的元素是B的栈顶元素就要同步删除掉栈B的栈顶元素；</li></ul><p>这种方式可以保证在删除掉A和B的栈顶元素（最小值）之后，B的栈顶元素依然还是A的最小值。</p><p>嗯厉害~ o(<em>￣▽￣</em>)o</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MinStack</span>:</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-string">"""</span><br><span class="hljs-string">        initialize your data structure here.</span><br><span class="hljs-string">        """</span><br>        self.A,self.B = [],[]<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">push</span>(<span class="hljs-params">self, x: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-literal">None</span>:</span><br>self.A.append(x)<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.B <span class="hljs-keyword">or</span> self.B[-<span class="hljs-number">1</span>]&gt;=x: <span class="hljs-comment">#注意是大于等于，因为需要记录避免后续弹出导致元素不同步</span><br>            self.B.append(x)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">pop</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-literal">None</span>:</span><br><span class="hljs-keyword">if</span>(self.A.pop() == self.B[-<span class="hljs-number">1</span>]): <span class="hljs-comment">#如果是相同元素就注意同步删除</span><br>            self.B.pop()<br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">top</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-keyword">return</span> self.A[-<span class="hljs-number">1</span>]<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">min</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-keyword">return</span> self.B[-<span class="hljs-number">1</span>]<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>栈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>栈</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer35 复杂链表的复制</title>
    <link href="/2021/09/16/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer35/"/>
    <url>/2021/09/16/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer35/</url>
    
    <content type="html"><![CDATA[<blockquote><p>复杂链表的复制</p></blockquote><h2 id="题目">题目</h2><p>请实现 copyRandomList 函数，复制一个复杂链表。在复杂链表中，每个节点除了有一个 next 指针指向下一个节点，还有一个 random 指针指向链表中的任意节点或者 null。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：head = <span class="hljs-comment">[<span class="hljs-comment">[7,null]</span>,<span class="hljs-comment">[13,0]</span>,<span class="hljs-comment">[11,4]</span>,<span class="hljs-comment">[10,2]</span>,<span class="hljs-comment">[1,0]</span>]</span><br>输出：<span class="hljs-comment">[<span class="hljs-comment">[7,null]</span>,<span class="hljs-comment">[13,0]</span>,<span class="hljs-comment">[11,4]</span>,<span class="hljs-comment">[10,2]</span>,<span class="hljs-comment">[1,0]</span>]</span><br><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight lua"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs lua">输入：head = <span class="hljs-string">[[1,1],[2,1]]</span><br>输出：<span class="hljs-string">[[1,1],[2,1]]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-3：">示例 3：</h3><figure class="highlight lua"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs lua">输入：head = <span class="hljs-string">[[3,null],[3,0],[3,null]]</span><br>输出：<span class="hljs-string">[[3,null],[3,0],[3,null]]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-4：">示例 4：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：head = <span class="hljs-comment">[]</span><br>输出：<span class="hljs-comment">[]</span><br>解释：给定的链表为空（空指针），因此返回 null。<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>-10000 &lt;= Node.val &lt;= 10000</li><li>Node.random 为空（null）或指向链表中的节点。</li><li>节点数目不超过 1000 。</li></ul><h2 id="题解">题解</h2><p>通常普通的链表复制只需要遍历链表，每轮新建立一个节点，在添加前驱节点到当前节点的引用指向即可，但是本题的节点新增了random指针，因此需要处理random指针。</p><ul><li>第一种方法是使用<code>哈希表</code></li><li>第二种方法是使用<code>拼接+拆分</code></li></ul><h4 id="哈希表">哈希表</h4><p>先构建原链表节点和新链表节点的键值对映射关系，再遍历构建新链表节点的next和random的引用指向。</p><p>这里可以直接使用字典，键值对就是（原节点，新节点），然后直接在字典中构建；</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">copyRandomList</span>(<span class="hljs-params">self,head:<span class="hljs-string">'Node'</span></span>)-&gt;'Node':</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> head:<span class="hljs-keyword">return</span><br>        dic = {}<br>        cur = head<br>        <span class="hljs-keyword">while</span> cur:<br>            dic[cur] = Node(cur.val)<br>            cur = cur.<span class="hljs-built_in">next</span><br>        cur = head<br>        <span class="hljs-keyword">while</span> cur:<br>            dic[cur].<span class="hljs-built_in">next</span> = dic.get(cur.<span class="hljs-built_in">next</span>)<br>            dic[cur].random = dic.get(cur.random)<br>            cur = cur.<span class="hljs-built_in">next</span><br>        <span class="hljs-keyword">return</span> dic[head]<br></code></pre></td></tr></tbody></table></figure><blockquote><p>dict.get(key,default=None) key是字典中要查找的键，default是指定键值不存在时，返回默认值；</p></blockquote><p>此时时间复杂度为O(N),空间复杂度为O(N)。</p><h4 id="拼接-拆分">拼接+拆分</h4><p>构建拼接链表<code>原节点1-&gt;新节点1-&gt;原节点2-&gt;新节点2-&gt;......</code>,这时，在访问原节点的random时可以找到新对应新节点的random的指向节点。<br>当访问<code>cur.random</code>时，对应的新节点<code>cur.next</code>的随机指向节点为<code>cur.random.next</code>，就可以解决random的问题，再进行拆分链表。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">copyRandomList</span>(<span class="hljs-params">self,head:<span class="hljs-string">'Node'</span></span>)-&gt;'Node':</span><br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> head:<span class="hljs-keyword">return</span><br>cur = head<br><span class="hljs-comment">#复制各个节点，并构建拼接链表</span><br><span class="hljs-keyword">while</span> cur:<br>tmp = Node(cur.val)<br>tmp.<span class="hljs-built_in">next</span> = cur.<span class="hljs-built_in">next</span><br>cur.<span class="hljs-built_in">next</span> = tmp<br>cur = tmp.<span class="hljs-built_in">next</span><br><span class="hljs-comment">#构建random指向</span><br>cur = head<br><span class="hljs-keyword">while</span> cur:<br><span class="hljs-keyword">if</span> cur.random:<br>cur.<span class="hljs-built_in">next</span>.random = cur.random.<span class="hljs-built_in">next</span><br>            cur = cur.<span class="hljs-built_in">next</span>.<span class="hljs-built_in">next</span><br>        <span class="hljs-comment">#拆分链表</span><br>        cur = res = head.<span class="hljs-built_in">next</span><br>        <span class="hljs-keyword">while</span> cur.<span class="hljs-built_in">next</span>:<br>            cur.<span class="hljs-built_in">next</span> = cur.<span class="hljs-built_in">next</span>.<span class="hljs-built_in">next</span><br>            cur = cur.<span class="hljs-built_in">next</span><br>        <span class="hljs-keyword">return</span> res<br></code></pre></td></tr></tbody></table></figure><p>此时时间复杂度为O(N),空间复杂度为O(1)。</p>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>链表</category>
      
    </categories>
    
    
    <tags>
      
      <tag>链表</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随机数的总结</title>
    <link href="/2021/09/09/python/package_usage/random-summarize/"/>
    <url>/2021/09/09/python/package_usage/random-summarize/</url>
    
    <content type="html"><![CDATA[<blockquote><p>经常会用到随机数，在此，对numpy包中的随机数相关函数进行总结。</p></blockquote><ul><li><p>numpy.random.rand(d0, d1, …, dn)<br>该函数可以指定shape，返回服从0~1均匀分布的随机样本值。</p></li><li><p>numpy.random.randint(low, high=None, size=None, dtype=‘l’)<br>该函数返回随机的整数，可以指定随机数组范围和大小；在这里low是包含，high不包含;默认数据类型是long。</p></li><li><p>numpy.random.randn(d0, d1, …, dn)<br>该函数与rand类似，但是分布不同，这里是返回服从标准正态分布的随机样本值。</p></li><li><p>numpy.random.uniform(low=0.0, high=1.0, size=None)<br>该函数与randint类似，可以指定范围和大小，但是这里返回的随机数服从区间的均匀分布。</p></li><li><p>numpy.random.choice(a, size=None, replace=True, p=None)<br>该函数的作用是在给定的数据点中（一维数组）随机不重复的抽取大小为size的样本数据。</p></li><li><p>numpy.random.random_sample(size=None)<br>该函数是在[0,1)的范围随机返回指定大小的浮点数。也就是说与numpy.random.rand()类似，但是这里是需要输入size，而rand直接输入维度即可。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>python</category>
      
      <category>package</category>
      
    </categories>
    
    
    <tags>
      
      <tag>numpy</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>获取两个向量角度</title>
    <link href="/2021/09/08/img_process/getAngle/"/>
    <url>/2021/09/08/img_process/getAngle/</url>
    
    <content type="html"><![CDATA[<blockquote><p>获取两个向量的夹角</p></blockquote><p><img src="https://picture.mulindya.com/getAngle.jpg" alt=""></p><p>比如AB向量表示为[1,-3,5,-1],前两位是A的坐标，后两位是B的坐标。</p><p>直接计算出每个向量与x正轴的夹角，然后相减即可；核心的部分使用atan2函数（atan和atan2优先使用atan2）。</p><blockquote><p>atan与atan2的区别：<br>atan 和 atan2 都是求反正切函数，如：有两个点 point(x1,y1), 和 point(x2,y2);<br>那么这两个点形成的斜率的角度计算方法分别是：<br>float angle = atan( (y2-y1)/(x2-x1) ); 或 float angle = atan2( y2-y1, x2-x1 );<br>atan2 的优点在于如果 x2-x1等于0 依然可以计算，但是atan函数就会导致程序出错；</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_angle</span>(<span class="hljs-params">vec1,vec2</span>):</span><br>    dx1 = vec1[<span class="hljs-number">2</span>] - vec1[<span class="hljs-number">0</span>]<br>    dy1 = vec1[<span class="hljs-number">3</span>] - vec1[<span class="hljs-number">1</span>]<br>    dx2 = vec2[<span class="hljs-number">2</span>] - vec2[<span class="hljs-number">0</span>]<br>    dy2 = vec2[<span class="hljs-number">3</span>] - vec2[<span class="hljs-number">1</span>]<br>    angle1 = math.atan2(dy1,dx1)*<span class="hljs-number">180</span>/math.pi <span class="hljs-comment">#atan2结果为弧度制(可以处理90度的情况)</span><br>    angle2 = math.atan2(dy2,dx2)*<span class="hljs-number">180</span>/math.pi<br>    angle = <span class="hljs-built_in">abs</span>(angle1-angle2)<br>    <span class="hljs-keyword">if</span>(angle&gt;<span class="hljs-number">180</span>):angle = <span class="hljs-number">360</span>-angle<br>    <span class="hljs-keyword">return</span> angle<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>图像处理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>图像处理，角度</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>YOLOv2</title>
    <link href="/2021/08/27/deep_learning/yolov2/"/>
    <url>/2021/08/27/deep_learning/yolov2/</url>
    
    <content type="html"><![CDATA[<h2 id="YOLOv2">YOLOv2</h2><h3 id="综述">综述</h3><p><strong>论文地址</strong>：<a href="https://arxiv.org/abs/1612.08242">https://arxiv.org/abs/1612.08242</a></p><p>Yolov2与Yolov1在保持速度的基础上，对预测效果的准确度，耗费时间，鲁棒性三个方面进行了改进，检测能力提高到9000种不同对象。文章提出了一种新的<strong>训练方法–联合训练</strong>方法。这种算法可以将两种数据集混合到一起，使用一种分层的观点进行分类，用大型的分类数据集扩充检测的数据集。也成为YOLO9000.</p><p>联合训练的思路：<strong>在检测数据集和分类数据集上训练物体检测器（Object Detectors），用检测数据集学习物体的准确位置，用分类数据集来增加分类的类别两。提升健壮性。</strong></p><p>Yolo9000就是使用联合训练的算法，拥有来自于Imagenet的9000种分类信息，物体检测的部分来自于CoCo的检测数据集。</p><h3 id="论文">论文</h3><details><summary> yolov2 论文：YOLO9000: Better, Faster, Stronger</summary><iframe src="/js/pdfjs_old/web/viewer.html?file=https://paper.mulindya.com/YOLOv2.pdf" width="100%" height="650"></iframe></details><h3 id="改进点">改进点</h3><h4 id="BN-batch-normalization-批量归一化">BN(batch normalization) 批量归一化</h4><p>BN层有助于解决反向传播过程的<strong>梯度消失和梯度爆炸</strong>的问题，<strong>降低</strong>对超参数的<strong>敏感性</strong>，同时对batch归一化时，起到了一定的<strong>正则化</strong>的效果（去掉的dropout层）。通常，在网络的线性变换与激活函数之前增加一个BN层，BN层可以将其特征量归一化使得变换后的特征均值为0，方差为1，从而每一批训练样本都有类似的分布。同时还有修正的参数$\gamma,\beta$可以恢复原有信息。实验结果mAP提升2.4%</p><p>一般的归一化公式：</p>$$\widehat x^{(k)} = \frac{x^{(k)}-E[x^{(k)}]}{\sqrt {Var[x^{(k)}]}} \\$$<p><img src="https://picture.mulindya.com/yolov2-pic1.png" alt=""></p><h4 id="High-resolution-classifier（高分辨率图像分类器）">High resolution classifier（高分辨率图像分类器）</h4><p>由于对象检测的样本相对图像分类的训练样本要少得多，在对象检测时模型通常时先用图像分类的样本训练卷积层提取图像特征（训练backbone）。但是图像分类样本的分辨率不高，比如在yolov1中，训练集是224*224的图片来训练卷积层，但是在训练对象检测的模型使用的是448*448的图片，这样的切换对模型性能有一定影响。所以Yolo2在采用<strong>224*224图像分类模型预训练之后再采用448*448的高分辨率样本对分类模型进行微调</strong>(10个epoch)，这样再训练对象检测模型之前，网络特征就逐渐适应448*448的分辨率，然后再使用448*448的检测样本进行对象检测模型的训练，以缓解了分辨率突然切换造成的影响。通过这种方式，mAP提升了3.7%。</p><h4 id="Convolution-with-anchor-boxes-使用先验框">Convolution with anchor boxes(使用先验框)</h4><p>Yolov1是使用全连接层直接预测BBox的坐标值（每个grid预测k个Bbox），Faster R-CNN的方法是只用卷积层和region proposal network来预测锚框的偏移度和置信度。但是作者发现采用Faster R-CNN的方法比Yolov1的方法更加简便，让神经网络学习起来更加容易。</p><p>因此，Yolov2也尝试了先验框（anchor），在每个grid预先设定一组不同大小不同宽高比的边框，来覆盖整个图像的不同位置和多种尺度，这些先验框作为预定义的候选区检测框内是否有目标，以及微调边框的位置。之前yolov1并没有采用先验框，并且每个grid只预测两个bounding box，整个图像有98个，yolov2入轨每个grid采用9个先验框，收缩网络运行在416*416的图片，一个grid有32像素，那么总共有13*13*9=1521个先验框，最终去掉了全连接层，采用anchor boxes来预测bounding boxes。由于图片中的物体都倾向于出现在图片的中心位置，特别是那种比较大的物体，所以有一个单独位于物体中心的位置用于预测这些物体。YOLO的卷积层采用32这个值来下采样图片，所以通过选择416*416用作输入尺寸最终能输出一个13*13的Feature Map。使用Anchor Box会让精确度稍微下降，但用了它能让YOLO能预测出大于一千个框，同时recall达到88%，mAP达到69.2%。</p><h4 id="Dimension-clusters（聚类提取先验框的尺度信息）">Dimension clusters（聚类提取先验框的尺度信息）</h4><p>之前Anchor Box的尺寸是手动选择的，所以尺寸还有优化的余地。YOLO2尝试统计出更符合样本中对象尺寸的先验框，这样就可以减少网络微调先验框到实际位置的难度。YOLO2的做法是对训练集中标注的边框进行K-mean聚类分析，以寻找尽可能匹配样本的边框尺寸。</p><p>在使用Kmeans聚类分析时，并不是直接采用的欧氏距离度量，因为这样大边框的距离会相对小边框大，这样误差就很大，因此我们采用IOU的形式。<br>$$<br>d(box,centroid) = 1-IOU(box,centroid)<br>$$<br>centroid是聚类时被选作中心的边框，box就是其它边框，d就是两者间的“距离”。IOU越大，“距离”越近。YOLO2给出的聚类分析结果如下图所示：</p><p><img src="https://picture.mulindya.com/yolov2-pic2.png" alt=""></p><p>通过分析实验结果，在model复杂性与high recall之间权衡之后，选择聚类分类数K=5。</p><p><img src="https://picture.mulindya.com/yolov2-pic3.png" alt=""></p><p>说明用K-means选择Anchor Boxes时，选择值为5时，AVG IOU的值是61，这个值要比不用聚类的方法的60.9要高。选择值为9的时候，AVG IOU更有显著提高。总之就是说明用聚类的方法是有效果的。</p><h4 id="Direct-location-prediction（约束预测边框的位置）">Direct location prediction（约束预测边框的位置）</h4><p>借鉴于Faster RCNN的先验框方法，在训练的早期阶段，其位置预测容易不稳定。其位置预测公式为：</p>$$x = (t_x*w_a)+x_a \\y = (t_y*h_a)+y_a$$<p>其中， 是预测边框的中心， $x_a,y_a$是先验框（anchor）的中心点坐标， $w_a,h_a$是先验框（anchor）的宽和高，$t_x,t_y$ 是要学习的参数。注意，YOLO论文中写的是$x = (t_x*w_a)-x_a$ ，根据Faster RCNN，应该是"+"。</p><p>但是$t_x,t_y$ 不加约束的这种方式，会导致预测边框中心会出现在任意位置，因此在早期训练阶段不稳定，文章将边框的中心约束在grid网格当中。</p><p><img src="https://picture.mulindya.com/yolov2-pic4.png" alt=""></p><p>其中， $b_x,b_y,b_w,b_h$是预测边框的中心和宽高。 $Pr(object)*IOU(b,object)$是预测边框的置信度，在YOLO1是直接预测置信度的值，这里对预测参数$t_o$进行σ变换后作为置信度的值。 $c_x,c_y$是当前网格左上角到图像左上角的距离，要先将网格大小归一化，即令一个网格的宽=1，高=1。 $p_w,p_h$是先验框的宽和高($t_w,t_h$会对初始的设置进行调整)。σ是sigmoid函数。 $t_x,t_y,t_w,t_h,t_o$是要学习的参数($t_o$也可以学习的嘛，学到某种规律用以表示置信度❓)，分别用于预测边框的中心和宽高，以及置信度。</p><p><img src="https://picture.mulindya.com/yolov2-pic5.png" alt=""></p><p>这种方式可以让数值更幅度稳定，也让网络更容易学习。</p><h4 id="Fine-Grained-Features-passthrough层检测细粒度特征">Fine-Grained Features(passthrough层检测细粒度特征)</h4><p>对象检测面临一个问题：即目标检测的对象有大有小，输入图像经过多层网络提取特征，最后输出的特征图中（比如YOLO2中输入416<em>416经过卷积网络下采样最后输出是13</em>13），较小的对象可能特征已经不明显甚至被忽略掉了。为了更好的检测出一些比较小的对象，最后输出的特征图需要保留一些更细节的信息。</p><p>YOLO2引入一种称为passthrough层的方法在特征图中保留一些细节信息。具体来说，就是在最后一个pooling之前，特征图的大小是26*26*512，将其1拆4，直接传递（passthrough）到pooling后（并且又经过一组卷积）的特征图，两者叠加到一起作为输出的特征图。<br><img src="https://picture.mulindya.com/yolov2-pic11.png" alt=""></p><p>具体怎样1拆4，下面借用一副图看的很清楚。图中示例的是1个4*4拆成4个2*2。另外，根据YOLO2的代码，特征图先用1*1卷积从 26*26*512 降维到 26*26*64，再做1拆4并passthrough。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">ut = tf.extract_image_patches(<span class="hljs-keyword">in</span>, [<span class="hljs-number">1</span>, stride, stride, <span class="hljs-number">1</span>], [<span class="hljs-number">1</span>, stride, stride, <span class="hljs-number">1</span>], [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>], padding=<span class="hljs-string">"VALID"</span>)<br><span class="hljs-comment"># or use tf.space_to_depth</span><br><span class="hljs-comment"># out = tf.space_to_depth(in, 2)</span><br></code></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">tf.extract_image_patches(<br>    images,<br>    ksizes,<br>    strides,<br>    rates,<br>    padding,<br>    name=<span class="hljs-literal">None</span><br>)<br><span class="hljs-comment">#images：必须是shape为[batch, in_rows, in_cols, depth]的tensor；</span><br><span class="hljs-comment">#ksize：长度大于等于4的list，滑动窗的大小</span><br><span class="hljs-comment">#strides:每块patch区域之间中心点之间的距离，必须是: [1, stride_rows, stride_cols, 1].</span><br>    <span class="hljs-comment">#具体点说就是用来计算每次选取patch的初始点位置</span><br><span class="hljs-comment">#rates: 在每次提取的patch中，对应dim像素点位置之间的差距，必须是[1, rate_rows, rate_cols, 1]；「或者理解为 提取出来的每个框里面的像素不是都选择的 根据rate的不同 隔几个选一个 默认是1也就是的都选择 若为2 那么就是隔一个来选择」</span><br><span class="hljs-comment">#padding:有两个取值，“VALID”或者“SAME”，“VALID”表示所取的patch区域必须完全包含在原始图像中."SAME"表示可以取超出原始图像的部分，这一部分进行0填充。</span><br></code></pre></td></tr></tbody></table></figure><h4 id="Multi-scale-Training（多尺度图像训练）">Multi-scale Training（多尺度图像训练）</h4><p>作者希望YOLOv2能健壮的运行于不同尺寸的图片之上，所以把这一想法用于训练model中。</p><p>区别于之前的补全图片的尺寸的方法，YOLOv2每迭代几次都会改变网络参数。每10个Batch，网络会<strong>随机地选择一个新的图片尺寸</strong>，由于使用了下采样参数是32，所以不同的尺寸大小也选择为32的倍数{320，352……608}，最小320*320，最大608*608，网络会自动改变尺寸，并继续训练的过程。</p><p>这一方法让网络在不同的输入尺寸上都能达到一个很好的预测效果，同一网络能在不同分辨率上进行检测。当输入图片尺寸比较小的精度高，输入图片尺寸比较大的时候精度相对低，所以你可以在YOLOv2的速度和精度上进行权衡。</p><center class="half"><img src="https://picture.mulindya.com/yolov2-pic6.png"><img src="https://picture.mulindya.com/yolov2-pic7.png"></center><h4 id="hi-res-detect-高分辨率图像的对象检测">hi-res-detect(高分辨率图像的对象检测)</h4><p>上面左图表格中最后一行是使用高分辨l率的图像hi-res detector，因为YOLO2调整网络结构后能够支持多种尺寸的输入图像。通常是使用416*416的输入图像，如果用较高分辨率的输入图像，比如544*544，则mAP可以达到78.6，有1.8的提升。</p><h4 id="Hierarchical-classification-分层分类">Hierarchical classification(分层分类)</h4><p>作者提出了一种在分类数据集和检测数据集上联合训练的机制。使用检测数据集的图片去学习检测相关的信息，例如bounding box 坐标预测，是否包含物体以及属于各个物体的概率。使用仅有类别标签的分类数据集图片去扩展可以检测的种类。作者通过ImageNet训练分类、COCO和VOC数据集来训练检测，这是一个很有价值的思路，可以让我们达到比较优的效果。通过将两个数据集混合训练，<strong>如果遇到来自分类集的图片则只计算分类的Loss，遇到来自检测集的图片则计算完整的Loss</strong>。</p><p>但是ImageNet对应分类有9000种，而COCO则只提供80种目标检测，作者使用multi-label模型，即假定一张图片可以有多个label，并且不要求label间独立。因为作者选择在COCO和ImageNet数据集上进行联合训练，遇到的第一问题是两者的类别并不是完全互斥的，比如"Norfolk terrier"明显属于"dog"，所以作者提出了一种层级分类方法（Hierarchical classification），主要思路是根据各个类别之间的从属关系（根据WordNet）建立一种树结构WordTree，结合COCO和ImageNet建立的WordTree如下图所示：</p><p><img src="https://picture.mulindya.com/yolov2-pic8.png" alt=""></p><ol><li>遍历Imagenet的label，然后在WordNet中寻找该label到根节点(指向一个物理对象)的路径；</li><li>如果路径只有一条，那么就将该路径直接加入到分层树结构中；</li><li>否则，从剩余的路径中选择一条最短路径，加入到分层树。</li></ol><p>这个分层树我们称之为 WordTree，作用就在于将两种数据集按照层级进行结合。(感觉就是为了扩充数据集同时简便计算)</p><p>分类时的概率计算借用了<strong>决策树思想</strong>，<strong>某个节点的概率值等于该节点到根节点的所有条件概率之积</strong>。最终结果是一颗 WordTree （视觉名词组成的层次结构模型）。用WordTree执行分类时，预测每个节点的条件概率。如果想求得特定节点的绝对概率，只需要沿着路径做连续乘积。例如，如果想知道一张图片是不是“Norfolk terrier ”需要计算：</p><p><img src="https://picture.mulindya.com/yolov2-pic10.png" alt=""></p><p>另外，为了验证这种方法作者在WordTree（用1000类别的ImageNet创建）上训练了Darknet-19模型。为了创建WordTree1k，作者添加了很多中间节点，把label由1000扩展到1369。训练过程中ground truth标签要顺着向根节点的路径传播。例如，如果一张图片被标记为“Norfolk terrier”，它也被标记为“dog” 和“mammal”等。为了计算条件概率，模型预测了一个包含1369个元素的向量，而且基于所有“同义词集”计算softmax。</p><p>softmax操作也同时应该采用分组操作，下图上半部分为ImageNet对应的原生Softmax，下半部分对应基于WordTree的Softmax：</p><p><img src="https://picture.mulindya.com/yolov2-pic9.png" alt=""></p><p>通过上述方案构造WordTree，得到对应9418个分类，通过重采样保证Imagenet和COCO的样本数据比例为4:1。</p><h3 id="总结">总结</h3><p>通过联合训练策略，YOLO9000可以快速检测出超过9000个类别的物体，总体mAP值为19,7%。我觉得这是作者在这篇论文作出的最大的贡献，因为YOLOv2的改进策略亮点并不是很突出，但是YOLO9000算是开创之举。</p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
      <category>目标检测</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>目标检测</tag>
      
      <tag>yolo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在博客中显示pdf&amp;折叠</title>
    <link href="/2021/08/25/config/pdf-config/"/>
    <url>/2021/08/25/config/pdf-config/</url>
    
    <content type="html"><![CDATA[<blockquote><p>参考师兄的方法配置<br><a href="https://www.zywvvd.com/2021/08/15/hexo-theme/fluid/fluid-pdf/fluid-pdf/">https://www.zywvvd.com/2021/08/15/hexo-theme/fluid/fluid-pdf/fluid-pdf/</a></p></blockquote><h2 id="配置">配置</h2><p>pdf.js 是用于解析和呈现 PDF 的基于 Web 标准平台的通用解决方案，功能强大。</p><p>官方网站：<a href="https://mozilla.github.io/pdf.js/">https://mozilla.github.io/pdf.js/</a></p><p>由于我的浏览器的版本可能不高，考虑到兼容性下载旧版的文件。然后按师兄的步骤配置即可。</p><h2 id="使用">使用</h2><figure class="highlight llvm"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs llvm">&lt;iframe src<span class="hljs-operator">=</span>'/js/pdfjs_old/web/viewer.html?file<span class="hljs-operator">=</span>https://paper.mulindya.com/An<span class="hljs-variable">%20</span>Isotropic<span class="hljs-variable">%203</span><span class="hljs-keyword">x</span><span class="hljs-number">3</span><span class="hljs-variable">%20</span>Image<span class="hljs-variable">%20</span>Gradient<span class="hljs-variable">%20</span>Operator.pdf' width<span class="hljs-operator">=</span><span class="hljs-number">100</span>% height<span class="hljs-operator">=</span><span class="hljs-number">450</span>&gt;&lt;/iframe&gt;<br></code></pre></td></tr></tbody></table></figure><p>file设置为文件的地址，宽高可以自己设置。</p><h2 id="效果">效果</h2><iframe src="/js/pdfjs_old/web/viewer.html?file=https://paper.mulindya.com/An%20Isotropic%203x3%20Image%20Gradient%20Operator.pdf" width="100%" height="450"></iframe><h2 id="折叠">折叠</h2><p>通过html的details元素可以折叠隐藏的内容。</p><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs xml">使用 <span class="hljs-tag">&lt;<span class="hljs-name">details</span>&gt;</span> <span class="hljs-tag">&lt;/<span class="hljs-name">details</span>&gt;</span> 标签包裹需要隐藏的内容<br>在其中使用<span class="hljs-tag">&lt;<span class="hljs-name">summary</span>&gt;</span> <span class="hljs-tag">&lt;/<span class="hljs-name">summary</span>&gt;</span>标签包裹需要隐藏内容的标题<br></code></pre></td></tr></tbody></table></figure><p>这样如果需要阅读pdf就可以展开，不需要就隐藏，真是炒鸡便利！😉</p><details><summary>展开pdf</summary><iframe src="/js/pdfjs_old/web/viewer.html?file=https://paper.mulindya.com/An%20Isotropic%203x3%20Image%20Gradient%20Operator.pdf" width="100%" height="650"></iframe></details>]]></content>
    
    
    <categories>
      
      <category>配置</category>
      
    </categories>
    
    
    <tags>
      
      <tag>配置</tag>
      
      <tag>pdf</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>swin网络</title>
    <link href="/2021/08/25/deep_learning/swin/"/>
    <url>/2021/08/25/deep_learning/swin/</url>
    
    <content type="html"><![CDATA[<blockquote><p>swin_transformer的结构和代码实现部分，在此基础上添加freeze的相关操作，记录如下。</p></blockquote><h2 id="论文中的架构">论文中的架构</h2><p><img src="https://picture.mulindya.com/swin-pic1.png" alt=""></p><h2 id="论文笔记">论文笔记</h2><details><summary>Swin Transformer:Hierarchical Vision Transformer using Shifted Windows</summary><iframe src="/js/pdfjs_old/web/viewer.html?file=https://paper.mulindya.com/Swin%20Transformer%20Hierarchical%20Vision%20Transformer%20using%20Shifted%20Windows.pdf" width="100%" height="650"></iframe></details><h2 id="model架构">model架构</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br><span class="line">686</span><br><span class="line">687</span><br><span class="line">688</span><br><span class="line">689</span><br><span class="line">690</span><br><span class="line">691</span><br><span class="line">692</span><br><span class="line">693</span><br><span class="line">694</span><br><span class="line">695</span><br><span class="line">696</span><br><span class="line">697</span><br><span class="line">698</span><br></pre></td><td class="code"><pre><code class="hljs python">ImageClassifier(<br>  (backbone): SwinTransformer(<br>    (patch_embed): PatchEmbed(<br>      (projection): Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">96</span>, kernel_size=(<span class="hljs-number">4</span>, <span class="hljs-number">4</span>), stride=(<span class="hljs-number">4</span>, <span class="hljs-number">4</span>))<br>      (norm): LayerNorm((<span class="hljs-number">96</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>    )<br>    (drop_after_pos): Dropout(p=<span class="hljs-number">0.0</span>, inplace=<span class="hljs-literal">False</span>)<br>    (stages): ModuleList(<br>      (<span class="hljs-number">0</span>): SwinBlockSequence(<br>        (blocks): ModuleList(<br>          (<span class="hljs-number">0</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">96</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">96</span>, out_features=<span class="hljs-number">288</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">96</span>, out_features=<span class="hljs-number">96</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">96</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">96</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">96</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">1</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">96</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">96</span>, out_features=<span class="hljs-number">288</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">96</span>, out_features=<span class="hljs-number">96</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">96</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">96</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">96</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>        )<br>        (downsample): PatchMerging(<br>          (sampler): Unfold(kernel_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), dilation=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>))<br>          (norm): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>          (reduction): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">192</span>, bias=<span class="hljs-literal">False</span>)<br>        )<br>      )<br>      (<span class="hljs-number">1</span>): SwinBlockSequence(<br>        (blocks): ModuleList(<br>          (<span class="hljs-number">0</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">192</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">192</span>, out_features=<span class="hljs-number">576</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">192</span>, out_features=<span class="hljs-number">192</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">192</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">192</span>, out_features=<span class="hljs-number">768</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">768</span>, out_features=<span class="hljs-number">192</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">1</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">192</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">192</span>, out_features=<span class="hljs-number">576</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">192</span>, out_features=<span class="hljs-number">192</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">192</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">192</span>, out_features=<span class="hljs-number">768</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">768</span>, out_features=<span class="hljs-number">192</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>        )<br>        (downsample): PatchMerging(<br>          (sampler): Unfold(kernel_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), dilation=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>))<br>          (norm): LayerNorm((<span class="hljs-number">768</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>          (reduction): Linear(in_features=<span class="hljs-number">768</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">False</span>)<br>        )<br>      )<br>      (<span class="hljs-number">2</span>): SwinBlockSequence(<br>        (blocks): ModuleList(<br>          (<span class="hljs-number">0</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1152</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1536</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">1536</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">1</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1152</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1536</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">1536</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">2</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1152</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1536</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">1536</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">3</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1152</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1536</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">1536</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">4</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1152</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1536</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">1536</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">5</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1152</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1536</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">1536</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">6</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1152</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1536</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">1536</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">7</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1152</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1536</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">1536</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">8</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1152</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1536</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">1536</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">9</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1152</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1536</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">1536</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">10</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1152</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1536</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">1536</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">11</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1152</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1536</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">1536</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">12</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1152</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1536</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">1536</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">13</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1152</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1536</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">1536</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">14</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1152</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1536</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">1536</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">15</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1152</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1536</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">1536</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">16</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1152</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1536</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">1536</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">17</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1152</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">384</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">384</span>, out_features=<span class="hljs-number">1536</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">1536</span>, out_features=<span class="hljs-number">384</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>        )<br>        (downsample): PatchMerging(<br>          (sampler): Unfold(kernel_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), dilation=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>))<br>          (norm): LayerNorm((<span class="hljs-number">1536</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>          (reduction): Linear(in_features=<span class="hljs-number">1536</span>, out_features=<span class="hljs-number">768</span>, bias=<span class="hljs-literal">False</span>)<br>        )<br>      )<br>      (<span class="hljs-number">3</span>): SwinBlockSequence(<br>        (blocks): ModuleList(<br>          (<span class="hljs-number">0</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">768</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">768</span>, out_features=<span class="hljs-number">2304</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">768</span>, out_features=<span class="hljs-number">768</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">768</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">768</span>, out_features=<span class="hljs-number">3072</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">3072</span>, out_features=<span class="hljs-number">768</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>          (<span class="hljs-number">1</span>): SwinBlock(<br>            (norm1): LayerNorm((<span class="hljs-number">768</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (attn): ShiftWindowMSA(<br>              (w_msa): WindowMSA(<br>                (qkv): Linear(in_features=<span class="hljs-number">768</span>, out_features=<span class="hljs-number">2304</span>, bias=<span class="hljs-literal">True</span>)<br>                (attn_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (proj): Linear(in_features=<span class="hljs-number">768</span>, out_features=<span class="hljs-number">768</span>, bias=<span class="hljs-literal">True</span>)<br>                (proj_drop): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                (softmax): Softmax(dim=-<span class="hljs-number">1</span>)<br>              )<br>              (drop): DropPath()<br>            )<br>            (norm2): LayerNorm((<span class="hljs-number">768</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>            (ffn): FFN(<br>              (activate): GELU()<br>              (layers): Sequential(<br>                (<span class="hljs-number">0</span>): Sequential(<br>                  (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">768</span>, out_features=<span class="hljs-number">3072</span>, bias=<span class="hljs-literal">True</span>)<br>                  (<span class="hljs-number">1</span>): GELU()<br>                  (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>                )<br>                (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">3072</span>, out_features=<span class="hljs-number">768</span>, bias=<span class="hljs-literal">True</span>)<br>                (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0</span>, inplace=<span class="hljs-literal">False</span>)<br>              )<br>              (dropout_layer): DropPath()<br>            )<br>          )<br>        )<br>      )<br>    )<br>    (norm): LayerNorm((<span class="hljs-number">768</span>,), eps=<span class="hljs-number">1e-05</span>, elementwise_affine=<span class="hljs-literal">True</span>)<br>  )<br>  (neck): GlobalAveragePooling(<br>    (gap): AdaptiveAvgPool1d(output_size=<span class="hljs-number">1</span>)<br>  )<br>  (head): MultiLabelLinearClsHead(<br>    (compute_loss): CrossEntropyLoss()<br>    (fc): Linear(in_features=<span class="hljs-number">768</span>, out_features=<span class="hljs-number">11</span>, bias=<span class="hljs-literal">True</span>)<br>  )<br>)<br></code></pre></td></tr></tbody></table></figure><h2 id="代码">代码</h2><p>添加fronzen_stages:</p><blockquote><p>该参数表示你想冻结前几个 stages 的权重，swin 结构包括 4 stage内部结构(2,2,18,2)</p><p>frozen_stages=-1，表示全部可学习</p><p>frozen_stage=0，表示stem权重固定</p><p>frozen_stages=1，表示 stem 和第一个 stage 权重固定</p><p>frozen_stages=2，表示 stem 和前两个 stage 权重固定</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">stage = SwinBlockSequence(**_stage_cfg)<br><span class="hljs-comment"># 冻结某几层frozen_stages</span><br><span class="hljs-keyword">if</span>(frozen_stages==<span class="hljs-number">0</span> <span class="hljs-keyword">or</span> (i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,frozen_stages))):<br>stage.<span class="hljs-built_in">eval</span>()<br><span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> stage.parameters():<br>param.requires_grad = <span class="hljs-literal">False</span><br></code></pre></td></tr></tbody></table></figure><p>全部代码</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> copy <span class="hljs-keyword">import</span> deepcopy<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Sequence</span><br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> mmcv.cnn <span class="hljs-keyword">import</span> build_norm_layer<br><span class="hljs-keyword">from</span> mmcv.cnn.bricks.transformer <span class="hljs-keyword">import</span> FFN<br><span class="hljs-keyword">from</span> mmcv.cnn.utils.weight_init <span class="hljs-keyword">import</span> trunc_normal_<br><span class="hljs-keyword">from</span> mmcv.runner.base_module <span class="hljs-keyword">import</span> BaseModule, ModuleList<br><br><span class="hljs-keyword">from</span> ..builder <span class="hljs-keyword">import</span> BACKBONES<br><span class="hljs-keyword">from</span> ..utils <span class="hljs-keyword">import</span> PatchEmbed, PatchMerging, ShiftWindowMSA<br><span class="hljs-keyword">from</span> .base_backbone <span class="hljs-keyword">import</span> BaseBackbone<br><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SwinBlock</span>(<span class="hljs-params">BaseModule</span>):</span><br>    <span class="hljs-string">"""Swin Transformer block.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        embed_dims (int): Number of input channels.</span><br><span class="hljs-string">        input_resolution (Tuple[int, int]): The resolution of the input feature</span><br><span class="hljs-string">            map.</span><br><span class="hljs-string">        num_heads (int): Number of attention heads.</span><br><span class="hljs-string">        window_size (int, optional): The height and width of the window.</span><br><span class="hljs-string">            Defaults to 7.</span><br><span class="hljs-string">        shift (bool, optional): Shift the attention window or not.</span><br><span class="hljs-string">            Defaults to False.</span><br><span class="hljs-string">        ffn_ratio (float, optional): The expansion ratio of feedforward network</span><br><span class="hljs-string">            hidden layer channels. Defaults to 4.</span><br><span class="hljs-string">        drop_path (float, optional): The drop path rate after attention and</span><br><span class="hljs-string">            ffn. Defaults to 0.</span><br><span class="hljs-string">        attn_cfgs (dict, optional): The extra config of Shift Window-MSA.</span><br><span class="hljs-string">            Defaults to empty dict.</span><br><span class="hljs-string">        ffn_cfgs (dict, optional): The extra config of FFN.</span><br><span class="hljs-string">            Defaults to empty dict.</span><br><span class="hljs-string">        norm_cfg (dict, optional): The config of norm layers.</span><br><span class="hljs-string">            Defaults to dict(type='LN').</span><br><span class="hljs-string">        auto_pad (bool, optional): Auto pad the feature map to be divisible by</span><br><span class="hljs-string">            window_size, Defaults to False.</span><br><span class="hljs-string">        init_cfg (dict, optional): The extra config for initialization.</span><br><span class="hljs-string">            Default: None.</span><br><span class="hljs-string">    """</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self,</span></span><br><span class="hljs-params"><span class="hljs-function">                 embed_dims,</span></span><br><span class="hljs-params"><span class="hljs-function">                 input_resolution,</span></span><br><span class="hljs-params"><span class="hljs-function">                 num_heads,</span></span><br><span class="hljs-params"><span class="hljs-function">                 window_size=<span class="hljs-number">7</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                 shift=<span class="hljs-literal">False</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                 ffn_ratio=<span class="hljs-number">4.</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                 drop_path=<span class="hljs-number">0.</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                 attn_cfgs=<span class="hljs-built_in">dict</span>(<span class="hljs-params"></span>),</span></span><br><span class="hljs-params"><span class="hljs-function">                 ffn_cfgs=<span class="hljs-built_in">dict</span>(<span class="hljs-params"></span>),</span></span><br><span class="hljs-params"><span class="hljs-function">                 norm_cfg=<span class="hljs-built_in">dict</span>(<span class="hljs-params"><span class="hljs-built_in">type</span>=<span class="hljs-string">'LN'</span></span>),</span></span><br><span class="hljs-params"><span class="hljs-function">                 auto_pad=<span class="hljs-literal">False</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                 init_cfg=<span class="hljs-literal">None</span></span>):</span><br><br>        <span class="hljs-built_in">super</span>(SwinBlock, self).__init__(init_cfg)<br><br>        _attn_cfgs = {<br>            <span class="hljs-string">'embed_dims'</span>: embed_dims,<br>            <span class="hljs-string">'input_resolution'</span>: input_resolution,<br>            <span class="hljs-string">'num_heads'</span>: num_heads,<br>            <span class="hljs-string">'shift_size'</span>: window_size // <span class="hljs-number">2</span> <span class="hljs-keyword">if</span> shift <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>,<br>            <span class="hljs-string">'window_size'</span>: window_size,<br>            <span class="hljs-string">'dropout_layer'</span>: <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">type</span>=<span class="hljs-string">'DropPath'</span>, drop_prob=drop_path),<br>            <span class="hljs-string">'auto_pad'</span>: auto_pad,<br>            **attn_cfgs<br>        }<br>        self.norm1 = build_norm_layer(norm_cfg, embed_dims)[<span class="hljs-number">1</span>]<br>        self.attn = ShiftWindowMSA(**_attn_cfgs)<br><br>        _ffn_cfgs = {<br>            <span class="hljs-string">'embed_dims'</span>: embed_dims,<br>            <span class="hljs-string">'feedforward_channels'</span>: <span class="hljs-built_in">int</span>(embed_dims * ffn_ratio),<br>            <span class="hljs-string">'num_fcs'</span>: <span class="hljs-number">2</span>,<br>            <span class="hljs-string">'ffn_drop'</span>: <span class="hljs-number">0</span>,<br>            <span class="hljs-string">'dropout_layer'</span>: <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">type</span>=<span class="hljs-string">'DropPath'</span>, drop_prob=drop_path),<br>            <span class="hljs-string">'act_cfg'</span>: <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">type</span>=<span class="hljs-string">'GELU'</span>),<br>            **ffn_cfgs<br>        }<br>        self.norm2 = build_norm_layer(norm_cfg, embed_dims)[<span class="hljs-number">1</span>]<br>        self.ffn = FFN(**_ffn_cfgs)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        identity = x<br>        x = self.norm1(x)<br>        x = self.attn(x)<br>        x = x + identity<br><br>        identity = x<br>        x = self.norm2(x)<br>        x = self.ffn(x, identity=identity)<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SwinBlockSequence</span>(<span class="hljs-params">BaseModule</span>):</span><br>    <span class="hljs-string">"""Module with successive Swin Transformer blocks and downsample layer.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        embed_dims (int): Number of input channels.</span><br><span class="hljs-string">        input_resolution (Tuple[int, int]): The resolution of the input feature</span><br><span class="hljs-string">            map.</span><br><span class="hljs-string">        depth (int): Number of successive swin transformer blocks.</span><br><span class="hljs-string">        num_heads (int): Number of attention heads.</span><br><span class="hljs-string">        downsample (bool, optional): Downsample the output of blocks by patch</span><br><span class="hljs-string">            merging. Defaults to False.</span><br><span class="hljs-string">        downsample_cfg (dict, optional): The extra config of the patch merging</span><br><span class="hljs-string">            layer. Defaults to empty dict.</span><br><span class="hljs-string">        drop_paths (Sequence[float] | float, optional): The drop path rate in</span><br><span class="hljs-string">            each block. Defaults to 0.</span><br><span class="hljs-string">        block_cfgs (Sequence[dict] | dict, optional): The extra config of each</span><br><span class="hljs-string">            block. Defaults to empty dicts.</span><br><span class="hljs-string">        auto_pad (bool, optional): Auto pad the feature map to be divisible by</span><br><span class="hljs-string">            window_size, Defaults to False.</span><br><span class="hljs-string">        init_cfg (dict, optional): The extra config for initialization.</span><br><span class="hljs-string">            Default: None.</span><br><span class="hljs-string">    """</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self,</span></span><br><span class="hljs-params"><span class="hljs-function">                 embed_dims,</span></span><br><span class="hljs-params"><span class="hljs-function">                 input_resolution,</span></span><br><span class="hljs-params"><span class="hljs-function">                 depth,</span></span><br><span class="hljs-params"><span class="hljs-function">                 num_heads,</span></span><br><span class="hljs-params"><span class="hljs-function">                 downsample=<span class="hljs-literal">False</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                 downsample_cfg=<span class="hljs-built_in">dict</span>(<span class="hljs-params"></span>),</span></span><br><span class="hljs-params"><span class="hljs-function">                 drop_paths=<span class="hljs-number">0.</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                 block_cfgs=<span class="hljs-built_in">dict</span>(<span class="hljs-params"></span>),</span></span><br><span class="hljs-params"><span class="hljs-function">                 auto_pad=<span class="hljs-literal">False</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                 init_cfg=<span class="hljs-literal">None</span></span>):</span><br>        <span class="hljs-built_in">super</span>().__init__(init_cfg)<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(drop_paths, <span class="hljs-type">Sequence</span>):<br>            drop_paths = [drop_paths] * depth<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(block_cfgs, <span class="hljs-type">Sequence</span>):<br>            block_cfg = [deepcopy(block_cfgs) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(depth)]<br><br>        self.blocks = ModuleList()<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(depth):<br>            _block_cfg = {<br>                <span class="hljs-string">'embed_dims'</span>: embed_dims,<br>                <span class="hljs-string">'input_resolution'</span>: input_resolution,<br>                <span class="hljs-string">'num_heads'</span>: num_heads,<br>                <span class="hljs-string">'shift'</span>: <span class="hljs-literal">False</span> <span class="hljs-keyword">if</span> i % <span class="hljs-number">2</span> == <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">True</span>,<br>                <span class="hljs-string">'drop_path'</span>: drop_paths[i],<br>                <span class="hljs-string">'auto_pad'</span>: auto_pad,<br>                **block_cfg[i]<br>            }<br>            block = SwinBlock(**_block_cfg)<br>            self.blocks.append(block)<br><br>        <span class="hljs-keyword">if</span> downsample:<br>            _downsample_cfg = {<br>                <span class="hljs-string">'input_resolution'</span>: input_resolution,<br>                <span class="hljs-string">'in_channels'</span>: embed_dims,<br>                <span class="hljs-string">'expansion_ratio'</span>: <span class="hljs-number">2</span>,<br>                <span class="hljs-string">'norm_cfg'</span>: <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">type</span>=<span class="hljs-string">'LN'</span>),<br>                **downsample_cfg<br>            }<br>            self.downsample = PatchMerging(**_downsample_cfg)<br>        <span class="hljs-keyword">else</span>:<br>            self.downsample = <span class="hljs-literal">None</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        <span class="hljs-keyword">for</span> block <span class="hljs-keyword">in</span> self.blocks:<br>            x = block(x)<br><br>        <span class="hljs-keyword">if</span> self.downsample:<br>            x = self.downsample(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-meta">@BACKBONES.register_module()</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SwinTransformer</span>(<span class="hljs-params">BaseBackbone</span>):</span><br>    <span class="hljs-string">""" Swin Transformer</span><br><span class="hljs-string">    A PyTorch implement of : `Swin Transformer:</span><br><span class="hljs-string">    Hierarchical Vision Transformer using Shifted Windows`  -</span><br><span class="hljs-string">        https://arxiv.org/abs/2103.14030</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Inspiration from</span><br><span class="hljs-string">    https://github.com/microsoft/Swin-Transformer</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        arch (str | dict): Swin Transformer architecture</span><br><span class="hljs-string">            Defaults to 'T'.</span><br><span class="hljs-string">        img_size (int | tuple): The size of input image.</span><br><span class="hljs-string">            Defaults to 224.</span><br><span class="hljs-string">        in_channels (int): The num of input channels.</span><br><span class="hljs-string">            Defaults to 3.</span><br><span class="hljs-string">        drop_rate (float): Dropout rate after embedding.</span><br><span class="hljs-string">            Defaults to 0.</span><br><span class="hljs-string">        drop_path_rate (float): Stochastic depth rate.</span><br><span class="hljs-string">            Defaults to 0.1.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        # add attr</span><br><span class="hljs-string">        frozen_stages: defaults-1 dont freeze,0: all freeze,other: frozen_stages stages to freeze</span><br><span class="hljs-string"></span><br><span class="hljs-string">        use_abs_pos_embed (bool): If True, add absolute position embedding to</span><br><span class="hljs-string">            the patch embedding. Defaults to False.</span><br><span class="hljs-string">        auto_pad (bool): If True, auto pad feature map to fit window_size.</span><br><span class="hljs-string">            Defaults to False.</span><br><span class="hljs-string">        norm_cfg (dict, optional): Config dict for normalization layer at end</span><br><span class="hljs-string">            of backone. Defaults to dict(type='LN')</span><br><span class="hljs-string">        stage_cfgs (Sequence | dict, optional): Extra config dict for each</span><br><span class="hljs-string">            stage. Defaults to empty dict.</span><br><span class="hljs-string">        patch_cfg (dict, optional): Extra config dict for patch embedding.</span><br><span class="hljs-string">            Defaults to empty dict.</span><br><span class="hljs-string">        init_cfg (dict, optional): The Config for initialization.</span><br><span class="hljs-string">            Defaults to None.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Examples:</span><br><span class="hljs-string">        &gt;&gt;&gt; from mmcls.models import SwinTransformer</span><br><span class="hljs-string">        &gt;&gt;&gt; import torch</span><br><span class="hljs-string">        &gt;&gt;&gt; extra_config = dict(</span><br><span class="hljs-string">        &gt;&gt;&gt;     arch='tiny',</span><br><span class="hljs-string">        &gt;&gt;&gt;     stage_cfgs=dict(downsample_cfg={'kernel_size': 3,</span><br><span class="hljs-string">        &gt;&gt;&gt;                                     'expansion_ratio': 3}),</span><br><span class="hljs-string">        &gt;&gt;&gt;     auto_pad=True)</span><br><span class="hljs-string">        &gt;&gt;&gt; self = SwinTransformer(**extra_config)</span><br><span class="hljs-string">        &gt;&gt;&gt; inputs = torch.rand(1, 3, 224, 224)</span><br><span class="hljs-string">        &gt;&gt;&gt; output = self.forward(inputs)</span><br><span class="hljs-string">        &gt;&gt;&gt; print(output.shape)</span><br><span class="hljs-string">        (1, 2592, 4)</span><br><span class="hljs-string">    """</span><br>    arch_zoo = {<br>        **<span class="hljs-built_in">dict</span>.fromkeys([<span class="hljs-string">'t'</span>, <span class="hljs-string">'tiny'</span>],<br>                        {<span class="hljs-string">'embed_dims'</span>: <span class="hljs-number">96</span>,<br>                         <span class="hljs-string">'depths'</span>:     [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>,  <span class="hljs-number">6</span>,  <span class="hljs-number">2</span>],<br>                         <span class="hljs-string">'num_heads'</span>:  [<span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">12</span>, <span class="hljs-number">24</span>]}),<br>        **<span class="hljs-built_in">dict</span>.fromkeys([<span class="hljs-string">'s'</span>, <span class="hljs-string">'small'</span>],<br>                        {<span class="hljs-string">'embed_dims'</span>: <span class="hljs-number">96</span>,<br>                         <span class="hljs-string">'depths'</span>:     [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">18</span>,  <span class="hljs-number">2</span>],<br>                         <span class="hljs-string">'num_heads'</span>:  [<span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">12</span>, <span class="hljs-number">24</span>]}),<br>        **<span class="hljs-built_in">dict</span>.fromkeys([<span class="hljs-string">'b'</span>, <span class="hljs-string">'base'</span>],<br>                        {<span class="hljs-string">'embed_dims'</span>: <span class="hljs-number">128</span>,<br>                         <span class="hljs-string">'depths'</span>:     [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">18</span>,  <span class="hljs-number">2</span>],<br>                         <span class="hljs-string">'num_heads'</span>:  [<span class="hljs-number">4</span>, <span class="hljs-number">8</span>, <span class="hljs-number">16</span>, <span class="hljs-number">32</span>]}),<br>        **<span class="hljs-built_in">dict</span>.fromkeys([<span class="hljs-string">'l'</span>, <span class="hljs-string">'large'</span>],<br>                        {<span class="hljs-string">'embed_dims'</span>: <span class="hljs-number">192</span>,<br>                         <span class="hljs-string">'depths'</span>:     [<span class="hljs-number">2</span>,  <span class="hljs-number">2</span>, <span class="hljs-number">18</span>,  <span class="hljs-number">2</span>],<br>                         <span class="hljs-string">'num_heads'</span>:  [<span class="hljs-number">6</span>, <span class="hljs-number">12</span>, <span class="hljs-number">24</span>, <span class="hljs-number">48</span>]}),<br>    }  <span class="hljs-comment"># yapf: disable</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self,</span></span><br><span class="hljs-params"><span class="hljs-function">                 arch=<span class="hljs-string">'T'</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                 img_size=<span class="hljs-number">224</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                 in_channels=<span class="hljs-number">3</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                 drop_rate=<span class="hljs-number">0.</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                 drop_path_rate=<span class="hljs-number">0.1</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                 frozen_stages=-<span class="hljs-number">1</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                 use_abs_pos_embed=<span class="hljs-literal">False</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                 auto_pad=<span class="hljs-literal">False</span>,</span></span><br><span class="hljs-params"><span class="hljs-function">                 norm_cfg=<span class="hljs-built_in">dict</span>(<span class="hljs-params"><span class="hljs-built_in">type</span>=<span class="hljs-string">'LN'</span></span>),</span></span><br><span class="hljs-params"><span class="hljs-function">                 stage_cfgs=<span class="hljs-built_in">dict</span>(<span class="hljs-params"></span>),</span></span><br><span class="hljs-params"><span class="hljs-function">                 patch_cfg=<span class="hljs-built_in">dict</span>(<span class="hljs-params"></span>),</span></span><br><span class="hljs-params"><span class="hljs-function">                 init_cfg=<span class="hljs-literal">None</span></span>):</span><br>        <span class="hljs-built_in">super</span>(SwinTransformer, self).__init__(init_cfg)<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(arch, <span class="hljs-built_in">str</span>):<br>            arch = arch.lower()<br>            <span class="hljs-keyword">assert</span> arch <span class="hljs-keyword">in</span> <span class="hljs-built_in">set</span>(self.arch_zoo), \<br>                <span class="hljs-string">f'Arch <span class="hljs-subst">{arch}</span> is not in default archs <span class="hljs-subst">{<span class="hljs-built_in">set</span>(self.arch_zoo)}</span>'</span><br>            self.arch_settings = self.arch_zoo[arch]<br>        <span class="hljs-keyword">else</span>:<br>            essential_keys = {<span class="hljs-string">'embed_dims'</span>, <span class="hljs-string">'depths'</span>, <span class="hljs-string">'num_head'</span>}<br>            <span class="hljs-keyword">assert</span> <span class="hljs-built_in">isinstance</span>(arch, <span class="hljs-built_in">dict</span>) <span class="hljs-keyword">and</span> <span class="hljs-built_in">set</span>(arch) == essential_keys, \<br>                <span class="hljs-string">f'Custom arch needs a dict with keys <span class="hljs-subst">{essential_keys}</span>'</span><br>            self.arch_settings = arch<br><br>        self.embed_dims = self.arch_settings[<span class="hljs-string">'embed_dims'</span>]<br>        self.depths = self.arch_settings[<span class="hljs-string">'depths'</span>]<br>        self.num_heads = self.arch_settings[<span class="hljs-string">'num_heads'</span>]<br>        self.num_layers = <span class="hljs-built_in">len</span>(self.depths)<br>        self.use_abs_pos_embed = use_abs_pos_embed<br>        self.auto_pad = auto_pad<br><br>        _patch_cfg = <span class="hljs-built_in">dict</span>(<br>            img_size=img_size,<br>            in_channels=in_channels,<br>            embed_dims=self.embed_dims,<br>            conv_cfg=<span class="hljs-built_in">dict</span>(<br>                <span class="hljs-built_in">type</span>=<span class="hljs-string">'Conv2d'</span>, kernel_size=<span class="hljs-number">4</span>, stride=<span class="hljs-number">4</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>),<br>            norm_cfg=<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">type</span>=<span class="hljs-string">'LN'</span>),<br>            **patch_cfg)<br>        self.patch_embed = PatchEmbed(**_patch_cfg)<br>        num_patches = self.patch_embed.num_patches<br>        patches_resolution = self.patch_embed.patches_resolution<br>        self.patches_resolution = patches_resolution<br><br>        <span class="hljs-keyword">if</span> self.use_abs_pos_embed:<br>            self.absolute_pos_embed = nn.Parameter(<br>                torch.zeros(<span class="hljs-number">1</span>, num_patches, self.embed_dims))<br><br>        self.drop_after_pos = nn.Dropout(p=drop_rate)<br><br>        <span class="hljs-comment"># stochastic depth</span><br>        total_depth = <span class="hljs-built_in">sum</span>(self.depths)<br>        dpr = [<br>            x.item() <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> torch.linspace(<span class="hljs-number">0</span>, drop_path_rate, total_depth)<br>        ]  <span class="hljs-comment"># stochastic depth decay rule</span><br><br>        self.stages = ModuleList()<br>        embed_dims = self.embed_dims<br>        input_resolution = patches_resolution<br>        <span class="hljs-keyword">for</span> i, (depth,<br>                num_heads) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(<span class="hljs-built_in">zip</span>(self.depths, self.num_heads)):<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(stage_cfgs, <span class="hljs-type">Sequence</span>):<br>                stage_cfg = stage_cfgs[i]<br>            <span class="hljs-keyword">else</span>:<br>                stage_cfg = deepcopy(stage_cfgs)<br>            downsample = <span class="hljs-literal">True</span> <span class="hljs-keyword">if</span> i &lt; self.num_layers - <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">False</span><br>            _stage_cfg = {<br>                <span class="hljs-string">'embed_dims'</span>: embed_dims,<br>                <span class="hljs-string">'depth'</span>: depth,<br>                <span class="hljs-string">'num_heads'</span>: num_heads,<br>                <span class="hljs-string">'downsample'</span>: downsample,<br>                <span class="hljs-string">'input_resolution'</span>: input_resolution,<br>                <span class="hljs-string">'drop_paths'</span>: dpr[:depth],<br>                <span class="hljs-string">'auto_pad'</span>: auto_pad,<br>                **stage_cfg<br>            }<br><br>            stage = SwinBlockSequence(**_stage_cfg)<br>            <span class="hljs-comment"># 冻结某几层frozen_stages</span><br>            <span class="hljs-keyword">if</span>(frozen_stages==<span class="hljs-number">0</span> <span class="hljs-keyword">or</span> (i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,frozen_stages))):<br>                stage.<span class="hljs-built_in">eval</span>()<br>                <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> stage.parameters():<br>                    param.requires_grad = <span class="hljs-literal">False</span><br>            <br>            self.stages.append(stage)<br><br>            dpr = dpr[depth:]<br>            <span class="hljs-keyword">if</span> downsample:<br>                embed_dims = stage.downsample.out_channels<br>                input_resolution = stage.downsample.output_resolution<br>            <br><br>        <span class="hljs-keyword">if</span> norm_cfg <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            self.norm = build_norm_layer(norm_cfg, embed_dims)[<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">else</span>:<br>            self.norm = <span class="hljs-literal">None</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">init_weights</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>(SwinTransformer, self).init_weights()<br><br>        <span class="hljs-keyword">if</span> self.use_abs_pos_embed:<br>            trunc_normal_(self.absolute_pos_embed, std=<span class="hljs-number">0.02</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        x = self.patch_embed(x)<br>        <span class="hljs-keyword">if</span> self.use_abs_pos_embed:<br>            x = x + self.absolute_pos_embed<br>        x = self.drop_after_pos(x)<br><br>        <span class="hljs-keyword">for</span> stage <span class="hljs-keyword">in</span> self.stages:<br>            x = stage(x)<br><br>        x = self.norm(x) <span class="hljs-keyword">if</span> self.norm <span class="hljs-keyword">else</span> x<br><br>        <span class="hljs-keyword">return</span> x.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
      <category>网络架构</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>swin</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer40 最小的k个数</title>
    <link href="/2021/08/24/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer40/"/>
    <url>/2021/08/24/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer40/</url>
    
    <content type="html"><![CDATA[<blockquote><p>最小的k个数</p></blockquote><h2 id="题目">题目</h2><p>输入整数数组 arr ，找出其中最小的 k 个数。例如，输入4、5、1、6、2、7、3、8这8个数字，则最小的4个数字是1、2、3、4。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：arr = <span class="hljs-comment">[3,2,1]</span>, k = 2<br>输出：<span class="hljs-comment">[1,2]</span> 或者 <span class="hljs-comment">[2,1]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：arr = <span class="hljs-comment">[0,1,2,1]</span>, k = 1<br>输出：<span class="hljs-comment">[0]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>0 &lt;= k &lt;= arr.length &lt;= 10000</li><li>0 &lt;= arr[i] &lt;= 10000</li></ul><h2 id="题解">题解</h2><p>使用封装的sorted函数，这种方法需要排序O(NlogN)</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getLeastNumbers</span>(<span class="hljs-params">self, arr: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], k: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:</span><br>         <span class="hljs-keyword">return</span> <span class="hljs-built_in">sorted</span>(arr)[<span class="hljs-number">0</span>:k]<br></code></pre></td></tr></tbody></table></figure><p>还有一种方法是采取快速排序的思想，可以将复杂度降到O(N)<br>首先复习一下快速排序的代码。K神的方法是i&lt;j的情况下就进行比对，这种方式要注意j的收缩要在i的扩张之前；这样可以保证最后停止的时候i，j指向都是比较小的那个数值。(最后交换时i,j都可以，因为结束时一定有i和j相等)</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">quicksort</span>(<span class="hljs-params">l,r</span>):</span><br>    <span class="hljs-keyword">if</span> l&gt;=r: <span class="hljs-keyword">return</span><br>    pivot = arr[l]<br>    i,j = l,r<br>    <span class="hljs-keyword">while</span> (i&lt;j):<br>        <span class="hljs-keyword">while</span> i&lt;j <span class="hljs-keyword">and</span> arr[j]&gt;=pivot:j -= <span class="hljs-number">1</span> <span class="hljs-comment">#在i&lt;j的约束下 j在i的移动前面</span><br>        <span class="hljs-keyword">while</span> i&lt;j <span class="hljs-keyword">and</span> arr[i]&lt;=pivot:i += <span class="hljs-number">1</span>         <br>        arr[i],arr[j] = arr[j],arr[i]<br>    arr[l], arr[j] = arr[j], arr[l]<br>    quicksort(l,j-<span class="hljs-number">1</span>)<br>    quicksort(j+<span class="hljs-number">1</span>,r)<br></code></pre></td></tr></tbody></table></figure><p>最后交换的时候只能是j并且一定要保证i和j不可越界，也就是说在i和j到临界值的时候就不用移动了</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">quicksort</span>(<span class="hljs-params">l,r</span>):</span><br>    <span class="hljs-keyword">if</span> l&gt;=r: <span class="hljs-keyword">return</span><br>    pivot = arr[l]<br>    i,j = l,r<br>    <span class="hljs-keyword">while</span> (<span class="hljs-literal">True</span>):<br>        <span class="hljs-keyword">while</span> j&gt;l <span class="hljs-keyword">and</span> arr[j]&gt;=pivot:j -= <span class="hljs-number">1</span> <br>        <span class="hljs-keyword">while</span> i&lt;r <span class="hljs-keyword">and</span> arr[i]&lt;=pivot:i += <span class="hljs-number">1</span>   <br>        <span class="hljs-keyword">if</span>(i&gt;=j):<span class="hljs-keyword">break</span><br>        arr[i],arr[j] = arr[j],arr[i]<br>    arr[l], arr[j] = arr[j], arr[l]<br>    quicksort(l,j-<span class="hljs-number">1</span>)<br>    quicksort(j+<span class="hljs-number">1</span>,r)<br></code></pre></td></tr></tbody></table></figure><p>那么这个题目借用这种思想只要找到这个pivot他原本所在的位置下标为k，那么他的左边的部分就是要找的部分哦~~😉</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getLeastNumbers</span>(<span class="hljs-params">self, arr: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], k: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">quicksort</span>(<span class="hljs-params">l,r</span>):</span><br>            <span class="hljs-keyword">if</span> l&gt;=r: <span class="hljs-keyword">return</span><br>            pivot = arr[l]<br>            i,j = l,r<br>            <span class="hljs-keyword">while</span> (i&lt;j):<br>                <span class="hljs-keyword">while</span> i&lt;j <span class="hljs-keyword">and</span> arr[j]&gt;=pivot:j -= <span class="hljs-number">1</span> <span class="hljs-comment">#在i&lt;j的约束下 j在i的移动前面</span><br>                <span class="hljs-keyword">while</span> i&lt;j <span class="hljs-keyword">and</span> arr[i]&lt;=pivot:i += <span class="hljs-number">1</span>         <br>                arr[i],arr[j] = arr[j],arr[i]<br>            arr[l], arr[j] = arr[j], arr[l]<br>            <span class="hljs-keyword">if</span>(k&gt;j):quicksort(j+<span class="hljs-number">1</span>,r)<br>            <span class="hljs-keyword">if</span>(k&lt;j):quicksort(l,j-<span class="hljs-number">1</span>)            <br>        quicksort(<span class="hljs-number">0</span>,<span class="hljs-built_in">len</span>(arr)-<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> arr[:k]<br></code></pre></td></tr></tbody></table></figure><p>这种方法的复杂度是N+N/2+N/4+N/8+… = N(1/2+1/4+1/8+…) ~ 2N</p>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>快速排序</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>快速排序</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>博客中的emoji</title>
    <link href="/2021/08/24/config/hexo-emoji/"/>
    <url>/2021/08/24/config/hexo-emoji/</url>
    
    <content type="html"><![CDATA[<blockquote><p>在博客中使用emoji，可可爱爱小表情😍</p></blockquote><blockquote><p>相关配置参见这个博客哟 <a href="https://www.zywvvd.com/2021/08/23/hexo/19%20hexo-emoji/hexo-emoji/">Hexo -19- 添加emoji表情</a><br>可以在这两个网站看看有哪些小表情<br><a href="https://www.webfx.com/tools/emoji-cheat-sheet/">https://www.webfx.com/tools/emoji-cheat-sheet/</a><br><a href="https://www.zywvvd.com/2021/08/13/git/git-emoji/git-emoji/">https://www.zywvvd.com/2021/08/13/git/git-emoji/git-emoji/</a></p></blockquote><h2 id="安装渲染器">安装渲染器</h2><figure class="highlight applescript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs applescript">npm un hexo-renderer-marked <span class="hljs-comment">--save</span><br>npm i hexo-renderer-markdown-<span class="hljs-keyword">it</span> <span class="hljs-comment">--save</span><br></code></pre></td></tr></tbody></table></figure><h2 id="修改配置文件">修改配置文件</h2><p>在_config.yml文件尾部添加下段代码</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># Markdown-it config</span><br><span class="hljs-comment">## Docs: https://github.com/celsomiranda/hexo-renderer-markdown-it/wiki</span><br><span class="hljs-attr">markdown:</span><br>  <span class="hljs-attr">render:</span><br>    <span class="hljs-attr">html:</span> <span class="hljs-literal">true</span><br>    <span class="hljs-attr">xhtmlOut:</span> <span class="hljs-literal">false</span><br>    <span class="hljs-attr">breaks:</span> <span class="hljs-literal">true</span><br>    <span class="hljs-attr">linkify:</span> <span class="hljs-literal">true</span><br>    <span class="hljs-attr">typographer:</span> <span class="hljs-literal">true</span><br>    <span class="hljs-attr">quotes:</span> <span class="hljs-string">'“”‘’'</span><br>  <span class="hljs-attr">plugins:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">markdown-it-abbr</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">markdown-it-footnote</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">markdown-it-ins</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">markdown-it-sub</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">markdown-it-sup</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">markdown-it-emoji</span>  <span class="hljs-comment"># add emoji</span><br></code></pre></td></tr></tbody></table></figure><p>使用的时候就直接在md文件中用两个引号中间填写emoji的名称即可啦 :happy:</p>]]></content>
    
    
    <categories>
      
      <category>配置</category>
      
      <category>hexo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>emoji</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>YOLOv1</title>
    <link href="/2021/08/21/deep_learning/yolov1/"/>
    <url>/2021/08/21/deep_learning/yolov1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>YOLO系列是基于深度学习的回归方法。YOLO：you only look once的优点是实时快速目标检测。一直都很想把YOLO系统的学习一下。在此，记录下相关的知识和个人理解。做笔记也算是督促我好好的整理相关内容叭！ok开始！😉</p></blockquote><blockquote><p>参考：<br><a href="https://zhuanlan.zhihu.com/p/136382095">https://zhuanlan.zhihu.com/p/136382095</a><br><a href="https://mp.weixin.qq.com/s/df1JaGtnoEY4FQford4UIw">https://mp.weixin.qq.com/s/df1JaGtnoEY4FQford4UIw</a></p></blockquote><h2 id="YOLO-和-Faster-R-CNN">YOLO 和 Faster R-CNN</h2><p>两个网络的差异有两个方面：</p><ol><li><p>Yolo没有显示求取region proposal的过程，虽然Faster R-CNN中的RPN于Fast R-CNN共享卷积层，但是在模型训练过程中，还是需要反复的训练RPN于Fast R-CNN，也就是说这种方式还是需要”look twice“ ：确定候选框和分类；而Yolo系列只需要”look once“</p><blockquote><p>关于Faster R-CNN的知识后续再填坑…</p></blockquote></li><li><p>Yolo将检测统一为一个回归问题。而R-CNN将检测结果分为两个部分进行求解：分类<code>物体的类别</code> ， 回归<code>物体的bounding  box</code></p></li></ol><h2 id="YOLOv1">YOLOv1</h2><h3 id="综述">综述</h3><p><strong>论文下载：</strong> <a href="http://arxiv.org/abs/1506.02640">http://arxiv.org/abs/1506.02640</a></p><p><strong>代码下载：</strong> <a href="https://github.com/pjreddie/darknet">https://github.com/pjreddie/darknet</a></p><p><strong>核心思想</strong>：将整张图作为网络的输入（与Faster-RCNN类似），直接在输出层对BBox的位置和类别进行回归。</p><h3 id="论文">论文</h3><details><summary> yolov1 论文：You Only Look Once:Unified, Real-Time Object Detection</summary><iframe src="/js/pdfjs_old/web/viewer.html?file=https://paper.mulindya.com/yolov1.pdf" width="100%" height="650"></iframe></details><p>实现方法：</p><p><img src="https://picture.mulindya.com/yolov1-pic1.png" alt=""></p><ul><li><p>首先将一幅图像分成S*S个网格（grid cell）,如果某个物体的中心落在这个网格中，那么这个网格就负责预测这个物体。</p></li><li><p>每个网格需要预测B个边界框(BBox)的位置信息和对应的置信度（confidence）;一个BBox对应四个位置信息和一个confidence信息，confidence表示所预测的Box中含有objext的置信度和box的预测情况。</p><blockquote><p>也就是$conf = Pr(object)\times IOU^{truth}_{pred}$ 如果有object落在其中的grid cell里，那么第一项为1否则取0.</p></blockquote></li></ul><p>每个bounding box要预测(x, y, w, h)和confidence共5个值，每个网格还要预测一个类别信息，记为C类。则SxS个网格，每个网格要预测B个bounding box还要预测C个categories。判断这个落在此网格的物体是c个物体中的哪一个物体。输出就是S x S x (5*B+C)的一个tensor。（<strong>注意：class信息是针对每个网格的，confidence信息是针对每个bounding box的。</strong>）</p><p>举例说明: 在PASCAL VOC中，图像输入为448x448，取S=7，B=2，一共有20个类别(C=20)。则输出就是7x7x30的一个tensor。*其中30也就是2*5+20，整个网络结构如下图所示：</p><p><img src="https://picture.mulindya.com/yolov1-pic2.png" alt=""></p><p>在test的时候，每个网格预测的class信息与BBox得到的confidenci信息相乘，就可以得到每个BBox的class-specific confidence score：</p>$$Pr(Class_i \vert Object) \times Pr(Object) \times IOU^{truth}_{pred} = Pr(Class_i) \times IOU^{truth}_{pred}$$<p>得到每个box的class-specific confidence score之后，设置阈值，过滤掉得分低的boxes，对保留的boxes进行NMS处理，即可得到最终的检测结果。</p><blockquote><p>NMS：non-maximum suppression 非极大抑制，其操作即是从集合中找到得分score最高的候选框，与其他候选框计算IOU，删除重合率高的候选框，因为这些候选框和最高score的框“竞争”同一个物体，但是score又不够高，所以是应该被淘汰的。确定了这个最高score的BBOX之后就可以不考虑他了，再继续找寻最高score的候选框，把与他竞争的候选框给pass掉即可，以此类推。</p></blockquote><h4 id="流程">流程</h4><ol><li>输入一张图像将其分为7*7的网格</li><li>对于每一个网格,预测两个边框；（包括边框的置信度和其对应的类别概率）</li><li>根据预测的7*7*2的目标窗口，首先通过阈值去除可能性地的窗口，再采用NMS去除冗余的窗口。</li></ol><h3 id="损失函数">损失函数</h3><p>最重要的是设计损失函数，作者使用了sum-squared error loss（<a href="https://blog.csdn.net/shengyan5515/article/details/84036734">https://blog.csdn.net/shengyan5515/article/details/84036734</a> ）</p><blockquote><p>关于YOLO的损失函数，采用sum-squared error整合localization error（bboxes的坐标误差）和classification error，其中classification error包括两部分，一部分是没有包含object的box的confidence loss权值，另一部分则是有包含object的box的confidence loss权值</p></blockquote><p><img src="https://picture.mulindya.com/yolov1-pic3.png" alt=""></p><h4 id="问题：">问题：</h4><ul><li>8维的localization error(4*2),和20维的classification error同等重要是不合理的</li><li>如果一个网格中没有object(大部分),将这些网格的box对应confidence设置为0，是比较“暴力”的，会让loss特别大，网络不稳定并且不容易收敛。</li></ul><h4 id="解决方案：">解决方案：</h4><ul><li><p>对于坐标预测赋予更大的权重（重视框的位置）</p></li><li><p>对没有object的confidence loss，赋予小的权重(注意力转移到其他地方)</p></li><li><p>对存在object的box的confidence loss和类别的预测权重正常取1</p></li></ul><blockquote><p>为什么第二项出现了根号呢？</p><p>是因为我们的误差度量量反应出大box的小偏差要小于小box。为了逐步解决这个问题，我们预测了边界框的宽度和高度的平⽅根，而不是直接预测宽度和⾼度。因为根号之后曲线越大越平缓。这样对小的box的偏差相对更加敏感。</p></blockquote><p>观察损失函数可以看出：</p><ul><li><p>只有在网格中存在object的时候才会对classification error进行计算</p></li><li><p>只有当某个网格的box的和对于的ground truth box是负责回归的，才会对这个box 的位置xywh损失进行计算，确定对应ground truth box就需要将这个box与这个网格中的所有bbox计算IOU，最大的那个ground truth是由这个网络负责预测的。</p><p>激活函数使用的是leak relu，模型是使用预训练的Imagenet。</p></li></ul><h3 id="优点">优点</h3><ul><li><p>快速，pipline简单</p></li><li><p>背景误检率低</p></li><li><p>通用性强，对艺术品中的物体也可以检测，对非自然的图像物体的检测率比一般的DOM，R-CNN都要好很多</p></li></ul><h3 id="缺点">缺点</h3><ul><li>由于输出层是全连接层，因此在检测时，YOLO训练模型只能支持与训练图像分辨率相同的图像</li><li>每个格子可以预测B个Bbox，但是最终只能选择IOU最高的BBox作为物体检测结果，也就是说，一个各自只能最多预测出一个物体；当物体比较小或者分布密集的时候也只能检测出一个。</li><li>在loss的求解方程中，大目标和小目标的IOU误差在loss计算上是接近的（即使用了平方根缓解），因此对于小物体的检测准确性不高。</li></ul>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
      <category>目标检测</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>目标检测</tag>
      
      <tag>yolo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer19</title>
    <link href="/2021/08/21/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer19/"/>
    <url>/2021/08/21/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer19/</url>
    
    <content type="html"><![CDATA[<blockquote><p>正则表达式匹配</p></blockquote><h2 id="题目">题目</h2><p>请实现一个函数用来匹配包含’. ‘和’<em>‘的正则表达式。模式中的字符’.‘表示任意一个字符，而’</em>'表示它前面的字符可以出现任意次（含0次）。在本题中，匹配是指字符串的所有字符匹配整个模式。例如，字符串"aaa"与模式"a.a"和"ab<em>ac</em>a"匹配，但与"aa.a"和"ab*a"均不匹配。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入:</span><br>s = <span class="hljs-string">"aa"</span><br>p = <span class="hljs-string">"a"</span><br><span class="hljs-section">输出: false</span><br><span class="hljs-section">解释: "a" 无法匹配 "aa" 整个字符串。</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight smalltalk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs smalltalk">输入:<br>s = <span class="hljs-comment">"aa"</span><br>p = <span class="hljs-comment">"a*"</span><br>输出: <span class="hljs-keyword">true</span><br>解释:&nbsp;因为 <span class="hljs-string">'*'</span> 代表可以匹配零个或多个前面的那一个元素, 在这里前面的元素就是 <span class="hljs-string">'a'</span>。因此，字符串 <span class="hljs-comment">"aa"</span> 可被视为 <span class="hljs-string">'a'</span> 重复了一次。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-3：">示例 3：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入:</span><br>s = <span class="hljs-string">"ab"</span><br>p = <span class="hljs-string">".*"</span><br><span class="hljs-section">输出: true</span><br><span class="hljs-section">解释: ".*" 表示可匹配零个或多个（'*'）任意字符（'.'）。</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-4：">示例 4：</h3><figure class="highlight smalltalk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs smalltalk">输入:<br>s = <span class="hljs-comment">"aab"</span><br>p = <span class="hljs-comment">"c*a*b"</span><br>输出: <span class="hljs-keyword">true</span><br>解释:&nbsp;因为 <span class="hljs-string">'*'</span> 表示零个或多个，这里 <span class="hljs-string">'c'</span> 为 <span class="hljs-number">0</span> 个, <span class="hljs-string">'a'</span> 被重复一次。因此可以匹配字符串 <span class="hljs-comment">"aab"</span>。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-5：">示例 5：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入:</span><br>s = <span class="hljs-string">"mississippi"</span><br>p = <span class="hljs-string">"mis*is*p*."</span><br><span class="hljs-section">输出: false</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><code>s</code> 可能为空，且只包含从 <code>a-z</code> 的小写字母。</li><li><code>p</code> 可能为空，且只包含从 <code>a-z</code> 的小写字母以及字符 <code>.</code> 和 <code>*</code>，无连续的 <code>'*'</code>。</li></ul><h2 id="题解">题解</h2><p>动态规划的核心是建立状态转移方程。dp[i][j]表示前j个模式串匹配s的前i个字母的匹配情况。</p><p>那么就要分情况讨论了，一种是p[j]是<code>字母</code>，第二是<code> .</code> ,第三是 <code>*</code>.</p><ol><li><p><code>字母</code>:直接判断是否一致，如果$p[j]==s[i]$就可以转移 $dp[i][j] = dp[i-1][j-1]$</p></li><li><p><code> .</code> : 可以匹配任意字符直接转移$dp[i][j] = dp[i-1][j-1]$</p></li><li><p><code>*</code>：如果前一个字符$p[j-1]==s[i]$，那么这个<code>*</code>可以选择是匹配s的<strong>一个元素还是多个元素</strong></p><p>$dp[i][j] = dp[i][j-2] \quad or \quad dp[i-1][j]$</p></li></ol><p>如果元素不相等，就直接向前匹配（0次匹配）$dp[i][j-2]$</p><blockquote><p>$dp[i][j-2]$是匹配0个；$dp[i-1][j]$是匹配多个，忽略i元素继续向前查找；$dp[i-1][j-2]$是匹配1个是包含于多个$dp[i-1][j]$中</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">isMatch</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span>, p: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">bool</span>:</span><br>        s = <span class="hljs-string">" "</span>+s<br>        p = <span class="hljs-string">" "</span>+p<br>        dp = [[<span class="hljs-literal">False</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(p))] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(s))]<br>        dp[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] = <span class="hljs-literal">True</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,<span class="hljs-built_in">len</span>(s)):<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(p)):<br>                <span class="hljs-keyword">if</span>(p[j]!=<span class="hljs-string">'*'</span>):<br>                    <span class="hljs-keyword">if</span>((p[j]==<span class="hljs-string">'.'</span> <span class="hljs-keyword">and</span> s[i]!=<span class="hljs-string">" "</span>) <span class="hljs-keyword">or</span> p[j]==s[i]):<br>                        dp[i][j] = dp[i-<span class="hljs-number">1</span>][j-<span class="hljs-number">1</span>]<br>                <span class="hljs-keyword">else</span>:<br>                    <span class="hljs-keyword">if</span>(p[j-<span class="hljs-number">1</span>]==s[i] <span class="hljs-keyword">or</span> (p[j-<span class="hljs-number">1</span>]==<span class="hljs-string">'.'</span> <span class="hljs-keyword">and</span> s[i]!=<span class="hljs-string">" "</span>)): dp[i][j] = dp[i][j-<span class="hljs-number">2</span>] <span class="hljs-keyword">or</span> dp[i-<span class="hljs-number">1</span>][j-<span class="hljs-number">2</span>] <span class="hljs-keyword">or</span> dp[i-<span class="hljs-number">1</span>][j] <br>                    <span class="hljs-comment">#dp[i][j] = dp[i][j-2] or dp[i-1][j] #直接0次或者多次</span><br>                    <span class="hljs-keyword">else</span>:dp[i][j] = dp[i][j-<span class="hljs-number">2</span>]<br>        <span class="hljs-keyword">return</span> dp[<span class="hljs-built_in">len</span>(s)-<span class="hljs-number">1</span>][<span class="hljs-built_in">len</span>(p)-<span class="hljs-number">1</span>]<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>动态规划</category>
      
    </categories>
    
    
    <tags>
      
      <tag>动态规划</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer18 删除链表的节点</title>
    <link href="/2021/08/21/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer18/"/>
    <url>/2021/08/21/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer18/</url>
    
    <content type="html"><![CDATA[<blockquote><p>删除链表的节点</p></blockquote><h2 id="题目">题目</h2><p>给定单向链表的头指针和一个要删除的节点的值，定义一个函数删除该节点。返回删除后的链表的头节点。<br>注意：此题对比原题有改动</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入: head = [4,5,1,9], val = 5</span><br><span class="hljs-section">输出: [4,1,9]</span><br><span class="hljs-section">解释: 给定你链表中值为&nbsp;5&nbsp;的第二个节点，那么在调用了你的函数之后，该链表应变为 4 -&gt; 1 -&gt; 9.</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight makefile"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-section">输入: head = [4,5,1,9], val = 1</span><br><span class="hljs-section">输出: [4,5,9]</span><br><span class="hljs-section">解释: 给定你链表中值为&nbsp;1&nbsp;的第三个节点，那么在调用了你的函数之后，该链表应变为 4 -&gt; 5 -&gt; 9.</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>题目保证链表中节点的值互不相同</li><li>若使用 C 或 C++ 语言，你不需要 free 或 delete 被删除的节点</li></ul><h2 id="题解">题解</h2><p>常规操作</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode:</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.next = None</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">deleteNode</span>(<span class="hljs-params">self, head: ListNode, val: <span class="hljs-built_in">int</span></span>) -&gt; ListNode:</span><br>        p = head<br>        <span class="hljs-keyword">if</span>(head.val==val):<span class="hljs-keyword">return</span> p.<span class="hljs-built_in">next</span><br>        <span class="hljs-keyword">while</span>(p.<span class="hljs-built_in">next</span>):<br>            <span class="hljs-keyword">if</span>(p.<span class="hljs-built_in">next</span>.val == val):<br>                p.<span class="hljs-built_in">next</span> = p.<span class="hljs-built_in">next</span>.<span class="hljs-built_in">next</span><br>                <span class="hljs-keyword">return</span> head<br>            p = p.<span class="hljs-built_in">next</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>链表</category>
      
    </categories>
    
    
    <tags>
      
      <tag>链表</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer24 反转链表</title>
    <link href="/2021/08/21/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer24/"/>
    <url>/2021/08/21/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer24/</url>
    
    <content type="html"><![CDATA[<blockquote><p>反转链表</p></blockquote><h2 id="题目">题目</h2><p>定义一个函数，输入一个链表的头节点，反转该链表并输出反转后链表的头节点。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight clean"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs clean">输入: <span class="hljs-number">1</span>-&gt;<span class="hljs-number">2</span>-&gt;<span class="hljs-number">3</span>-&gt;<span class="hljs-number">4</span>-&gt;<span class="hljs-number">5</span>-&gt;NULL<br>输出: <span class="hljs-number">5</span>-&gt;<span class="hljs-number">4</span>-&gt;<span class="hljs-number">3</span>-&gt;<span class="hljs-number">2</span>-&gt;<span class="hljs-number">1</span>-&gt;NULL<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>0 &lt;= 节点个数 &lt;= 5000</li></ul><h2 id="题解">题解</h2><p>比较常规，遍历链表把元素移动到头节点。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode:</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.next = None</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reverseList</span>(<span class="hljs-params">self, head: ListNode</span>) -&gt; ListNode:</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span>(head):<span class="hljs-keyword">return</span> head<br>        p = head.<span class="hljs-built_in">next</span><br>        head.<span class="hljs-built_in">next</span> = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">while</span>(p):<br>            t = p.<span class="hljs-built_in">next</span><br>            p.<span class="hljs-built_in">next</span> = head<br>            head = p<br>            p = t<br>        <span class="hljs-keyword">return</span> head<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>链表</category>
      
    </categories>
    
    
    <tags>
      
      <tag>链表</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer16  数值的整数次方</title>
    <link href="/2021/08/21/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer16/"/>
    <url>/2021/08/21/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer16/</url>
    
    <content type="html"><![CDATA[<blockquote><p>数值的整数次方</p></blockquote><h2 id="题目">题目</h2><p>实现 pow(x, n) ，即计算 x 的 n 次幂函数（即，xn）。不得使用库函数，同时不需要考虑大数问题。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight dns"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs dns">输入：x = <span class="hljs-number">2.00000</span>, n = <span class="hljs-number">10</span><br>输出：<span class="hljs-number">1024.00000</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight dns"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs dns">输入：x = <span class="hljs-number">2.10000</span>, n = <span class="hljs-number">3</span><br>输出：<span class="hljs-number">9.26100</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>-100.0 &lt; x &lt; 100.0</li><li>$-2^{31}$ &lt;= n &lt;= $2^{31}-1$</li><li>$-10^4$ &lt;= $x^n$ &lt;= $10^4$</li></ul><h2 id="题解">题解</h2><p>一种方法是将x乘以n次，但是这种时间复杂度是O(n)。判题时时间超出限制。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">myPow</span>(<span class="hljs-params">self, x: <span class="hljs-built_in">float</span>, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">float</span>:</span><br>        <span class="hljs-keyword">if</span>(n==<span class="hljs-number">0</span>):<span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>        result=<span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span>(n&lt;<span class="hljs-number">0</span>):<br>            n = -n<br>            x = <span class="hljs-number">1</span>/x<br>        <span class="hljs-keyword">while</span>(n):<br>            result *= x<br>            n -=<span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></tbody></table></figure><p>实际上可以利用x *= x 和对n右移操作可以得到$x,x<sup>2,x</sup>4,x<sup>8,x</sup>{16}…$，而$x<sup>{11}$可以二进制指数表示为$x</sup>{1011}$也就是$x \times x^2 \times x^8$。这样原本需要循环11次就只需要循环4次</p><p>根据提示条件，循环最多不会超过32次。就很棒！</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">myPow</span>(<span class="hljs-params">self, x: <span class="hljs-built_in">float</span>, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">float</span>:</span><br>        <span class="hljs-keyword">if</span>(n==<span class="hljs-number">0</span>):<span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>        result=<span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span>(n&lt;<span class="hljs-number">0</span>):<br>            n = -n<br>            x = <span class="hljs-number">1</span>/x<br>        <span class="hljs-keyword">while</span>(n): <span class="hljs-comment">#时间复杂度大大降低 不超过32次 O(logn)</span><br>            <span class="hljs-keyword">if</span>(n &amp; <span class="hljs-number">1</span>):result *= x <span class="hljs-comment">#看最后一位是否为1</span><br>            x *= x<br>            n = n&gt;&gt;<span class="hljs-number">1</span> <span class="hljs-comment">#n右移 1011-》101</span><br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>快速幂</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>idea</tag>
      
      <tag>快速幂</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer17 打印从1到最大的n位数</title>
    <link href="/2021/08/20/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer17/"/>
    <url>/2021/08/20/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer17/</url>
    
    <content type="html"><![CDATA[<blockquote><p>打印从1到最大的n位数</p></blockquote><h2 id="题目">题目</h2><p>输入数字 n，按顺序打印出从 1 到最大的 n 位十进制数。比如输入 3，则打印出 1、2、3 一直到最大的 3 位数 999。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight dns"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs dns">输入: n = <span class="hljs-number">1</span><br>输出: [<span class="hljs-number">1,2,3,4</span>,<span class="hljs-number">5,6,7,8</span>,<span class="hljs-number">9</span>]<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>用返回一个整数列表来代替打印</li><li>n 为正整数</li></ul><h2 id="题解">题解</h2><p>借用python的类型转换的包容性，直接可以返回列表</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">printNumbers</span>(<span class="hljs-params">self, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:</span><br>        <span class="hljs-keyword">return</span> [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">pow</span>(<span class="hljs-number">10</span>,n))] <span class="hljs-comment">#或者10**n</span><br></code></pre></td></tr></tbody></table></figure><p>实际上，考点是大数越界情况下的打印。<br>解决思路，用字符串的全排列来解决数字的越界情况。基于分治算法的思想，先固定高位，向低位递归，当个位已被固定时，添加数字的字符串。例如当 n = 2时（数字范围 1 - 99 ），固定十位为 0- 9 ，按顺序依次开启递归，固定个位 0 - 9 ，终止递归并添加数字字符串。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">printNumbers</span>(<span class="hljs-params">self, n: <span class="hljs-built_in">int</span></span>) -&gt; [<span class="hljs-built_in">int</span>]:</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dfs</span>(<span class="hljs-params">x</span>):</span><br>            <span class="hljs-keyword">if</span> x == n:<br>                s = <span class="hljs-string">''</span>.join(num[self.start:])<br>                <span class="hljs-keyword">if</span> s != <span class="hljs-string">'0'</span>: res.append(<span class="hljs-built_in">int</span>(s))<br>                <span class="hljs-keyword">if</span> n - self.start == self.nine: self.start -= <span class="hljs-number">1</span><br>                <span class="hljs-keyword">return</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>                <span class="hljs-keyword">if</span> i == <span class="hljs-number">9</span>: self.nine += <span class="hljs-number">1</span><br>                num[x] = <span class="hljs-built_in">str</span>(i)<br>                dfs(x + <span class="hljs-number">1</span>)<br>            self.nine -= <span class="hljs-number">1</span><br>        <br>        num, res = [<span class="hljs-string">'0'</span>] * n, []<br>        self.nine = <span class="hljs-number">0</span><br>        self.start = n - <span class="hljs-number">1</span><br>        dfs(<span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> res<br></code></pre></td></tr></tbody></table></figure><ul><li>字符串左边界定义： 声明变量 start 规定字符串的左边界，以保证添加的数字字符串 num[start:] 中无高位多余的 0 。例如当 n = 2 时, 1 - 9时 start = 1， 10 - 99 时 start = 0。</li><li>左边界 start 变化规律： 观察可知，当输出数字的所有位都是 9 时，则下个数字需要向更高位进 11 ，此时左边界 start 需要减11 （即高位多余的 0 减少一个）。例如当 n = 3（数字范围 1 - 999 ）时，左边界 start 需要减 1 的情况有： “009” 进位至 “010” ， “099” 进位至 “100” 。设数字各位中 9 的数量为 nine ，所有位都为 9 的判断条件可用以下公式表示：n - start = nine统计 nine 的方法： 固定第 x 位时，当 i = 9则执行 nine = nine + 1 ，并在回溯前恢复 nine = nine - 1</li></ul>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>大数</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>大数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>拉普拉斯算子</title>
    <link href="/2021/08/20/img_process/laplace/"/>
    <url>/2021/08/20/img_process/laplace/</url>
    
    <content type="html"><![CDATA[<blockquote><p>​图像锐化处理的作用是使灰度反差增强，从而使模糊图像变得更加清晰。图像模糊的实质就是图像受到平均运算或积分运算，因此可以对图像进行逆运算，如微分运算能够突出图像细节，使图像变得更为清晰。<br>​积分运算的模板可以平滑图像，反过来对应微分运算的模板卷积可以锐化图像。锐化模板系数的取值再中心为正数而周围为负数。或者中心为负数周围为正数。而拉普拉斯算子就是一种常用的线性锐化滤波的方法。</p></blockquote><h2 id="拉普拉斯的背景">拉普拉斯的背景</h2><p>在图像中的边缘区域，像素值会发生“跳跃”，对这些像素求导，在其一阶导数在边缘位置为极值（Sobel算子）：</p><p><img src="https://picture.mulindya.com/laplace-pic1.png" alt="img"></p><p>如果对像素值求二阶导数，会发现边缘处的导数值为0；<strong>但是并不是说二阶导数为0就意味着是边缘</strong>。</p><p><img src="https://picture.mulindya.com/laplace-pic2.png" alt=""></p><h2 id="计算方法">计算方法</h2><h3 id="像素二阶导数">像素二阶导数</h3><p>二阶导数的计算方法：<br>$$<br>\nabla^2f = \frac{\partial^2 f}{\partial x<sup>2}+\frac{\partial</sup>2 f}{\partial y^2}<br>$$<br>分别沿着X和Y方向有二阶偏导数均可借用差分计算：<br>$$<br>\frac{\partial^2 f}{\partial x^2} = f(x+1,y)+f(x-1,y)-2f(x,y)<br>$$</p><p>$$<br>\frac{\partial^2 f}{\partial y^2} = f(x,y+1)+f(x,y-1)-2f(x,y)<br>$$</p><p>那么可以得到<br>$$<br>\nabla^2f = f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)<br>$$</p><h3 id="模板卷积">模板卷积</h3><p>对应的模板卷积即为</p>$$\begin{bmatrix} 0 &amp; 1 &amp; 0\\ 1 &amp; -4 &amp; 1 \\ 0 &amp; 1 &amp; 0 \end{bmatrix} 或者\begin{bmatrix} 0 &amp; -1 &amp; 0 \\ -1 &amp; 4 &amp; -1 \\ 0 &amp; -1 &amp; 0 \end{bmatrix}$$<p>前者是mask中心为负数，后者是mask中心为正数；他们的目的和效果是一致的，只是表现形式稍有不同，前者在卷积后，在边缘的亮处为负数，在边缘暗处为正数。后者相反。</p><p>mask为负数时，在边缘的亮处为负数，在边缘暗处为正数。可以参见下图：</p><p><img src="https://picture.mulindya.com/laplace-pic3.png" alt=""></p><p>上述是考虑中心像素4邻域，类似还有考虑8邻域，此时中心点区8或-8，周围为-1或1。</p>$$\begin{bmatrix} 1 &amp; 1 &amp; 1 \\ 1 &amp; -8 &amp; 1 \\ 1 &amp; 1 &amp; 1 \end{bmatrix} 或者\begin{bmatrix} -1 &amp; -1 &amp; -1 \\ -1 &amp; 8 &amp; -1 \\ -1 &amp; -1 &amp; -1 \end{bmatrix}$$<h2 id="图像锐化">图像锐化</h2><p>锐化处理可选择拉普拉斯算子对原图像进行处理，产生描述灰度突变的图像，再将拉普拉斯图像与原始图像叠加而产生锐化图像。拉普拉斯锐化的基本方法可以由下式表示：<br>$$<br>g(x,y) = \begin{cases} f(x,y) - \nabla^2f(x,y) &amp; \text{mask中心为负数}\f(x,y) + \nabla^2f(x,y) &amp; \text{mask中心为正数} \end{cases}<br>$$</p><p>这种简单的锐化方法既可以产生拉普拉斯锐化处理的效果，同时又能保留背景信息，将原始图像叠加到拉普拉斯变换的处理结果中去，可以使图像中的各灰度值得到保留，使灰度突变处的对比度得到增强，<strong>最终结果是在保留图像背景的前提下，突现出图像中小的细节信息</strong>。</p><p>缺点是没有了边缘的方向信息；双倍加强了噪声的影响。</p><blockquote><p>锐化处理的公式从模板形式容易看出，如果在图像中一个较暗的区域中出现了一个亮点，那么用拉普拉斯运算就会使这个亮点变得更亮。因为图像中的边缘就是那些灰度发生跳变的区域，所以拉普拉斯锐化模板在边缘检测中很有用。一般增强技术对于陡峭的边缘和缓慢变化的边缘很难确定其边缘线的位置。但此算子却可用二次微分正峰和负峰之间的过零点来确定，对孤立点或端点更为敏感，因此特别适用于以<strong>突出图像中的孤立点、孤立线或线端点为目的的场合</strong>。同梯度算子一样，拉普拉斯算子也会增强图像中的噪声，有时用拉普拉斯算子进行边缘检测时，可将图像先进行<strong>平滑处理</strong>。</p></blockquote><h2 id="代码">代码</h2><p>在OpenCV内使用函数cv2.Laplacian()实现Laplacian算子的计算，该函数的语法格式为：</p><figure class="highlight reasonml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">dst = cv2.<span class="hljs-constructor">Laplacian( <span class="hljs-params">src</span>, <span class="hljs-params">ddepth</span>[, <span class="hljs-params">ksize</span>[, <span class="hljs-params">scale</span>[, <span class="hljs-params">delta</span>[, <span class="hljs-params">borderType</span>]]]] )</span><br></code></pre></td></tr></tbody></table></figure><p>式中：<br>● dst代表目标图像。<br>● src代表原始图像。<br>● ddepth代表目标图像的深度。<br>● ksize代表用于计算二阶导数的核尺寸大小。该值必须是正的奇数。<br>● scale代表计算Laplacian值的缩放比例因子，该参数是可选的。默认情况下，该值为1，表示不进行缩放。<br>● delta代表加到目标图像上的可选值，默认为0。<br>● borderType : 用于推断图像外部像素的边界模式，一般是DORDER_DEFAULT,不支持BORDER_WRAP.</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br>img = cv2.imread(<span class="hljs-string">"img.png"</span>,<span class="hljs-number">0</span>)<br>laplacian = cv2.Laplacian(img,cv2.CV_64F)<br>laplacian = cv2.convertScaleABs(laplacian)<br>cv2.imshow(img)<br>cv2.imshow(laplacian)<br></code></pre></td></tr></tbody></table></figure><p>原图<br><img src="https://picture.mulindya.com/laplace-pic4.png" alt=""><br>处理之后<br><img src="https://picture.mulindya.com/laplace-pic5.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>图像处理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>图像处理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer22 链表中倒数第k个节点</title>
    <link href="/2021/08/20/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer22/"/>
    <url>/2021/08/20/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer22/</url>
    
    <content type="html"><![CDATA[<blockquote><p>链表中倒数第k个节点</p></blockquote><h2 id="题目">题目</h2><p>输入一个链表，输出该链表中倒数第k个节点。为了符合大多数人的习惯，本题从1开始计数，即链表的尾节点是倒数第1个节点。</p><p>例如，一个链表有 6 个节点，从头节点开始，它们的值依次是 1、2、3、4、5、6。这个链表的倒数第 3 个节点是值为 4 的节点。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight clean"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs clean">给定一个链表: <span class="hljs-number">1</span>-&gt;<span class="hljs-number">2</span>-&gt;<span class="hljs-number">3</span>-&gt;<span class="hljs-number">4</span>-&gt;<span class="hljs-number">5</span>, 和 k = <span class="hljs-number">2.</span><br>返回链表 <span class="hljs-number">4</span>-&gt;<span class="hljs-number">5.</span><br></code></pre></td></tr></tbody></table></figure><h2 id="题解">题解</h2><p>一种方法是先确定链表的长度，然后再移动对应的结点个数。那么就需要O(2n)</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getKthFromEnd</span>(<span class="hljs-params">self, head: ListNode, k: <span class="hljs-built_in">int</span></span>) -&gt; ListNode:</span><br>        y = x = head<br>        cnt = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">while</span>(x):<br>            cnt += <span class="hljs-number">1</span><br>            x = x.<span class="hljs-built_in">next</span><br>        t = cnt - k<br>        <span class="hljs-keyword">while</span>(t):<br>            y = y.<span class="hljs-built_in">next</span><br>            t -= <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> y<br></code></pre></td></tr></tbody></table></figure><p>使用快慢指针，使得x与y相距k元素，然后x遍历到最后，y就可以得到对应的结果。此时只需要O(n)</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getKthFromEnd</span>(<span class="hljs-params">self, head: ListNode, k: <span class="hljs-built_in">int</span></span>) -&gt; ListNode:</span><br>        y = x = head<br>        <span class="hljs-keyword">while</span>(x):<br>            <span class="hljs-keyword">if</span>(k&lt;=<span class="hljs-number">0</span>):y = y.<span class="hljs-built_in">next</span><br>            x = x.<span class="hljs-built_in">next</span><br>            k -= <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> y<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>链表</category>
      
    </categories>
    
    
    <tags>
      
      <tag>链表</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>外刊阅读--Self-awareness</title>
    <link href="/2021/08/19/english/self-aware/"/>
    <url>/2021/08/19/english/self-aware/</url>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://paper.mulindya.com/Self-awareness.pdf">https://paper.mulindya.com/Self-awareness.pdf</a></p></blockquote><iframe src="/js/pdfjs_old/web/viewer.html?file=https://paper.mulindya.com/Self-awareness.pdf" width="100%" height="600"></iframe>]]></content>
    
    
    <categories>
      
      <category>英语</category>
      
    </categories>
    
    
    <tags>
      
      <tag>英语</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer29 顺时针打印矩阵</title>
    <link href="/2021/08/19/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer29/"/>
    <url>/2021/08/19/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer29/</url>
    
    <content type="html"><![CDATA[<blockquote><p>顺时针打印矩阵</p></blockquote><h2 id="题目">题目</h2><p>输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：matrix = <span class="hljs-comment">[<span class="hljs-comment">[1,2,3]</span>,<span class="hljs-comment">[4,5,6]</span>,<span class="hljs-comment">[7,8,9]</span>]</span><br>输出：<span class="hljs-comment">[1,2,3,6,9,8,7,4,5]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight dns"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs dns">输入：matrix = [[<span class="hljs-number">1,2,3,4</span>],[<span class="hljs-number">5,6,7,8</span>],[<span class="hljs-number">9,10,11,12</span>]]<br>输出：[<span class="hljs-number">1,2,3,4</span>,<span class="hljs-number">8,12,11,10</span>,<span class="hljs-number">9,5,6,7</span>]<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><code>0 &lt;= matrix.length &lt;= 100</code></li><li><code>0 &lt;= matrix[i].length &lt;= 100</code></li></ul><h2 id="题解">题解</h2><p>一种是对数组进行常规操作，安装题目要求进行遍历判断。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">spiralOrder</span>(<span class="hljs-params">self, matrix: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> matrix: <span class="hljs-keyword">return</span> []<br>        l, r, t, b, res = <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(matrix[<span class="hljs-number">0</span>]) - <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(matrix) - <span class="hljs-number">1</span>, []<br>        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(l, r + <span class="hljs-number">1</span>): res.append(matrix[t][i]) <span class="hljs-comment"># left to right</span><br>            t += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> t &gt; b: <span class="hljs-keyword">break</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(t, b + <span class="hljs-number">1</span>): res.append(matrix[i][r]) <span class="hljs-comment"># top to bottom</span><br>            r -= <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> l &gt; r: <span class="hljs-keyword">break</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(r, l - <span class="hljs-number">1</span>, -<span class="hljs-number">1</span>): res.append(matrix[b][i]) <span class="hljs-comment"># right to left</span><br>            b -= <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> t &gt; b: <span class="hljs-keyword">break</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(b, t - <span class="hljs-number">1</span>, -<span class="hljs-number">1</span>): res.append(matrix[i][l]) <span class="hljs-comment"># bottom to top</span><br>            l += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> l &gt; r: <span class="hljs-keyword">break</span><br>        <span class="hljs-keyword">return</span> res<br><br></code></pre></td></tr></tbody></table></figure><p>第二种是采用相关的方法，<code>pop(0)</code>可以弹出第一个元素。使用$zip(<em>)$相当于对矩阵转置。<code>list(zip(*matrix))[::-1]</code>就是对矩阵逆旋转90度。zip和zip(</em>)也是一对逆操作；前者表示压缩，后者表示解压。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">spiralOrder</span>(<span class="hljs-params">self, matrix: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:</span><br>        res = []<br>        <span class="hljs-keyword">while</span> matrix:<br>            res += matrix.pop(<span class="hljs-number">0</span>)<br>            matrix = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">zip</span>(*matrix))[::-<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">return</span> res<br></code></pre></td></tr></tbody></table></figure><blockquote><p>pop &amp; zip知识参考</p><p><a href="https://blog.csdn.net/zhanshen112/article/details/90341177">https://blog.csdn.net/zhanshen112/article/details/90341177</a></p><p><a href="https://www.cnblogs.com/Aurora-Twinkle/p/8660778.html">https://www.cnblogs.com/Aurora-Twinkle/p/8660778.html</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>数组</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>数组</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer15 二进制中1的个数</title>
    <link href="/2021/08/19/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer15/"/>
    <url>/2021/08/19/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer15/</url>
    
    <content type="html"><![CDATA[<blockquote><p>二进制中1的个数</p></blockquote><h2 id="题目">题目</h2><p>编写一个函数，输入是一个无符号整数（以二进制串的形式），返回其二进制表达式中数字位数为 ‘1’ 的个数（也被称为 汉明重量).）。<br>提示：</p><ul><li>请注意，在某些语言（如 Java）中，没有无符号整数类型。在这种情况下，输入和输出都将被指定为有符号整数类型，并且不应影响您的实现，因为无论整数是有符号的还是无符号的，其内部的二进制表示形式都是相同的。</li><li>在 Java 中，编译器使用 二进制补码 记法来表示有符号整数。因此，在上面的&nbsp;示例 3&nbsp;中，输入表示有符号整数 -3。</li></ul><h3 id="示例-1：">示例 1：</h3><figure class="highlight 1c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs 1c">输入：n = <span class="hljs-number">11</span> (控制台输入 <span class="hljs-number">00000000000000000000000000001011</span>)<br>输出：<span class="hljs-number">3</span><br>解释：输入的二进制串 <span class="hljs-number">00000000000000000000000000001011</span>&nbsp;中，共有三位为 '1'。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight 1c"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs 1c">输入：n = <span class="hljs-number">128</span> (控制台输入 <span class="hljs-number">00000000000000000000000010000000</span>)<br>输出：<span class="hljs-number">1</span><br>解释：输入的二进制串 <span class="hljs-number">00000000000000000000000010000000</span>&nbsp;中，共有一位为 '1'。<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-3：">示例 3：</h3><figure class="highlight tap"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs tap">输入：n =<span class="hljs-number"> 4294967293 </span>(控制台输入 11111111111111111111111111111101，部分语言中 n = -3）<br>输出：31<br>解释：输入的二进制串<span class="hljs-number"> 11111111111111111111111111111101 </span>中，共有<span class="hljs-number"> 31 </span>位为 '1'。<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>输入必须是长度为 32 的 二进制串 。</li></ul><h2 id="题解">题解</h2><p>第一种方式是采用内置的bin函数，将n转化为二进制格式。然后统计其字符串的1的个数。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hammingWeight</span>(<span class="hljs-params">self, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        s = <span class="hljs-built_in">str</span>(<span class="hljs-built_in">bin</span>(n))<br>        cnt = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> s:<br>            <span class="hljs-keyword">if</span>(x==<span class="hljs-string">'1'</span>):<br>                cnt+=<span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> cnt<br></code></pre></td></tr></tbody></table></figure><p>第二种方法是采用移位操作<code>&lt;&lt;</code>和按位与<code>&amp;</code>对输入的数字进行统计。如：11 &amp; 8 = 8（1011 &amp; 100 = 100）</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hammingWeight</span>(<span class="hljs-params">self, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>       cnt = <span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">32</span>) <span class="hljs-keyword">if</span>(n &amp; (<span class="hljs-number">1</span> &lt;&lt; i)))<br>       <span class="hljs-keyword">return</span> cnt<br></code></pre></td></tr></tbody></table></figure><p><font color="hotpink">下面这个就很妙了</font></p><p>第三种方法 利用 <code>n &amp;（n-1）</code></p><p>(n−1) 解析： 二进制数字 n 最右边的 1 变成 0 ，此 1 右边的 0 都变成 1。<br>n &amp; (n - 1) 解析： 二进制数字 n 最右边的 1变成 0，其余不变。<br>利用此特性每次循环可以消去一个1</p><p><img src="https://picture.mulindya.com/leetcode-offer15pic1.png" alt=""></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hammingWeight</span>(<span class="hljs-params">self, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        res = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">while</span> n:<br>            res += <span class="hljs-number">1</span><br>            n &amp;= n - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> res<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>变量</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>变量</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer20 表示数值的字符串</title>
    <link href="/2021/08/19/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer20/"/>
    <url>/2021/08/19/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer20/</url>
    
    <content type="html"><![CDATA[<blockquote><p>表示数值的字符串</p></blockquote><h2 id="题目">题目</h2><p>请实现一个函数用来判断字符串是否表示数值（包括整数和小数）。</p><p><strong>数值</strong>（按顺序）可以分成以下几个部分：</p><ol><li>若干空格</li><li>一个&nbsp;小数&nbsp;或者&nbsp;整数</li><li>（可选）一个&nbsp;‘e’&nbsp;或&nbsp;‘E’&nbsp;，后面跟着一个&nbsp;整数</li><li>若干空格</li></ol><p><strong>小数</strong>（按顺序）可以分成以下几个部分：</p><ol><li><p>（可选）一个符号字符（‘+’ 或 ‘-’）</p></li><li><p>下述格式之一：</p><ol><li>至少一位数字，后面跟着一个点 ‘.’</li><li>至少一位数字，后面跟着一个点 ‘.’ ，后面再跟着至少一位数字</li><li>一个点 ‘.’ ，后面跟着至少一位数字</li></ol></li></ol><p><strong>整数</strong>（按顺序）可以分成以下几个部分：</p><ol><li>（可选）一个符号字符（‘+’ 或 ‘-’）</li><li>至少一位数字</li></ol><p>部分<strong>数值</strong>列举如下：</p><ul><li>[“+100”, “5e2”, “-123”, “3.1416”, “-1E-16”, “0123”]</li></ul><p>部分非数值列举如下：</p><ul><li>[“12e”, “1a3.14”, “1.2.3”, “±5”, “12e+5.4”]</li></ul><h3 id="示例-1：">示例 1：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">s</span> = <span class="hljs-string">"0"</span><br>输出：<span class="hljs-literal">true</span><br><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">s</span> = <span class="hljs-string">"e"</span><br>输出：<span class="hljs-literal">false</span><br><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-3：">示例 3：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">s</span> = <span class="hljs-string">"."</span><br>输出：<span class="hljs-literal">false</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-4：">示例 4：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">s</span> = <span class="hljs-string">"    .1  "</span><br>输出：<span class="hljs-literal">true</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= s.length &lt;= 20</li><li>s 仅含英文字母（大写和小写），数字（0-9），加号 ‘+’ ，减号 ‘-’ ，空格 ’ ’ 或者点 ‘.’ 。</li></ul><h2 id="题解">题解</h2><h3 id="解题思路">解题思路</h3><p>本题解决方案是有限状态自动机。根据字符类型和合法数值的特点，定义状态，再画出状态转移图。</p><h4 id="字符类型">字符类型</h4><p>空格:’ ‘，数字:d，正负号:s，小数点:’.'，幂符号：e</p><h4 id="状态定义">状态定义</h4><p>从左到右可以定义为</p><p>0.左边的<code>空格</code></p><ol><li>E之前的<code>正负号</code></li><li>小数点前的<code>数字</code></li><li>小数点，小数点之后的<code>数字</code></li><li>小数点前为空格，<code>小数点</code>，小数点后为数字</li><li><code>幂符号</code></li><li>幂符号之后的<code>正负号</code></li><li>幂符号之后的<code>数字</code></li><li>结尾的<code>空格</code></li></ol><p><img src="https://picture.mulindya.com/leetcode-offer20-pic1.png" alt=""></p><h4 id="结束状态">结束状态</h4><p>正常的结束状态有2，3，7，8</p><h3 id="算法流程">算法流程</h3><h4 id="初始化">初始化</h4><h5 id="1，状态转移表status">1，状态转移表status</h5><p>$states[i]$表示所处的状态，$i$为所处的状态表示，$states[i]$使用哈希表存储从i状态到可转移的状态；使用键值对来表示$(key,value)$：若输入$key$，可从状态$i$转移至状态$value$.</p><p>当前状态p：初始状态为0</p><h5 id="2，转移循环">2，转移循环</h5><p>还需要<strong>记录字符类型</strong>t，遍历字符串的每个字符c</p><ul><li>当 c 为正负号时，执行 t = ‘s’ ;</li><li>当 c 为数字时，执行 t = ‘d’ ;</li><li>当 c 为 e , E 时，执行 t = ‘e’ ;</li><li>当 c 为 . , 空格 时，执行 t = c （即用字符本身表示字符类型）;</li><li>否则，执行 t = ‘?’ ，代表为不属于判断范围的非法字符，后续直接返回 false。</li></ul><p><strong>终止条件</strong>： 若字符类型 t不在哈希表  $states[p]$ 中，说明无法转移至下一状态，因此直接返回 False 。<br><strong>状态转移</strong>： 状态 p 转移至 $states[p][t]$。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">isNumber</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">bool</span>:</span><br>        states = [<br>            { <span class="hljs-string">' '</span>: <span class="hljs-number">0</span>, <span class="hljs-string">'s'</span>: <span class="hljs-number">1</span>, <span class="hljs-string">'d'</span>: <span class="hljs-number">2</span>, <span class="hljs-string">'.'</span>: <span class="hljs-number">4</span> }, <span class="hljs-comment"># 0. start with 'blank'</span><br>            { <span class="hljs-string">'d'</span>: <span class="hljs-number">2</span>, <span class="hljs-string">'.'</span>: <span class="hljs-number">4</span> } ,                <span class="hljs-comment"># 1. 'sign' before 'e'</span><br>            { <span class="hljs-string">'d'</span>: <span class="hljs-number">2</span>, <span class="hljs-string">'.'</span>: <span class="hljs-number">3</span>, <span class="hljs-string">'e'</span>: <span class="hljs-number">5</span>, <span class="hljs-string">' '</span>: <span class="hljs-number">8</span> }, <span class="hljs-comment"># 2. 'digit' before 'dot'</span><br>            { <span class="hljs-string">'d'</span>: <span class="hljs-number">3</span>, <span class="hljs-string">'e'</span>: <span class="hljs-number">5</span>, <span class="hljs-string">' '</span>: <span class="hljs-number">8</span> },         <span class="hljs-comment"># 3. 'digit' after 'dot'</span><br>            { <span class="hljs-string">'d'</span>: <span class="hljs-number">3</span> },                         <span class="hljs-comment"># 4. 'digit' after 'dot' (‘blank’ before 'dot')</span><br>            { <span class="hljs-string">'s'</span>: <span class="hljs-number">6</span>, <span class="hljs-string">'d'</span>: <span class="hljs-number">7</span> },                 <span class="hljs-comment"># 5. 'e'</span><br>            { <span class="hljs-string">'d'</span>: <span class="hljs-number">7</span> },                         <span class="hljs-comment"># 6. 'sign' after 'e'</span><br>            { <span class="hljs-string">'d'</span>: <span class="hljs-number">7</span>, <span class="hljs-string">' '</span>: <span class="hljs-number">8</span> },                 <span class="hljs-comment"># 7. 'digit' after 'e'</span><br>            { <span class="hljs-string">' '</span>: <span class="hljs-number">8</span> }                          <span class="hljs-comment"># 8. end with 'blank'</span><br>        ]<br>        p = <span class="hljs-number">0</span>                           <span class="hljs-comment"># start with state 0</span><br>        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> s:<br>            <span class="hljs-keyword">if</span> <span class="hljs-string">'0'</span> &lt;= c &lt;= <span class="hljs-string">'9'</span>: t = <span class="hljs-string">'d'</span> <span class="hljs-comment"># digit</span><br>            <span class="hljs-keyword">elif</span> c <span class="hljs-keyword">in</span> <span class="hljs-string">"+-"</span>: t = <span class="hljs-string">'s'</span>     <span class="hljs-comment"># sign</span><br>            <span class="hljs-keyword">elif</span> c <span class="hljs-keyword">in</span> <span class="hljs-string">"eE"</span>: t = <span class="hljs-string">'e'</span>     <span class="hljs-comment"># e or E</span><br>            <span class="hljs-keyword">elif</span> c <span class="hljs-keyword">in</span> <span class="hljs-string">". "</span>: t = c       <span class="hljs-comment"># dot, blank</span><br>            <span class="hljs-keyword">else</span>: t = <span class="hljs-string">'?'</span>               <span class="hljs-comment"># unknown</span><br>            <span class="hljs-keyword">if</span> t <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> states[p]: <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>            p = states[p][t]<br>        <span class="hljs-keyword">return</span> p <span class="hljs-keyword">in</span> (<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>)<br><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>有限状态机</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>idea</tag>
      
      <tag>有限状态机</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer21 调整数组顺序使奇数位于偶数前面</title>
    <link href="/2021/08/18/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer21/"/>
    <url>/2021/08/18/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer21/</url>
    
    <content type="html"><![CDATA[<blockquote><p>调整数组顺序使奇数位于偶数前面</p></blockquote><h2 id="题目">题目</h2><p>输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有奇数位于数组的前半部分，所有偶数位于数组的后半部分。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight dns"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs dns">输入：nums = [<span class="hljs-number">1,2,3,4</span>]<br>输出：[<span class="hljs-number">1,3,2,4</span>] <br>注：[<span class="hljs-number">3,1,2,4</span>] 也是正确的答案之一。<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>0 &lt;= nums.length &lt;= 50000</li><li>1 &lt;= nums[i] &lt;= 10000</li></ul><h2 id="题解">题解</h2><p>python的list的常规操作。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">exchange</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:</span><br>        odd = []<br>        even = []<br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> nums:<br>            <span class="hljs-keyword">if</span>(x%<span class="hljs-number">2</span>):<br>                odd.append(x)<br>            <span class="hljs-keyword">else</span>:<br>                even.append(x)<br>        <span class="hljs-keyword">return</span> odd+even<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>数组</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>数组</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer28 对称的二叉树</title>
    <link href="/2021/08/18/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer28/"/>
    <url>/2021/08/18/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer28/</url>
    
    <content type="html"><![CDATA[<blockquote><p>对称的二叉树</p></blockquote><h2 id="题目">题目</h2><p>请实现一个函数，用来判断一棵二叉树是不是对称的。如果一棵二叉树和它的镜像一样，那么它是对称的。</p><p>例如，二叉树&nbsp;[1,2,2,3,4,4,3] 是对称的。</p><p>1<br>&nbsp; &nbsp;/ <br>&nbsp; 2 &nbsp; 2<br>&nbsp;/ \ / <br>3 &nbsp;4 4 &nbsp;3<br>但是下面这个&nbsp;[1,2,2,null,3,null,3] 则不是镜像对称的:</p><p>1<br>&nbsp; &nbsp;/ <br>&nbsp; 2 &nbsp; 2<br>&nbsp; &nbsp;\ &nbsp; <br>&nbsp; &nbsp;3 &nbsp; &nbsp;3</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">root</span> = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">4</span>,<span class="hljs-number">3</span>]<br>输出：<span class="hljs-literal">true</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">root</span> = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">3</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">3</span>]<br>输出：<span class="hljs-literal">false</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>0 &lt;= 节点个数 &lt;= 1000</li></ul><h2 id="题解">题解</h2><p>如果root为空就直接返回True，然后判断其左右子树是否为镜像结构。如果两个子节点为空则为真，如果一空则为假，然后分别判断其对称结构。 <code>judge(A.left,B.right) and judge(A.right,B.left)</code> 注意是镜像因此左右时相反的呢</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for a binary tree node.</span><br><span class="hljs-comment"># class TreeNode:</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.left = None</span><br><span class="hljs-comment">#         self.right = None</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">isSymmetric</span>(<span class="hljs-params">self, root: TreeNode</span>) -&gt; <span class="hljs-built_in">bool</span>:</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root: <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">judge</span>(<span class="hljs-params">A,B</span>):</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> (A <span class="hljs-keyword">or</span> B): <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> (A <span class="hljs-keyword">and</span> B) <span class="hljs-keyword">or</span> (A.val!=B.val): <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>            <span class="hljs-keyword">return</span> judge(A.left,B.right) <span class="hljs-keyword">and</span> judge(A.right,B.left) <br>        <span class="hljs-keyword">return</span> judge(root.left,root.right)<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>树</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer26 树的子结构</title>
    <link href="/2021/08/18/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer26/"/>
    <url>/2021/08/18/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer26/</url>
    
    <content type="html"><![CDATA[<blockquote><p>树的子结构</p></blockquote><h2 id="题目">题目</h2><p>输入两棵二叉树A和B，判断B是不是A的子结构。(约定空树不是任意一个树的子结构)<br>B是A的子结构， 即 A中有出现和B相同的结构和节点值。</p><p>例如:<br>给定的树 A:</p><p>3<br>&nbsp; &nbsp; / <br>&nbsp; &nbsp;4 &nbsp; 5<br>&nbsp; / <br>&nbsp;1 &nbsp; 2<br>给定的树 B：</p><p>4&nbsp;<br>&nbsp; /<br>&nbsp;1<br>返回 true，因为 B 与 A 的一个子树拥有相同的结构和节点值。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">A</span> = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>], <span class="hljs-attr">B</span> = [<span class="hljs-number">3</span>,<span class="hljs-number">1</span>]<br>输出：<span class="hljs-literal">false</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">A</span> = [<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>], <span class="hljs-attr">B</span> = [<span class="hljs-number">4</span>,<span class="hljs-number">1</span>]<br>输出：<span class="hljs-literal">true</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>0 &lt;= 节点个数 &lt;= 10000</li></ul><h2 id="题解">题解</h2><p>python代码真的！好！简洁！</p><p><code>isSubStructure</code>的作用是先序查找A，B的匹配情况。而在内部会对匹配的<code>judgechildren(A,B)</code>进行判断，查看是否为其子结构。</p><p>如果B为空了则表示匹配成功。如果根节点不匹配或者A为空了就直接返回失败。如果可以继续判断，就继续判断对应的左右子树。</p><p><code>(judgechildren(A,B) or self.isSubStructure(A.left,B) or self.isSubStructure(A.right,B))</code> 判断AB两子树；先序判断左右子树，<code>注意这里是self.isSubStructure</code>进行递归哦~~</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for a binary tree node.</span><br><span class="hljs-comment"># class TreeNode:</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.left = None</span><br><span class="hljs-comment">#         self.right = None</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">isSubStructure</span>(<span class="hljs-params">self, A: TreeNode, B: TreeNode</span>) -&gt; <span class="hljs-built_in">bool</span>:</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">judgechildren</span>(<span class="hljs-params">A,B</span>):</span> <span class="hljs-comment">#判断以AB为根节点的条件下，B是否为A的子结构</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span>(B): <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>            <span class="hljs-keyword">if</span> (<span class="hljs-keyword">not</span> A) <span class="hljs-keyword">or</span> (A.val!=B.val): <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>            <span class="hljs-keyword">return</span> judgechildren(A.right,B.right) <span class="hljs-keyword">and</span> judgechildren(A.left,B.left)<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">bool</span>(A <span class="hljs-keyword">and</span> B) <span class="hljs-keyword">and</span> (judgechildren(A,B) <span class="hljs-keyword">or</span> self.isSubStructure(A.left,B) <span class="hljs-keyword">or</span> self.isSubStructure(A.right,B))<br></code></pre></td></tr></tbody></table></figure><blockquote><p>bool(A and B)注意要转换为bool变量</p></blockquote><ul><li><p>时间复杂度为O(MN)</p></li><li><p>空间复杂度 O(M)： 当树 A和树 B 都退化为链表时，递归调用深度最大。当 M≤N 时，遍历树 A 与递归判断的总递归深度为 M ；当 M&gt;N 时，最差情况为遍历至树 A叶子节点，此时总递归深度为 M。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>树</tag>
      
      <tag>剑指</tag>
      
      <tag>idea</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer14.2 剪绳子2</title>
    <link href="/2021/08/18/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer14-2/"/>
    <url>/2021/08/18/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer14-2/</url>
    
    <content type="html"><![CDATA[<blockquote><p>剪绳子2</p></blockquote><h2 id="题目">题目</h2><p>给你一根长度为 n 的绳子，请把绳子剪成整数长度的 m 段（m、n都是整数，n&gt;1并且m&gt;1），每段绳子的长度记为 k[0],k[1]…k[m - 1] .请问 k[0]<em>k[1]</em>…*k[m - 1] 可能的最大乘积是多少？例如，当绳子的长度是8时，我们把它剪成长度分别为2、3、3的三段，此时得到的最大乘积是18。</p><p>答案需要取模 1e9+7（1000000007），如计算初始结果为：1000000008，请返回 1。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight tap"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs tap">输入: 2<br>输出: 1<br>解释:<span class="hljs-number"> 2 </span>=<span class="hljs-number"> 1 </span>+ 1,<span class="hljs-number"> 1 </span>×<span class="hljs-number"> 1 </span>= 1<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight tap"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs tap">输入: 10<br>输出: 36<br>解释:<span class="hljs-number"> 10 </span>=<span class="hljs-number"> 3 </span>+<span class="hljs-number"> 3 </span>+ 4,<span class="hljs-number"> 3 </span>×<span class="hljs-number"> 3 </span>×<span class="hljs-number"> 4 </span>= 36<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><code>2 &lt;= n &lt;= 1000</code></li></ul><h2 id="题解">题解</h2><p>使用动态规划具体参照剪绳子1</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">cuttingRope</span>(<span class="hljs-params">self, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        dp = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n+<span class="hljs-number">1</span>)]<br>        dp[<span class="hljs-number">2</span>] = <span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>,n+<span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>,i):<br>                dp[i] = <span class="hljs-built_in">max</span>(dp[i],<span class="hljs-built_in">max</span>(j*(i-j),j*dp[i-j]))<br>        <span class="hljs-keyword">return</span> dp[n]%<span class="hljs-number">1000000007</span><br></code></pre></td></tr></tbody></table></figure><p>但是这种方式时间复杂度较大。</p><p>步骤如下：(数学可以证明尽量分成多的3)<a href="https://leetcode-cn.com/problems/jian-sheng-zi-lcof/solution/mian-shi-ti-14-i-jian-sheng-zi-tan-xin-si-xiang-by/">参见题解</a></p><ul><li>如果 n == 2，返回1，如果 n == 3，返回2，两个可以合并成n小于4的时候返回n - 1</li><li>如果 n == 4，返回4</li><li>如果 n &gt; 4，分成尽可能多的长度为3的小段，每次循环长度n减去3，乘积res乘以3；最后返回时乘以小于等于4的最后一小段；每次乘法操作后记得取余就行<br>以上2和3可以合并</li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">cuttingRope</span>(<span class="hljs-params">self, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-keyword">if</span> n &lt; <span class="hljs-number">4</span>:<br>            <span class="hljs-keyword">return</span> n - <span class="hljs-number">1</span><br>        res = <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> n &gt; <span class="hljs-number">4</span>: <span class="hljs-comment"># 找寻尽量多的3</span><br>            res = res * <span class="hljs-number">3</span> % <span class="hljs-number">1000000007</span><br>            n -= <span class="hljs-number">3</span><br>        <span class="hljs-keyword">return</span> res * n % <span class="hljs-number">1000000007</span> <span class="hljs-comment">#乘以剩余的</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>动态规划</category>
      
    </categories>
    
    
    <tags>
      
      <tag>动态规划</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer14.1 剪绳子1</title>
    <link href="/2021/08/17/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer14-1/"/>
    <url>/2021/08/17/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer14-1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>剪绳子</p></blockquote><h2 id="题目">题目</h2><p>给你一根长度为 n 的绳子，请把绳子剪成整数长度的 m 段（m、n都是整数，n&gt;1并且m&gt;1），每段绳子的长度记为 k[0],k[1]…k[m-1] 。请问 k[0]<em>k[1]</em>…*k[m-1] 可能的最大乘积是多少？例如，当绳子的长度是8时，我们把它剪成长度分别为2、3、3的三段，此时得到的最大乘积是18。</p><h4 id="示例-1：">示例 1：</h4><figure class="highlight tap"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs tap">输入: 2<br>输出: 1<br>解释:<span class="hljs-number"> 2 </span>=<span class="hljs-number"> 1 </span>+ 1,<span class="hljs-number"> 1 </span>×<span class="hljs-number"> 1 </span>= 1<br></code></pre></td></tr></tbody></table></figure><h4 id="示例-2：">示例 2：</h4><figure class="highlight tap"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs tap">输入: 10<br>输出: 36<br>解释:<span class="hljs-number"> 10 </span>=<span class="hljs-number"> 3 </span>+<span class="hljs-number"> 3 </span>+ 4,<span class="hljs-number"> 3 </span>×<span class="hljs-number"> 3 </span>×<span class="hljs-number"> 4 </span>= 36<br></code></pre></td></tr></tbody></table></figure><h5 id="提示：">提示：</h5><ul><li><code>2 &lt;= n &lt;= 58</code></li></ul><h4 id="题解">题解</h4><p>该题采用动态规划比较好理解，dp[i]表示长度为i的绳子分成m的最大乘积。j表示第一段的长度，遍历j的取值（可以直接从2开始），在剩余的i-j（<strong>缩小范围</strong>）的长度选择不切分或者最大乘积，即dp[i][j] = max(j*(i-j),j*dp[i-j])。<strong>但是实际上“【j】”并不关心</strong>，因此可以与dp[i]比较,选择最大的更新dp[i]即可。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">cuttingRope</span>(<span class="hljs-params">self, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        dp = [<span class="hljs-number">1</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n+<span class="hljs-number">1</span>)]  <span class="hljs-comment"># 表示长度为n的绳子得到的最大乘积</span><br>        dp[<span class="hljs-number">2</span>] = <span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>,n+<span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>,i): <span class="hljs-comment"># 第一段</span><br>                dp[i] = <span class="hljs-built_in">max</span>(dp[i],<span class="hljs-built_in">max</span>(j*(i-j),j*dp[i-j])) <br>                <span class="hljs-comment">#向前获取信息，在选定j之后，注意还要比较dp[i]本身，以及在第一段j的基础上剩下的是否切</span><br>        <span class="hljs-keyword">return</span> dp[n]<br><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>动态规划</category>
      
    </categories>
    
    
    <tags>
      
      <tag>动态规划</tag>
      
      <tag>剑指</tag>
      
      <tag>idea</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer07 重建二叉树</title>
    <link href="/2021/08/17/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer07/"/>
    <url>/2021/08/17/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer07/</url>
    
    <content type="html"><![CDATA[<blockquote><p>重建二叉树</p></blockquote><h2 id="题目">题目</h2><p>输入某二叉树的前序遍历和中序遍历的结果，请构建该二叉树并返回其根节点。</p><p>假设输入的前序遍历和中序遍历的结果中都不含重复的数字。</p><h3 id="示例-1：">示例 1：</h3><p><img src="https://picture.mulindya.com/leetcode-offer07-tree.jpg" alt="img"></p><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">Input: <span class="hljs-attr">preorder</span> = [<span class="hljs-number">3</span>,<span class="hljs-number">9</span>,<span class="hljs-number">20</span>,<span class="hljs-number">15</span>,<span class="hljs-number">7</span>], <span class="hljs-attr">inorder</span> = [<span class="hljs-number">9</span>,<span class="hljs-number">3</span>,<span class="hljs-number">15</span>,<span class="hljs-number">20</span>,<span class="hljs-number">7</span>]<br>Output: [<span class="hljs-number">3</span>,<span class="hljs-number">9</span>,<span class="hljs-number">20</span>,<span class="hljs-literal">null</span>,<span class="hljs-literal">null</span>,<span class="hljs-number">15</span>,<span class="hljs-number">7</span>]<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">Input: preorder = <span class="hljs-comment">[-1]</span>, inorder = <span class="hljs-comment">[-1]</span><br>Output: <span class="hljs-comment">[-1]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>0 &lt;= 节点个数 &lt;= 5000</li></ul><h2 id="题解">题解</h2><p>使用闭包函数，构建对应区域的树，返回根节点。关键步骤是查找到rootindex在中序遍历中的位置，然后分别构建对应的子树。在查找时可以先建立哈希表，使用字典和枚举结合构建flag <code>flag = {ele:i for i,ele in enumerate(inorder)}</code>。可以减少执行时间的开销。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for a binary tree node.</span><br><span class="hljs-comment"># class TreeNode:</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.left = None</span><br><span class="hljs-comment">#         self.right = None</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">buildTree</span>(<span class="hljs-params">self, preorder: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], inorder: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; TreeNode:</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">func</span>(<span class="hljs-params">rootindex,ins,ine</span>):</span><br>            <span class="hljs-keyword">if</span>(ins&gt;ine): <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br>            root = TreeNode(preorder[rootindex])<br>            <span class="hljs-comment"># t = ins</span><br>            <span class="hljs-comment"># while(inorder[t]!=preorder[rootindex]):t+=1</span><br>            t = flag[preorder[rootindex]]<br>            root.left = func(rootindex+<span class="hljs-number">1</span>,ins,t-<span class="hljs-number">1</span>)<br>            root.right = func(rootindex+t-ins+<span class="hljs-number">1</span>,t+<span class="hljs-number">1</span>,ine)<br>            <span class="hljs-keyword">return</span> root<br>        <span class="hljs-comment"># 构建哈希表 在查找时更方便</span><br>        flag = {ele:i <span class="hljs-keyword">for</span> i,ele <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(inorder)} <span class="hljs-comment">#使用字典构建</span><br>        root = func(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-built_in">len</span>(inorder)-<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> root<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>树</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>梯度消失&amp;梯度爆炸</title>
    <link href="/2021/08/17/deep_learning/gradient-exp/"/>
    <url>/2021/08/17/deep_learning/gradient-exp/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本文探讨深度学习中经常提到的概念–梯度消失和梯度爆炸 。他们是影响模型收敛，学习好坏的重要因素。对此现象也提出了很多对应的解决方案。我们来大致做一个总结，对其概念，原因和相关的解决方案进行探讨叭~~</p></blockquote><h2 id="梯度爆炸-梯度消失">梯度爆炸&amp;梯度消失</h2><p>梯度爆炸就是在梯度更新的时候偏导数很大，导致更新参数无法收敛到最值（总是跳到其他不好的地方）。</p><p>梯度消失就是在梯度更新的时候偏导数很小，导致更新参数无法收敛到最值（动不了）。<br>$$<br>w_1=w_1− \alpha \frac{∂J(w)}{∂w1}<br>$$</p><p>$$<br>w_2=w_2− \alpha \frac{∂J(w)}{∂w2}<br>$$</p><p><img src="https://picture.mulindya.com/gradient-exp-pic1.png" alt=""></p><h2 id="梯度消失和梯度爆炸原因">梯度消失和梯度爆炸原因</h2><ul><li><p>训练方式：网络训练时采用反向传播的方式，会使用链式求导法则，因此对激活函数求导时，如果权重乘以激活函数导数此部分大于1，那么当层数很多时，求出的梯度更新将以指数的形式增加，则会梯度爆炸。如果此部分小于1，则随着层数增多，求出的梯度会指数衰减，则会梯度消失。</p></li><li><p>激活函数：如果选用sigmoid，$S(x) = \frac{1}{1+e^{-x}}$ ，而其导数 $S’(x) = \frac{e<sup>{-x}}{(1+e</sup>{-x})^2}=S(x)(1-S(x))$ ，其梯度不会超过0.25。</p></li><li><p>权重初始值：因此一个均值为0标准差为1的高斯分布初始化参数很容易发生梯度消失，因为权重集中在-1到1之间。如果初始化比较大的值</p></li><li><p>根据链式求导和反向传播，我们很容易得出，其中C是代价函数</p><p><img src="https://picture.mulindya.com/gradient-exp-pic2.png" alt=""></p><p><img src="https://picture.mulindya.com/gradient-exp-pic3.png" alt=""></p></li></ul><h2 id="解决方案">解决方案</h2><h3 id="1，采用好的参数初始化方法。比如He方法">1，采用好的参数初始化方法。比如<a href="https://blog.csdn.net/u010505915/article/details/106608922/?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0.base&amp;spm=1001.2101.3001.4242">He方法</a></h3><ol><li>前向传播的时候, 每一层的卷积计算结果的方差为1.</li><li>反向传播的时候, 每一 层的继续往前传的梯度方差为1(因为每层会有两个梯度的计算, 一个用来更新当前层的权重, 一个继续传播, 用于前面层的梯度的计算.)</li></ol><h3 id="2，梯度剪切–梯度爆炸">2，梯度剪切–梯度爆炸</h3><p>梯度裁剪是解决<strong>梯度爆炸</strong>的一种高效的方法，这里介绍梯度裁剪（Gradient Clipping）的方法，对梯度进行裁剪，论文提出对梯度的L2范数进行裁剪，也就是所有参数偏导数的平方和再开方。<br>$$<br>g_1=\frac{∂J(w)}{∂w1}<br>$$</p><p>$$<br>g_2=\frac{∂J(w)}{∂w2}<br>$$</p><p>设定裁剪阈值为 C = max_norm，$\Vert g\Vert_2= \sqrt{g<sup>2_1+g</sup>2_2}$</p><p>当$\Vert g\Vert_2$大于c时：</p><p>$$<br>g = \frac{c}{\Vert g \Vert_2} \cdot g<br>$$<br>当$\Vert g\Vert_2$小于等于C时：g不变。其中，$\frac{c}{\Vert g \Vert_2}$是一个标量</p><h3 id="3，正则化–梯度爆炸">3，正则化–梯度爆炸</h3><p>​采用权重正则化，主要是通过对网络权重做正则来限制过拟合，同时，如果发生梯度爆炸，那么权值的范数就会变的非常大，反过来，通过限制正则化项的大小，也可以在一定程度上限制梯度爆炸的发生。比较常见的是l1正则，和l2正则，在各个深度框架中都有相应的API可以使用正则化，比如在pytorch中，若搭建网络的时候已经设置了正则化参数，则调用以下代码可以直接计算出正则损失。<br>​torch.optim集成了很多优化器，如SGD，Adadelta，Adam，Adagrad，RMSprop等，这些优化器自带的一个参数weight_decay，用于指定权值衰减率，相当于L2正则化中的λ参数，注意torch.optim集成的优化器只有L2正则化方法，你可以查看注释，参数weight_decay 的解析是：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">weight_decay (<span class="hljs-built_in">float</span>, optional): weight decay (L2 penalty) (default: <span class="hljs-number">0</span>)<br>optimizer = optim.Adam(model.parameters(),lr=learning_rate,weight_decay=<span class="hljs-number">0.01</span>)<br></code></pre></td></tr></tbody></table></figure><p>loss计算公式<br>$$<br>Loss = (y-W<sup>Tx)</sup>2+\alpha {\Vert W \Vert}^2<br>$$</p><h3 id="4，激活函数">4，激活函数</h3><h4 id="1-ReLU函数：">1.ReLU函数：</h4><p>如果激活函数的导数为1，那么就不存在梯度消失爆炸的问题了，每层的网络都可以得到相同的更新速度，ReLU就这样应运而生。</p><p>ReLU的主要贡献在于：</p><p><img src="https://picture.mulindya.com/gradient-exp-pic4.png" alt=""></p><h5 id="优点">优点</h5><p>解决了梯度消失、爆炸的问题。<br>计算方便，计算速度快。<br>加速了网络的训练。</p><h5 id="缺点：">缺点：</h5><p>由于负数部分恒为0，会导致一些神经元无法激活（可通过设置小学习率部分解决）。<br>输出不是以0为中心的。</p><h4 id="2-LeakyReLU函数：">2.LeakyReLU函数：</h4><p>LeakyReLU就是为了解决ReLU的0区间带来的影响，该函数输出对负值输入有很小的坡度，由于导数总是不为零，这能减少静默神经元的出现，允许基于梯度的学习（虽然会很慢），解决了ReLU函数进入负区间后，导致神经元不学习的问题。</p><p><img src="https://picture.mulindya.com/gradient-exp-pic5.png" alt=""></p><h4 id="3-ELU函数：">3.ELU函数：</h4><p><img src="https://picture.mulindya.com/gradient-exp-pic6.png" alt=""></p><ul><li><p>融合了sigmoid和ReLU，<strong>左侧具有软饱和性，右侧无饱和性</strong>。</p></li><li><p>右侧线性部分使得ELU能够缓解梯度消失，而左侧软饱能够让ELU对输入变化或噪声更鲁棒。</p></li><li><p>ELU的输出均值接近于零，所以收敛速度更快，但相对于LeakyReLU来说，计算要更耗时间一些。</p></li></ul><p><font size="3" color="BlueViolet">小知识：</font></p><blockquote><p>梯度饱和常常是和激活函数相关的，比如sigmod和tanh就属于典型容易进入梯度饱和区的函数，即自变量进入某个区间后，梯度变化会非常小，表现在图上就是函数曲线进入某些区域后，越来越趋近一条直线，梯度变化很小，梯度饱和会导致训练过程中梯度变化缓慢，从而造成模型训练缓慢</p></blockquote><h3 id="4，Batch-Normalization">4，Batch Normalization</h3><p>BN是深度学习发展以来提出的最重要的成果之一了，目前已经被广泛的应用到了各大网络中，具有加速网络收敛速度，提升训练稳定性的效果，**BN本质上是解决反向传播过程中的梯度问题。**BN全名是Batch Normalization，简称BN，即批规范化，<strong>通过规范化操作将输出信号x规范化保证网络的稳定性。</strong><br>反向传播式子中有w的存在，所以w的大小影响了梯度的消失和爆炸，<strong>BN就是通过对每一层的输出规范为均值和方差一致的方法</strong>，消除了w带来的放大缩小的影响，进而解决梯度消失和爆炸的问题，或者可以理解为BN将输出从饱和区拉倒了非饱和区。<br>有关Batch Normalization详细的内容可以参考这篇博客： <a href="http://blog.csdn.net/qq_25737169/article/details/79048516">Batch Normalization</a></p><h3 id="5-残差结构">5,残差结构</h3><p>事实上，就是残差网络的出现导致了image net比赛的终结，自从残差提出后，几乎所有的深度网络都离不开残差的身影，相比较之前的几层，几十层的深度网络，在残差网络面前都不值一提，残差可以很轻松的构建几百层，一千多层的网络而不用担心梯度消失过快的问题，原因就在于残差的捷径（shortcut）部分。原理可参见：<a href="https://zhuanlan.zhihu.com/p/42706477">残差结构</a></p><h3 id="6，LSTM网络">6，LSTM网络</h3><p>LSTM是循环神经网络RNN的变体，全称是长短期记忆网络（long-short term memory networks），它是不那么容易发生梯度消失的，主要原因在于LSTM内部复杂的“门”结构，<strong>LSTM通过它内部的“门”可以接下来更新的时候“记住”前几次训练的“残留记忆”</strong>，因此，经常用于生成文本中。关于LSTM的原理详解后续再分析。<a href="https://zhuanlan.zhihu.com/p/32085405">LSTM</a></p><p><img src="https://picture.mulindya.com/gradient-exp-pic7.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer27 二叉树的镜像</title>
    <link href="/2021/08/16/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer27/"/>
    <url>/2021/08/16/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer27/</url>
    
    <content type="html"><![CDATA[<blockquote><p>二叉树的镜像</p></blockquote><h2 id="题目">题目</h2><p>请完成一个函数，输入一个二叉树，该函数输出它的镜像。</p><p>例如输入：</p><p>​     4<br>2     7<br>1   3  6   9<br>镜像输出：</p><p>​     4<br>7     2<br>9   6 3   1</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight accesslog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">输入：root = <span class="hljs-string">[4,2,7,1,3,6,9]</span><br>输出：<span class="hljs-string">[4,7,2,9,6,3,1]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>0 &lt;= 节点个数 &lt;= 1000</li></ul><h2 id="题解">题解</h2><p>如果为空树就返回空。然后保存左子树，翻转右子树后赋值为左节点，翻转左子树赋值为右节点。</p><p><strong>if not(root.left or root.right): return root #为单一节点就直接返回 可以省略，因为已经包含在内</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for a binary tree node.</span><br><span class="hljs-comment"># class TreeNode:</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.left = None</span><br><span class="hljs-comment">#         self.right = None</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mirrorTree</span>(<span class="hljs-params">self, root: TreeNode</span>) -&gt; TreeNode:</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span>(root): <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br>        x = root.left<br>        root.left = self.mirrorTree(root.right)<br>        root.right = self.mirrorTree(x)<br>        <span class="hljs-keyword">return</span> root<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>树</category>
      
    </categories>
    
    
    <tags>
      
      <tag>树</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer06 合并两个排序的链表</title>
    <link href="/2021/08/16/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer25/"/>
    <url>/2021/08/16/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer25/</url>
    
    <content type="html"><![CDATA[<blockquote><p>合并两个排序的链表</p></blockquote><h2 id="题目">题目</h2><p>输入两个递增排序的链表，合并这两个链表并使新链表中的节点仍然是递增排序的。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight clean"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs clean">输入：<span class="hljs-number">1</span>-&gt;<span class="hljs-number">2</span>-&gt;<span class="hljs-number">4</span>, <span class="hljs-number">1</span>-&gt;<span class="hljs-number">3</span>-&gt;<span class="hljs-number">4</span><br>输出：<span class="hljs-number">1</span>-&gt;<span class="hljs-number">1</span>-&gt;<span class="hljs-number">2</span>-&gt;<span class="hljs-number">3</span>-&gt;<span class="hljs-number">4</span>-&gt;<span class="hljs-number">4</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>0 &lt;= 链表长度 &lt;= 1000</li></ul><h2 id="题解">题解</h2><p>如果直接用p = l.next  那么不能达到“指针”的效果。这样的操作对l没有影响，无法更新。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mergeTwoLists</span>(<span class="hljs-params">self, l1: ListNode, l2: ListNode</span>) -&gt; ListNode:</span><br>        l = ListNode(<span class="hljs-number">0</span>) <br>        p = l.<span class="hljs-built_in">next</span>     <br>        <span class="hljs-keyword">while</span>(l1 <span class="hljs-keyword">and</span> l2):<br>            <span class="hljs-keyword">if</span>(l1.val&gt;l2.val):<br>                p = l2<br>                l2 = l2.<span class="hljs-built_in">next</span><br>            <span class="hljs-keyword">else</span>:<br>                p = l1<br>                l1 = l1.<span class="hljs-built_in">next</span><br>            p = p.<span class="hljs-built_in">next</span><br>        p = l1 <span class="hljs-keyword">if</span> l1 <span class="hljs-keyword">else</span> l2<br>        <span class="hljs-keyword">return</span> l.<span class="hljs-built_in">next</span><br></code></pre></td></tr></tbody></table></figure><p>正确方式，不能使用 p = p.next， 因为next是一个None值，改变p值并不会修改l对应的next。所以首先浅拷贝l，然后再直接改变内部的next，才能对应的改变l的内容。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode:</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.next = None</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mergeTwoLists</span>(<span class="hljs-params">self, l1: ListNode, l2: ListNode</span>) -&gt; ListNode:</span><br>        p = l = ListNode(<span class="hljs-number">0</span>) <span class="hljs-comment">#先指向同一块空间</span><br>        <span class="hljs-comment">#p = p.next      </span><br>        <span class="hljs-comment"># 不能使用p = p.next  因为next是一个None值改变p值并不会修改l对应的next。</span><br>        <span class="hljs-comment"># 所以首先浅拷贝，然后再直接改变内部的next，才能对应的改变l的内容</span><br>        <span class="hljs-keyword">while</span>(l1 <span class="hljs-keyword">and</span> l2):<br>            <span class="hljs-keyword">if</span>(l1.val&gt;l2.val):<br>                p.<span class="hljs-built_in">next</span> = l2<br>                l2 = l2.<span class="hljs-built_in">next</span><br>            <span class="hljs-keyword">else</span>:<br>                p.<span class="hljs-built_in">next</span> = l1<br>                l1 = l1.<span class="hljs-built_in">next</span><br>            p = p.<span class="hljs-built_in">next</span><br>        p.<span class="hljs-built_in">next</span> = l1 <span class="hljs-keyword">if</span> l1 <span class="hljs-keyword">else</span> l2<br>        <span class="hljs-keyword">return</span> l.<span class="hljs-built_in">next</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>链表</category>
      
    </categories>
    
    
    <tags>
      
      <tag>链表</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer13 机器人的运动范围</title>
    <link href="/2021/08/14/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer13/"/>
    <url>/2021/08/14/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer13/</url>
    
    <content type="html"><![CDATA[<blockquote><p>机器人的运动范围</p></blockquote><h2 id="题目">题目</h2><p>地上有一个m行n列的方格，从坐标 [0,0] 到坐标 [m-1,n-1] 。一个机器人从坐标 [0, 0] 的格子开始移动，它每次可以向左、右、上、下移动一格（不能移动到方格外），也不能进入行坐标和列坐标的数位之和大于k的格子。例如，当k为18时，机器人能够进入方格 [35, 37] ，因为3+5+3+7=18。但它不能进入方格 [35, 38]，因为3+5+3+8=19。请问该机器人能够到达多少个格子？</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">m</span> = <span class="hljs-number">2</span>, <span class="hljs-attr">n</span> = <span class="hljs-number">3</span>, <span class="hljs-attr">k</span> = <span class="hljs-number">1</span><br>输出：<span class="hljs-number">3</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">m</span> = <span class="hljs-number">3</span>, <span class="hljs-attr">n</span> = <span class="hljs-number">1</span>, <span class="hljs-attr">k</span> = <span class="hljs-number">0</span><br>输出：<span class="hljs-number">1</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><code>1 &lt;= n,m &lt;= 100</code></li><li><code>0 &lt;= k &lt;= 20</code></li></ul><h2 id="题解">题解</h2><h3 id="解法一-DFS">解法一 DFS</h3><ul><li>深搜+剪枝</li><li>优化技巧就是只判断右边和下边就行了，因为左和上是一定会在搜索的过程中被包括的</li></ul><p>​        <font color="purple">注意[[1]*n]*m 是浅拷贝复制（“=”复制）因此如果一个元素改变了，此列都会改变</font></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">movingCount</span>(<span class="hljs-params">self, m, n, k</span>):</span><br>        <span class="hljs-string">"""</span><br><span class="hljs-string">        :type m: int</span><br><span class="hljs-string">        :type n: int</span><br><span class="hljs-string">        :type k: int</span><br><span class="hljs-string">        :rtype: int</span><br><span class="hljs-string">        """</span><br>        <br>        fflag = [[<span class="hljs-number">1</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n)] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(m)]  <br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">numsum</span>(<span class="hljs-params">i,j</span>):</span><br>            <span class="hljs-built_in">sum</span>=<span class="hljs-number">0</span><br>            <span class="hljs-keyword">while</span>(i):<br>                <span class="hljs-built_in">sum</span>+=(i%<span class="hljs-number">10</span>)<br>                i = i//<span class="hljs-number">10</span><br>            <span class="hljs-keyword">while</span>(j):<br>                <span class="hljs-built_in">sum</span>+=(j%<span class="hljs-number">10</span>)<br>                j = j//<span class="hljs-number">10</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dfs</span>(<span class="hljs-params">i,j</span>):</span><br>            <span class="hljs-keyword">if</span> (<span class="hljs-keyword">not</span> m&gt;i&gt;=<span class="hljs-number">0</span>) <span class="hljs-keyword">or</span> (<span class="hljs-keyword">not</span> n&gt;j&gt;=<span class="hljs-number">0</span>) <span class="hljs-keyword">or</span> (fflag[i][j]==<span class="hljs-number">0</span>) <span class="hljs-keyword">or</span> (numsum(i,j)&gt;k): <br>                <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>            fflag[i][j] = <span class="hljs-number">0</span><br>            <span class="hljs-comment"># return 1+dfs(i+1,j)+dfs(i-1,j)+dfs(i,j+1)+dfs(i,j-1)</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>+dfs(i+<span class="hljs-number">1</span>,j)+dfs(i,j+<span class="hljs-number">1</span>)<br><br>        <span class="hljs-keyword">return</span> dfs(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>)<br></code></pre></td></tr></tbody></table></figure><h3 id="解法二-递推">解法二 递推</h3><h4 id="思路">思路</h4><p>考虑到方法一提到搜索的方向只需要朝下或朝右，我们可以得出一种递推的求解方法。</p><h4 id="算法">算法</h4><p>定义 <code>vis[i][j]</code> 为 <code>(i, j)</code> 坐标是否可达，如果可达返回 1，否则返回 0。</p><p>首先 (i, j) 本身需要可以进入，因此需要先判断 i 和 j 的数位之和是否大于 k ，如果大于的话直接设置 <code>vis[i][j]</code> 为不可达即可。</p><p>否则，前面提到搜索方向只需朝下或朝右，因此 (i, j) 的格子只会从 (i - 1, j) 或者 (i, j - 1) 两个格子走过来（不考虑边界条件），那么 <code>vis[i][j]</code> 是否可达的状态则可由如下公式计算得到：</p><p>即只要有一个格子可达，那么 (i, j) 这个格子就是可达的，因此我们只要遍历所有格子，递推计算出它们是否可达然后用变量 ans 记录可达的格子数量即可。</p><p>初始条件 <code>vis[i][j] = 1</code> ，递推计算的过程中注意边界的处理。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">digitsum</span>(<span class="hljs-params">n</span>):</span><br>    ans = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span> n:<br>        ans += n % <span class="hljs-number">10</span><br>        n //= <span class="hljs-number">10</span><br>    <span class="hljs-keyword">return</span> ans<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">movingCount</span>(<span class="hljs-params">self, m: <span class="hljs-built_in">int</span>, n: <span class="hljs-built_in">int</span>, k: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        vis = <span class="hljs-built_in">set</span>([(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>)])<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(m):<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>                <span class="hljs-keyword">if</span> ((i - <span class="hljs-number">1</span>, j) <span class="hljs-keyword">in</span> vis <span class="hljs-keyword">or</span> (i, j - <span class="hljs-number">1</span>) <span class="hljs-keyword">in</span> vis) <span class="hljs-keyword">and</span> digitsum(i) + digitsum(j) &lt;= k:<br>                    vis.add((i, j))<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(vis)<br></code></pre></td></tr></tbody></table></figure><h3 id="解法三">解法三</h3><h4 id="思路和算法">思路和算法</h4><p>我们将行坐标和列坐标数位之和大于 k 的格子看作障碍物，那么这道题就是一道很传统的搜索题目，我们可以使用广度优先搜索或者深度优先搜索来解决它，本文选择使用广度优先搜索的方法来讲解。</p><p>那么如何计算一个数的数位之和呢？我们只需要对数 x 每次对 10 取余，就能知道数 x 的个位数是多少，然后再将 x 除 10，这个操作等价于将 x 的十进制数向右移一位，删除个位数（类似于二进制中的 &gt;&gt; 右移运算符），不断重复直到 x 为 0 时结束。</p><p>同时这道题还有一个隐藏的优化：我们在搜索的过程中搜索方向可以缩减为向右和向下，而不必再向上和向左进行搜索。如下图，我们展示了 16 * 16 的地图随着限制条件 k 的放大，可行方格的变化趋势，每个格子里的值为行坐标和列坐标的数位之和，蓝色方格代表非障碍方格，即其值小于等于当前的限制条件 k。我们可以发现随着限制条件 k 的增大，(0, 0) 所在的蓝色方格区域内新加入的非障碍方格都可以由上方或左方的格子移动一步得到。而其他不连通的蓝色方格区域会随着 k 的增大而连通，且连通的时候也是由上方或左方的格子移动一步得到，因此我们可以将我们的搜索方向缩减为向右或向下。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">digitsum</span>(<span class="hljs-params">n</span>):</span><br>    ans = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span> n:<br>        ans += n % <span class="hljs-number">10</span><br>        n //= <span class="hljs-number">10</span><br>    <span class="hljs-keyword">return</span> ans<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">movingCount</span>(<span class="hljs-params">self, m: <span class="hljs-built_in">int</span>, n: <span class="hljs-built_in">int</span>, k: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-keyword">from</span> queue <span class="hljs-keyword">import</span> Queue<br>        q = Queue()<br>        q.put((<span class="hljs-number">0</span>, <span class="hljs-number">0</span>))<br>        s = <span class="hljs-built_in">set</span>()<br>        <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> q.empty():<br>            x, y = q.get()<br>            <span class="hljs-keyword">if</span> (x, y) <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> s <span class="hljs-keyword">and</span> <span class="hljs-number">0</span> &lt;= x &lt; m <span class="hljs-keyword">and</span> <span class="hljs-number">0</span> &lt;= y &lt; n <span class="hljs-keyword">and</span> digitsum(x) + digitsum(y) &lt;= k:<br>                s.add((x, y))<br>                <span class="hljs-keyword">for</span> nx, ny <span class="hljs-keyword">in</span> [(x + <span class="hljs-number">1</span>, y), (x, y + <span class="hljs-number">1</span>)]:<br>                    q.put((nx, ny))<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(s)<br></code></pre></td></tr></tbody></table></figure><h4 id="复杂度分析">复杂度分析</h4><h5 id="时间复杂度：O-mn">时间复杂度：O(mn)</h5><p>其中 m 为方格的行数，n 为方格的列数。考虑所有格子都能进入，那么搜索的时候一个格子最多会被访问的次数为常数，所以时间复杂度为 O(2mn)=O(mn)。</p><h5 id="空间复杂度：O-mn">空间复杂度：O(mn)</h5><p>其中 m 为方格的行数，n 为方格的列数。搜索的时候需要一个大小为 O(mn)的标记结构用来标记每个格子是否被走过。</p>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>DFS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>idea</tag>
      
      <tag>DFS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Sobel算子</title>
    <link href="/2021/08/14/img_process/sobel/"/>
    <url>/2021/08/14/img_process/sobel/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本文主要介绍Sobel算子，主要用于边缘检测；由于该算子引入了局部平均，对噪声有平滑作用，因此还可以消除噪声。</p></blockquote><h2 id="图像边缘与梯度">图像边缘与梯度</h2><p>在图像边缘，灰度值的变化较大，因此图像在此处的梯度值也较大。一般情况，图像梯度时计算图像的边缘信息。图像梯度严格来说时需要求导数，但是在图像计算上时使用像素值的差得到梯度的近似值。<br>图像强度的显著变化可分为：</p><ul><li>阶跃变化函数，即图像强度在不连续处的两边的像素灰度值有着显著的差异；</li><li>线条（屋顶）变化函数，即图像强度突然从一个值变化到另一个值，保持一较小行程后又回到原来的值。</li></ul><p><img src="https://picture.mulindya.com/sobel-pic1.png" alt=""></p><p>（a）（b）分别是阶跃函数和屋顶函数的二维图像；（c）（d）是阶跃和屋顶函数的函数图象；（e）（f）对应一阶倒数；（g）（h）是二阶倒数。</p><h2 id="Sobel算子">Sobel算子</h2><p>常用如下两个模板进行边缘检测，将Gx，Gy与图像卷积，即可得到横向和纵向的亮度差分近似值。</p>$$G_x = \begin{bmatrix} -1 &amp; 0 &amp; 1 \\ -2 &amp; 0 &amp; 2\\-1 &amp; 0 &amp; 1\end{bmatrix} \qquad G_y = \begin{bmatrix} 1 &amp; 2 &amp; 1 \\ 0 &amp; 0 &amp; 0\\-1 &amp; -2 &amp; -1\end{bmatrix}$$<p>图像每一个像素的梯度可以使用$G = \sqrt{G<sup>2_x+G</sup>2_y}$来表示，梯度的方向使用$\Theta = arctan(\frac{G_y}{G_x})$。</p><p>还有另外一个比<code>Sobel</code>函数的近似效果更好的 <code>Scharr</code>函数，其内核矩阵如下:</p>$$G_x = \begin{bmatrix} -3 &amp; 0 &amp; 3 \\ -10 &amp; 0 &amp; 10 \\ -3 &amp; 0 &amp; 3\end{bmatrix} \qquad G_y = \begin{bmatrix} -3 &amp; -10 &amp; -3 \\ 0 &amp; 0 &amp; 0 \\ 3 &amp; 10 &amp; 3\end{bmatrix}$$<h2 id="代码使用">代码使用</h2><h3 id="cv2-Sobel">cv2.Sobel()</h3><p>Sobel算子依然是一种过滤器，只是其是带有方向的</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">dst = cv2.Sobel(src, ddepth, dx, dy[,ksize[, scale[, delta[, borderType]]]])<br></code></pre></td></tr></tbody></table></figure><ul><li>dst代表目标函数</li><li>src代表原始图像</li><li>ddpeth代表输出图像的深度 ，-1表示采用的是与原图像相同的深度。目标图像的深度必须大于等于原图像的深度；</li><li>dx代表x方向上的求导阶数 ，0表示这个方向上没有求导，一般为0、1、2。</li><li>dy代表y方向上的求导阶数，0表示这个方向上没有求导，一般为0、1、2。</li><li>ksize代表Sobel核的大小，该值为-1时，则会使用Scharr算子进行运算,一般选择为1、3、5、7</li><li>scale代表计算导数时所采用的缩放因子，默认为1，无缩放</li><li>delta代表加在目标图像dst上的值，该值是可选的，默认为0</li><li>borderType代表边界样式，这个参数默认值为cv2.BORDER_DEFAULT。</li></ul><blockquote><p>其中ddepth设计图像深度的概念：<br>图像深度是指存储每个像素值所用的位数，例如cv2.CV_8U，指的是8位无符号数，取值范围为0~255，超出范围则会被截断（截断指的是，当数值大于255保留为255，当数值小于0保留为0，其余不变）。</p><p>具体还有：CV_16S（16位无符号数），CV_16U（16位有符号数），CV_32F（32位浮点数），CV_64F（64位浮点数）等.</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-comment">#载入原图，图像深度为CV_8U</span><br>img_original=cv2.imread(<span class="hljs-string">'E:\ShannonT\\notebook workspace\\images\\4.28.9.jpg'</span>,<span class="hljs-number">0</span>)<br><span class="hljs-comment">#求X方向梯度，并且输出图像一个为CV_8U,一个为CV_64F</span><br>img_gradient_X_8U=cv2.Sobel(img_original,-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)<br>img_gradient_X_64F=cv2.Sobel(img_original,cv2.CV_64F,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)<br><span class="hljs-comment">#将图像深度改为CV_8U</span><br>img_gradient_X_64Fto8U=cv2.convertScaleAbs(img_gradient_X_64F)<br><span class="hljs-comment">#图像显示</span><br>cv2.imshow(<span class="hljs-string">'X_gradient_8U'</span>,img_gradient_X)<br>cv2.imshow(<span class="hljs-string">'X_gradient_64Fto8U'</span>,img_gradient_X_64Fto8U)<br>cv2.waitKey()<br>cv2.destroyAllWindows()<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/sobel-pic2.png" alt=""></p><p><code>cv2.imshow()</code>的默认显示为8位无符号数，即[0,255]，因此在显示<code>CV_64F</code>的图像前使用了函数<code>cv2.convertScaleAbs()</code>将图像深度为<code>CV_64F</code>的梯度图像重新转化为<code>CV_8U</code>。</p><h3 id="cv2-convertScaleAbs">cv2.convertScaleAbs()</h3><figure class="highlight reasonml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">cv2.convert<span class="hljs-constructor">ScaleAbs(<span class="hljs-params">src</span>[,<span class="hljs-params">alpha</span>[,<span class="hljs-params">beta</span>]])</span><br></code></pre></td></tr></tbody></table></figure><p>先计算数组绝对值，后转化为8位无符号数</p><ul><li>src:输入图像（多维数组）</li><li>alpha:比例因子</li><li>beta:保存新图像（数组）前可以增加的值</li></ul><h3 id="归一化">归一化</h3><p>防止梯度大小被截断最简单的方法就是先将输入图像归一化（实际归一化的过程就已经实现了图像深度的转变）。在使用深度大于8U的格式之前将灰度先归一化，就不用<code>convertScaleAbs</code>转换了。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-comment">#载入灰度原图，图像深度为CV_8U</span><br>img_original=cv2.imread(<span class="hljs-string">'E:\ShannonT\\notebook workspace\\images\\4.28.9.jpg'</span>,<span class="hljs-number">0</span>)<br><span class="hljs-comment">#原图归一化,实际图像深度已经变为CV_64F</span><br>img_standard=img_original/<span class="hljs-number">255</span><br><span class="hljs-comment">#采用灰度原图求X方向梯度</span><br>original_gradient_X_64F=cv2.Sobel(img_original,cv2.CV_64F,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)<br>original_gradient_X_64Fto8U=cv2.convertScaleAbs(original_gradient_X_64F)<br><span class="hljs-comment">#采用归一化的图像求X方向梯度</span><br>standard_gradient_X=cv2.Sobel(img_standard,-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)<br><span class="hljs-comment">#图像显示</span><br>cv2.imshow(<span class="hljs-string">'original'</span>,img_original)<br>cv2.imshow(<span class="hljs-string">'original_X'</span>,original_gradient_X_64Fto8U)<br>cv2.imshow(<span class="hljs-string">'standard_X'</span>,standard_gradient_X)<br>cv2.waitKey()<br>cv2.destroyAllWindows()<br></code></pre></td></tr></tbody></table></figure><p><img src="https://picture.mulindya.com/sobel-pic3.png" alt=""></p><h3 id="cv2-addWeighted">cv2.addWeighted()</h3><figure class="highlight reasonml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">cv2.add<span class="hljs-constructor">Weighted(<span class="hljs-params">src1</span>, <span class="hljs-params">alpha</span>, <span class="hljs-params">src2</span>, <span class="hljs-params">beta</span>, <span class="hljs-params">gamma</span>[, <span class="hljs-params">dst</span>[, <span class="hljs-params">dtype</span>]])</span> → dst<br></code></pre></td></tr></tbody></table></figure><ul><li>src1 输入的第一个数组</li><li>alpha 第一个数组的权重</li><li>src2 输入的第二个数组（与第一个数组有相同的shape）</li><li>beta 第二个数组的权重</li><li>dst 输出的数组名称</li><li>gamma 计算和时所采用的缩放因子，默认为1，无缩放</li><li>dtype 输出图像的深度，-1表示和input相同</li><li></li></ul><blockquote><p>dst = src1 * alpha + src2 * beta + gamma;</p></blockquote><p>注意：由参数说明可以看出，被叠加的两幅图像必须是尺寸相同、类型相同的；并且，当输出图像array的深度为CV_32S时，这个函数就不适用了，这时候就会内存溢出或者算出的结果压根不对。</p><h3 id="边缘检测">边缘检测</h3><p>通过cv2.Sobel()我们可以轻松计算出X,Y方向的梯度大小，根据公式</p><p>$$<br>G = \sqrt{G<sup>2_x+G</sup>2_y}<br>$$<br>可以求出梯度图像，实际操作时，为了简化运算，我们使用公式</p><p>$$<br>G = \vert{G_x}\vert+\vert{G_y}\vert<br>$$</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-comment">#载入灰度原图，并且归一化</span><br>img_original=cv2.imread(<span class="hljs-string">'E:\ShannonT\\notebook workspace\\images\\4.28.9.jpg'</span>,<span class="hljs-number">0</span>)/<span class="hljs-number">255</span><br><span class="hljs-comment">#分别求X,Y方向的梯度</span><br>grad_X=cv2.Sobel(img_original,-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)<br>grad_Y=cv2.Sobel(img_original,-<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)<br><span class="hljs-comment">#求梯度图像</span><br>grad=cv2.addWeighted(grad_X,<span class="hljs-number">0.5</span>,grad_Y,<span class="hljs-number">0.5</span>,<span class="hljs-number">0</span>)<br>cv2.imshow(<span class="hljs-string">'gradient'</span>,grad)<br></code></pre></td></tr></tbody></table></figure><h2 id="官方说明">官方说明</h2><p>当年作者并没有公开发表过论文，仅仅是在一次博士生课题讨论会(1968)上提出(“A 3x3 Isotropic Gradient Operator for Image Processing”)，后在1973年出版的一本专著（“Pattern Classification and Scene Analysis”）的脚注里作为注释出现和公开的。</p><p>详细介绍，请参考以下内容。</p><iframe src="/js/pdfjs_old/web/viewer.html?file=https://paper.mulindya.com/An%20Isotropic%203x3%20Image%20Gradient%20Operator.pdf" width="100%" height="450"></iframe>]]></content>
    
    
    <categories>
      
      <category>图像处理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>图像处理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer06 从尾到头打印链表</title>
    <link href="/2021/08/14/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer06/"/>
    <url>/2021/08/14/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer06/</url>
    
    <content type="html"><![CDATA[<blockquote><p>从尾到头打印链表</p></blockquote><h2 id="题目">题目</h2><p>输入一个链表的头节点，从尾到头反过来返回每个节点的值（用数组返回）。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">输入：head = <span class="hljs-comment">[1,3,2]</span><br>输出：<span class="hljs-comment">[2,3,1]</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>0 &lt;= 链表长度 &lt;= 10000</li></ul><h2 id="题解">题解</h2><p>遍历链表，直接插入到头位置。就可以直接输出了。或者采用递归，超级简洁，值得借鉴。注意if的条件和对应结果。（递归就从中间普适的节点开始考虑 然后补充边界细节）</p><p><font color="orange">return self.reversePrint( head.next ) + [ head.val ] if head else []</font></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode(object):</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.next = None</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reversePrint</span>(<span class="hljs-params">self, head</span>):</span><br>        <span class="hljs-string">"""</span><br><span class="hljs-string">        :type head: ListNode</span><br><span class="hljs-string">        :rtype: List[int]</span><br><span class="hljs-string">        """</span><br>        p=head<br>        result = []<br>        <span class="hljs-keyword">while</span>(p):<br>            result = [p.val]+result <span class="hljs-comment">#直接添加到前面</span><br>            p = p.<span class="hljs-built_in">next</span><br>        <span class="hljs-keyword">return</span> result<br>        <span class="hljs-comment">#使用递归一条语句超级简洁 递归后一个元素+当前元素 如果当前为空则+【】 也是终止未知</span><br>        <span class="hljs-comment">#return self.reversePrint(head.next) + [head.val] if head else []</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>链表</category>
      
    </categories>
    
    
    <tags>
      
      <tag>链表</tag>
      
      <tag>剑指</tag>
      
      <tag>idea</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer12 矩阵中的路径</title>
    <link href="/2021/08/14/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer12/"/>
    <url>/2021/08/14/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer12/</url>
    
    <content type="html"><![CDATA[<blockquote><p>矩阵中的路径</p></blockquote><h2 id="题目">题目</h2><p>给定一个 m x n 二维字符网格 board 和一个字符串单词 word 。如果 word 存在于网格中，返回 true ；否则，返回 false 。</p><p>单词必须按照字母顺序，通过相邻的单元格内的字母构成，其中“相邻”单元格是那些水平相邻或垂直相邻的单元格。同一个单元格内的字母不允许被重复使用。</p><p>例如，在下面的 3×4 的矩阵中包含单词 “ABCCED”（单词中的字母已标出）。</p><p><img src="https://picture.mulindya.com/leetcode-offer12-pic1.jpg" alt=""></p><h3 id="示例-1：">示例 1：</h3><figure class="highlight prolog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs prolog">输入：board = [[<span class="hljs-string">"A"</span>,<span class="hljs-string">"B"</span>,<span class="hljs-string">"C"</span>,<span class="hljs-string">"E"</span>],[<span class="hljs-string">"S"</span>,<span class="hljs-string">"F"</span>,<span class="hljs-string">"C"</span>,<span class="hljs-string">"S"</span>],[<span class="hljs-string">"A"</span>,<span class="hljs-string">"D"</span>,<span class="hljs-string">"E"</span>,<span class="hljs-string">"E"</span>]], word = <span class="hljs-string">"ABCCED"</span><br>输出：true<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight nix"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nix">输入：<span class="hljs-attr">board</span> = [[<span class="hljs-string">"a"</span>,<span class="hljs-string">"b"</span>],[<span class="hljs-string">"c"</span>,<span class="hljs-string">"d"</span>]], <span class="hljs-attr">word</span> = <span class="hljs-string">"abcd"</span><br>输出：<span class="hljs-literal">false</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li><code>1 &lt;= board.length &lt;= 200</code></li><li><code>1 &lt;= board[i].length &lt;= 200</code></li><li><code>board</code> 和 <code>word</code> 仅由大小写英文字母组成</li></ul><h2 id="题解">题解</h2><p>循环遍历二维数组，以此为起点判断是否存在连续的字符串。在dfs中首先进行边界范围判断，以及此点是否满足要求，如果不满足要求直接返回假，为真则继续word判断之后的字符。如果以及是最后的字符就可以直接返回结果。<font color="purple">注意在判断k+1之前需要先mask掉自身的值，防止后续“路线返回”</font></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">exist</span>(<span class="hljs-params">self, board, word</span>):</span><br>        <span class="hljs-string">"""</span><br><span class="hljs-string">        :type board: List[List[str]]</span><br><span class="hljs-string">        :type word: str</span><br><span class="hljs-string">        :rtype: bool</span><br><span class="hljs-string">        """</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dfs</span>(<span class="hljs-params">i,j,k</span>):</span><br>            <span class="hljs-keyword">if</span> (<span class="hljs-keyword">not</span> <span class="hljs-built_in">len</span>(board)&gt;i&gt;=<span class="hljs-number">0</span>) <span class="hljs-keyword">or</span> (<span class="hljs-keyword">not</span> <span class="hljs-built_in">len</span>(board[<span class="hljs-number">0</span>])&gt;j&gt;=<span class="hljs-number">0</span>) <span class="hljs-keyword">or</span> board[i][j]!=word[k]: <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span> <br>            <span class="hljs-comment">#不匹配的情况</span><br>            <span class="hljs-keyword">if</span> k == <span class="hljs-built_in">len</span>(word)-<span class="hljs-number">1</span>: <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span> <span class="hljs-comment">#不用继续判断</span><br>            board[i][j] = <span class="hljs-string">' '</span><br>            <span class="hljs-comment"># #注意不能直接返回 因为在处理邻近的内容会判断到自身，这是不允许的，所以先mask</span><br>            <span class="hljs-comment"># return dfs(i+1,j,k+1) or dfs(i-1,j,k+1) or dfs(i,j+1,k+1) or dfs(i,j-1,k+1) </span><br>            res = dfs(i+<span class="hljs-number">1</span>,j,k+<span class="hljs-number">1</span>) <span class="hljs-keyword">or</span> dfs(i-<span class="hljs-number">1</span>,j,k+<span class="hljs-number">1</span>) <span class="hljs-keyword">or</span> dfs(i,j+<span class="hljs-number">1</span>,k+<span class="hljs-number">1</span>) <span class="hljs-keyword">or</span> dfs(i,j-<span class="hljs-number">1</span>,k+<span class="hljs-number">1</span>) <br>            board[i][j] = word[k]<br>            <span class="hljs-keyword">return</span> res<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(board)):<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(board[<span class="hljs-number">0</span>])):<br>                <span class="hljs-keyword">if</span> dfs(i,j,<span class="hljs-number">0</span>): <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span> <span class="hljs-comment">#如果从ij开始找0之后的字符串找到则为真</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>DFS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>idea</tag>
      
      <tag>DFS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer11 旋转数组的最小数字</title>
    <link href="/2021/08/13/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer11/"/>
    <url>/2021/08/13/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer11/</url>
    
    <content type="html"><![CDATA[<blockquote><p>旋转数组的最小数字</p></blockquote><h2 id="题目">题目</h2><p>把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。输入一个递增排序的数组的一个旋转，输出旋转数组的最小元素。例如，数组 [3,4,5,1,2] 为 [1,2,3,4,5] 的一个旋转，该数组的最小值为1。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight accesslog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">输入：<span class="hljs-string">[3,4,5,1,2]</span><br>输出：<span class="hljs-number">1</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight accesslog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">输入：<span class="hljs-string">[2,2,2,0,1]</span><br>输出：<span class="hljs-number">0</span><br></code></pre></td></tr></tbody></table></figure><h2 id="题解">题解</h2><p>将数组遍历一遍，遇到第一个非增序的元素即为最小值。复杂度为线性级别。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">minArray</span>(<span class="hljs-params">self, numbers: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span>(numbers):<span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>        minitem = numbers[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(numbers)):<br>            <span class="hljs-keyword">if</span> numbers[i]&lt;numbers[i-<span class="hljs-number">1</span>]:<br>                <span class="hljs-keyword">return</span> <span class="hljs-built_in">min</span>(minitem,numbers[i])<br>        <span class="hljs-keyword">return</span> minitem<br></code></pre></td></tr></tbody></table></figure><p>还可以使用二分法，将线性级别的复杂度降低到对数级别。</p><p><img src="https://picture.mulindya.com/leetcode-offer11-pic1.png" alt=""></p><p>最低点有特性：左边的所有元素都要比右边所有元素大。利用这个特性可以逐渐缩小范围。</p><p>中间元素和某个边界元素比较大小，来确定范围，<u>但是要注意两者相等时就没有确切的判断了</u>。可以直接用线性比较来替代。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">minArray</span>(<span class="hljs-params">self, numbers: [<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        i, j = <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(numbers) - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> i &lt; j:<br>            m = (i + j) // <span class="hljs-number">2</span><br>            <span class="hljs-keyword">if</span> numbers[m] &gt; numbers[j]: i = m + <span class="hljs-number">1</span><br>            <span class="hljs-keyword">elif</span> numbers[m] &lt; numbers[j]: j = m<br>            <span class="hljs-keyword">else</span>: j -= <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> numbers[i]<br></code></pre></td></tr></tbody></table></figure><p>实际上，当出现 nums[m] = nums[j] 时，一定有区间[i,m]内所有元素相等 或 区间 [m,j] 内所有元素相等（或两者皆满足）。对于寻找此类数组的最小值问题，可直接放弃二分查找，而使用线性查找替代。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">minArray</span>(<span class="hljs-params">self, numbers: [<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        i, j = <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(numbers) - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> i &lt; j:<br>            m = (i + j) // <span class="hljs-number">2</span><br>            <span class="hljs-keyword">if</span> numbers[m] &gt; numbers[j]: i = m + <span class="hljs-number">1</span><br>            <span class="hljs-keyword">elif</span> numbers[m] &lt; numbers[j]: j = m<br>            <span class="hljs-keyword">else</span>: <span class="hljs-keyword">return</span> <span class="hljs-built_in">min</span>(numbers[i:j])<br>        <span class="hljs-keyword">return</span> numbers[i]<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>数组</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>数组</tag>
      
      <tag>idea</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>文献整理笔记</title>
    <link href="/2021/08/13/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E6%95%B4%E7%90%86%E5%BD%92%E7%BA%B3/paper-site/"/>
    <url>/2021/08/13/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/paper/%E6%95%B4%E7%90%86%E5%BD%92%E7%BA%B3/paper-site/</url>
    
    <content type="html"><![CDATA[<blockquote><p>查找文献的网站<br><a href="https://www.thecvf.com/">https://www.thecvf.com/</a><br><a href="https://arxiv.org/list/cs/recent">https://arxiv.org/list/cs/recent</a><br><a href="https://www.researchgate.net/">https://www.researchgate.net/</a></p></blockquote><blockquote><p>超宝藏博主： <a href="https://www.zhihu.com/people/wang-jia-hao-53-3">科技猛兽</a><br>宝藏公众号： 极市平台<br>系列学习： <a href="https://zhuanlan.zhihu.com/p/348593638">VIT学习</a></p></blockquote><h3 id="微调技巧">微调技巧</h3><p><a href="https://paper.mulindya.com/Accurate%2C%20Large%20Minibatch%20SGD%20Training%20ImageNet%20in%201%20Hour.pdf"><strong>Accurate, Large Minibatch SGD Training ImageNet in 1 Hour.pdf</strong></a></p><p><a href="https://paper.mulindya.com/BITGeneral%20Visual%20Representation%20Learning.pdf"><strong>BIT : General Visual Representation Learning.pdf</strong></a></p><p><a href="https://paper.mulindya.com/Co-Tuning%20for%20Transfer%20Learning.pdf"><strong>Co-Tuning for Transfer Learning.pdf</strong></a></p><p><a href="https://paper.mulindya.com/EfficientNet%20Rethinking%20Model%20Scaling%20for%20Convolutional%20Neural%20Networks.pdf"><strong>EfficientNet Rethinking Model Scaling for Convolutional Neural Networks.pdf</strong></a></p><p><a href="https://paper.mulindya.com/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf"><strong>He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf</strong></a></p><p><a href="https://paper.mulindya.com/Simple%20Copy-Paste%20is%20a%20Strong%20Data%20Augmentation%20Method.pdf"><strong>Simple Copy-Paste is a Strong Data Augmentation Method.pdf</strong></a></p><p><a href="https://paper.mulindya.com/Discriminative%20Feature%20Alignment%20Improving%20Transferability%20of.pdf"><strong>Discriminative Feature Alignment Improving Transferability of.pdf</strong></a></p><p><a href="https://paper.mulindya.com/Movement%20Pruning%20adaptive%20sparsity%20by%20fine-tuning.pdf"><strong>Movement Pruning adaptive sparsity by fine-tuning.pdf</strong></a></p><h3 id="FPN">FPN</h3><p><a href="https://paper.mulindya.com/Feature%20Pyramid%20Networks%20for%20Object%20Detection.pdf"><strong>Feature Pyramid Networks for Object Detection</strong></a>（FPN目标检测 解读https://zhuanlan.zhihu.com/p/36461718）</p><h3 id="Transformer">Transformer</h3><p><a href="https://paper.mulindya.com/Feature%20Pyramid%20Networks%20for%20Object%20Detection.pdf"><strong>Attention Is All You Need</strong></a> (讲解Attention机制)</p><p><a href="https://paper.mulindya.com/A%20Survey%20on%20Visual%20Transformer.pdf"><strong>A Survey of Transformers</strong></a>（Transformer的总结）</p><h3 id="VIT">VIT</h3><p><a href="https://paper.mulindya.com/A%20Survey%20on%20Visual%20Transformer.pdf"><strong>AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT</strong></a>（将transformer应用于图像分类）</p><p><a href="https://paper.mulindya.com/How%20to%20train%20your%20ViT.pdf"><strong>How to train your ViT? Data, Augmentation,and Regularization in Vision Transformers</strong></a>（训练技巧）</p><p><a href="https://paper.mulindya.com/Scaling%20Vision%20Transformers.pdf"><strong>Scaling Vision Transformers</strong></a>（精炼VIT）</p><p><a href="https://paper.mulindya.com/levit.pdf"><strong>LeViT: a Vision Transformer in ConvNet’s Clothing for Faster Inference</strong></a> （混合网络）</p><p><a href="https://paper.mulindya.com/End-to-End%20Semi-Supervised%20Object%20Detection%20with%20Soft%20Teacher.pdf"><strong>End-to-End Video Instance Segmentation with Transformers</strong></a>（使用transformer进行实例分割）</p><p><a href="https://paper.mulindya.com/A%20Survey%20on%20Visual%20Transformer.pdf"><strong>A Survey on Visual Transformer</strong></a> （总结）</p><h3 id="EfficientNet">EfficientNet</h3><p><a href="https://paper.mulindya.com/EfficientNet%20Rethinking%20Model%20Scaling%20for%20Convolutional%20Neural%20Networks.pdf"><strong>EfficientNet Rethinking Model Scaling for Convolutional Neural Networks.pdf</strong></a></p><h3 id="BIT">BIT</h3><p><a href="https://paper.mulindya.com/BITGeneral%20Visual%20Representation%20Learning.pdf"><strong>BIT : General Visual Representation Learning.pdf</strong></a></p><h3 id="YOLOv4">YOLOv4</h3><p><a href="https://paper.mulindya.com/yolo4.pdf"><strong>YOLOv4: Optimal Speed and Accuracy of Object Detection</strong></a></p><h3 id="PaDim">PaDim</h3><p><a href="https://paper.mulindya.com/PaDiM_a%20Patch%20Distribution%20Modeling%20Framework.pdf"><strong>PaDiM: a Patch Distribution Modeling Framework for Anomaly Detection and Localization</strong></a> (使用马氏距离)</p><p><a href="https://paper.mulindya.com/Semi-orthogonal%20Embedding%20for%20Efficient%20Unsupervised%20Anomaly%20Segmentation.pdf"><strong>Semi-orthogonal Embedding for Efficient Unsupervised Anomaly Segmentation</strong></a> （很多数学知识）</p><h3 id="Swin">Swin</h3><p><a href="https://paper.mulindya.com/Swin%20Transformer%20Hierarchical%20Vision%20Transformer%20using%20Shifted%20Windows.pdf"><strong>Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</strong></a></p><h3 id="其他">其他</h3><p>谷歌提出的使用MPL代替Transformer，CNN（<a href="https://zhuanlan.zhihu.com/p/370780575">也引发了一些争议</a>）</p><p><a href="https://paper.mulindya.com/MLP-Mixer_An%20all-MLP%20Architecture%20for%20Vision.pdf"><strong>MLP-Mixer: An all-MLP Architecture for Vision</strong></a></p>]]></content>
    
    
    <categories>
      
      <category>文献</category>
      
      <category>整理归纳</category>
      
    </categories>
    
    
    <tags>
      
      <tag>文献</tag>
      
      <tag>整理归纳</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>fine-tuning的方法</title>
    <link href="/2021/08/13/deep_learning/fine-tuning/"/>
    <url>/2021/08/13/deep_learning/fine-tuning/</url>
    
    <content type="html"><![CDATA[<blockquote><p>收集关于深度学习的调参的相关笔记，主要用于网络训练的微调。</p></blockquote><h3 id="训练技巧"><strong>训练技巧</strong></h3><p>1.要做<strong>梯度归一化</strong>,即算出来的梯度除以minibatch size</p><p>2.clip c(梯度裁剪): 限制最大梯度,其实是value = sqrt(w1^2 +w2^2….),如果value超过了阈值,就算一个衰减系数,让value的值等于阈值: 5,10,15</p><p><strong>3.防止过拟合</strong></p><p>​一般常用的防止过拟合方法有使用<strong>L1正则项、L2正则项、dropout、提前终止、数据集扩充等</strong>。如果模型在训练集上表现比较好但在测试集上表现欠佳可以选择增大L1或L2正则的惩罚力度（<strong>L2正则经验上首选1.0</strong>，超过10很少见），或<strong>增大dropout的随机失活概率</strong>（经验首选0.5）；或者当随着训练的持续在测试集上不增反降时，使用提前终止训练的方法。当然<strong>最有效的还是增大训练集的规模</strong>，实在难以获得新数据也可以使用数据集增强的方法，比如CV任务可以对数据集进行裁剪、翻转、平移等方法进行数据集增强，这种方法往往都会提高最后模型的测试精度。<br>dropout对小数据防止过拟合有很好的效果,值一般设为0.5,小数据上dropout+sgd。在大部分实验中，效果提升都非常明显.<strong>建议尝试</strong>。 dropout的位置比较有讲究, 对于RNN,建议放到输入-&gt;RNN与RNN-&gt;输出的位置.关于RNN如何用dropout,可以参考:<a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1409.2329">http://arxiv.org/abs/1409.2329</a>(Captain Jack令言:(不仅仅可以防止过拟合, 其实这相当于做人力成本最低的Ensemble, 当然, 训练起来会比没有Dropout的要慢一点, 同时网络参数你最好相应加一点, 对, 这会再慢一点).)</p><p><strong>4.超参</strong></p><p>​learning rate 最重要**，推荐了解 cosine learning rate 和 cyclic learning rate，其次是 <strong>batchsize 和 weight decay</strong>。当你的模型还不错的时候，可以试着做数据增广和改损失函数锦上添花了。(罗浩ZJU令言：随着网络训练的进行，学习率要逐渐降下来；网络性能越好，学习率要越小（即越需要微调而非粗调)；batchsize通常影响没那么大，塞满卡就行，除了特殊的算法需要batch大一点)<br>​adam,adadelta等,在小数据上,我这里实验的效果不如sgd, sgd收敛速度会慢一些，但是最终收敛后的结果，一般都比较好。<strong>如果使用sgd的话,可以选择从1.0或者0.1的学习率开始,隔一段时间,在验证集上检查一下,如果cost没有下降,就对</strong>学习率减半**. 我看过很多论文都这么搞,我自己实验的结果也很好. 当然,也可以先用ada系列先跑,最后快收敛的时候,更换成sgd继续训练.同样也会有提升.据说adadelta一般在分类问题上效果比较好，adam在生成问题上效果比较好。(Captain Jack令言：sgd adam 这些选择上, 看你个人选择. 一般对网络不是决定性的. 反正我无脑用sgd + momentum. ）</p><p>5.<strong>激活函数</strong><br>除了gate之类的地方,需要把输出限制成0-1之外,<strong>尽量不要用sigmoid</strong>,可以用tanh或者relu之类的激活函数.1. sigmoid函数在-4到4之外的区间梯度接近0，很容易造成梯度消失问题。2. 输入0均值，sigmoid函数的输出不是0均值的。（hzwer令言:虽然有至少十种激活函数，但在 Relu 外只推荐试一下 Swish。)</p><p>6.BN层具有加速训练速度，有效防止梯度消失与梯度爆炸，具有防止过拟合的效果，所以构建网络时最好要加上这个组件。(Captain Jack令言：batch normalization我一直没用, 虽然我知道这个很好, 我不用仅仅是因为我懒. 所以要鼓励使用batch normalization.）</p><p>7.如果你的模型包含全连接层（MLP），并且输入和输出大小一样，可以考虑将MLP替换成<strong>Highway Network</strong>,我尝试对结果有一点提升，建议作为最后提升模型的手段，原理很简单，就是给<strong>输出加了一个gate来控制信息的流动</strong>，详细介绍请参考论文: <a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1505.00387">http://arxiv.org/abs/1505.00387</a></p><p>8.来自@张馨宇的技巧：<strong>一轮加正则，一轮不加正则，反复进行。</strong></p><p><strong>9.Ensemble</strong><br>Ensemble是论文刷结果的终极核武器,深度学习中一般有以下几种方式<br>同样的参数,不同的初始化方式<br>不同的参数,通过cross-validation,选取最好的几组<br>同样的参数,模型训练的不同阶段，即不同迭代次数的模型。<br>不同的模型,进行线性融合. 例如RNN和传统模型.</p><p><strong>10.自动调参方法</strong><br>（1）Grid Search：其原理就像是在数组里找最大值。缺点是太费时间了，特别像神经网络，一般尝试不了太多的参数组合。<br>（2）Random Search：经验上，Random Search比Gird Search更有效。实际操作的时候，一般也是先用Gird Search的方法，得到所有候选参数，然后每次从中随机选择进行训练。另外Random Search往往会和由粗到细的调参策略结合使用，即在效果比较好的参数附近进行更加精细的搜索。<br>（3）Bayesian Optimization：贝叶斯优化，考虑到了不同参数对应的 实验结果值，因此更节省时间，贝叶斯调参比Grid Search迭代次数少， 速度快；而且其针对非凸问题依然稳健。</p><p><strong>11.Loss设计</strong><br>+ 一般来说分类就是Softmax, 回归就是L2的loss. 但是要注意loss的错误范围(主要是回归), 你预测一个label是10000的值, 模型输出0, 你算算这loss多大, 这还是单变量的情况下. 一般结果都是nan. 所以不仅仅输入要做normalization, 输出也要.<br>+ 多任务情况下, 各loss想法限制在一个量级上, 或者最终限制在一个量级上, 初期可以着重一个任务的loss。</p><h3 id="网络结构设计（关于SE"><strong>网络结构设计（关于SE)</strong></h3><p>SE在分类上是个涨点必备的工具，换言之，堆最高精度是一定要给每个block都加上它的，但是如果需要考虑时间，参数量和精度等的trade-off，无脑堆就没有意义了，这个时候应该要选择在合适的地方使用合适的模块。这个时候，<strong>推荐在block数量和添加SE上做权衡</strong>，即<strong>给部分blcok加上SE，同时砍掉一些block来加速</strong>，这样可以在精度差不多的情况下减少一些参数量。当然inference时间这个事需要看具体的应用平台对SE的实现，就是GAP和FC的速度，这就具体问题具体分析了。<strong>有余力有卡的人，可以迁移某种NAS方法来做这个的搜索。</strong><br>参考自：<br>你有哪些deep learning（rnn、cnn）调参的经验？ - 萧瑟的回答 - 知乎 <a href="https://www.zhihu.com/question/41631631/answer/94816420">https://www.zhihu.com/question/41631631/answer/94816420</a><br>你有哪些deep learning（rnn、cnn）调参的经验？ - Towser的回答 - 知乎 <a href="https://www.zhihu.com/question/41631631/answer/862075836">https://www.zhihu.com/question/41631631/answer/862075836</a><br>你有哪些deep learning（rnn、cnn）调参的经验？ - 罗浩.ZJU的回答 - 知乎 <a href="https://www.zhihu.com/question/41631631/answer/216788968">https://www.zhihu.com/question/41631631/answer/216788968</a><br>你有哪些deep learning（rnn、cnn）调参的经验？ - 京东白条的回答 - 知乎 <a href="https://www.zhihu.com/question/41631631/answer/776852832">https://www.zhihu.com/question/4163</a></p><blockquote><p>所谓SE：SENet是Squeeze-and-Excitation Networks的简称，拿到了ImageNet2017分类比赛冠军，其效果得到了认可，其提出的SE模块思想简单，易于实现，并且很容易可以加载到现有的网络模型框架中。<em><u>SENet主要是学习了channel之间的相关性，筛选出了针对通道的注意力</u></em>，稍微增加了一点计算量，但是效果比较好。</p></blockquote><p>对于CNN网络来说，其核心计算是卷积算子，其通过卷积核从输入特征图学习到新特征图。从本质上讲，卷积是对一个局部区域进行特征融合，这包括空间上（H和W维度）以及通道间（C维度）的特征融合。</p><p><img src="https://picture.mulindya.com/fine-tuning-pic1.png" alt=""></p><p>卷积实际上是对<u>局部区域</u>进行的特征融合。 这也导致了普通卷积神经网络的感受野不大，当然你也可以设计出更多的通道特征来增加这个，但是这样做导致了计算量大大的增加。因此为了空间上融合更多特征融合，或者是提取多尺度空间信息。也提出了许多不同的方法如Inception网络的多分支结构。对于channel维度的特征融合，卷积操作基本上默认对输入特征图的所有channel进行融合。<u>而SENet网络的创新点在于关注channel之间的关系，希望模型可以自动学习到不同channel特征的重要程度</u>。为此，SENet提出了Squeeze-and-Excitation (SE)模块，如下图所示：</p><p><img src="https://picture.mulindya.com/fine-tuning-pic2.png" alt=""></p><h3 id="反面训诫">反面训诫</h3><p>1.1、一上来就自己动手写模型。<br>建议首先用<strong>成熟的开源项目及其默认配置</strong>（例如 Gluon 对经典模型的各种复现、各个著名模型作者自己放出来的代码仓库）在自己的数据集上跑一遍，在等程序运行结束的时间里仔细研究一下代码里的各种细节，最后再自己写或者改代码。</p><p>1.2、<strong>不推荐做人肉模型设计</strong>，比如把某层卷积改大一点，或者微调一下通道数。除非有特别 insight，不要自己乱设计新组件。</p><p>2、训 RNN 不加 gradient clipping，导致训练一段时间以后 loss 突然变成 Nan。</p><p>3、tying input &amp; output embedding（就是词向量层和输出 softmax 前的矩阵共享参数，在语言模型或机器翻译中常用）时学习率需要设置得非常小，不然容易 Nan。</p><p>4.1、在数据集很大的情况下，一上来就跑全量数据。建议先用 1/100、1/10 的数据跑一跑，对模型性能和训练时间有个底。</p><p>4.2认为网络层数越大越好。参数量什么的都不是大问题，在性能不丢的情况下，网络层数减到最小.（Captain Jack令言：你有95%概率不会使用超过40层的模型. ）</p><p>5、只喜欢漂亮的模型结构，瞧不起调参数的论文/实验报告，<strong>看论文时经常不看超参数设置等细节</strong>。殊不知在自己没有太多资源实验的情况下，实验报告类文章简直是业界良心！<br>NLP 领域主要推荐以下几篇：<br>Regularizing and Optimizing LSTM Language Models（LSTM 的训练技巧）<br>Massive Exploration of Neural Machine Translation Architectures（NMT 里各个超参的影响）<br>Training Tips for the Transformer Model（训练 Transformer 时会发生的各种现象）<br>RoBERTa: A Robustly Optimized BERT Pretraining Approach（BERT 预训练技巧，虽然跟大部分人没啥关系）<br>CV 我不算太熟，不过也可以勉强推荐几篇：</p><p><a href="https://arxiv.org/pdf/1706.02677.pdf">Training ImageNet in 1 Hour（大批量训练技巧）</a><br><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf">Bag of Tricks for Image Classification with Convolutional Neural Networks（各种训练技巧集大成）</a><br><a href="https://arxiv.org/pdf/1905.11946.pdf">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks（当前对参数利用最有效的 CNN）</a></p><p>6、对于loss这种受 batch size、sequence length 各种因素影响的数字，人是没有数感的，建议首先计算一下 per token loss（如果是多任务，可以每个任务单独算；类似地，某些 CV 任务可以计算 per pixel loss），心里有点感觉。<strong>脱离损失函数的形式谈学习率没有意义</strong>（例如单是对 batch size 求和或者取平均这个差异就会使梯度差成百上千倍）。<br>在确定初始学习率的时候，从一个很小的值（例如 1e-7）开始，然后**每一步指数增大学习率（例如扩大1.05 倍）进行训练。**训练几百步应该能观察到损失函数随训练步数呈对勾形，选择损失下降最快那一段的学习率即可。<br>(Captain Jack令言：<strong>观察loss胜于观察准确率</strong><br>准确率虽然是评测指标, 但是训练过程中还是要注意loss的. 你会发现有些情况下, 准确率是突变的, 原来一直是0, 可能保持上千迭代, 然后突然变1. 要是因为这个你提前中断训练了, 只有老天替你惋惜了. 而loss是不会有这么诡异的情况发生的, 毕竟优化目标是loss.<br>给NN一点时间, 要根据任务留给NN的学习一定空间. 不能说前面一段时间没起色就不管了. 有些情况下就是前面一段时间看不出起色, 然后开始稳定学习.）</p><p>7.1、优化器<strong>只推荐</strong> Momentum 和 Adam。在这些方面做尝试意义不大，如果性能提升反倒可能说明模型不成熟。</p><p>7.2、<strong>Adam 可以解决一堆奇奇怪怪的问题</strong>（有时 loss 降不下去，换 Adam 瞬间就好了），<strong>也可以带来一堆奇奇怪怪的问题</strong>（比如单词词频差异很大，当前 batch 没有的单词的词向量也被更新；再比如Adam和L2正则结合产生的复杂效果）。用的时候要胆大心细，万一遇到问题找各种魔改 Adam（比如 <a href="https://www.zhihu.com/question/265357659/answer/580469438">MaskedAdam</a>, AdamW 啥的）抢救。</p><p>8、subword 总是会很稳定地涨点，只管用就对了。</p><p>9、<strong>GPU 上报错时尽量放在 CPU 上重跑</strong>，错误信息更友好。例如 “ERROR:tensorflow:Model diverged with loss = NaN” 其实很有可能是输入 ID 超出了 softmax 词表的范围。</p><p><strong>10、别没耐心</strong>！<br>**有些指标是有滞后性的，需要等训练一段时间才开始动。**很多人训练几步看没什么效果就把程序停掉开始 debug 了，但其实代码毫无问题。如此反复好几天甚至一两周都在原地踏步，其实需要做的仅仅是让程序自个儿安安静静地跑上几个小时或者一天……</p><h3 id="相关trick">相关trick</h3><ul><li><p>fine-tuning: 通常来说，直接把预训练模型来用效果不一定足够好，因此需要进行fine-tuning（微调）。fine-tuning需要冻结网络的前几层参数，只更新网络结构的后面几层和最后的全连接层，这样效果会更好。</p></li><li><p>Learning rate:在迁移学习的微调过程中一般不建议使用过大的学习率，通常来说1e-5是比较合适的选择。</p></li></ul><h4 id="迁移学习往往还和你的任务中的数据关系密切，可以考虑以下几种情况。">迁移学习往往还和你的任务中的数据关系密切，可以考虑以下几种情况。</h4><ul><li><h5 id="新的数据集较小，并且和pre-trained-model所使用的训练数据集相似度较高">新的数据集较小，并且和pre-trained model所使用的训练数据集相似度较高</h5><p>由于数据集较小，在进行finetune存在overfit的风险，又由于数据集和原始数据集相似度较高，因此二者不论是local feature还是global feature都比较相   近，所以此时最佳的方法是把CNN网络当做特征提取器然后训练一个分类器进行分类</p></li><li><h5 id="新的数据集较大，并且和pre-trained-model所使用的训练数据集相似度较高：">新的数据集较大，并且和pre-trained model所使用的训练数据集相似度较高：</h5><p>很明显，此时我们不用担心overfit，因此对全部网络结构进行fine-tune是较好的。</p></li><li><h5 id="新的数据集较小，并且和pre-trained-model所使用的训练数据集差异很大：">新的数据集较小，并且和pre-trained model所使用的训练数据集差异很大：</h5><p>由于数据集较小，不适合进行fine-tune，由于数据集差异大，应该在单独训练网络结构中较高的层，前面几层local的就不用训练了，直接固定权值。在实际中，这种问题下较好的解决方案一般是从网络的某层开始取出特征，然后训练SVM分类器。</p></li><li><h5 id="新的数据集较大，并且和pre-trained-model所使用的训练数据集差异很大：">新的数据集较大，并且和pre-trained model所使用的训练数据集差异很大：</h5><p>本来由于数据集较大，可以从头开始训练的，但是在实际中更偏向于训练整个pre-trained model的网络。</p></li></ul><p>​</p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>微调</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>梯度裁剪</title>
    <link href="/2021/08/12/deep_learning/gradient-clip/"/>
    <url>/2021/08/12/deep_learning/gradient-clip/</url>
    
    <content type="html"><![CDATA[<blockquote><p>阅读代码 optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))，就此探究一下grap_clip。他的作用是梯度裁剪，为了防止梯度爆炸。其中max_norm是最大梯度阈值，norm_type是指定的范数类型。</p></blockquote><h2 id="梯度爆炸">梯度爆炸</h2><p>梯度爆炸就是在梯度更新的时候偏导数很大，导致更新参数无法收敛到最值（总是跳到其他不好的地方）。</p><p>$$<br>w_1=w_1− \alpha \frac{∂J(w)}{∂w1}<br>$$</p><p>$$<br>w_2=w_2− \alpha \frac{∂J(w)}{∂w2}<br>$$</p><p><img src="https://picture.mulindya.com/gradient-exp-pic1.png" alt=""></p><h2 id="梯度裁剪">梯度裁剪</h2><p>梯度裁剪是解决<strong>梯度爆炸</strong>的一种高效的方法，这里介绍梯度裁剪（Gradient Clipping）的方法，对梯度进行裁剪，论文提出对梯度的L2范数进行裁剪，也就是所有参数偏导数的平方和再开方。<br>$$<br>g_1=\frac{∂J(w)}{∂w1}<br>$$</p><p>$$<br>g_2=\frac{∂J(w)}{∂w2}<br>$$</p><p>设定裁剪阈值为 C = max_norm，$\Vert g\Vert_2= \sqrt{g<sup>2_1+g</sup>2_2}$</p><p>当$\Vert g\Vert_2$大于c时：</p><p>$$<br>g = \frac{c}{\Vert g \Vert_2} \cdot g<br>$$<br>当$\Vert g\Vert_2$小于等于C时：g不变。其中，$\frac{c}{\Vert g \Vert_2}$是一个标量</p><h2 id="总结">总结</h2><p>训练模型出现Loss值出现跳动，一直不收敛时，除了设小学习率之外，梯度裁剪也是一个好方法。</p><p>然而效果不佳时，那这就跟学习率和梯度爆炸没啥关系了。因此，<strong>学习率</strong>的设定和<strong>梯度裁剪</strong>的阈值并不能提高模型的准确率</p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习，梯度</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer05 替换空格</title>
    <link href="/2021/08/11/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer05/"/>
    <url>/2021/08/11/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer05/</url>
    
    <content type="html"><![CDATA[<blockquote><p>替换空格</p></blockquote><h2 id="题目">题目</h2><p>请实现一个函数，把字符串 <code>s</code> 中的每个空格替换成"%20"。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight perl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs perl">输入：s = <span class="hljs-string">"We are happy."</span><br>输出：<span class="hljs-string">"We%20are%20happy."</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>0 &lt;= s 的长度 &lt;= 10000</li></ul><h2 id="题解">题解</h2><p>直接替换即可。相当于使用replace方法</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">replaceSpace</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">str</span>:</span><br>       <span class="hljs-comment">#相当于现成函数 return s.replace(" ","%20")</span><br>        result = <span class="hljs-string">""</span><br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> s:<br>            <span class="hljs-keyword">if</span> x==<span class="hljs-string">' '</span>:<br>                x = <span class="hljs-string">"%20"</span><br>            result += x<br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>字符串</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>字符串</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer04 二维数组中的查找</title>
    <link href="/2021/08/11/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer04/"/>
    <url>/2021/08/11/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer04/</url>
    
    <content type="html"><![CDATA[<blockquote><p>二维数组中的查找</p></blockquote><h2 id="题目">题目</h2><p>在一个 n * m 的二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个高效的函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。</p><h3 id="示例-1：">示例 1：</h3><p>现有矩阵 matrix 如下：</p><figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs json">[<br>  [<span class="hljs-number">1</span>,   <span class="hljs-number">4</span>,  <span class="hljs-number">7</span>, <span class="hljs-number">11</span>, <span class="hljs-number">15</span>],<br>  [<span class="hljs-number">2</span>,   <span class="hljs-number">5</span>,  <span class="hljs-number">8</span>, <span class="hljs-number">12</span>, <span class="hljs-number">19</span>],<br>  [<span class="hljs-number">3</span>,   <span class="hljs-number">6</span>,  <span class="hljs-number">9</span>, <span class="hljs-number">16</span>, <span class="hljs-number">22</span>],<br>  [<span class="hljs-number">10</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>, <span class="hljs-number">17</span>, <span class="hljs-number">24</span>],<br>  [<span class="hljs-number">18</span>, <span class="hljs-number">21</span>, <span class="hljs-number">23</span>, <span class="hljs-number">26</span>, <span class="hljs-number">30</span>]<br>]<br></code></pre></td></tr></tbody></table></figure><p>给定 target = <code>5</code>，返回 <code>true</code>。</p><p>给定 target = <code>20</code>，返回 <code>false</code>。</p><h3 id="提示：">提示：</h3><ul><li>0 &lt;= n &lt;= 1000</li><li>0 &lt;= m &lt;= 1000</li></ul><h2 id="题解">题解</h2><p>当开始想要采用二分法的思想进行判断。但是发现二分只能考虑到左上和右下块的内容。右上和左下的内容无法判断其大小划分。所以会有视觉盲区无法二分缩小区域。</p><p><font color="purple">二维数组无法用二分法，因为其“二分”是分为4份，无法充分涵盖进行判断，会出现错误。</font></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">findNumberIn2DArray</span>(<span class="hljs-params">self, matrix: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">bool</span>:</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span>(matrix): <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>        si,sj = <span class="hljs-number">0</span>,<span class="hljs-number">0</span><br>        ei,ej = <span class="hljs-built_in">len</span>(matrix)-<span class="hljs-number">1</span>,<span class="hljs-built_in">len</span>(matrix[<span class="hljs-number">0</span>])-<span class="hljs-number">1</span><br>        <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">isExit</span>(<span class="hljs-params">matrix: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]], si, sj, ei, ej, target: <span class="hljs-built_in">int</span></span>):</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> (si&lt;=ei <span class="hljs-keyword">and</span> sj&lt;=ej): <span class="hljs-comment">#先判断范围</span><br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>            <span class="hljs-keyword">if</span>(target&lt;matrix[si][sj] <span class="hljs-keyword">or</span> target&gt;matrix[ei][ej]): <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>            <span class="hljs-keyword">if</span>(target==matrix[si][sj] <span class="hljs-keyword">or</span> target==matrix[ei][ej]): <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>            mi,mj = <span class="hljs-built_in">int</span>((si+ei)/<span class="hljs-number">2</span>),<span class="hljs-built_in">int</span>((sj+ej)/<span class="hljs-number">2</span>)<br>            <span class="hljs-keyword">if</span>(target==matrix[mi][mj]):<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>            <span class="hljs-keyword">elif</span> (target&gt;matrix[mi][mj]):<br>                <span class="hljs-keyword">return</span> isExit(matrix,mi+<span class="hljs-number">1</span>,mj,ei,ej,target) <span class="hljs-keyword">or</span> isExit(matrix,mi,mj+<span class="hljs-number">1</span>,ei,ej,target)<br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">return</span> isExit(matrix,si,sj,mi-<span class="hljs-number">1</span>,mj,target) <span class="hljs-keyword">or</span> isExit(matrix,si,sj,mi,mj-<span class="hljs-number">1</span>,target)<br>        <span class="hljs-keyword">return</span> isExit(matrix,si,sj,ei,ej,target)<br></code></pre></td></tr></tbody></table></figure><p>使用线性查找的方法，可以使得复杂度从暴力的O(n*m)到O(n+m)<br>思想是选取左下角或者右上角，周围不均衡的点开始进行判断，这样才知道应该向哪个方向缩小区域.</p><p><font color="hotpink">例如此处是选取左下角作为初始，向上此列逐渐变小，向右此行逐渐变大。因此target如果比此点小，就向上移动查找，如果比此点大，就向右查找。</font></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">findNumberIn2DArray</span>(<span class="hljs-params">self, matrix: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">bool</span>:</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span>(matrix): <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>        i,j = <span class="hljs-built_in">len</span>(matrix)-<span class="hljs-number">1</span>,<span class="hljs-number">0</span><br>        <span class="hljs-keyword">while</span>(i&gt;=<span class="hljs-number">0</span> <span class="hljs-keyword">and</span> j&lt;=<span class="hljs-built_in">len</span>(matrix[<span class="hljs-number">0</span>])-<span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">if</span>(target==matrix[i][j]):<span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>            <span class="hljs-keyword">elif</span>(target&gt;matrix[i][j]):j += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:i -= <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>数组</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>idea</tag>
      
      <tag>数组查找</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer03 数组中重复的数字</title>
    <link href="/2021/08/11/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer03/"/>
    <url>/2021/08/11/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer03/</url>
    
    <content type="html"><![CDATA[<blockquote><p>数组中重复的数字</p></blockquote><h2 id="题目">题目</h2><p>找出数组中重复的数字。</p><p>在一个长度为 n 的数组 nums 里的所有数字都在 0～n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight accesslog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">输入：<br><span class="hljs-string">[2, 3, 1, 0, 2, 5, 3]</span><br>输出：<span class="hljs-number">2</span> 或 <span class="hljs-number">3</span> <br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>2 &lt;= n &lt;= 100000</li></ul><h2 id="题解">题解</h2><p>创建一个flag数组进行标记；</p><p>指定大小的数组创建</p><p><strong>填坑：</strong> <font color="red"> 不要使用后者,因为后者是浅拷贝，改变某一元素，该列均会改变</font></p><ul><li><p>一维</p><p>a = [0 for _ in range(n)]  《=》  a = [0] * n</p></li><li><p>二维</p><p>a = [[0 for col in range(m)] for row in range(n)]  <em># 创建一个n*m的二维矩阵a，每个初值都是0</em>   《=》  a = [[0] *m] *n</p></li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">findRepeatNumber</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        flag = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(nums))] <span class="hljs-comment">#创建长度为nums的数组 也可以用[0]*n</span><br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> nums:<br>            flag[x] += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span>(flag[x]&gt;<span class="hljs-number">1</span>):<br>                <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></tbody></table></figure><p><font color="purple" size="4">实际上无需构建新的数组进行标记，可以直接使用set的长度进行判断。或者使用sort，使用list的sort方法。判断相邻的元素是否相等。</font></p><p>方法1：利用python set的无序不重复特性：利用Python中的set集合为无序不重复集合，通过判断temp_set的长度确定是否是重复数字。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">findRepeatNumber</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        temp_set = <span class="hljs-built_in">set</span>()<br>        repeat = -<span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(nums)):<br>            temp_set.add(nums[i])<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(temp_set) &lt; i + <span class="hljs-number">1</span>:<br>                repeat = nums[i]<br>                <span class="hljs-keyword">break</span><br>        <span class="hljs-keyword">return</span> repeat<br></code></pre></td></tr></tbody></table></figure><p>方法2：利用python的sort函数排序，然后计算相邻两个数据是否相等即可。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">findRepeatNumber</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        nums.sort()<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(nums)-<span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">if</span> nums[i]==nums[i+<span class="hljs-number">1</span>]:<br>                <span class="hljs-keyword">return</span> nums[i]<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>数组</category>
      
    </categories>
    
    
    <tags>
      
      <tag>剑指</tag>
      
      <tag>数组</tag>
      
      <tag>idea</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>dvc相关设置</title>
    <link href="/2021/08/10/config/dvc/dvc-config/"/>
    <url>/2021/08/10/config/dvc/dvc-config/</url>
    
    <content type="html"><![CDATA[<p>运行 sh <a href="http://setup.sh">setup.sh</a> detection报错：</p><blockquote><p>(base) root@9b1a4b217508:/workspace/fanmeilin/project/task/ai_lab# sh <a href="http://setup.sh">setup.sh</a> detection<br><a href="http://setup.sh">setup.sh</a>: 12: <a href="http://setup.sh">setup.sh</a>: dvc: not found<br>cp: failed to get attributes of ‘assets/examples’: No such file or directory<br>[*] copy DETECTION skeleton scripts to upper directory</p></blockquote><p>原因是未安装dvc，运行下面的命令安装dvc</p><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">pip</span> install dvc==<span class="hljs-number">2</span>.<span class="hljs-number">3</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">pip</span> install 'dvc[s<span class="hljs-number">3</span>]'<br></code></pre></td></tr></tbody></table></figure><blockquote><p>在Win平台下可能会报错：</p><figure class="highlight subunit"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs subunit"><span class="hljs-keyword">ERROR: </span>Cannot uninstall 'ruamel-yaml'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.<br></code></pre></td></tr></tbody></table></figure><p>此时需要进入python 的lib/site-packages 中删除 ‘ruamel-yaml’ 相关的文件</p></blockquote><p><strong>注意：</strong> dvc 2.3.0 版本与之后的hash计算方法不同，不能混用</p><p>再次执行 sh <a href="http://setup.sh">setup.sh</a> detection报错</p><blockquote><p>ERROR: unexpected error - Cannot connect to host ceph01:80 ssl:default [Name or service not known]: [Errno -2] Name or service not known</p></blockquote><p>则修改etc/hosts文件</p><ul><li>配置hosts文件，在hosts文件中增加以下内容<br><code>192.168.10.91 ceph01</code></li></ul><h5 id="详细dvc的各种操作，可移步-师兄博客-DVC-使用手册"><em>详细dvc的各种操作，可移步</em> <a href="https://www.zywvvd.com/2020/12/17/dvc/dvc/">师兄博客 DVC 使用手册</a></h5>]]></content>
    
    
    <categories>
      
      <category>配置</category>
      
      <category>dvc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>dvc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>docker的ssh相关配置</title>
    <link href="/2021/08/10/config/docker/docker-ssh/"/>
    <url>/2021/08/10/config/docker/docker-ssh/</url>
    
    <content type="html"><![CDATA[<blockquote><p>参考师兄博客：<a href="https://www.zywvvd.com/2020/11/02/windows/win_ssh_linux_docker/win_ssh_linux_docker/">https://www.zywvvd.com/2020/11/02/windows/win_ssh_linux_docker/win_ssh_linux_docker/</a></p></blockquote><blockquote><p>ssh是较可靠，专为远程登录会话和其他网络服务提供安全性的协议，广泛用于远程登录的场景，也是远程调试代码的神兵利器。在开发中经常会在服务器启动自己的 docker 容器进行开发，又需要调试代码，vim的调试环境配置起来门槛又太高。于是就有了使用Windows直接ssh打通docker进行调试的需求。本文记录Windows远程登录Linux服务器docker容器的方法。</p></blockquote><h2 id="环境说明">环境说明</h2><ul><li>登录主机操作系统 Win 10</li><li>被登录主机操作系统 docker container in Linux</li><li>主机与被登录主机（此处指服务器，不是docker）网络联通，IP在同一网段</li><li>服务器与docker的IP在同一网段</li></ul><h2 id="配置方法">配置方法</h2><h3 id="建立docker与Linux服务器的端口映射">建立docker与Linux服务器的端口映射</h3><blockquote><p>ssh协议链接时默认使用22端口，Windows与docker的端口往往不能直接进行映射（很可能不在一个网段），因此需要将docker的22端口映射到Linux服务器的某个端口，此时需要在建立docker容器时进行<a href="https://www.zywvvd.com/2020/05/14/coding/environment/wingide-remote-docker/wingide-remote-docker/#docker%E9%85%8D%E7%BD%AE">配置</a>：</p></blockquote><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">$ docker run -it --name vvd -p <span class="hljs-number">3721</span>:<span class="hljs-number">22</span> -v <span class="hljs-regexp">/root/</span>tmp:<span class="hljs-regexp">/root/</span>tmp my_docker bash<br></code></pre></td></tr></tbody></table></figure><ul><li>其中 <code>-p</code> 的部分表示将本机（服务器）的3721端口映射到容器的22端口。</li></ul><h3 id="容器内部安装ssh服务">容器内部安装ssh服务</h3><blockquote><p>需要在被登录的容器内部建立并启动ssh服务。</p></blockquote><ul><li>首先需要安装：</li></ul><figure class="highlight routeros"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">apt-<span class="hljs-builtin-name">get</span> update<br>apt-<span class="hljs-builtin-name">get</span> install openssh-server<br>apt-<span class="hljs-builtin-name">get</span> install openssh-client<br></code></pre></td></tr></tbody></table></figure><ul><li>安装完成后需要容器每次启动时自动运行相关服务，可以在 <code>~/.bashrc</code>中加入：</li></ul><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">/etc/i</span>nit.d/ssh start<br></code></pre></td></tr></tbody></table></figure><blockquote><p>这样就保证了docker容器自动启动该服务。</p></blockquote><ul><li>查看ssh运行状态</li></ul><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">/etc/i</span>nit.d/ssh status<br></code></pre></td></tr></tbody></table></figure><blockquote><p>如果是 <code>* sshd is running</code> 说明ssh正常运行</p></blockquote><h3 id="修改容器内root用户登录设置">修改容器内root用户登录设置</h3><blockquote><p>有的容器默认不支持root用户远程使用ssh协议进行密码登录的，此时需要更改设置。</p></blockquote><ul><li>打开 <code>/etc/ssh/sshd_config</code>文件：</li></ul><figure class="highlight nginx"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-comment"># PermitRootLogin prohibit-password # 默认打开 禁止root用户使用密码登陆，需要将其注释</span><br><span class="hljs-attribute">RSAAuthentication</span> <span class="hljs-literal">yes</span> <span class="hljs-comment">#启用 RSA 认证</span><br>PubkeyAuthentication <span class="hljs-literal">yes</span> <span class="hljs-comment">#启用公钥私钥配对认证方式</span><br>PermitRootLogin <span class="hljs-literal">yes</span> <span class="hljs-comment">#允许root用户使用ssh登录</span><br></code></pre></td></tr></tbody></table></figure><ul><li>将 <code>PermitRootLogin</code> 设置为 yes</li></ul><h3 id="修改root密码">修改root密码</h3><blockquote><p>远程登录时需要使用系统的用户密码，我们就直接使用root用户登录好了，需要设置新建容器的密码：</p></blockquote><figure class="highlight ebnf"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">passwd root</span><br></code></pre></td></tr></tbody></table></figure><h3 id="设置SSH">设置SSH</h3><ul><li><a href="https://www.zywvvd.com/2020/02/23/git/link_github/Git-connect-remote-pos/#%E5%88%9B%E5%BB%BASSH%E5%AF%86%E9%92%A5">本地生成ssh key</a></li><li>将.pub 内容复制粘贴加入到远程 ~/.ssh/authorized_keys</li></ul><h3 id="SSH连接服务器">SSH连接服务器</h3><blockquote><p>需要用户名（被登录端用户）与被登录的主机ip和端口号</p><p>例如： 用户名- root ip：192.168.10.12 端口映射为 3721</p></blockquote><ul><li>linux</li></ul><figure class="highlight nginx"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">ssh</span> root@<span class="hljs-number">192.168.10.12:3721</span><br></code></pre></td></tr></tbody></table></figure><ul><li>Windows</li></ul><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">ssh</span> -p <span class="hljs-number">3721</span> root@<span class="hljs-number">192.168.10.12</span><br></code></pre></td></tr></tbody></table></figure><p><img src="https://photos.zywvvd.com/images_matrixtime/20201102200256.png" alt=""></p><ul><li>如果不清楚Linux系统端口映射配置情况：</li></ul><figure class="highlight excel"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs excel">iptables -<span class="hljs-built_in">t</span> nat -L -<span class="hljs-built_in">n</span><br></code></pre></td></tr></tbody></table></figure><h3 id="X-shell配置">X-shell配置</h3><blockquote><p>命令行ssh登录成功后就可以在X-shell中建立配置信息方便地连接了。</p></blockquote><ul><li>新建会话，填写名称、IP、端口号（我们刚刚配置过的）：</li></ul><p><img src="https://photos.zywvvd.com/images_matrixtime/20201102200522.png" alt=""></p><ul><li>用户身份认证，填入用户名密码（刚刚配置过的）：</li></ul><p><img src="https://photos.zywvvd.com/images_matrixtime/20201102200640.png" alt=""></p><ul><li>随后就可以使用该会话直接登录docker容器了，为远程调试打下了坚实的基础：</li></ul><p><img src="https://photos.zywvvd.com/images_matrixtime/20201102200804.png" alt=""></p><h3 id="填坑">填坑</h3><ul><li><p>ssh: Could not resolve hostname 192.168.10.12:3721: Name or service not known</p><blockquote><p>这是在Windows中使用了Linux格式的SSH登录命令导致的解析错误</p><p>将命令语法更换为Windows的格式即可</p></blockquote></li><li><p>root 用户无论如何密码不被接受</p><blockquote><p>需要在被登录主机 /etc/ssh/sshd_config 中设置：</p><figure class="highlight nginx"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-comment"># PermitRootLogin prohibit-password # 默认打开 禁止root用户使用密码登陆，需要将其注释</span><br><span class="hljs-attribute">RSAAuthentication</span> <span class="hljs-literal">yes</span> <span class="hljs-comment">#启用 RSA 认证</span><br>PubkeyAuthentication <span class="hljs-literal">yes</span> <span class="hljs-comment">#启用公钥私钥配对认证方式</span><br>PermitRootLogin <span class="hljs-literal">yes</span> <span class="hljs-comment">#允许root用户使用ssh登录</span><br></code></pre></td></tr></tbody></table></figure><ul><li>重点：<strong>PermitRootLogin yes</strong></li></ul></blockquote></li><li><p>Connection to 192.168.10.12 closed.</p></li><li><p>或</p></li><li><p>Connection closed by foreign host.</p><blockquote><p>意思是 断开主机链接了，出现这种问题，跟你的IPTABLES，防火墙什么的都没关系。</p><p>造成这个原 因是因为原来连接到SSHD服务器进程的22端口，当你的客户端突然断开时，服务器端的TCP连接就处于一个半打开状态。当下一次同一客户机再次建立 TCP连接时，服务器检测到这个半打开的TCP连接，并向客户机回传一个置位RST的TCP报文，客户机就会显示connection closed by foreign host。<br>这是TCP协议本身的一个保护措施，并不是什么错误，你只要再重新连接服务器就能连上。</p><p>——— <a href="http://www.pooy.net/connection-closed-foreign-host.html">http://www.pooy.net/connection-closed-foreign-host.html</a></p><p>总结一下解决方案： <strong>关机重启</strong></p></blockquote></li></ul><h3 id="关于ssh的相关配置">关于ssh的相关配置</h3><h4 id="修改配置文件">修改配置文件</h4><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">cd <span class="hljs-regexp">/etc/</span>ssh<br>vi ssh_config <span class="hljs-comment">#可设置ssh的默认端口（22）</span><br>vi sshd_config<br></code></pre></td></tr></tbody></table></figure><p>ssh_config和sshd_config都是ssh服务器的配置文件，二者区别在于，前者是针对客户端的配置文件，后者则是针对服务端的配置文件。两个配置文件都允许你通过设置不同的选项来改变客户端程序的运行方式。</p><h4 id="重启ssh服务">重启ssh服务</h4><figure class="highlight ebnf"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">service sshd restart</span><br></code></pre></td></tr></tbody></table></figure><p>如果报错 sshd: unrecognized service 则需要开启ssh服务。</p><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">/etc/i</span>nit.d/ssh start<br></code></pre></td></tr></tbody></table></figure><h2 id="vscode连接远程服务器">vscode连接远程服务器</h2><ul><li><p>正确的ssh服务</p></li><li><p>密码设置完成（passwd root）</p></li></ul><h3 id="安装插件">安装插件</h3><ul><li><p>安装 Remote Development 插件</p><blockquote><p>会自动安装 Remote-WSL / Containers / SSH 等插件。</p></blockquote></li></ul><p><img src="https://photos.zywvvd.com/images_matrixtime/20201028143530.png" alt=""></p><h3 id="配置主机信息">配置主机信息</h3><blockquote><p>ctrl + shift + p</p></blockquote><p><img src="https://photos.zywvvd.com/images_matrixtime/20201028174129.png" alt=""></p><p><img src="https://photos.zywvvd.com/images_matrixtime/20201028175152.png" alt=""></p><figure class="highlight crmsh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">Host Enter<br>  HostName <span class="hljs-number">192.168</span>.<span class="hljs-number">10.15</span><br>  Port <span class="hljs-number">12345</span><br>  <span class="hljs-keyword">User</span> <span class="hljs-title">root</span><br>  IdentityFile ~\.ssh\id_rsa<br>  IdentitiesOnly yes<br></code></pre></td></tr></tbody></table></figure><h3 id="vs-code-连接远程主机">vs code 连接远程主机</h3><p><img src="https://photos.zywvvd.com/images_matrixtime/20201028175324.png" alt=""></p><blockquote><p>之后选择目标主机的操作系统。</p></blockquote><ul><li><p>成功连接到远程主机：</p></li><li><p>打开文件夹运行程序时，选择使用的Python环境：</p></li></ul><h4 id="相对路径的设置">相对路径的设置</h4><p>在读取文件时，可能使用相对路径出现错误。</p><blockquote><p>python 插件设置中没有设置<code>终端执行命令时使用文件的路径代替现在打开的目录</code>。</p></blockquote><h3 id="解决方案">解决方案</h3><ul><li>搜索配置 <code>execute in file</code>：</li></ul><p><img src="https://photos.zywvvd.com/win11-mt/20210717114300.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>配置</category>
      
      <category>docker</category>
      
    </categories>
    
    
    <tags>
      
      <tag>docker</tag>
      
      <tag>远程配置</tag>
      
      <tag>ssh</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>docker相关命令</title>
    <link href="/2021/08/10/config/docker/docker-intro/"/>
    <url>/2021/08/10/config/docker/docker-intro/</url>
    
    <content type="html"><![CDATA[<blockquote><p>简要介绍Docker，记录Docker常用命令使用方法。</p><p>搬运自师兄的博客 又见苍岚 ：<a href="https://www.zywvvd.com/2020/05/06/docker/docker_usage/">https://www.zywvvd.com/2020/05/06/docker/docker_usage/</a></p></blockquote><h3 id="Docker-简介">Docker 简介</h3><blockquote><p>**Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。**Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。</p></blockquote><h3 id="Docker-使用流程">Docker 使用流程</h3><ul><li><a href="https://docs.docker.com/desktop/">安装docker</a></li><li>创建Image</li><li>从Image创建Container</li><li>在Container中工作</li><li>将在Container中做的修改提交给Image</li><li>销毁Container</li></ul><h3 id="命令介绍">命令介绍</h3><ul><li>拉取 image</li></ul><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">docker</span> image pull<span class="hljs-meta"> [docker-url]</span><br></code></pre></td></tr></tbody></table></figure><ul><li>获取docker images 列表</li></ul><figure class="highlight mel"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mel">docker images<br>或<br>docker <span class="hljs-keyword">image</span> <span class="hljs-keyword">ls</span><br></code></pre></td></tr></tbody></table></figure><ul><li>建立container （nvidia docker)</li></ul><figure class="highlight stylus"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">NV_GPU=<span class="hljs-selector-attr">[gpu_num]</span> nvidia-docker run -it --name <span class="hljs-selector-attr">[container_name]</span> --shm-size=<span class="hljs-selector-attr">[shm_size]</span> --rm -v <span class="hljs-selector-attr">[current_dir]</span>:<span class="hljs-selector-attr">[container_dir]</span> -<span class="hljs-selector-tag">p</span> <span class="hljs-selector-attr">[current_port]</span>:<span class="hljs-selector-attr">[container_port]</span> <span class="hljs-selector-attr">[image_name]</span>:<span class="hljs-selector-attr">[image_tag]</span>  <span class="hljs-selector-attr">[command]</span> <br></code></pre></td></tr></tbody></table></figure><p>实例：</p><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">nvidia</span>-docker run -it --name mlfan --shm-size=<span class="hljs-number">10</span>g -v /disk/fanmeilin:/workspace/fanmeilin -p <span class="hljs-number">12345</span>:<span class="hljs-number">22</span> -p <span class="hljs-number">12346</span>:<span class="hljs-number">8080</span> -p <span class="hljs-number">12347</span>:<span class="hljs-number">5678</span> tf-<span class="hljs-number">1</span>.<span class="hljs-number">14</span>-<span class="hljs-number">2</span>.<span class="hljs-number">0</span>-<span class="hljs-number">2</span>.<span class="hljs-number">1</span>:<span class="hljs-number">1</span>.<span class="hljs-number">0</span> bash<br></code></pre></td></tr></tbody></table></figure><p><font color="SlateBlue" size="4">注意不要加 --rm&nbsp; 否则载在container stop之后会自动删除此容器</font></p><blockquote><p>NV_GPU: container中可见的GPU，如果不设置可见所有GPU</p><p>-it: 将容器的 Shell 映射到当前的 Shell，然后你在本机窗口输入的命令，就会传入容器</p><p>–name: 容器名称，如果不设置会随机分配一个名字</p><p>–shm-size: 容器共享内存大小设置。如果不设置默认大小64M，对于需要使用共享内存的情况往往是不够用的，如果设置为10g，这样配置： <code>--ssh-size="10g"</code></p><p>–rm: 容器关闭后自动删除，如果不设置容器不会自动删除</p><p>-v: 驱动器映射，将本机的目录映射到容器的指定文件夹中；需要说明的是，在主机文件夹中的挂载目录在容器中是可见的；需要再说明的是容器启动时主机挂载的目录容器是见不到的；最后说明，容器关闭再打开就可以看到主机挂载的所有文件夹了。</p><p>-p: 暴漏容器的端口到本机的端口上，例如用于ssh连接容器时需要将容器的22端口暴露到主机的端口上(比如3721)，则可以设置 <code>-p 3721:22</code></p><p>image_name, image_tag: 这是docker镜像的名称与标记，如果使用本机镜像可以在docker images列表中查询到</p><p>command: 启动容器后内部执行的第一个命令，一般为 <code>/bin/bash</code></p></blockquote><ul><li>查询container列表</li></ul><figure class="highlight jboss-cli"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">docker container <span class="hljs-keyword">ls</span> <span class="hljs-params">--all</span><br></code></pre></td></tr></tbody></table></figure><blockquote><p>–all: 加上该参数会显示没有在运行的容器，不加的话仅显示运行中的容器</p></blockquote><ul><li>停止指定的容器运行</li></ul><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs inform7">docker <span class="hljs-keyword">container</span> kill <span class="hljs-comment">[containerID]</span><br>docker stop <span class="hljs-comment">[containerID]</span><br></code></pre></td></tr></tbody></table></figure><blockquote><p><code>docker container kill</code>命令终止容器运行，相当于向容器里面的主进程发出 SIGKILL 信号。<code>docker container stop</code>命令相当于向容器里面的主进程发出 SIGTERM 信号，然后过一段时间再发出 SIGKILL 信号。</p></blockquote><ul><li>启动停止的容器</li></ul><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">docker</span> start<span class="hljs-meta"> [containerID]</span><br></code></pre></td></tr></tbody></table></figure><ul><li>重启运行的容器</li></ul><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">docker</span> restart<span class="hljs-meta"> [containerID]</span><br></code></pre></td></tr></tbody></table></figure><ul><li>删除指定的容器文件（仅在停止运行时可用）</li></ul><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs inform7">docker <span class="hljs-keyword">container</span> rm <span class="hljs-comment">[containerID]</span><br></code></pre></td></tr></tbody></table></figure><ul><li>查看容器输出</li></ul><figure class="highlight inform7"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs inform7">docker <span class="hljs-keyword">container</span> logs <span class="hljs-comment">[containerID]</span><br></code></pre></td></tr></tbody></table></figure><ul><li>启动容器的一个终端</li></ul><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">docker exec -it [containerID] <span class="hljs-regexp">/bin/</span>bash<br></code></pre></td></tr></tbody></table></figure><blockquote><p>此种方法启动的终端，即使退出也不会关闭容器</p><p>相反 - 如果直接通过端口映射连接 docker 建立的ssh链接，窗口退出后该终端的工作也会一同停止</p></blockquote><ul><li>进入容器的主终端</li></ul><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">docker</span> attach<span class="hljs-meta"> [containerID]</span><br></code></pre></td></tr></tbody></table></figure><blockquote><p>连接到容器的主终端，该终端退出后容器关闭。</p><p>如果不希望退出后关闭，可以加入选项 <code>--sig-proxy=false</code></p></blockquote><ul><li>退出终端</li></ul><figure class="highlight css"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">ctrl <span class="hljs-selector-tag">p</span> + ctrl <span class="hljs-selector-tag">q</span><br></code></pre></td></tr></tbody></table></figure><blockquote><p>可以在退出终端的同时保持终端继续工作</p></blockquote><ul><li>退出容器</li></ul><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-keyword">exit</span><br></code></pre></td></tr></tbody></table></figure><blockquote><p>在容器中运行此命令</p></blockquote><ul><li>拷贝容器里的文件到本机</li></ul><figure class="highlight gradle"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gradle">docker container cp [containerID]:[<span class="hljs-regexp">/path/</span>to/<span class="hljs-keyword">file</span>]<br></code></pre></td></tr></tbody></table></figure><ul><li>提交容器修改到镜像</li></ul><figure class="highlight css"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">docker commit -<span class="hljs-selector-tag">a</span> <span class="hljs-selector-attr">[name]</span> -m <span class="hljs-selector-attr">[comments]</span> -<span class="hljs-selector-tag">p</span>  <span class="hljs-selector-attr">[containerID[:TAG]</span>]<br></code></pre></td></tr></tbody></table></figure><blockquote><p>-a: 提交的镜像作者</p><p>-m: 提交时的说明文字</p><p>-p: 在commit时，将容器暂停</p></blockquote><ul><li>删除镜像</li></ul><figure class="highlight apache"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">docker</span> rmi<span class="hljs-meta"> [image]</span><br></code></pre></td></tr></tbody></table></figure><blockquote><p>或</p></blockquote><figure class="highlight arduino"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arduino">docker image rm [image]<br></code></pre></td></tr></tbody></table></figure><blockquote><p>支持的子命令如下：</p></blockquote><ul><li><code>-f, -force</code>: 强制删除镜像，即便有容器引用该镜像；</li><li><code>-no-prune</code>: 不要删除未带标签的父镜像；</li></ul><h3 id="参考资料">参考资料</h3><ul><li><a href="http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html">http://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html</a></li><li><a href="https://www.runoob.com/docker/docker-tutorial.html">https://www.runoob.com/docker/docker-tutorial.html</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>配置</category>
      
      <category>docker</category>
      
    </categories>
    
    
    <tags>
      
      <tag>docker</tag>
      
      <tag>远程配置</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer10-2 青蛙跳台阶问题</title>
    <link href="/2021/08/10/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer10-2/"/>
    <url>/2021/08/10/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer10-2/</url>
    
    <content type="html"><![CDATA[<blockquote><p>青蛙跳台阶问题</p></blockquote><h2 id="题目">题目</h2><p>一只青蛙一次可以跳上1级台阶，也可以跳上2级台阶。求该青蛙跳上一个 n 级的台阶总共有多少种跳法。</p><p>答案需要取模 1e9+7（1000000007），如计算初始结果为：1000000008，请返回 1。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight excel"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs excel">输入：<span class="hljs-built_in">n</span> = <span class="hljs-number">2</span><br>输出：<span class="hljs-number">2</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight excel"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs excel">输入：<span class="hljs-built_in">n</span> = <span class="hljs-number">7</span><br>输出：<span class="hljs-number">21</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例3：">示例3：</h3><figure class="highlight excel"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs excel">输入：<span class="hljs-built_in">n</span> = <span class="hljs-number">0</span><br>输出：<span class="hljs-number">1</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>0 &lt;= n &lt;= 100</li></ul><h2 id="题解">题解</h2><p>实际上是斐波那契数列的变种。跳上n级台阶的方法个数 可以分解为：<em>跳上此台阶前的一步是1步还是2步</em>。也就是 $f(n) = f(n-1) + f(n-2)$。</p><p>不同之处在于此时的f(0) = 1</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">numWays</span>(<span class="hljs-params">self, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        a,b = <span class="hljs-number">1</span>,<span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            a,b = b,a+b<br>        <span class="hljs-keyword">return</span> a%<span class="hljs-number">1000000007</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>动态规划</category>
      
    </categories>
    
    
    <tags>
      
      <tag>动态规划</tag>
      
      <tag>剑指</tag>
      
      <tag>idea</tag>
      
      <tag>斐波那契</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer10-1 斐波那契数列</title>
    <link href="/2021/08/10/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer10-1/"/>
    <url>/2021/08/10/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer10-1/</url>
    
    <content type="html"><![CDATA[<blockquote><p>斐波那契数列</p></blockquote><h2 id="题目">题目</h2><p>写一个函数，输入 n ，求斐波那契（Fibonacci）数列的第 n 项（即 F(N)）。斐波那契数列的定义如下：</p><p>$$<br>F(0) = 0,   F(1) = 1 \\<br>F(N) = F(N - 1) + F(N - 2), 其中 N &gt; 1.<br>$$<br>斐波那契数列由 0 和 1 开始，之后的斐波那契数就是由之前的两数相加而得出。</p><p>答案需要取模 1e9+7（1000000007），如计算初始结果为：1000000008，请返回 1。</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight excel"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs excel">输入：<span class="hljs-built_in">n</span> = <span class="hljs-number">2</span><br>输出：<span class="hljs-number">1</span><br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight excel"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs excel">输入：<span class="hljs-built_in">n</span> = <span class="hljs-number">5</span><br>输出：<span class="hljs-number">5</span><br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>0 &lt;= n &lt;= 100</li></ul><h2 id="题解">题解</h2><p>有三种方向：</p><ul><li><p>使用递归</p><p>大量重复计算，时间超时。</p></li><li><p>使用数组存储</p><p>新建长度为n的数组，在递归基础上，存储计算的结果，后直接取用。但是占用了额外的空间$O(n)$</p></li><li><p>使用动态规划</p><p><code>以其公式F(N) = F(N - 1) + F(N - 2)为转移方程。</code></p></li></ul><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fib</span>(<span class="hljs-params">self, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        a,b = <span class="hljs-number">0</span>,<span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            a,b = b,a+b <span class="hljs-comment">#sum = a+b a = b b = sum a相当于f(i) b相当于f(i+1)</span><br>        <span class="hljs-keyword">return</span> a%<span class="hljs-number">1000000007</span><br>    <span class="hljs-comment"># def fib(self, n: int) -&gt; int:</span><br>    <span class="hljs-comment">#     if(n==0): return 0</span><br>    <span class="hljs-comment">#     if(n==1): return 1</span><br>    <span class="hljs-comment">#     return (self.fib(n-1)+self.fib(n-2))%1000000007 #超时 递归时间复杂度大</span><br></code></pre></td></tr></tbody></table></figure><p>循环n次</p><p>注意<code>a,b = b,a+b</code> 相当于sum = a+b ；a = b； b = sum ；</p><p>第i轮中 a相当于f(i)，b相当于f(i+1) 。因此最后返回a</p>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>动态规划</category>
      
    </categories>
    
    
    <tags>
      
      <tag>动态规划</tag>
      
      <tag>剑指</tag>
      
      <tag>斐波那契</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>剑指offer09 用两个栈实现队列</title>
    <link href="/2021/08/10/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer09/"/>
    <url>/2021/08/10/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/leetcode/leetcode-offer09/</url>
    
    <content type="html"><![CDATA[<blockquote><p>用两个栈实现队列</p></blockquote><h2 id="题目">题目</h2><p>用两个栈实现一个队列。队列的声明如下，请实现它的两个函数 appendTail 和 deleteHead ，分别完成在队列尾部插入整数和在队列头部删除整数的功能。(若队列中没有元素，deleteHead 操作返回 -1 )</p><h3 id="示例-1：">示例 1：</h3><figure class="highlight prolog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs prolog">输入：<br>[<span class="hljs-string">"CQueue"</span>,<span class="hljs-string">"appendTail"</span>,<span class="hljs-string">"deleteHead"</span>,<span class="hljs-string">"deleteHead"</span>]<br>[[],[<span class="hljs-number">3</span>],[],[]]<br>输出：[null,null,<span class="hljs-number">3</span>,<span class="hljs-number">-1</span>]<br></code></pre></td></tr></tbody></table></figure><h3 id="示例-2：">示例 2：</h3><figure class="highlight prolog"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs prolog">输入：<br>[<span class="hljs-string">"CQueue"</span>,<span class="hljs-string">"deleteHead"</span>,<span class="hljs-string">"appendTail"</span>,<span class="hljs-string">"appendTail"</span>,<span class="hljs-string">"deleteHead"</span>,<span class="hljs-string">"deleteHead"</span>]<br>[[],[],[<span class="hljs-number">5</span>],[<span class="hljs-number">2</span>],[],[]]<br>输出：[null,<span class="hljs-number">-1</span>,null,null,<span class="hljs-number">5</span>,<span class="hljs-number">2</span>]<br></code></pre></td></tr></tbody></table></figure><h3 id="提示：">提示：</h3><ul><li>1 &lt;= values &lt;= 10000</li><li>最多会对 appendTail、deleteHead 进行 10000 次调用</li></ul><h2 id="题解">题解</h2><p>使用两个栈，<em>一个作为插入栈，一个作为删除栈</em>。<code>使用list进行相关操作（append，pop）</code>；在插入时直接对stack1进行append操作，删除时首先需要构建删除栈内容，再进行判断，最后同步到插入栈中（此时删除栈又为空）。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CQueue</span>:</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-comment"># stack1是insert栈 stack2是delete栈</span><br>        self.stack1 = [] <span class="hljs-comment">#list作用和stack类似</span><br>        self.stack2 = []<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">appendTail</span>(<span class="hljs-params">self, value: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-literal">None</span>:</span><br>        self.stack1.append(value) <span class="hljs-comment"># 直接插入栈顶</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">deleteHead</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">int</span>:</span><br>        <span class="hljs-keyword">while</span> self.stack1: <span class="hljs-comment">#首先更新delete栈</span><br>            self.stack2.append(self.stack1.pop())<br>        <span class="hljs-comment">#进行deleteHead操作</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.stack2: <br>            <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span><br>        popitem = self.stack2.pop()<br>        <span class="hljs-comment"># 将更新结果写回stack1中 保持一致</span><br>        <span class="hljs-keyword">while</span> self.stack2:<br>            self.stack1.append(self.stack2.pop())<br>        <span class="hljs-keyword">return</span> popitem<br><br><span class="hljs-comment"># Your CQueue object will be instantiated and called as such:</span><br><span class="hljs-comment"># obj = CQueue()</span><br><span class="hljs-comment"># obj.appendTail(value)</span><br><span class="hljs-comment"># param_2 = obj.deleteHead()</span><br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>剑指</category>
      
      <category>栈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>栈</tag>
      
      <tag>剑指</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Mahalanobis_distance</title>
    <link href="/2021/08/09/math/Mahalanobis-distance/"/>
    <url>/2021/08/09/math/Mahalanobis-distance/</url>
    
    <content type="html"><![CDATA[<blockquote><p>马氏距离(Mahalanobis Distance)是度量学习中一种常用的距离指标，同欧氏距离、曼哈顿距离、汉明距离等一样被用作评定数据之间的相似度指标。但却可以应对高维线性分布的数据中各维度间非独立同分布的问题。</p></blockquote><p><em>使用马氏距离，对高维非独立分布的数据进行距离度量。</em></p><p><strong>那我们为什么要用马氏距离呢？</strong><br>马氏距离有很多<strong>优点：</strong> <strong>马氏距离不受量纲的影响</strong>，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。<strong>马氏距离还可以排除变量之间的相关性的干扰</strong>。</p><h2 id="什么是马氏距离">什么是马氏距离</h2><p>马氏距离(Mahalanobis Distance)是一种距离的度量，可以看作是欧氏距离的一种修正，修正了欧式距离中各个维度尺度不一致且相关的问题。</p><p>单个数据点的马氏距离</p><p><img src="https://picture.mulindya.com/Mahalanobis-distance-pic1.png" alt=""></p><p>数据点x, y之间的马氏距离</p><p><img src="https://picture.mulindya.com/Mahalanobis-distance-pic2.png" alt=""></p><p><em>其中Σ是多维随机变量的协方差矩阵，μ为样本均值，如果协方差矩阵是单位向量，也就是各维度独立同分布，马氏距离就变成了欧氏距离。</em></p><h2 id="马氏距离实际意义">马氏距离实际意义</h2><p>那么马氏距离就能能干什么？它比欧氏距离好在哪里？举几个栗子</p><p><strong>欧式距离近就一定相似？</strong></p><p>先举个比较常用的例子，身高和体重，这两个变量拥有不同的单位标准，也就是有不同的scale。比如身高用毫米计算，而体重用千克计算，显然差10mm的身高与差10kg的体重是完全不同的。但在普通的欧氏距离中，这将会算作相同的差距。</p><p><strong>归一化后欧氏距离近就一定相似？</strong></p><p>当然我们可以先做归一化来消除这种维度间scale不同的问题，但是样本分布也会影响分类</p><p>举个一维的栗子，现在有两个类别，统一单位，第一个类别均值为0，方差为0.1，第二个类别均值为5，方差为5。那么一个值为2的点属于第一类的概率大还是第二类的概率大？距离上说应该是第一类，但是直觉上显然是第二类，因为第一类不太可能到达2这个位置。</p><p>所以，在一个方差较小的维度下很小的差别就有可能成为离群点。就像下图一样，A与B相对于原点的距离是相同的。但是由于样本总体沿着横轴分布，所以B点更有可能是这个样本中的点，而A则更有可能是离群点。</p><p><img src="https://picture.mulindya.com/Mahalanobis-distance-pic3.png" alt=""></p><p><strong>算上维度的方差就够了？</strong></p><p>还有一个问题——如果维度间不独立同分布，样本点一定与欧氏距离近的样本点同类的概率更大吗？</p><p><img src="https://picture.mulindya.com/Mahalanobis-distance-pic4.png" alt=""></p><p>可以看到样本基本服从f(x) = x的线性分布，A与B相对于原点的距离依旧相等，显然A更像是一个离群点</p><p>即使数据已经经过了标准化，也不会改变AB与原点间距离大小的相互关系。所以要本质上解决这个问题，就要针对<a href="https://link.zhihu.com/?target=https%3A//www.ph0en1x.space/2018/03/06/PCA/">主成分分析</a>中的<code>主成分</code>来进行标准化。</p><h2 id="马氏距离的几何意义">马氏距离的几何意义</h2><p>上面搞懂了，马氏距离就好理解了，<u>只需要将变量<code>按照主成分进行旋转</code>，让维度间相互<strong>独立</strong>，然后进行<code>标准化</code></u>，让维度<strong>同分布</strong>就可以了。</p><p>由主成分分析可知，由于主成分就是特征向量方向，每个方向的方差就是对应的特征值，所以只需要按照特征向量的方向旋转，然后缩放特征值倍就可以了，可以得到以下的结果：</p><p><img src="https://picture.mulindya.com/Mahalanobis-distance-pic5.png" alt=""></p><p>离群点就被成功分离，这时候的欧式距离就是马氏距离。</p><h2 id="马氏距离的推导">马氏距离的推导</h2><p>首先要对数据点进行<em>旋转</em>，旋转至主成分，维度间线性无关，假设新的坐标为</p><p><img src="https://picture.mulindya.com/Mahalanobis-distance-pic6.png" alt=""></p><p>又变换后<em>维度间线性无关且每个维度自己的方差为特征值</em>，所以满足：</p><p><img src="https://picture.mulindya.com/Mahalanobis-distance-pic7.png" alt=""></p><p>马氏距离是旋转变换缩放之后的欧式距离，所以马氏距离的计算公式为：</p><p><img src="https://picture.mulindya.com/Mahalanobis-distance-pic8.png" alt=""></p><p>这就是之前提到的马氏距离的公式</p><h2 id="马氏距离的问题">马氏距离的问题</h2><ul><li>协方差矩阵必须满秩</li></ul><p>里面有求逆矩阵的过程，不满秩不行，要求数据要有原维度个特征值，如果没有可以考虑先进行PCA，这种情况下PCA不会损失信息</p><ul><li>不能处理非线性流形(manifold)上的问题</li></ul><p>只对线性空间有效，如果要处理流形，只能在局部定义，可以用来建立KNN图</p><blockquote><p>参考：</p><p><a href="https://zhuanlan.zhihu.com/p/46626607">https://zhuanlan.zhihu.com/p/46626607</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>math</category>
      
      <category>概率论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>马氏距离</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Eckark_young定理</title>
    <link href="/2021/08/09/math/Eckark-young/"/>
    <url>/2021/08/09/math/Eckark-young/</url>
    
    <content type="html"><![CDATA[<p>最佳低秩逼近和奇异值的关系(<em>Eckart</em>-<em>Young定理</em>)</p><h3 id="定理">定理</h3><p>Suppose a matrix $A\in \mathbb{R}^{m\times n}$has an SVD-decomposition$A=U\Sigma V^T$. Let $k &lt; r= \mathsf{rank}(A)$and truncated matrix<br>$$<br>A_k = \sum_{i=1}^k \sigma_i \mathbf u_i \mathbf v_i^T,<br>$$<br>then, for any matrix B of rank k , the minimal error is achieved with $A_k$:</p>$$\min_{\mathsf{rank}(B)=k}||A-B||_2 = || A - A_k||_2 = \sigma_{k+1}.$$<p>The same holds for Frobenius norm as well</p>$$\min_{\mathsf{rank}(B)=k}||A-B||_F = || A - A_k||_F = \sqrt{\sigma_{k+1}^2 + \cdots + \sigma_p^2}.$$<h3 id="证明-2-norm-case">证明 (2-norm case)</h3><p>Since $U^\ A_k V = \mathrm{diag}(\sigma_1,\ldots, \sigma_k,0,\ldots,0)$ it means that $A_k$ is rank K. Moreover, $U^T (A-A_k) V =  \mathrm{diag}(0,\ldots, 0,\sigma_{k+1},\ldots, \sigma_p)$with the largest singular value is $\sigma_{k+1}$ and thus $||A-A_k||_2 = \sigma_{k+1}$.</p><h3 id="证明-Frobenius-norm-case">证明 (Frobenius norm case)</h3><blockquote><p>Lemma: If $A,B \in \mathbb{R}^{m\times n}$ , with B having rank K , then $\sigma_{k+i}(A) \le \sigma_i(A-B) \text{ for all }; i.$</p></blockquote><p>To prove the lemma, first consider the case i=1, we have proved that $\sigma_{k+1}(A) \le \sigma_1(A-B) = ||A-B||_2$in the 2-norm case. Then we do the general case:</p>$$\begin{aligned} \sigma_i(A-B) = &amp; \sigma_i(A-B) + \sigma_1(B-B_k)\qquad\text{since } B=B_k\\ =&amp; \sigma_1(A-B - (A-B)_{i-1}) + \sigma_1(B-B_k)\qquad\\ \ge &amp; \sigma_1(A-B - (A-B)_{i-1}+B-B_k)   \\ =&amp; \sigma_1(A  - (A-B)_{i-1} -B_k)\\ \ge &amp; \sigma_1(A - A_{k+i-1})\\ =&amp; \sigma_{k+i}(A)   \end{aligned} $$<blockquote><p><a href="https://zhuanlan.zhihu.com/p/361938622">https://zhuanlan.zhihu.com/p/361938622</a></p><p><a href="https://zhuanlan.zhihu.com/p/75283604">https://zhuanlan.zhihu.com/p/75283604</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>math</category>
      
      <category>线性代数</category>
      
    </categories>
    
    
    <tags>
      
      <tag>math</tag>
      
      <tag>线性代数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>低秩逼近的思考</title>
    <link href="/2021/08/06/math/low-rank-app/"/>
    <url>/2021/08/06/math/low-rank-app/</url>
    
    <content type="html"><![CDATA[<blockquote><p>阅读文章<strong>Semi-orthogonal Embedding for Effificient Unsupervised Anomaly Segmentation</strong>时出现一个概念–<strong>Low-rank approximation</strong> ，就此进行相关讨论。</p></blockquote><h3 id="低秩（Low-Rank）">低秩（Low-Rank）</h3><p>如果X是一个m行n列的数值矩阵，rank(X)是X的秩，假如rank (X)远小于m和n，则我们称X是低秩矩阵。低秩矩阵每行或每列都可以用其他的行或列线性表出，可见它包含大量的冗余信息。利用这种冗余信息，可以对缺失数据进行恢复，也可以对数据进行特征提取。</p><p>图像处理中，<em>rank可以理解为图像所包含的信息的丰富程度</em>，在显示生活中，一张图片中大部分成分是相似的。比如给一张大草原的图片</p><p><img src="https://picture.mulindya.com/low-rank-app-pic1.png" alt=""></p><p>草原是由很多草组成的，而草是相似的，所以如果全是草，那么这张图所包含的信息量是很少的的，因为可以理解为草是草的复制品。而上图的蒙古包，人，马之类的则可以理解为图片所包含的信息，实际上，相对于只有草的草原图片和有草和蒙古包的草原图片，后者的秩是较高的。也就是说，图片中比较突兀的成分，比如蒙古包，比如人像照片中的红眼亮点，会增加图像矩阵的秩。而现实生活中一张不错的图片的秩其实是比较低的，如果图像的秩比较高，往往是因为图像中的噪声比较严重。比如拍照的时候ISO感光度设置过高造成噪点太过泛滥之类的。所以，<em>图像处理的低秩性其实可以拿来去除照片中的噪点</em>。</p><h3 id="低秩和稀疏">低秩和稀疏</h3><p>我们认为图像有一些公共的模式，所有图像都由这些基本的模式组成。例如，如果图像是一个叉，可以看成是一个正斜线和反斜线的叠加。<strong>只要我们找到了所有的基底（称作字典</strong>，就是上面说的正斜线和反斜线之类的东西）**，就能通过基底的线性组合表示出所有的图像。**这就好像学画画，先学会基本的画正方体、球体、圆柱体等等，就可以组合出各种各样的复杂形状。</p><p><strong>在很多情形下，基底的数量是很少的</strong>，比如一张照片拍的是一面砖墙，那么它显然具有周期重复的特点，换句话说低秩。即使整个图不低秩，往往也能找出一些相似的块，这些块是低秩的。再退一步，就算这也做不到，往往也可以把已有的数据看成一组低维的结果加上噪声，也即原来的数据<strong>可以被低秩矩阵很好的逼近</strong>。<strong>稀疏性</strong>的意思是（以稀疏表示为例），任给一个图像，<strong>字典可能是过完备的</strong>，从而用字典里的基向量表出这幅图有很多种不同的方案。我们希望<strong>选取使用基底数量最少的那种方案</strong>，</p><p>应用：</p><p><em><strong>1）矩阵填充(Matrix Completion)</strong></em></p><p><em><strong>2）鲁棒PCA</strong></em></p><p><em><strong>3）背景建模</strong></em></p><p><em><strong>4）变换不变低秩纹理（TILT）</strong></em></p><blockquote><p>在论文 <strong>Semi-orthogonal Embedding for Effificient Unsupervised Anomaly Segmentation</strong>中有一段可以参考。</p></blockquote><p><strong>Low-rank approximation of precision matrix</strong></p><p>The feature data <strong>X</strong> is subject to low-rank approximation due to the narrower target domain for anomaly-free images than the ImageNet dataset’s. The multi-scale features from different layers may also contribute to it due to the inter-dependency among the features from the layers. Inspired by the truncated SVD of a precision matrix, a low-rank embedding of input features with $W \in R^{F \times k}$,where <em>F &gt; k</em>, is considered as follows:</p>$$d^2_{i,j} = X^TW(W^TC_{i,j}W)^{−1}W^TX$$<p>where the below Theorem 1 shows the optimal <strong>W</strong>* is the eigenvectors related to the <em>k</em>-smallest eigenvalues of $C_{i,j}$ . Notice that 1) the computational complexity of the equation is cubically reduced to <em>O</em>($HWk^3$) set aside the cost of SVD, although which is the concern, 2) PCA embedding would fail to minimize approximation error since it uses the <em>k</em>-largest eigenvectors [14], and 3) near-zero eigenvalues may induce substantial anomaly scores.</p><p>选取协方差矩阵的k个最小的特征值对应的特征向量，进行低秩逼近</p><blockquote><p>参考</p><p><a href="https://www.zhihu.com/question/28630628">https://www.zhihu.com/question/28630628</a></p><p><a href="https://blog.csdn.net/zouxy09/article/details/24972869">https://blog.csdn.net/zouxy09/article/details/24972869</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>math</category>
      
      <category>线性代数</category>
      
    </categories>
    
    
    <tags>
      
      <tag>math</tag>
      
      <tag>线性代数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>子模块为空的解决方案</title>
    <link href="/2021/08/06/config/git-submodule/"/>
    <url>/2021/08/06/config/git-submodule/</url>
    
    <content type="html"><![CDATA[<blockquote><p>针对子模块文件夹为空的情况，采取下列解决方案。</p><p>当一个 git 项目包含子模块（submodule) 时，直接克隆下来的子模块目录里面是空的。</p></blockquote><p><strong>有两种方法解决</strong>：</p><h3 id="方法一">方法一</h3><p>如果项目已经克隆到了本地，执行下面的步骤：</p><ol><li><p>初始化本地子模块配置文件</p><figure class="highlight csharp"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs csharp">git submodule <span class="hljs-keyword">init</span><br></code></pre></td></tr></tbody></table></figure></li><li><p>更新项目，抓取子模块内容。</p><figure class="highlight ebnf"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">git submodule update</span><br></code></pre></td></tr></tbody></table></figure></li><li><p>进入对应子模块目录，执行</p><figure class="highlight brainfuck"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs brainfuck"><span class="hljs-comment">git</span> <span class="hljs-comment">submodule</span> <span class="hljs-comment">update</span> --<span class="hljs-comment">init</span> --<span class="hljs-comment">recursive</span><br></code></pre></td></tr></tbody></table></figure></li></ol><h3 id="方法二">方法二</h3><p>另外一种更简单的方法，就是在执行 <code>git clone</code> 时加上 <code>--recursive</code> 参数。它会自动初始化并更新每一个子模块。例如：</p><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">git clone --recursive https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/example/</span>example.git<br></code></pre></td></tr></tbody></table></figure>]]></content>
    
    
    <categories>
      
      <category>配置</category>
      
      <category>git</category>
      
    </categories>
    
    
    <tags>
      
      <tag>配置</tag>
      
      <tag>git</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo中公式显示</title>
    <link href="/2021/08/05/config/hexo-math-config/"/>
    <url>/2021/08/05/config/hexo-math-config/</url>
    
    <content type="html"><![CDATA[<blockquote><p>公式的显示问题。Hexo中Mathjax是用于显示公式的插件，但是多行显示会出现问题，有时还会出现乱码的情况。</p></blockquote><h3 id="配置">配置</h3><p>在根目录下的config_fluid.yml​文件中打开math的相关配置。</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># 数学公式，开启之前需要更换 Markdown 渲染器，否则复杂公式会有兼容问题，具体请见：https://hexo.fluid-dev.com/docs/guide/##latex-数学公式</span><br><span class="hljs-comment"># Mathematical formula. If enable, you need to change the Markdown renderer, see: https://hexo.fluid-dev.com/docs/en/guide/#math</span><br><span class="hljs-attr">math:</span><br>  <span class="hljs-comment"># 开启后文章默认可用，自定义页面如需使用，需在 Front-matter 中指定 `math: true`</span><br>  <span class="hljs-comment"># If you want to use math on the custom page, you need to set `math: true` in Front-matter</span><br>  <span class="hljs-attr">enable:</span> <span class="hljs-literal">true</span><br><br>  <span class="hljs-comment"># 开启后，只有在文章 Front-matter 里指定 `math: true` 才会在文章页启动公式转换，以便在页面不包含公式时提高加载速度</span><br>  <span class="hljs-comment"># If true, only set `math: true` in Front-matter will enable math, to load faster when the page does not contain math</span><br>  <span class="hljs-attr">specific:</span> <span class="hljs-literal">true</span><br><br>  <span class="hljs-comment"># Options: mathjax | katex</span><br>  <span class="hljs-attr">engine:</span> <span class="hljs-string">mathjax</span><br><br></code></pre></td></tr></tbody></table></figure><h3 id="出现的问题">出现的问题</h3><h4 id="问题1">问题1</h4><ul><li>由于hexo解码时关注，%% 等连续字符，会将这部分代码解读为其他带有特殊含义的内容</li><li>如果公式中恰巧出现了此类字符，会报出上述错误</li></ul><h4 id="问题2">问题2</h4><ul><li>由于hexo在公式中的<code>\\</code>错会成了转义符，也就是说他只看见了一个反斜杠，不会执行换行命令，导致公式堆成一行</li></ul><h3 id="解决方案">解决方案</h3><h4 id="临时方案">临时方案</h4><h5 id="针对问题1">针对问题1</h5><ul><li>可以在连续的 <code>{</code> <code>}</code> <code>%</code>中间插入空格，分开就没事了</li></ul><h5 id="针对问题2">针对问题2</h5><ul><li>可以将<code>\\</code>换成<code>\\\\</code>，可以实现公式的多行正确显示</li></ul><h4 id="终极方案">终极方案</h4><ul><li><p>在官方文档中提到了可以为hexo提供标记，阻止其按照自己的规则解释我们的字符串，显示其原本的含义</p></li><li><p>标记为</p><figure class="highlight django"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs django"><span class="hljs-template-tag">{% <span class="hljs-name">raw</span> %}</span><span class="xml"></span><br><span class="xml">$$</span><br><span class="xml">...</span><br><span class="xml">$$</span><br><span class="xml"></span><span class="hljs-template-tag">{% <span class="hljs-name">endraw</span> %}</span><br></code></pre></td></tr></tbody></table></figure></li></ul><h3 id="多行显示和对齐">多行显示和对齐</h3><ul><li><p>默认是显示为一行要实现公式多行和对齐可以使用{aligned}模式，使用"&amp;“来标记对齐位置。”\\"表示换行</p>  <figure class="highlight taggerscript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs taggerscript">$$<br><span class="hljs-symbol">\b</span>egin{aligned}<br><span class="hljs-symbol">\b</span>oldsymbol{x}^{<span class="hljs-symbol">\m</span>athrm{T}}C<span class="hljs-symbol">\b</span>oldsymbol{x}&amp;=<span class="hljs-symbol">\b</span>oldsymbol{x}^{<span class="hljs-symbol">\m</span>athrm{T}}<span class="hljs-symbol">\m</span>athrm{E}<span class="hljs-symbol">\l</span>eft[<span class="hljs-symbol">\l</span>eft(X-<span class="hljs-symbol">\m</span>u<span class="hljs-symbol">\r</span>ight)<span class="hljs-symbol">\l</span>eft(X-<span class="hljs-symbol">\m</span>u<span class="hljs-symbol">\r</span>ight)^{<span class="hljs-symbol">\m</span>athrm{T}}<span class="hljs-symbol">\r</span>ight]<span class="hljs-symbol">\b</span>oldsymbol{x} <br><span class="hljs-symbol">\\</span>&amp;=<span class="hljs-symbol">\m</span>athrm{E}<span class="hljs-symbol">\l</span>eft[<span class="hljs-symbol">\b</span>oldsymbol{x}^{<span class="hljs-symbol">\m</span>athrm{T}}<span class="hljs-symbol">\l</span>eft(X-<span class="hljs-symbol">\m</span>u<span class="hljs-symbol">\r</span>ight)<span class="hljs-symbol">\l</span>eft(X-<span class="hljs-symbol">\m</span>u<span class="hljs-symbol">\r</span>ight)^{<span class="hljs-symbol">\m</span>athrm{T}}<span class="hljs-symbol">\b</span>oldsymbol{x}<span class="hljs-symbol">\r</span>ight] <span class="hljs-symbol">\\</span>&amp;=<span class="hljs-symbol">\m</span>athrm{E}<span class="hljs-symbol">\l</span>eft[<span class="hljs-symbol">\l</span>eft(<span class="hljs-symbol">\l</span>eft(X-<span class="hljs-symbol">\m</span>u<span class="hljs-symbol">\r</span>ight)^{<span class="hljs-symbol">\m</span>athrm{T}}<span class="hljs-symbol">\b</span>oldsymbol{x}<span class="hljs-symbol">\r</span>ight)^{<span class="hljs-symbol">\m</span>athrm{T}}<span class="hljs-symbol">\l</span>eft(<span class="hljs-symbol">\l</span>eft(X-<span class="hljs-symbol">\m</span>u<span class="hljs-symbol">\r</span>ight)^{<span class="hljs-symbol">\m</span>athrm{T}}<span class="hljs-symbol">\b</span>oldsymbol{x}<span class="hljs-symbol">\r</span>ight)<span class="hljs-symbol">\r</span>ight] <br><span class="hljs-symbol">\\</span>&amp;=<span class="hljs-symbol">\m</span>athrm{E}<span class="hljs-symbol">\l</span>eft(<span class="hljs-symbol">\l</span>eft<span class="hljs-symbol">\V</span>ert <span class="hljs-symbol">\l</span>eft(X-<span class="hljs-symbol">\m</span>u<span class="hljs-symbol">\r</span>ight)^{<span class="hljs-symbol">\m</span>athrm{T}}<span class="hljs-symbol">\b</span>oldsymbol{x}<span class="hljs-symbol">\r</span>ight<span class="hljs-symbol">\V</span>ert ^{2}<span class="hljs-symbol">\r</span>ight) <br><span class="hljs-symbol">\\</span>&amp;=<span class="hljs-symbol">\s</span>igma_{X}^{2}<br><span class="hljs-symbol">\e</span>nd{aligned}<br>$$<br></code></pre></td></tr></tbody></table></figure></li><li><p>显示为</p></li></ul>$$\begin{aligned}\boldsymbol{x}^{\mathrm{T}}C\boldsymbol{x}&amp;=\boldsymbol{x}^{\mathrm{T}}\mathrm{E}\left[\left(X-\mu\right)\left(X-\mu\right)^{\mathrm{T}}\right]\boldsymbol{x} \\&amp;=\mathrm{E}\left[\boldsymbol{x}^{\mathrm{T}}\left(X-\mu\right)\left(X-\mu\right)^{\mathrm{T}}\boldsymbol{x}\right] \\&amp;=\mathrm{E}\left[\left(\left(X-\mu\right)^{\mathrm{T}}\boldsymbol{x}\right)^{\mathrm{T}}\left(\left(X-\mu\right)^{\mathrm{T}}\boldsymbol{x}\right)\right] \\&amp;=\mathrm{E}\left(\left\Vert \left(X-\mu\right)^{\mathrm{T}}\boldsymbol{x}\right\Vert ^{2}\right) \\&amp;=\sigma_{X}^{2}\end{aligned}$$]]></content>
    
    
    <categories>
      
      <category>配置</category>
      
      <category>hexo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>配置</tag>
      
      <tag>hexo</tag>
      
      <tag>fluid</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>直观理解协方差矩阵</title>
    <link href="/2021/08/05/math/covariance-matrix/"/>
    <url>/2021/08/05/math/covariance-matrix/</url>
    
    <content type="html"><![CDATA[<blockquote><p>原文出自 <a href="https://zhuanlan.zhihu.com/p/349802953">https://zhuanlan.zhihu.com/p/349802953</a></p></blockquote><h2 id="1-概率论中的定义">1 概率论中的定义</h2><h3 id="随机变量：">随机变量：</h3><p>随机变量(Random Variable) X 是一个映射，把随机试验的结果与实数建立起了一一对应的关系。而期望与方差是随机变量的两个重要的数字特征。</p><h3 id="数学期望：">数学期望：</h3><p>在概率论和统计学中，数学期望(mean)(或均值，亦简称期望(Expectation, or expected value))是试验中每次可能结果的概率乘以其结果的总和，是最基本的数学特征之一。它反映随机变量平均取值的大小。 期望值是该变量输出值的平均数。期望值并不一定包含于变量的输出值集合里。</p><p>大数定律规定，随着重复次数接近无穷大，数值的算术平均值几乎肯定地收敛于期望值。</p><h3 id="方差：">方差：</h3><p>方差(Variance)是在概率论和统计方差衡量随机变量或一组数据时离散程度的度量。概率论中方差用来度量随机变量和其数学期望(即均值)之间的偏离程度。统计中的方差(样本方差)是每个样本值与全体样本值的平均数之差的平方值的平均数。</p><p>设$X$为随机变量， 如果$\mathrm{E}[X]$，则随机变量$X$的方差为：<br>$$<br>\mu=\mathrm{E}[X]<br>$$</p><p>方差也记为 $\sigma_{X}^{2}$。</p><p>样本方差计算公式：</p>$$S^{2}=\Sigma\left(X-\overline{X}\right)^{2}/\left(n-1\right)$$<p>其中，$S^{2}$为样本方差，$X$ 为变量，$\overline{X}$为样本均值，$n$ 为样本例数。如果要了解为什么要除以$n-1$，请看<a href="https://link.zhihu.com/?target=https%3A//www.visiondummy.com/2014/03/divide-variance-n-1/">这篇文章</a>。</p><h3 id="标准差：">标准差：</h3><p>标准差(Standard Deviation)是离均差平方的算术平均数(即：方差)的算术平方根，用$\sigma$表示。标准差也被称为标准偏差，或者实验标准差，在概率统计中最常使用作为统计分布程度上的测量依据。 见下图：</p><p><img src="https://picture.mulindya.com/covariance-matrix-pic1.jpg" alt=""></p><p>标准差是方差的算术平方根。标准差能反映一个数据集的离散程度。平均数相同的两组数据，标准差未必相同。</p><h3 id="协方差：">协方差：</h3><p><strong>协方差(Covariance)在概率论和统计学中用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。</strong></p><p>期望值分别为$ E[X]$与$[Y]$的两个实随机变量$X$与$Y$之间的协方差 $\mathrm{Cov}(X,Y)$ 定义为：</p>$$\begin{aligned}\mathrm{Cov}(X,Y)&amp;=\mathrm{E}\left[\left(X\mathrm{E}\left[X\right]\right)\left(Y-\mathrm{E}\left[Y\right]\right)\right]  \\&amp;=\mathrm{E}\left[XY\right]-2\mathrm{E}\left[Y\right]\mathrm{E}\left[X\right]+\mathrm{E}\left[X\right]\mathrm{E}\left[Y\right]\\&amp;=\mathrm{E}\left[XY\right]-\mathrm{E}\left[X\right]\mathrm{E}\left[Y\right] \\&amp;=\mathrm{E}\left[XY\right]-\mathrm{E}\left[X\right]\mathrm{E}\left[Y\right]\end{aligned}$$<p>协方差表示的是两个变量总体误差的期望。 如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。 如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。</p><p>如果$X$与$Y$是统计独立的，那么二者之间的协方差就是0，因为两个独立的随机变量满足$\mathrm{E}[XY]=\mathrm{E}[X]\mathrm{E}[Y]$。但是，反过来并不成立。即如果$X$与$Y$的协方差为0，二者并不一定是统计独立的。</p><p><strong>协方差为0的两个随机变量称为是不相关的。</strong></p><h3 id="协方差矩阵：">协方差矩阵：</h3><p>在统计学与概率论中，协方差矩阵(Covariance matrix)的每个元素是各个向量元素之间的协方差，是从标量随机变量到高维度随机向量的自然推广。</p><p>设$X=\left(X_{1},X_{2},\ldots,X_{n}\right)^{\mathrm{T}}$为$n$ 维随机变量，称矩阵</p>$$C=\left(\begin{array}{cccc} c_{11} &amp; c_{12} &amp; \cdots &amp; c_{1n}\\ c_{21} &amp; c_{22} &amp; \cdots &amp; c_{2n}\\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\ c_{n1} &amp; c_{n2} &amp; \cdots &amp; c_{nn} \end{array}\right)$$<p>为 n 维随机变量x的协方差矩阵，也记为 $D\left(X\right)$ ，其中<br>$$<br>c_{ij}=\mathrm{Cov}(X_{i},X_{j}),\quad i,j=1,2,\ldots,n<br>$$<br>为X的分量$X_{i}$和$X_{j}$的协方差。<em>并且对角线上的元素为各个随机变量的方差：</em></p><p>$$<br>c_{ii}=\mathrm{Cov}(X_{i},X_{i}),\quad i=1,2,\ldots,n<br>$$</p><p>协方差矩阵是对称半正定矩阵。协方差矩阵的对称性，可从定义得知。对于半正定特性，证明如下：</p><p>现给定任意一个非零向量$\boldsymbol{x}$，则</p>$$\begin{aligned}\boldsymbol{x}^{\mathrm{T}}C\boldsymbol{x}&amp;=\boldsymbol{x}^{\mathrm{T}}\mathrm{E}\left[\left(X-\mu\right)\left(X-\mu\right)^{\mathrm{T}}\right]\boldsymbol{x} \\&amp;=\mathrm{E}\left[\boldsymbol{x}^{\mathrm{T}}\left(X-\mu\right)\left(X-\mu\right)^{\mathrm{T}}\boldsymbol{x}\right] \\&amp;=\mathrm{E}\left[\left(\left(X-\mu\right)^{\mathrm{T}}\boldsymbol{x}\right)^{\mathrm{T}}\left(\left(X-\mu\right)^{\mathrm{T}}\boldsymbol{x}\right)\right] \\&amp;=\mathrm{E}\left(\left\Vert \left(X-\mu\right)^{\mathrm{T}}\boldsymbol{x}\right\Vert ^{2}\right) \\&amp;=\sigma_{X}^{2}\end{aligned}$$<p>其中，<br>$$<br>\sigma_{X}=\left(X-\mu \right)^{\mathrm{T}}\boldsymbol{x}<br>$$<br>由于 $\sigma_{X}<sup>{2}\geq0$，因此$\boldsymbol{x}</sup>{\mathrm{T}}C\boldsymbol{x}\geq0$，因此协方差矩阵$C$ 是半正定矩阵。</p>]]></content>
    
    
    <categories>
      
      <category>math</category>
      
      <category>概率论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>math</tag>
      
      <tag>概率论</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
